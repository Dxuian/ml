{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "##load saved bm.keras and optimize it and then also train on test data and train data then upload final \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#default ml libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sklearn as sk\n",
    "#tf libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, ConfusionMatrixDisplay, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import kfold from sklearn\n",
    "from sklearn.model_selection import KFold\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test.csv file\n",
    "DEV = True\n",
    "loaddata = pd.read_csv('train.csv')\n",
    "testdata = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  person_age  person_income person_home_ownership  person_emp_length  \\\n",
      "0   0          37          35000                  RENT                0.0   \n",
      "1   1          22          56000                   OWN                6.0   \n",
      "2   2          29          28800                   OWN                8.0   \n",
      "3   3          30          70000                  RENT               14.0   \n",
      "4   4          22          60000                  RENT                2.0   \n",
      "\n",
      "  loan_intent loan_grade  loan_amnt  loan_int_rate  loan_percent_income  \\\n",
      "0   EDUCATION          B       6000          11.49                 0.17   \n",
      "1     MEDICAL          C       4000          13.35                 0.07   \n",
      "2    PERSONAL          A       6000           8.90                 0.21   \n",
      "3     VENTURE          B      12000          11.11                 0.17   \n",
      "4     MEDICAL          A       6000           6.92                 0.10   \n",
      "\n",
      "  cb_person_default_on_file  cb_person_cred_hist_length  loan_status  \n",
      "0                         N                          14            0  \n",
      "1                         N                           2            0  \n",
      "2                         N                          10            0  \n",
      "3                         N                           5            0  \n",
      "4                         N                           3            0  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      id  person_age  person_income person_home_ownership  person_emp_length  \\\n",
      "0  58645          23          69000                  RENT                3.0   \n",
      "1  58646          26          96000              MORTGAGE                6.0   \n",
      "2  58647          26          30000                  RENT                5.0   \n",
      "3  58648          33          50000                  RENT                4.0   \n",
      "4  58649          26         102000              MORTGAGE                8.0   \n",
      "\n",
      "         loan_intent loan_grade  loan_amnt  loan_int_rate  \\\n",
      "0    HOMEIMPROVEMENT          F      25000          15.76   \n",
      "1           PERSONAL          C      10000          12.68   \n",
      "2            VENTURE          E       4000          17.19   \n",
      "3  DEBTCONSOLIDATION          A       7000           8.90   \n",
      "4    HOMEIMPROVEMENT          D      15000          16.32   \n",
      "\n",
      "   loan_percent_income cb_person_default_on_file  cb_person_cred_hist_length  \n",
      "0                 0.36                         N                           2  \n",
      "1                 0.10                         Y                           4  \n",
      "2                 0.13                         Y                           2  \n",
      "3                 0.14                         N                           7  \n",
      "4                 0.15                         Y                           4  \n"
     ]
    }
   ],
   "source": [
    "train = loaddata.copy()\n",
    "print(train.head())\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "test = testdata.copy()\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1838/3091855500.py:68: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test['person_home_ownership'] = test['person_home_ownership'].replace({'RENT': 0, 'MORTGAGE': 1, 'OWN': 2, 'OTHER': 3}).astype('category')\n",
      "/tmp/ipykernel_1838/3091855500.py:69: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test['loan_intent'] = test['loan_intent'].replace({'EDUCATION': 0, 'MEDICAL': 1, 'PERSONAL': 2, 'VENTURE': 3, 'DEBTCONSOLIDATION': 4, 'HOMEIMPROVEMENT': 5}).astype('category')\n",
      "/tmp/ipykernel_1838/3091855500.py:70: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test['loan_grade'] = test['loan_grade'].replace({'A':6, 'B':5, 'C':4, 'D':3, 'E':2, 'F':1, 'G':0}).astype('category')\n",
      "/tmp/ipykernel_1838/3091855500.py:71: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test['cb_person_default_on_file'] = test['cb_person_default_on_file'].replace({'N': 0, 'Y': 1}).astype('category')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, ..., 3136, 3137, 3138, 3139, 3140]\n",
       "Length: 3141\n",
       "Categories (3141, int64): [0, 1, 2, 3, ..., 3137, 3138, 3139, 3140]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature engineering\n",
    "test[\"loantoincome\"] = ((test[\"loan_amnt\"] / test[\"person_income\"])).astype('Float64')\n",
    "test[\"loan_percent_incometoincome\"] = ((test[\"loan_percent_income\"] / test[\"person_income\"])).astype('Float64')\n",
    "test['person_age_to_person_income'] = (test['person_age'] / test['person_income']).astype(str).astype('Float64')\n",
    "test['person_emp_length_to_person_age'] = (test['person_emp_length'] / test['person_age']).astype('Float64')\n",
    "test['loan_int_rate_to_loan_amnt'] = (test['loan_int_rate'] / test['loan_amnt']).astype('Float64')\n",
    "\n",
    "\n",
    "\n",
    "test['income_to_age'] = test['person_income'] / test['person_age']\n",
    "test['loan_to_income'] = test['loan_amnt'] / test['person_income']\n",
    "test['rate_to_loan'] = test['loan_int_rate'] / test['loan_amnt']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test['log_income'] = (np.log1p(test['person_income'])).astype('Float64')\n",
    "test['age_credit_history_interaction'] = (test['person_age'] * test['cb_person_cred_hist_length']).astype('float64')\n",
    "test['high_loan_to_income'] = (test['loan_percent_income'] > 0.5).astype('float64')\n",
    "test['is_new_credit_user'] = (test['cb_person_cred_hist_length'] < 2).astype('float64')\n",
    "test['high_interest_rate'] = (test['loan_int_rate'] > test['loan_int_rate'].mean()).astype('float64')\n",
    "test['loan_to_employment'] = test['loan_amnt'] / (test['person_emp_length'] + 1)\n",
    "test['rate_to_grade'] = test.groupby('loan_grade')['loan_int_rate'].transform('mean')\n",
    "\n",
    "\n",
    "def categorize_age(age):\n",
    "    if age <= 25:\n",
    "        return 0\n",
    "    elif age <= 35:\n",
    "        return 0.1\n",
    "    elif age <= 45:\n",
    "        return 0.2\n",
    "    elif age <= 55:\n",
    "        return 0.3\n",
    "    else:\n",
    "        return 0.4\n",
    "\n",
    "# test['income_category'] = pd.qcut(test['person_income'], q=5, labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])\n",
    "# test['intent_grade_interaction'] = test['loan_intent'].astype(str) + '_' + test['loan_grade'].astype(str)\n",
    "# test['home_ownership_intent'] = test['person_home_ownership'].astype(str) + '_' + test['loan_intent'].astype(str)\n",
    "\n",
    "# Function to calculate and store quantiles\n",
    "\n",
    "\n",
    "\n",
    "test['age_category'] = test['person_age'].apply(categorize_age).astype('category')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test['person_home_ownership'] = test['person_home_ownership'].replace({'RENT': 0, 'MORTGAGE': 1, 'OWN': 2, 'OTHER': 3}).astype('category')\n",
    "test['loan_intent'] = test['loan_intent'].replace({'EDUCATION': 0, 'MEDICAL': 1, 'PERSONAL': 2, 'VENTURE': 3, 'DEBTCONSOLIDATION': 4, 'HOMEIMPROVEMENT': 5}).astype('category')\n",
    "test['loan_grade'] = test['loan_grade'].replace({'A':6, 'B':5, 'C':4, 'D':3, 'E':2, 'F':1, 'G':0}).astype('category')\n",
    "test['cb_person_default_on_file'] = test['cb_person_default_on_file'].replace({'N': 0, 'Y': 1}).astype('category')\n",
    "test[\"person_home_ownership_income\"] = pd.Series(pd.factorize((test[\"person_home_ownership\"].astype(str) + test[\"person_income\"].astype(str)).to_numpy())[0]).astype('category')\n",
    "\n",
    "test['person_home_ownership_income'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete all files that start with lgbm and xgb \n",
    "\n",
    "for item in os.listdir():\n",
    "    if item.startswith(\"lgbm\") or item.startswith(\"xgb\"):\n",
    "        os.remove(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1838/4037952647.py:11: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train['person_home_ownership'] = train['person_home_ownership'].replace({'RENT': 0, 'MORTGAGE': 1, 'OWN': 2, 'OTHER': 3}).astype('category')\n",
      "/tmp/ipykernel_1838/4037952647.py:12: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train['loan_intent'] = train['loan_intent'].replace({'EDUCATION': 0, 'MEDICAL': 1, 'PERSONAL': 2, 'VENTURE': 3, 'DEBTCONSOLIDATION': 4, 'HOMEIMPROVEMENT': 5}).astype('category')\n",
      "/tmp/ipykernel_1838/4037952647.py:13: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train['loan_grade'] = train['loan_grade'].replace({'A':6, 'B':5, 'C':4, 'D':3, 'E':2, 'F':1, 'G':0}).astype('category')\n",
      "/tmp/ipykernel_1838/4037952647.py:14: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train['cb_person_default_on_file'] = train['cb_person_default_on_file'].replace({'N': 0, 'Y': 1}).astype('category')\n",
      "/tmp/ipykernel_1838/4037952647.py:27: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  train['rate_to_grade'] = train.groupby('loan_grade')['loan_int_rate'].transform('mean').astype('float64')\n",
      "/tmp/ipykernel_1838/4037952647.py:35: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  train['normalized_loan_amount'] = train.groupby('loan_intent')['loan_amnt'].transform(lambda x: (x - x.mean()) / x.std()).astype('float64')\n",
      "/tmp/ipykernel_1838/4037952647.py:36: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  test['normalized_loan_amount'] = test.groupby('loan_intent')['loan_amnt'].transform(lambda x: (x - x.mean()) / x.std()).astype('float64')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05, 0.14, 0.26, 0.35, 0.16, ..., 0.1, 0.5, 0.2, 0.0, 0.4]\n",
       "Length: 42\n",
       "Categories (42, float64): [0.00, 0.01, 0.02, 0.03, ..., 0.53, 0.54, 0.55, 0.56]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature engineering\n",
    "train[\"loantoincome\"] = ((train[\"loan_amnt\"] / train[\"person_income\"])).astype('Float64')\n",
    "train[\"loan_percent_incometoincome\"] = ((train[\"loan_percent_income\"] / train[\"person_income\"])).astype('Float64')\n",
    "train['person_age_to_person_income'] = (train['person_age'] / train['person_income']).astype(str).astype('Float64')\n",
    "train['person_emp_length_to_person_age'] = (train['person_emp_length'] / train['person_age']).astype('Float64')\n",
    "train['loan_int_rate_to_loan_amnt'] = (train['loan_int_rate'] / train['loan_amnt']).astype('Float64')\n",
    "\n",
    "\n",
    "train['income_to_age'] = train['person_income'] / train['person_age']\n",
    "train['rate_to_loan'] = train['loan_int_rate'] / train['loan_amnt']\n",
    "train['person_home_ownership'] = train['person_home_ownership'].replace({'RENT': 0, 'MORTGAGE': 1, 'OWN': 2, 'OTHER': 3}).astype('category')\n",
    "train['loan_intent'] = train['loan_intent'].replace({'EDUCATION': 0, 'MEDICAL': 1, 'PERSONAL': 2, 'VENTURE': 3, 'DEBTCONSOLIDATION': 4, 'HOMEIMPROVEMENT': 5}).astype('category')\n",
    "train['loan_grade'] = train['loan_grade'].replace({'A':6, 'B':5, 'C':4, 'D':3, 'E':2, 'F':1, 'G':0}).astype('category')\n",
    "train['cb_person_default_on_file'] = train['cb_person_default_on_file'].replace({'N': 0, 'Y': 1}).astype('category')\n",
    "train[\"person_home_ownership_income\"] = pd.Series(pd.factorize((train[\"person_home_ownership\"].astype(str) + train[\"person_income\"].astype(str)).to_numpy())[0]).astype('category')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train['log_income'] = np.log1p(train['person_income']).astype('float64')\n",
    "train['age_credit_history_interaction'] = (train['person_age'] * train['cb_person_cred_hist_length']).astype('float64')\n",
    "train['high_loan_to_income'] = (train['loan_percent_income'] > 0.5).astype('float64')\n",
    "train['is_new_credit_user'] = (train['cb_person_cred_hist_length'] < 2).astype('float64')\n",
    "train['high_interest_rate'] = (train['loan_int_rate'] > train['loan_int_rate'].mean()).astype('float64')\n",
    "train['loan_to_employment'] = (train['loan_amnt'] / (train['person_emp_length'] + 1)).astype('float64')\n",
    "train['rate_to_grade'] = train.groupby('loan_grade')['loan_int_rate'].transform('mean').astype('float64')\n",
    "train['age_category'] = train['person_age'].apply(categorize_age).astype('category')\n",
    "\n",
    "\n",
    "train['age_to_credit_history'] = (train['person_age'] / (train['cb_person_cred_hist_length'] + 1)).astype('float64')\n",
    "test['age_to_credit_history'] = (test['person_age'] / (test['cb_person_cred_hist_length'] + 1)).astype('float64')\n",
    "train['income_to_loan'] = (train['person_income'] / train['loan_amnt']).astype('float64')\n",
    "test['income_to_loan'] = (test['person_income'] / test['loan_amnt']).astype('float64')\n",
    "train['normalized_loan_amount'] = train.groupby('loan_intent')['loan_amnt'].transform(lambda x: (x - x.mean()) / x.std()).astype('float64')\n",
    "test['normalized_loan_amount'] = test.groupby('loan_intent')['loan_amnt'].transform(lambda x: (x - x.mean()) / x.std()).astype('float64')\n",
    "train['log_loan_amnt'] = np.log1p(train['loan_amnt']).astype('float64')\n",
    "test['log_loan_amnt'] = np.log1p(test['loan_amnt']).astype('float64')\n",
    "train['income_home_mismatch'] = ((train['person_income'] > train['person_income'].quantile(0.8)) & (train['person_home_ownership'] == 0)).astype('float64')\n",
    "test['income_home_mismatch'] = ((test['person_income'] > test['person_income'].quantile(0.8)) & (test['person_home_ownership'] == 0)).astype('float64')\n",
    "train['default_grade_interaction'] = ((train['cb_person_default_on_file'].astype('float64')*10 +  train['loan_grade'].astype('float64'))/16).astype('category')\n",
    "test['default_grade_interaction'] = ((test['cb_person_default_on_file'].astype('float64')*10 +  test['loan_grade'].astype('float64'))/16).astype('category')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train['age_interest_interaction'] = (train['person_age'].astype('float64') * train['loan_int_rate'].astype('float64')).astype('float64')   \n",
    "test['age_interest_interaction'] = (test['person_age'] * test['loan_int_rate']).astype('float64')   \n",
    "\n",
    "\n",
    "train['credit_history_to_age'] = (train['cb_person_cred_hist_length'].astype('float64') / train['person_age'].astype('float64')).astype('float64')\n",
    "test['credit_history_to_age'] = (test['cb_person_cred_hist_length'].astype('float64') / test['person_age'].astype('float64')).astype('float64') \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train['rate_to_credit_history'] = (train['loan_int_rate'].astype('float64') / (train['cb_person_cred_hist_length'].astype('float64') + 1)).astype('float64')\n",
    "test['rate_to_credit_history'] = (test['loan_int_rate'].astype('float64') / (test['cb_person_cred_hist_length'].astype('float64') + 1)).astype('float64')\n",
    "\n",
    "# train['loan_amount_category'] = pd.qcut(train['loan_amnt'], q=5, labels=[0,1,2,3,4])\n",
    "# train['high_loan_amount'] = (train['loan_amnt'] > train['loan_amnt'].quantile(0.75)).astype(int)\n",
    "# train['home_ownership_loan_interaction'] = train['person_home_ownership'].astype(str) + '_' + train['loan_amount_category'].astype(str)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# train['creditworthiness_score'] = (train['person_income'] / (train['loan_amnt'] * train['loan_int_rate'])) * (train['cb_person_cred_hist_length'] + 1)\n",
    "# train['age_to_employment'] = train['person_age'] / (train['person_emp_length'] + 1)\n",
    "# train['age_income_mismatch'] = ((train['person_age'] < 30) & (train['person_income'] > train['person_income'].quantile(0.9))).astype(int)\n",
    "# train['default_rate_interaction'] = train['cb_person_default_on_file'].astype(str) + '_' + pd.cut(train['loan_int_rate'], bins=5, labels=['Very Low', 'Low', 'Medium', 'High', 'Very High']).astype(str)\n",
    "\n",
    "\n",
    "\n",
    "train['creditworthiness_score'] = (train['person_income'].astype('float64') / (train['loan_amnt'].astype('float64') * train['loan_int_rate'].astype('float64'))) * (train['cb_person_cred_hist_length'].astype('float64') + 1).astype('float64')\n",
    "\n",
    "train['age_to_employment'] = (train['person_age'].astype('float64') / (train['person_emp_length'].astype('float64') + 1)).astype('float64')\n",
    "\n",
    "train['intent_home_match'] = ((train['loan_intent'].astype('float64') == 5) & (train['person_home_ownership'].astype('float64') == 2)).astype('float64')\n",
    "\n",
    "train['normalized_income'] = train.groupby('age_category')['person_income'].transform(lambda x: ((x.astype('float64') - x.mean().astype('float64')) / x.std().astype('float64'))).astype('float64')\n",
    "\n",
    "train['rate_to_age'] = (train['loan_int_rate'].astype('float64') / train['person_age'].astype('float64')).astype('float64')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to calculate and store quantiles in a dictionary\n",
    "def calculate_quantiles(data, column):\n",
    "    quantiles = {}\n",
    "    for q in [0.2, 0.4, 0.6, 0.8]:\n",
    "        quantiles[f'q{int(q*100)}'] = data[column].quantile(q)\n",
    "    return quantiles\n",
    "\n",
    "# Calculate quantiles for the train dataset\n",
    "income_quantiles = calculate_quantiles(train, 'person_income')\n",
    "\n",
    "# Function to categorize income using cached quantiles\n",
    "def categorize_income(income, quantiles):\n",
    "    if income <= quantiles['q20']:\n",
    "        return 0\n",
    "    elif income <= quantiles['q40']:\n",
    "        return 0.1\n",
    "    elif income <= quantiles['q60']:\n",
    "        return 0.2\n",
    "    elif income <= quantiles['q80']:\n",
    "        return 0.3\n",
    "    else:\n",
    "        return 0.4\n",
    "\n",
    "# Apply the categorize_income function to create the income_category column\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train['risk_score'] = train['loan_percent_income'] * train['loan_int_rate'] * (6 - train['loan_grade'].astype('float64'))\n",
    "test['risk_score'] = test['loan_percent_income'] * test['loan_int_rate'] * (6 - test['loan_grade'].astype('float64'))\n",
    "train['loan_intent_grade'] = ((train['loan_intent'].astype('float64') * 10 + train['loan_grade'].astype('float64'))/100).astype('category')\n",
    "test['loan_intent_grade'] = ((test['loan_intent'].astype('float64') * 10 + test['loan_grade'].astype('float64'))/100).astype('category')\n",
    "train['income_category'] = train['person_income'].apply(categorize_income, args=(income_quantiles,)).astype('category')\n",
    "test['income_category'] = test['person_income'].apply(categorize_income, args=(income_quantiles,)).astype('category')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Add the transformed columns\n",
    "\n",
    "\n",
    "\n",
    "# more feature engineering\n",
    "\n",
    "train['loan_intent_grade'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loan_status\n",
      "0    50295\n",
      "1     8350\n",
      "Name: count, dtype: int64\n",
      "loan_status\n",
      "0    0.857618\n",
      "1    0.142382\n",
      "Name: proportion, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Plot histograms for numerical columns\n",
    "numerical_columns = ['person_age','loantoincome','person_emp_length_to_person_age',\n",
    "                     'loan_int_rate_to_loan_amnt','loan_percent_incometoincome',\n",
    "                     'person_age_to_person_income','person_income', 'loan_amnt',\"person_emp_length\" ,\n",
    "                     'loan_int_rate', 'loan_percent_income', 'cb_person_cred_hist_length','income_to_age','rate_to_loan','log_income',\n",
    "                     'age_credit_history_interaction','high_loan_to_income','is_new_credit_user','high_interest_rate','loan_to_employment','rate_to_grade',\n",
    "                     'risk_score','age_to_credit_history','income_to_loan','normalized_loan_amount','log_loan_amnt','income_home_mismatch',\n",
    "                     'age_interest_interaction','credit_history_to_age','rate_to_credit_history'\n",
    "                     ]\n",
    "train[numerical_columns].hist(bins=30, figsize=(15, 10))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot count plots for categorical columns\n",
    "categorical_columns = ['person_home_ownership', 'loan_intent', 'loan_grade', 'cb_person_default_on_file', 'loan_status',\n",
    "    \"person_home_ownership_income\",\n",
    "    'age_category',\n",
    "    'loan_intent_grade',\n",
    "    'income_category',\n",
    "    'default_grade_interaction'\n",
    "    # 'intent_grade_interaction','home_ownership_intent'\n",
    "]\n",
    "numerical_features = numerical_columns\n",
    "categorical_features = categorical_columns\n",
    "if  not  DEV:\n",
    "    fig, axes = plt.subplots(math.ceil(len(categorical_columns)/2)+1, 2, figsize=(15, 15))  # Adjusted to 3x2 grid\n",
    "    for ax, col in zip(axes.flatten(), categorical_columns):\n",
    "        sns.countplot(data=train, x=col, ax=ax)\n",
    "        ax.set_title(f'Distribution of {col}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "features = numerical_columns + categorical_columns \n",
    "categorical_columns.remove('loan_status')\n",
    "features.remove('loan_status')\n",
    "# Define the preprocessing for numerical and categorical features\n",
    "#print how many 'load_status' 0 and 1 and find the ratio\n",
    "print(train['loan_status'].value_counts())\n",
    "print(train['loan_status'].value_counts(normalize=True))\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58645, 41)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_intent</th>\n",
       "      <th>loan_grade</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_default_on_file</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>loantoincome</th>\n",
       "      <th>loan_percent_incometoincome</th>\n",
       "      <th>person_age_to_person_income</th>\n",
       "      <th>person_emp_length_to_person_age</th>\n",
       "      <th>loan_int_rate_to_loan_amnt</th>\n",
       "      <th>income_to_age</th>\n",
       "      <th>rate_to_loan</th>\n",
       "      <th>person_home_ownership_income</th>\n",
       "      <th>log_income</th>\n",
       "      <th>age_credit_history_interaction</th>\n",
       "      <th>high_loan_to_income</th>\n",
       "      <th>is_new_credit_user</th>\n",
       "      <th>high_interest_rate</th>\n",
       "      <th>loan_to_employment</th>\n",
       "      <th>rate_to_grade</th>\n",
       "      <th>age_category</th>\n",
       "      <th>age_to_credit_history</th>\n",
       "      <th>income_to_loan</th>\n",
       "      <th>normalized_loan_amount</th>\n",
       "      <th>log_loan_amnt</th>\n",
       "      <th>income_home_mismatch</th>\n",
       "      <th>default_grade_interaction</th>\n",
       "      <th>age_interest_interaction</th>\n",
       "      <th>credit_history_to_age</th>\n",
       "      <th>rate_to_credit_history</th>\n",
       "      <th>risk_score</th>\n",
       "      <th>loan_intent_grade</th>\n",
       "      <th>income_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>35000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6000</td>\n",
       "      <td>11.49</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>945.945946</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>0</td>\n",
       "      <td>10.463132</td>\n",
       "      <td>518.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>11.034733</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.466667</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>-0.558667</td>\n",
       "      <td>8.699681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>425.13</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.766000</td>\n",
       "      <td>1.9533</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>56000</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4000</td>\n",
       "      <td>13.35</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.003337</td>\n",
       "      <td>2545.454545</td>\n",
       "      <td>0.003337</td>\n",
       "      <td>1</td>\n",
       "      <td>10.933125</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>571.428571</td>\n",
       "      <td>13.510343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>-0.896247</td>\n",
       "      <td>8.294300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>293.70</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>4.450000</td>\n",
       "      <td>1.8690</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>28800</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6000</td>\n",
       "      <td>8.90</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.001483</td>\n",
       "      <td>993.103448</td>\n",
       "      <td>0.001483</td>\n",
       "      <td>2</td>\n",
       "      <td>10.268165</td>\n",
       "      <td>290.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>666.666667</td>\n",
       "      <td>7.335176</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.636364</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>-0.584460</td>\n",
       "      <td>8.699681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>258.10</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.809091</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>70000</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>12000</td>\n",
       "      <td>11.11</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>2333.333333</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>3</td>\n",
       "      <td>11.156265</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>11.034733</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>0.492919</td>\n",
       "      <td>9.392745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>333.30</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.851667</td>\n",
       "      <td>1.8887</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  person_age  person_income person_home_ownership  person_emp_length  \\\n",
       "0   0          37          35000                     0                0.0   \n",
       "1   1          22          56000                     2                6.0   \n",
       "2   2          29          28800                     2                8.0   \n",
       "3   3          30          70000                     0               14.0   \n",
       "\n",
       "  loan_intent loan_grade  loan_amnt  loan_int_rate  loan_percent_income  \\\n",
       "0           0          5       6000          11.49                 0.17   \n",
       "1           1          4       4000          13.35                 0.07   \n",
       "2           2          6       6000           8.90                 0.21   \n",
       "3           3          5      12000          11.11                 0.17   \n",
       "\n",
       "  cb_person_default_on_file  cb_person_cred_hist_length  loan_status  \\\n",
       "0                         0                          14            0   \n",
       "1                         0                           2            0   \n",
       "2                         0                          10            0   \n",
       "3                         0                           5            0   \n",
       "\n",
       "   loantoincome  loan_percent_incometoincome  person_age_to_person_income  \\\n",
       "0      0.171429                     0.000005                     0.001057   \n",
       "1      0.071429                     0.000001                     0.000393   \n",
       "2      0.208333                     0.000007                     0.001007   \n",
       "3      0.171429                     0.000002                     0.000429   \n",
       "\n",
       "   person_emp_length_to_person_age  loan_int_rate_to_loan_amnt  income_to_age  \\\n",
       "0                              0.0                    0.001915     945.945946   \n",
       "1                         0.272727                    0.003337    2545.454545   \n",
       "2                         0.275862                    0.001483     993.103448   \n",
       "3                         0.466667                    0.000926    2333.333333   \n",
       "\n",
       "   rate_to_loan person_home_ownership_income  log_income  \\\n",
       "0      0.001915                            0   10.463132   \n",
       "1      0.003337                            1   10.933125   \n",
       "2      0.001483                            2   10.268165   \n",
       "3      0.000926                            3   11.156265   \n",
       "\n",
       "   age_credit_history_interaction  high_loan_to_income  is_new_credit_user  \\\n",
       "0                           518.0                  0.0                 0.0   \n",
       "1                            44.0                  0.0                 0.0   \n",
       "2                           290.0                  0.0                 0.0   \n",
       "3                           150.0                  0.0                 0.0   \n",
       "\n",
       "   high_interest_rate  loan_to_employment  rate_to_grade age_category  \\\n",
       "0                 1.0         6000.000000      11.034733          0.2   \n",
       "1                 1.0          571.428571      13.510343          0.0   \n",
       "2                 0.0          666.666667       7.335176          0.1   \n",
       "3                 1.0          800.000000      11.034733          0.1   \n",
       "\n",
       "   age_to_credit_history  income_to_loan  normalized_loan_amount  \\\n",
       "0               2.466667        5.833333               -0.558667   \n",
       "1               7.333333       14.000000               -0.896247   \n",
       "2               2.636364        4.800000               -0.584460   \n",
       "3               5.000000        5.833333                0.492919   \n",
       "\n",
       "   log_loan_amnt  income_home_mismatch default_grade_interaction  \\\n",
       "0       8.699681                   0.0                    0.3125   \n",
       "1       8.294300                   0.0                    0.2500   \n",
       "2       8.699681                   0.0                    0.3750   \n",
       "3       9.392745                   0.0                    0.3125   \n",
       "\n",
       "   age_interest_interaction  credit_history_to_age  rate_to_credit_history  \\\n",
       "0                    425.13               0.378378                0.766000   \n",
       "1                    293.70               0.090909                4.450000   \n",
       "2                    258.10               0.344828                0.809091   \n",
       "3                    333.30               0.166667                1.851667   \n",
       "\n",
       "   risk_score loan_intent_grade income_category  \n",
       "0      1.9533              0.05             0.0  \n",
       "1      1.8690              0.14             0.2  \n",
       "2      0.0000              0.26             0.0  \n",
       "3      1.8887              0.35             0.3  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(train.head(4))\n",
    "#print all the columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(train.shape)\n",
    "train.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['person_age',\n",
       " 'loantoincome',\n",
       " 'person_emp_length_to_person_age',\n",
       " 'loan_int_rate_to_loan_amnt',\n",
       " 'loan_percent_incometoincome',\n",
       " 'person_age_to_person_income',\n",
       " 'person_income',\n",
       " 'loan_amnt',\n",
       " 'person_emp_length',\n",
       " 'loan_int_rate',\n",
       " 'loan_percent_income',\n",
       " 'cb_person_cred_hist_length',\n",
       " 'income_to_age',\n",
       " 'rate_to_loan',\n",
       " 'log_income',\n",
       " 'age_credit_history_interaction',\n",
       " 'high_loan_to_income',\n",
       " 'is_new_credit_user',\n",
       " 'high_interest_rate',\n",
       " 'loan_to_employment',\n",
       " 'rate_to_grade',\n",
       " 'risk_score',\n",
       " 'age_to_credit_history',\n",
       " 'income_to_loan',\n",
       " 'normalized_loan_amount',\n",
       " 'log_loan_amnt',\n",
       " 'income_home_mismatch',\n",
       " 'age_interest_interaction',\n",
       " 'credit_history_to_age',\n",
       " 'rate_to_credit_history',\n",
       " 'person_home_ownership',\n",
       " 'loan_intent',\n",
       " 'loan_grade',\n",
       " 'cb_person_default_on_file',\n",
       " 'person_home_ownership_income',\n",
       " 'age_category',\n",
       " 'loan_intent_grade',\n",
       " 'income_category',\n",
       " 'default_grade_interaction']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((58645, 39), (58645, 1), (39098, 39), (39098,))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "target = ['loan_status']  # Replace with the actual target column name\n",
    "\n",
    "# Preprocess the data\n",
    "X = train[features]\n",
    "y = train[target]\n",
    "ids = train['id']\n",
    "testx = test[features]\n",
    "test_ids = test['id']\n",
    "\n",
    "X.shape , y.shape , testx.shape,  test_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140748, 39)\n",
      "(35187, 39)\n",
      "(140748, 1)\n",
      "(35187, 1)\n",
      "(140748,)\n",
      "(35187,)\n",
      "(39098, 39)\n",
      "(39098,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test, ids_train, ids_test = train_test_split(X, y, ids, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the preprocessing for numerical and categorical features\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    # ('onehot', OneHotEncoder(handle_unknown='error'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "testx = preprocessor.transform(testx)\n",
    "\n",
    "# Function to add noise\n",
    "def add_noise(data, noise_level=0.01):\n",
    "    noise = np.random.normal(0, noise_level, data.shape)\n",
    "    return data + noise\n",
    "\n",
    "# Add noise to the numerical features\n",
    "X_train_noisy = X_train.copy()\n",
    "X_test_noisy = X_test.copy()\n",
    "X_train_noisy[:, :len(numerical_features)] = add_noise(X_train[:, :len(numerical_features)])\n",
    "X_test_noisy[:, :len(numerical_features)] = add_noise(X_test[:, :len(numerical_features)])\n",
    "\n",
    "\n",
    "X_train_less_noise = X_train.copy()\n",
    "X_test_less_noise = X_test.copy()\n",
    "X_train_less_noise[:, :len(numerical_features)] = add_noise(X_train[:, :len(numerical_features)],noise_level=0.001)\n",
    "X_test_less_noise[:, :len(numerical_features)] = add_noise(X_test[:, :len(numerical_features)],noise_level=0.001)\n",
    "\n",
    "# Concatenate the original data with the noisy data vertically\n",
    "X_train_combined = np.vstack((X_train, X_train_noisy, X_train_less_noise))\n",
    "X_test_combined = np.vstack((X_test, X_test_noisy, X_test_less_noise))\n",
    "\n",
    "# Concatenate the target variable as well\n",
    "y_train_combined = np.vstack((y_train, y_train, y_train))\n",
    "y_test_combined = np.vstack((y_test, y_test,y_test))\n",
    "\n",
    "# Concatenate the ids as well\n",
    "ids_train_combined = np.hstack((ids_train, ids_train, ids_train))\n",
    "ids_test_combined = np.hstack((ids_test, ids_test, ids_test))\n",
    "\n",
    "# Update the original variables\n",
    "X_train = X_train_combined\n",
    "X_test = X_test_combined\n",
    "y_train = y_train_combined\n",
    "y_test = y_test_combined\n",
    "ids_train = ids_train_combined\n",
    "ids_test = ids_test_combined\n",
    "xult , yult  , idsult= np.vstack((X_train, X_test)), np.vstack((y_train, y_test)) , np.hstack((ids_train, ids_test))\n",
    "print(X_train.shape)  # Should output (46916 + 46916, 26)\n",
    "print(X_test.shape)   # Should output (11729 + 11729, 26)\n",
    "print(y_train.shape)  # Should output (46916 + 46916, 1)\n",
    "print(y_test.shape)   # Should output (11729 + 11729, 1)\n",
    "print(ids_train.shape)  # Should output (46916 + 46916,)\n",
    "print(ids_test.shape)   # Should output (11729 + 11729,)\n",
    "print(testx.shape)   # Should output (11729 + 11729,)\n",
    "print(test_ids.shape)   # Should output (11729 + 11729,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmax(value=False):\n",
    "    #see if fmax.txt exists and if it does then read the value and return it\n",
    "    #if it does not exist then return 0\n",
    "    #if value exists then save it to fmax.txt\n",
    "    if(value):\n",
    "        try:\n",
    "            with open(\"fmax.txt\", \"w\") as f:\n",
    "                f.write(str(value))\n",
    "            return 0    \n",
    "        except:\n",
    "            return 0\n",
    "    try:\n",
    "        with open(\"fmax.txt\", \"r\") as f:\n",
    "            return float(f.read())\n",
    "    except:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ensemble:\n",
    "    def __init__(self):\n",
    "        self.models = []\n",
    "        \n",
    "    def add_model(self, model):\n",
    "        self.models.append(model)\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        predictions = []\n",
    "        for model in self.models:\n",
    "            pred = model.predict(X_test)\n",
    "            predictions.append(pred)\n",
    "            count_greater_than_0_5 = (pred > model.THRESHOLD).sum()\n",
    "            count_less_than_or_equal_0_5 = (pred <= model.THRESHOLD).sum()\n",
    "            print(f'Percentage of predictions greater than {model.THRESHOLD}: {count_greater_than_0_5 / len(pred) * 100:.2f}%')\n",
    "            passc = count_greater_than_0_5 / len(pred) * 100\n",
    "            if passc < 5:\n",
    "                predictions.pop()\n",
    "                continue\n",
    "            print(f'Percentage of predictions less than or equal to {model.THRESHOLD}: {count_less_than_or_equal_0_5 / len(pred) * 100:.2f}%')\n",
    "        \n",
    "        # Stack predictions to form a 2D array\n",
    "        stacked_predictions = np.hstack(predictions)\n",
    "        \n",
    "        # Average the predictions across models\n",
    "        y_pred = np.mean(stacked_predictions, axis=1)\n",
    "        \n",
    "        # Apply threshold\n",
    "        # y_pred = (y_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Flatten the predictions to form a 1D array\n",
    "        y_pred = y_pred.flatten()\n",
    "        \n",
    "        # Assuming test_ids is defined elsewhere in your code\n",
    "        ids = test_ids\n",
    "        predictions_df = pd.DataFrame({'id': ids, 'loan_status': y_pred})\n",
    "        return predictions_df\n",
    "    \n",
    "    def save(self, testx, path=\"ftt.csv\"):\n",
    "        df = self.predict(testx)\n",
    "        df.to_csv(path, index=False)\n",
    "        csvfile =  pd.read_csv(path)\n",
    "        csvfile\n",
    "        \n",
    "    def rmamodel(self):\n",
    "        self.models = []\n",
    "\n",
    "ens = ensemble()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ktrain( model , xult , yult,splits=5,epochs=15,batch_size=32,random_state=42):\n",
    "    \n",
    "    if splits==1:\n",
    "        class temp:\n",
    "            def split(self, X):\n",
    "                n_samples = len(X)\n",
    "                indices = list(range(n_samples))\n",
    "                yield indices, indices  # Use the same indices for train and test\n",
    "\n",
    "        kf = temp()\n",
    "    else:\n",
    "        kf = KFold(n_splits=splits, shuffle=True, random_state=random_state)\n",
    "        obj = kf \n",
    "    losses, aucs, precisions, recalls, f1s, roc_aucs = [], [], [], [], [], []\n",
    "    iter = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        xt, xv = xult[train_index], xult[test_index]\n",
    "        yt, yv = yult[train_index], yult[test_index]\n",
    "        \n",
    "        # Initialize and compile the model\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(xt, yt, epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        results = model.evaluate(xv, yv)\n",
    "        loss, auc, precision, recall = results[0], results[1], results[2], results[3]\n",
    "        \n",
    "        # Predict probabilities for the test set\n",
    "        y_pred_prob = model.predict(xult)\n",
    "        y_pred = (y_pred_prob > model.THRESHOLD).astype(int)\n",
    "        \n",
    "        # Calculate F1 score and ROC AUC score\n",
    "        f1 = f1_score(yult, y_pred)\n",
    "        #count which iteration is this\n",
    "        count = train_index[0]\n",
    "        roc_auc = roc_auc_score(yult, y_pred_prob)\n",
    "        if f1 > fmax():\n",
    "            model.f1max(iter,epochs,splits)\n",
    "            fmax(f1)\n",
    "            model.save('best.keras')\n",
    "            print(colored(f'F1 Score improved to {f1}. Saving model...', 'green','on_red'))\n",
    "        # Store metrics\n",
    "        losses.append(loss)\n",
    "        aucs.append(auc)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1s.append(f1)\n",
    "        roc_aucs.append(roc_auc)\n",
    "        iter += 1\n",
    "    print('losses: ', losses)\n",
    "    print('aucs: ', aucs)\n",
    "    print('precisions: ', precisions)\n",
    "    print('recalls: ', recalls)\n",
    "    print('f1s: ', f1s)\n",
    "    print('roc_aucs: ', roc_aucs)\n",
    "    print(f'Average Loss: {sum(losses) / len(losses)}')\n",
    "    print(f'Average AUC: {sum(aucs) / len(aucs)}')\n",
    "    print(f'Average Precision: {sum(precisions) / len(precisions)}')\n",
    "    print(f'Average Recall: {sum(recalls) / len(recalls)}')\n",
    "    print(f'Average F1 Score: {sum(f1s) / len(f1s)}')\n",
    "    print(f'Average ROC AUC Score: {sum(roc_aucs) / len(roc_aucs)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[9923  103]\n",
      " [ 437 1266]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10045    49]\n",
      " [  239  1396]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10048    32]\n",
      " [  167  1482]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10091    12]\n",
      " [   92  1534]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[9979    0]\n",
      " [  44 1706]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [0.962885927006694, 0.9912539559334913, 0.9970858360526341, 0.999589407454997, 0.99992641690407]\n",
      "precisions:  [0.9247626004382761, 0.9660899653979239, 0.9788639365918098, 0.9922380336351876, 1.0]\n",
      "recalls:  [0.7433940105695831, 0.8538226299694189, 0.8987265009096422, 0.9434194341943419, 0.9748571428571429]\n",
      "f1s:  [0.8580431975840865, 0.894417631230513, 0.9153127367623537, 0.9303177212292711, 0.935537533790809]\n",
      "roc_aucs:  [0.8878644044052266, 0.9152170239499131, 0.9316659731536033, 0.9440570176874604, 0.9471959848074009]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 0.9901483086703774\n",
      "Average Precision: 0.9723909072126394\n",
      "Average Recall: 0.8828439437000257\n",
      "Average F1 Score: 0.9067257641194066\n",
      "Average ROC AUC Score: 0.9252000808007208\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10049     6]\n",
      " [   40  1634]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10054     1]\n",
      " [   11  1663]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10064     1]\n",
      " [    1  1663]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[9989    0]\n",
      " [   0 1740]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10118     0]\n",
      " [    0  1611]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [0.9999056562858877, 0.9999937619080719, 0.9999997611677939, 1.0, 1.0]\n",
      "precisions:  [0.9963414634146341, 0.9993990384615384, 0.9993990384615384, 1.0, 1.0]\n",
      "recalls:  [0.97610513739546, 0.9934289127837514, 0.9993990384615384, 1.0, 1.0]\n",
      "f1s:  [0.9406112813716557, 0.9450250448333436, 0.9470221820200234, 0.9494530752970632, 0.950702636167812]\n",
      "roc_aucs:  [0.9515770288630414, 0.9557554678891546, 0.9578848010312012, 0.9599105556656843, 0.9607585882018644]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 0.9999798358723506\n",
      "Average Precision: 0.9990279080675422\n",
      "Average Recall: 0.9937866177281499\n",
      "Average F1 Score: 0.9465628439379797\n",
      "Average ROC AUC Score: 0.9571772883301893\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10025     0]\n",
      " [    0  1704]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10065     0]\n",
      " [    0  1664]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10030     0]\n",
      " [    0  1699]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10067     0]\n",
      " [    0  1662]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10095     0]\n",
      " [    0  1634]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "precisions:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "recalls:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "f1s:  [0.9512335054503729, 0.9523907033889628, 0.9526653847727365, 0.9528937293999632, 0.9530157432017993]\n",
      "roc_aucs:  [0.9615173033989681, 0.9624153522163348, 0.9629678390509964, 0.9627945163455771, 0.963353785519725]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 1.0\n",
      "Average Precision: 1.0\n",
      "Average Recall: 1.0\n",
      "Average F1 Score: 0.9524398132427668\n",
      "Average ROC AUC Score: 0.9626097593063203\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10055     0]\n",
      " [    0  1674]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10063     0]\n",
      " [    0  1666]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10030     0]\n",
      " [    0  1699]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10054     0]\n",
      " [    0  1675]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10080     0]\n",
      " [    0  1649]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "XGBClassifier(base_score='1.9275978E-1', booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric='auc', feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n",
      "None\n",
      "iter: 4, epochs: 10, splits: 5\n",
      "{}\n",
      "\u001b[41m\u001b[32mF1 Score improved to 0.9555510204081633. Saving model...\u001b[0m\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "precisions:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "recalls:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "f1s:  [0.9538719368881441, 0.9540302652806992, 0.9544285189268651, 0.9545361709080511, 0.9555510204081633]\n",
      "roc_aucs:  [0.9639890395171483, 0.9643751407613245, 0.964687797087007, 0.964624448290019, 0.9654993006332498]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 1.0\n",
      "Average Precision: 1.0\n",
      "Average Recall: 1.0\n",
      "Average F1 Score: 0.9544835824823845\n",
      "Average ROC AUC Score: 0.9646351452577498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [12:31:48] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10054     0]\n",
      " [    0  1675]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10078     0]\n",
      " [    0  1651]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10070     0]\n",
      " [    0  1659]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10013     0]\n",
      " [    0  1716]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10067     0]\n",
      " [    0  1662]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "XGBClassifier(base_score='1.9275978E-1', booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric='logloss',\n",
      "              feature_types=None, gamma=None, grow_policy=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
      "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)\n",
      "None\n",
      "iter: 4, epochs: 10, splits: 5\n",
      "{}\n",
      "\u001b[41m\u001b[32mF1 Score improved to 0.9559036193657454. Saving model...\u001b[0m\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "precisions:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "recalls:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "f1s:  [0.955109876644065, 0.9553066927768599, 0.9550832245430809, 0.9550376215819416, 0.9559036193657454]\n",
      "roc_aucs:  [0.9649669286538762, 0.965539452956102, 0.9654197698647837, 0.9655263526034719, 0.9664579261796519]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 1.0\n",
      "Average Precision: 1.0\n",
      "Average Recall: 1.0\n",
      "Average F1 Score: 0.9552882069823385\n",
      "Average ROC AUC Score: 0.9655820860515771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [12:32:17] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10089     0]\n",
      " [    0  1640]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10098     0]\n",
      " [    0  1631]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10034     0]\n",
      " [    0  1695]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10013     0]\n",
      " [    0  1716]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10048     0]\n",
      " [    0  1681]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "precisions:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "recalls:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "f1s:  [0.9555310996983778, 0.9558041445076105, 0.9554467564259486, 0.9553151170609451, 0.9557435531546223]\n",
      "roc_aucs:  [0.966018727035441, 0.9662449154777234, 0.9655959420258795, 0.9659656291354064, 0.9660385323398336]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 1.0\n",
      "Average Precision: 1.0\n",
      "Average Recall: 1.0\n",
      "Average F1 Score: 0.9555681341695008\n",
      "Average ROC AUC Score: 0.9659727492028567\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10092     0]\n",
      " [    0  1637]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10075     0]\n",
      " [    0  1654]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[9999    0]\n",
      " [   0 1730]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "XGBClassifier(base_score='1.9275978E-1', booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric='logloss',\n",
      "              feature_types=None, gamma=None, grow_policy=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
      "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)\n",
      "None\n",
      "iter: 2, epochs: 10, splits: 5\n",
      "{}\n",
      "\u001b[41m\u001b[32mF1 Score improved to 0.9559159061277706. Saving model...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [12:33:14] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10064     0]\n",
      " [    0  1665]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10052     0]\n",
      " [    0  1677]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "precisions:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "recalls:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "f1s:  [0.9558038080482734, 0.9556565883096495, 0.9559159061277706, 0.9556230507368979, 0.9558308206340151]\n",
      "roc_aucs:  [0.9660651199837129, 0.9659420457226516, 0.9663946547703876, 0.9659853570520753, 0.9663148144510264]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 1.0\n",
      "Average Precision: 1.0\n",
      "Average Recall: 1.0\n",
      "Average F1 Score: 0.9557660347713213\n",
      "Average ROC AUC Score: 0.9661403983959709\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10025     0]\n",
      " [    0  1704]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "XGBClassifier(base_score='1.9275978E-1', booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric='auc', feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n",
      "None\n",
      "iter: 0, epochs: 10, splits: 5\n",
      "{}\n",
      "\u001b[41m\u001b[32mF1 Score improved to 0.9566668022948285. Saving model...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [12:33:39] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10054     0]\n",
      " [    0  1675]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10042     0]\n",
      " [    0  1687]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10164     0]\n",
      " [    0  1565]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[9997    0]\n",
      " [   0 1732]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "precisions:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "recalls:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "f1s:  [0.9566668022948285, 0.9558254207587922, 0.9557879288204, 0.9555469498400017, 0.9558293452805213]\n",
      "roc_aucs:  [0.967339638250093, 0.9662648755575637, 0.9660950987973352, 0.9659887482218187, 0.9664779636472159]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 1.0\n",
      "Average Precision: 1.0\n",
      "Average Recall: 1.0\n",
      "Average F1 Score: 0.9559312893989087\n",
      "Average ROC AUC Score: 0.9664332648948053\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10064     0]\n",
      " [    0  1665]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10009     0]\n",
      " [    0  1720]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10066     0]\n",
      " [    0  1663]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10079     0]\n",
      " [    0  1650]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10064     0]\n",
      " [    0  1665]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [1.0, 1.0, 1.0, 0.9999999999999999, 1.0]\n",
      "precisions:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "recalls:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "f1s:  [0.9557828673893553, 0.9558538920691833, 0.9563835638763828, 0.9558979375560447, 0.9559868836432514]\n",
      "roc_aucs:  [0.966224955397883, 0.9663514208286875, 0.9666539810328642, 0.9662281917921786, 0.9665211202011922]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 1.0\n",
      "Average Precision: 1.0\n",
      "Average Recall: 1.0\n",
      "Average F1 Score: 0.9559810289068433\n",
      "Average ROC AUC Score: 0.9663959338505611\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10048     0]\n",
      " [    0  1681]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10016     0]\n",
      " [    0  1713]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10067     0]\n",
      " [    0  1662]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10138     0]\n",
      " [    0  1591]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10013     0]\n",
      " [    0  1716]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "precisions:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "recalls:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "f1s:  [0.9557320301364284, 0.9559530600603048, 0.9564651049193007, 0.9561889250814333, 0.9560048046580752]\n",
      "roc_aucs:  [0.9664613947371189, 0.9663846360366056, 0.9670601197446047, 0.9668006387066805, 0.9666875831794012]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 1.0\n",
      "Average Precision: 1.0\n",
      "Average Recall: 1.0\n",
      "Average F1 Score: 0.9560687849711084\n",
      "Average ROC AUC Score: 0.9666788744808821\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, precision_score, recall_score\n",
    "\n",
    "class XGBoostClassifierModel:\n",
    "    def __init__(self, eval_metric='logloss', model_path='xgb_model.json', **kwargs):\n",
    "        self.model = xgb.XGBClassifier(objective='binary:logistic', eval_metric=eval_metric, **kwargs)\n",
    "        self.model_path = model_path\n",
    "        self.THRESHOLD = 0.5\n",
    "        self.load_model()\n",
    "        self.f1 = 0 # Placeholder for F1 score\n",
    "\n",
    "    def fit(self, X_train, y_train, verbose=0, **kwargs):\n",
    "        self.model.fit(X_train, y_train, verbose=verbose, xgb_model=self.model_path if self.model_exists() else None)\n",
    "        self.save_model()\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        print(colored('predicting using xgboost model', 'green'))\n",
    "        return self.model.predict(X_test).reshape(-1, 1)\n",
    "\n",
    "    def predict_proba(self, X_test):\n",
    "        return self.model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        y_pred = self.predict(X_test)\n",
    "        y_pred_proba = self.predict_proba(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        print(cm)\n",
    "        # Assuming loss is not directly available, using log loss as a proxy\n",
    "        loss = -1  # Placeholder, as XGBoost does not directly provide loss in this context\n",
    "        return [loss, auc, precision, recall]\n",
    "\n",
    "    def summary(self):\n",
    "        print(self.model)\n",
    "    def f1max(self, *args, **kwargs):\n",
    "        print(self.summary())\n",
    "        if args:\n",
    "            print(f\"iter: {args[0]}, epochs: {args[1]}, splits: {args[2]}\")\n",
    "        print(kwargs)\n",
    "    def save_model(self):\n",
    "        self.model.save_model(self.model_path)\n",
    "\n",
    "    def load_model(self):\n",
    "        if self.model_exists():\n",
    "            self.model.load_model(self.model_path)\n",
    "\n",
    "    def model_exists(self):\n",
    "        try:\n",
    "            with open(self.model_path, 'r'):\n",
    "                return True\n",
    "        except FileNotFoundError:\n",
    "            return False\n",
    "    def save(self, path):\n",
    "        self.model.save_model(path)\n",
    "\n",
    "# Example usage\n",
    "# Assuming xult and yult are your feature matrix and target vector\n",
    "# Split the data into training and test sets\n",
    "\n",
    "for i in range(10):\n",
    "    if i%2==0:\n",
    "        xgb_model = XGBoostClassifierModel(model_path=f'xgb_model.json')\n",
    "    else:\n",
    "        xgb_model = XGBoostClassifierModel(eval_metric='auc', model_path=f'xgb_model.json')\n",
    "    ktrain(xgb_model, xult, yult, epochs=10, batch_size=32, splits=5, random_state=i)\n",
    "    ens.add_model(xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - auc_12: 0.7533 - loss: 0.3947 - precision_12: 0.4795 - recall_12: 0.1559 - val_auc_12: 0.9030 - val_loss: 0.2433 - val_precision_12: 0.7644 - val_recall_12: 0.5076\n",
      "Epoch 2/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - auc_12: 0.8818 - loss: 0.2638 - precision_12: 0.7621 - recall_12: 0.4501 - val_auc_12: 0.9103 - val_loss: 0.2333 - val_precision_12: 0.8015 - val_recall_12: 0.5080\n",
      "Epoch 3/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - auc_12: 0.8997 - loss: 0.2406 - precision_12: 0.7745 - recall_12: 0.5095 - val_auc_12: 0.9105 - val_loss: 0.2349 - val_precision_12: 0.7913 - val_recall_12: 0.5689\n",
      "Epoch 4/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - auc_12: 0.9001 - loss: 0.2403 - precision_12: 0.7755 - recall_12: 0.5066 - val_auc_12: 0.9096 - val_loss: 0.2390 - val_precision_12: 0.8635 - val_recall_12: 0.4534\n",
      "Epoch 5/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - auc_12: 0.9058 - loss: 0.2301 - precision_12: 0.8074 - recall_12: 0.5290 - val_auc_12: 0.9099 - val_loss: 0.2429 - val_precision_12: 0.7894 - val_recall_12: 0.5430\n",
      "Epoch 6/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - auc_12: 0.9047 - loss: 0.2312 - precision_12: 0.8121 - recall_12: 0.5316 - val_auc_12: 0.9146 - val_loss: 0.2256 - val_precision_12: 0.7714 - val_recall_12: 0.6302\n",
      "Epoch 7/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - auc_12: 0.9083 - loss: 0.2284 - precision_12: 0.8038 - recall_12: 0.5469 - val_auc_12: 0.9125 - val_loss: 0.2343 - val_precision_12: 0.8312 - val_recall_12: 0.5056\n",
      "Epoch 8/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - auc_12: 0.9068 - loss: 0.2287 - precision_12: 0.8139 - recall_12: 0.5443 - val_auc_12: 0.9153 - val_loss: 0.2270 - val_precision_12: 0.7809 - val_recall_12: 0.5804\n",
      "Epoch 9/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - auc_12: 0.9131 - loss: 0.2185 - precision_12: 0.8094 - recall_12: 0.5571 - val_auc_12: 0.9179 - val_loss: 0.2166 - val_precision_12: 0.8039 - val_recall_12: 0.5939\n",
      "Epoch 10/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - auc_12: 0.9159 - loss: 0.2156 - precision_12: 0.8143 - recall_12: 0.5743 - val_auc_12: 0.9163 - val_loss: 0.2273 - val_precision_12: 0.7371 - val_recall_12: 0.6497\n",
      "Epoch 11/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - auc_12: 0.9127 - loss: 0.2215 - precision_12: 0.8037 - recall_12: 0.5521 - val_auc_12: 0.9199 - val_loss: 0.2133 - val_precision_12: 0.7943 - val_recall_12: 0.6178\n",
      "Epoch 12/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - auc_12: 0.9093 - loss: 0.2262 - precision_12: 0.8093 - recall_12: 0.5617 - val_auc_12: 0.8916 - val_loss: 0.2494 - val_precision_12: 0.8413 - val_recall_12: 0.5275\n",
      "Epoch 13/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - auc_12: 0.9150 - loss: 0.2115 - precision_12: 0.8057 - recall_12: 0.5724 - val_auc_12: 0.9219 - val_loss: 0.2106 - val_precision_12: 0.8200 - val_recall_12: 0.5912\n",
      "Epoch 14/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - auc_12: 0.9162 - loss: 0.2171 - precision_12: 0.8087 - recall_12: 0.5961 - val_auc_12: 0.9205 - val_loss: 0.2140 - val_precision_12: 0.8040 - val_recall_12: 0.6043\n",
      "Epoch 15/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - auc_12: 0.9194 - loss: 0.2099 - precision_12: 0.8270 - recall_12: 0.5955 - val_auc_12: 0.9227 - val_loss: 0.2085 - val_precision_12: 0.8594 - val_recall_12: 0.5888\n",
      "\u001b[1m1833/1833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_12: 0.9243 - loss: 0.2044 - precision_12: 0.8619 - recall_12: 0.5944\n",
      "\u001b[32mPredicting with encoding_dim 512...\u001b[0m\n",
      "\u001b[1m5498/5498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 925us/step\n",
      "losses:  [0.20502042770385742]\n",
      "aucs:  [0.9246081113815308]\n",
      "precisions:  [0.8594557642936707]\n",
      "recalls:  [0.5966758131980896]\n",
      "f1s:  [0.705603195113356]\n",
      "roc_aucs:  [0.9259889040555599]\n",
      "Average Loss: 0.20502042770385742\n",
      "Average AUC: 0.9246081113815308\n",
      "Average Precision: 0.8594557642936707\n",
      "Average Recall: 0.5966758131980896\n",
      "Average F1 Score: 0.705603195113356\n",
      "Average ROC AUC Score: 0.9259889040555599\n",
      "Epoch 1/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - auc_13: 0.6970 - loss: 0.3940 - precision_13: 0.6126 - recall_13: 0.0958 - val_auc_13: 0.8503 - val_loss: 0.2913 - val_precision_13: 0.8681 - val_recall_13: 0.2385\n",
      "Epoch 2/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_13: 0.8506 - loss: 0.2916 - precision_13: 0.7685 - recall_13: 0.3107 - val_auc_13: 0.8904 - val_loss: 0.2900 - val_precision_13: 0.5322 - val_recall_13: 0.6907\n",
      "Epoch 3/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_13: 0.8847 - loss: 0.2590 - precision_13: 0.7611 - recall_13: 0.4678 - val_auc_13: 0.9001 - val_loss: 0.2786 - val_precision_13: 0.8417 - val_recall_13: 0.3451\n",
      "Epoch 4/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_13: 0.8931 - loss: 0.2498 - precision_13: 0.7730 - recall_13: 0.4940 - val_auc_13: 0.9062 - val_loss: 0.2374 - val_precision_13: 0.8281 - val_recall_13: 0.4853\n",
      "Epoch 5/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_13: 0.9003 - loss: 0.2345 - precision_13: 0.7910 - recall_13: 0.5142 - val_auc_13: 0.9022 - val_loss: 0.2360 - val_precision_13: 0.8693 - val_recall_13: 0.4582\n",
      "Epoch 6/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_13: 0.9070 - loss: 0.2325 - precision_13: 0.7986 - recall_13: 0.5325 - val_auc_13: 0.9093 - val_loss: 0.2261 - val_precision_13: 0.8200 - val_recall_13: 0.5621\n",
      "Epoch 7/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_13: 0.9047 - loss: 0.2320 - precision_13: 0.8068 - recall_13: 0.5454 - val_auc_13: 0.9078 - val_loss: 0.2314 - val_precision_13: 0.8540 - val_recall_13: 0.4960\n",
      "Epoch 8/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_13: 0.9113 - loss: 0.2244 - precision_13: 0.8336 - recall_13: 0.5634 - val_auc_13: 0.9125 - val_loss: 0.2212 - val_precision_13: 0.8026 - val_recall_13: 0.5892\n",
      "Epoch 9/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_13: 0.9133 - loss: 0.2215 - precision_13: 0.8275 - recall_13: 0.5561 - val_auc_13: 0.9153 - val_loss: 0.2230 - val_precision_13: 0.8685 - val_recall_13: 0.5024\n",
      "Epoch 10/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_13: 0.9134 - loss: 0.2174 - precision_13: 0.8112 - recall_13: 0.5784 - val_auc_13: 0.9172 - val_loss: 0.2145 - val_precision_13: 0.8134 - val_recall_13: 0.5864\n",
      "Epoch 11/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_13: 0.9156 - loss: 0.2148 - precision_13: 0.8244 - recall_13: 0.5538 - val_auc_13: 0.9181 - val_loss: 0.2304 - val_precision_13: 0.8609 - val_recall_13: 0.4829\n",
      "Epoch 12/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_13: 0.9112 - loss: 0.2230 - precision_13: 0.8152 - recall_13: 0.5424 - val_auc_13: 0.9181 - val_loss: 0.2173 - val_precision_13: 0.8316 - val_recall_13: 0.5346\n",
      "Epoch 13/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_13: 0.9188 - loss: 0.2119 - precision_13: 0.8121 - recall_13: 0.5660 - val_auc_13: 0.9196 - val_loss: 0.2209 - val_precision_13: 0.8514 - val_recall_13: 0.5131\n",
      "Epoch 14/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_13: 0.9118 - loss: 0.2199 - precision_13: 0.8214 - recall_13: 0.5504 - val_auc_13: 0.9202 - val_loss: 0.2103 - val_precision_13: 0.8103 - val_recall_13: 0.6071\n",
      "Epoch 15/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_13: 0.9202 - loss: 0.2100 - precision_13: 0.8394 - recall_13: 0.5748 - val_auc_13: 0.9150 - val_loss: 0.2193 - val_precision_13: 0.8717 - val_recall_13: 0.5167\n",
      "\u001b[1m1833/1833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - auc_13: 0.9160 - loss: 0.2151 - precision_13: 0.8764 - recall_13: 0.5220\n",
      "\u001b[32mPredicting with encoding_dim 256...\u001b[0m\n",
      "\u001b[1m5498/5498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 961us/step\n",
      "losses:  [0.21618053317070007]\n",
      "aucs:  [0.9159666895866394]\n",
      "precisions:  [0.8796871900558472]\n",
      "recalls:  [0.5245725512504578]\n",
      "f1s:  [0.6620627757971629]\n",
      "roc_aucs:  [0.916188192525047]\n",
      "Average Loss: 0.21618053317070007\n",
      "Average AUC: 0.9159666895866394\n",
      "Average Precision: 0.8796871900558472\n",
      "Average Recall: 0.5245725512504578\n",
      "Average F1 Score: 0.6620627757971629\n",
      "Average ROC AUC Score: 0.916188192525047\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Reshape, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from colorama import init\n",
    "from termcolor import colored\n",
    "# Define the L2 regularizers\n",
    "\n",
    "\n",
    "k = .0001\n",
    "kernel_regularizer = l2(0.0001*k)\n",
    "bias_regularizer = l2(0.00001*k)\n",
    "\n",
    "# Define the CNN model with different regularization strengths for kernel and bias\n",
    "class AutoencoderModel:\n",
    "    def __init__(self, input_dim, encoding_dim=512):\n",
    "        self.input_dim = input_dim\n",
    "        self.encoding_dim = encoding_dim\n",
    "        self.autoencoder = self.build_model()\n",
    "        self.THRESHOLD = 0.5\n",
    "    def build_model(self):\n",
    "        # Encoder\n",
    "        input_layer = Input(shape=(self.input_dim,))\n",
    "        encoded = Dense(self.encoding_dim, activation='relu')(input_layer)\n",
    "        encoded = Dense(self.encoding_dim // 2, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(encoded)\n",
    "        encoded = Dense(self.encoding_dim // 4, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(encoded)\n",
    "        encoded = Dense(self.encoding_dim // 8, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(encoded)\n",
    "        encoded = Dense(self.encoding_dim // 16, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(encoded)\n",
    "        encoded = Dense(self.encoding_dim // 32, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(encoded)\n",
    "    \n",
    "        # Decoder\n",
    "        decoded = Dense(self.encoding_dim // 32, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(encoded)\n",
    "        decoded = Dense(self.encoding_dim // 16, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(encoded)\n",
    "        decoded = Dense(self.encoding_dim // 8, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(encoded)\n",
    "        decoded = Dense(self.encoding_dim // 4, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(decoded)\n",
    "        decoded = Dense(self.encoding_dim // 2, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(decoded)\n",
    "        decoded = Dense(1, activation='sigmoid')(decoded)\n",
    "    \n",
    "        # Autoencoder\n",
    "        autoencoder = Model(input_layer, decoded)\n",
    "    \n",
    "        # Compile the model with Binary Crossentropy loss\n",
    "        autoencoder.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(), metrics=[AUC(), Precision(), Recall()])    \n",
    "        return autoencoder\n",
    "\n",
    "    def fit(self, X_train, y_train, epochs=10, verbose=0, batch_size=32, validation_split=0.3, validation_data=None):\n",
    "        if validation_data is not None:\n",
    "            self.autoencoder.fit(X_train, y_train, epochs=epochs, verbose=verbose, batch_size=batch_size, validation_data=validation_data, validation_split=validation_split)\n",
    "            return \n",
    "        self.autoencoder.fit(X_train, y_train, epochs=epochs, verbose=verbose, batch_size=batch_size, validation_split=validation_split)\n",
    "    def f1max(self, *args, **kwargs):\n",
    "        print(self.summary())\n",
    "        if args:\n",
    "            print(f\"iter: {args[0]}, epochs: {args[1]}, splits: {args[2]}\")\n",
    "        print(kwargs)\n",
    "    def predict(self, X_test):\n",
    "        print(colored(f'Predicting with encoding_dim {self.encoding_dim}...', 'green'))\n",
    "        return self.autoencoder.predict(X_test)\n",
    "    \n",
    "    def summary(self):\n",
    "        self.autoencoder.summary()\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        return self.autoencoder.evaluate(X_test, y_test)\n",
    "    def save(self, path):\n",
    "        self.autoencoder.save(path)\n",
    "\n",
    "dim = [512, 256, 128, 64, 256]\n",
    "for i in range(2):\n",
    "    automodel = AutoencoderModel(X_train.shape[1], encoding_dim=dim[i])\n",
    "    ktrain(automodel, xult, yult, splits=1, epochs=15, batch_size=32, random_state=i)\n",
    "    ens.add_model(automodel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - auc_14: 0.7149 - loss: 0.4280 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_auc_14: 0.8808 - val_loss: 0.2938 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 2/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_14: 0.8613 - loss: 0.2975 - precision_14: 0.0000e+00 - recall_14: 0.0000e+00 - val_auc_14: 0.8732 - val_loss: 0.2964 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 3/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.8728 - loss: 0.2873 - precision_14: 0.3638 - recall_14: 0.0517 - val_auc_14: 0.9015 - val_loss: 0.2620 - val_precision_14: 0.7789 - val_recall_14: 0.4387\n",
      "Epoch 4/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.8703 - loss: 0.2791 - precision_14: 0.6110 - recall_14: 0.4244 - val_auc_14: 0.8927 - val_loss: 0.2719 - val_precision_14: 0.7872 - val_recall_14: 0.3528\n",
      "Epoch 5/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.8835 - loss: 0.2741 - precision_14: 0.7306 - recall_14: 0.4303 - val_auc_14: 0.8958 - val_loss: 0.2675 - val_precision_14: 0.7361 - val_recall_14: 0.5870\n",
      "Epoch 6/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.8819 - loss: 0.2738 - precision_14: 0.6677 - recall_14: 0.5427 - val_auc_14: 0.9082 - val_loss: 0.2548 - val_precision_14: 0.7914 - val_recall_14: 0.4368\n",
      "Epoch 7/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_14: 0.8964 - loss: 0.2561 - precision_14: 0.7451 - recall_14: 0.5135 - val_auc_14: 0.8622 - val_loss: 0.3030 - val_precision_14: 0.4636 - val_recall_14: 0.7436\n",
      "Epoch 8/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.8847 - loss: 0.2677 - precision_14: 0.6723 - recall_14: 0.5017 - val_auc_14: 0.8982 - val_loss: 0.2673 - val_precision_14: 0.8140 - val_recall_14: 0.3977\n",
      "Epoch 9/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_14: 0.8983 - loss: 0.2508 - precision_14: 0.7504 - recall_14: 0.5206 - val_auc_14: 0.9069 - val_loss: 0.2484 - val_precision_14: 0.8040 - val_recall_14: 0.4723\n",
      "Epoch 10/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_14: 0.9012 - loss: 0.2460 - precision_14: 0.7614 - recall_14: 0.5480 - val_auc_14: 0.8747 - val_loss: 0.2690 - val_precision_14: 0.7995 - val_recall_14: 0.4353\n",
      "Epoch 11/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.8977 - loss: 0.2470 - precision_14: 0.6876 - recall_14: 0.5801 - val_auc_14: 0.9000 - val_loss: 0.2538 - val_precision_14: 0.7883 - val_recall_14: 0.5390\n",
      "Epoch 12/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_14: 0.9039 - loss: 0.2434 - precision_14: 0.7242 - recall_14: 0.5775 - val_auc_14: 0.9131 - val_loss: 0.2379 - val_precision_14: 0.8254 - val_recall_14: 0.4906\n",
      "Epoch 13/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9069 - loss: 0.2366 - precision_14: 0.7941 - recall_14: 0.5260 - val_auc_14: 0.9110 - val_loss: 0.2331 - val_precision_14: 0.7803 - val_recall_14: 0.6003\n",
      "Epoch 14/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9055 - loss: 0.2381 - precision_14: 0.7819 - recall_14: 0.5552 - val_auc_14: 0.9116 - val_loss: 0.2439 - val_precision_14: 0.8470 - val_recall_14: 0.4541\n",
      "Epoch 15/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9107 - loss: 0.2292 - precision_14: 0.8097 - recall_14: 0.5316 - val_auc_14: 0.9163 - val_loss: 0.2270 - val_precision_14: 0.8396 - val_recall_14: 0.5069\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - auc_14: 0.9191 - loss: 0.2218 - precision_14: 0.8484 - recall_14: 0.5408\n",
      "\u001b[32mpredicting using dense model of hidden 64\u001b[0m\n",
      "\u001b[1m5498/5498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 661us/step\n",
      "Epoch 1/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_14: 0.9076 - loss: 0.2338 - precision_14: 0.8445 - recall_14: 0.5184 - val_auc_14: 0.9117 - val_loss: 0.2371 - val_precision_14: 0.8943 - val_recall_14: 0.3741\n",
      "Epoch 2/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9143 - loss: 0.2249 - precision_14: 0.8571 - recall_14: 0.5198 - val_auc_14: 0.9054 - val_loss: 0.2403 - val_precision_14: 0.8943 - val_recall_14: 0.4203\n",
      "Epoch 3/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9148 - loss: 0.2203 - precision_14: 0.8561 - recall_14: 0.5185 - val_auc_14: 0.9166 - val_loss: 0.2217 - val_precision_14: 0.8492 - val_recall_14: 0.5400\n",
      "Epoch 4/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9073 - loss: 0.2319 - precision_14: 0.8452 - recall_14: 0.5235 - val_auc_14: 0.9153 - val_loss: 0.2240 - val_precision_14: 0.8733 - val_recall_14: 0.4829\n",
      "Epoch 5/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9183 - loss: 0.2235 - precision_14: 0.8568 - recall_14: 0.5371 - val_auc_14: 0.9100 - val_loss: 0.2401 - val_precision_14: 0.8331 - val_recall_14: 0.5082\n",
      "Epoch 6/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9137 - loss: 0.2240 - precision_14: 0.8656 - recall_14: 0.5426 - val_auc_14: 0.9159 - val_loss: 0.2249 - val_precision_14: 0.8924 - val_recall_14: 0.4694\n",
      "Epoch 7/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9196 - loss: 0.2139 - precision_14: 0.8362 - recall_14: 0.5710 - val_auc_14: 0.9124 - val_loss: 0.2382 - val_precision_14: 0.6845 - val_recall_14: 0.6791\n",
      "Epoch 8/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9244 - loss: 0.2089 - precision_14: 0.8411 - recall_14: 0.5837 - val_auc_14: 0.9099 - val_loss: 0.2251 - val_precision_14: 0.8619 - val_recall_14: 0.5241\n",
      "Epoch 9/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - auc_14: 0.9149 - loss: 0.2168 - precision_14: 0.8315 - recall_14: 0.5677 - val_auc_14: 0.9110 - val_loss: 0.2388 - val_precision_14: 0.6974 - val_recall_14: 0.6538\n",
      "Epoch 10/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_14: 0.9183 - loss: 0.2161 - precision_14: 0.8346 - recall_14: 0.5671 - val_auc_14: 0.9206 - val_loss: 0.2136 - val_precision_14: 0.8804 - val_recall_14: 0.5450\n",
      "Epoch 11/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9202 - loss: 0.2118 - precision_14: 0.8449 - recall_14: 0.5858 - val_auc_14: 0.9023 - val_loss: 0.2337 - val_precision_14: 0.8932 - val_recall_14: 0.4655\n",
      "Epoch 12/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9226 - loss: 0.2107 - precision_14: 0.8512 - recall_14: 0.5718 - val_auc_14: 0.9198 - val_loss: 0.2171 - val_precision_14: 0.7874 - val_recall_14: 0.6403\n",
      "Epoch 13/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9194 - loss: 0.2151 - precision_14: 0.8374 - recall_14: 0.5825 - val_auc_14: 0.9214 - val_loss: 0.2123 - val_precision_14: 0.8390 - val_recall_14: 0.5643\n",
      "Epoch 14/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_14: 0.9263 - loss: 0.2075 - precision_14: 0.8500 - recall_14: 0.5942 - val_auc_14: 0.9181 - val_loss: 0.2193 - val_precision_14: 0.8727 - val_recall_14: 0.5281\n",
      "Epoch 15/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_14: 0.9308 - loss: 0.2001 - precision_14: 0.8316 - recall_14: 0.6115 - val_auc_14: 0.9212 - val_loss: 0.2148 - val_precision_14: 0.8625 - val_recall_14: 0.5703\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - auc_14: 0.9224 - loss: 0.2115 - precision_14: 0.8458 - recall_14: 0.5710\n",
      "\u001b[32mpredicting using dense model of hidden 64\u001b[0m\n",
      "\u001b[1m5498/5498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 665us/step\n",
      "Epoch 1/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_14: 0.9205 - loss: 0.2106 - precision_14: 0.8365 - recall_14: 0.5879 - val_auc_14: 0.9252 - val_loss: 0.2103 - val_precision_14: 0.8939 - val_recall_14: 0.4945\n",
      "Epoch 2/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_14: 0.9238 - loss: 0.2078 - precision_14: 0.8406 - recall_14: 0.5870 - val_auc_14: 0.9273 - val_loss: 0.2044 - val_precision_14: 0.8128 - val_recall_14: 0.6229\n",
      "Epoch 3/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_14: 0.9300 - loss: 0.2045 - precision_14: 0.8445 - recall_14: 0.6027 - val_auc_14: 0.9283 - val_loss: 0.2053 - val_precision_14: 0.8722 - val_recall_14: 0.5512\n",
      "Epoch 4/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_14: 0.9258 - loss: 0.2093 - precision_14: 0.8616 - recall_14: 0.5765 - val_auc_14: 0.9298 - val_loss: 0.2009 - val_precision_14: 0.8746 - val_recall_14: 0.5667\n",
      "Epoch 5/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - auc_14: 0.9279 - loss: 0.2007 - precision_14: 0.8469 - recall_14: 0.6031 - val_auc_14: 0.9298 - val_loss: 0.1998 - val_precision_14: 0.8545 - val_recall_14: 0.5893\n",
      "Epoch 6/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_14: 0.9251 - loss: 0.2026 - precision_14: 0.8522 - recall_14: 0.5956 - val_auc_14: 0.9304 - val_loss: 0.1984 - val_precision_14: 0.8525 - val_recall_14: 0.5973\n",
      "Epoch 7/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_14: 0.9307 - loss: 0.1984 - precision_14: 0.8535 - recall_14: 0.5936 - val_auc_14: 0.9295 - val_loss: 0.1996 - val_precision_14: 0.8446 - val_recall_14: 0.6133\n",
      "Epoch 8/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9277 - loss: 0.2061 - precision_14: 0.8285 - recall_14: 0.5991 - val_auc_14: 0.9312 - val_loss: 0.1991 - val_precision_14: 0.8494 - val_recall_14: 0.5772\n",
      "Epoch 9/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9286 - loss: 0.1994 - precision_14: 0.8489 - recall_14: 0.6025 - val_auc_14: 0.9318 - val_loss: 0.1998 - val_precision_14: 0.8944 - val_recall_14: 0.5481\n",
      "Epoch 10/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_14: 0.9311 - loss: 0.1987 - precision_14: 0.8641 - recall_14: 0.6099 - val_auc_14: 0.9229 - val_loss: 0.2138 - val_precision_14: 0.7390 - val_recall_14: 0.6459\n",
      "Epoch 11/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9313 - loss: 0.1988 - precision_14: 0.8522 - recall_14: 0.5998 - val_auc_14: 0.9315 - val_loss: 0.1963 - val_precision_14: 0.8863 - val_recall_14: 0.5747\n",
      "Epoch 12/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9341 - loss: 0.1939 - precision_14: 0.8528 - recall_14: 0.6096 - val_auc_14: 0.9329 - val_loss: 0.1944 - val_precision_14: 0.8473 - val_recall_14: 0.6093\n",
      "Epoch 13/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9368 - loss: 0.1938 - precision_14: 0.8480 - recall_14: 0.6196 - val_auc_14: 0.9308 - val_loss: 0.2038 - val_precision_14: 0.8635 - val_recall_14: 0.5677\n",
      "Epoch 14/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9294 - loss: 0.2026 - precision_14: 0.8479 - recall_14: 0.6107 - val_auc_14: 0.9314 - val_loss: 0.1989 - val_precision_14: 0.8914 - val_recall_14: 0.5517\n",
      "Epoch 15/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9344 - loss: 0.1933 - precision_14: 0.8502 - recall_14: 0.6110 - val_auc_14: 0.9315 - val_loss: 0.1990 - val_precision_14: 0.8544 - val_recall_14: 0.5858\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - auc_14: 0.9171 - loss: 0.2114 - precision_14: 0.8418 - recall_14: 0.5754\n",
      "\u001b[32mpredicting using dense model of hidden 64\u001b[0m\n",
      "\u001b[1m5498/5498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 654us/step\n",
      "Epoch 1/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9299 - loss: 0.1981 - precision_14: 0.8554 - recall_14: 0.6129 - val_auc_14: 0.9244 - val_loss: 0.2131 - val_precision_14: 0.8750 - val_recall_14: 0.5498\n",
      "Epoch 2/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9320 - loss: 0.1961 - precision_14: 0.8484 - recall_14: 0.6095 - val_auc_14: 0.9298 - val_loss: 0.1979 - val_precision_14: 0.8359 - val_recall_14: 0.6279\n",
      "Epoch 3/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9313 - loss: 0.1940 - precision_14: 0.8432 - recall_14: 0.6130 - val_auc_14: 0.9290 - val_loss: 0.2013 - val_precision_14: 0.8457 - val_recall_14: 0.6190\n",
      "Epoch 4/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9294 - loss: 0.1940 - precision_14: 0.8487 - recall_14: 0.6115 - val_auc_14: 0.9273 - val_loss: 0.2036 - val_precision_14: 0.8065 - val_recall_14: 0.6568\n",
      "Epoch 5/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9286 - loss: 0.1998 - precision_14: 0.8400 - recall_14: 0.5979 - val_auc_14: 0.9278 - val_loss: 0.2048 - val_precision_14: 0.8944 - val_recall_14: 0.5366\n",
      "Epoch 6/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9285 - loss: 0.1951 - precision_14: 0.8564 - recall_14: 0.6065 - val_auc_14: 0.9275 - val_loss: 0.2056 - val_precision_14: 0.7799 - val_recall_14: 0.6784\n",
      "Epoch 7/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9327 - loss: 0.1920 - precision_14: 0.8514 - recall_14: 0.6105 - val_auc_14: 0.9322 - val_loss: 0.1974 - val_precision_14: 0.8808 - val_recall_14: 0.5876\n",
      "Epoch 8/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9336 - loss: 0.1911 - precision_14: 0.8562 - recall_14: 0.6030 - val_auc_14: 0.9289 - val_loss: 0.2005 - val_precision_14: 0.8787 - val_recall_14: 0.5866\n",
      "Epoch 9/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9342 - loss: 0.1925 - precision_14: 0.8631 - recall_14: 0.6004 - val_auc_14: 0.9283 - val_loss: 0.2008 - val_precision_14: 0.8564 - val_recall_14: 0.5886\n",
      "Epoch 10/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9341 - loss: 0.1893 - precision_14: 0.8536 - recall_14: 0.6179 - val_auc_14: 0.9318 - val_loss: 0.1992 - val_precision_14: 0.8754 - val_recall_14: 0.5862\n",
      "Epoch 11/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9353 - loss: 0.1897 - precision_14: 0.8487 - recall_14: 0.6114 - val_auc_14: 0.9300 - val_loss: 0.2047 - val_precision_14: 0.8649 - val_recall_14: 0.5783\n",
      "Epoch 12/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9331 - loss: 0.1933 - precision_14: 0.8464 - recall_14: 0.6066 - val_auc_14: 0.9280 - val_loss: 0.2034 - val_precision_14: 0.8078 - val_recall_14: 0.6416\n",
      "Epoch 13/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9373 - loss: 0.1893 - precision_14: 0.8523 - recall_14: 0.6167 - val_auc_14: 0.9291 - val_loss: 0.2019 - val_precision_14: 0.8086 - val_recall_14: 0.6470\n",
      "Epoch 14/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9325 - loss: 0.1935 - precision_14: 0.8422 - recall_14: 0.6182 - val_auc_14: 0.9316 - val_loss: 0.2008 - val_precision_14: 0.8550 - val_recall_14: 0.5994\n",
      "Epoch 15/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9321 - loss: 0.1932 - precision_14: 0.8406 - recall_14: 0.6007 - val_auc_14: 0.9325 - val_loss: 0.1966 - val_precision_14: 0.8444 - val_recall_14: 0.6205\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - auc_14: 0.9346 - loss: 0.1957 - precision_14: 0.8154 - recall_14: 0.6351\n",
      "\u001b[32mpredicting using dense model of hidden 64\u001b[0m\n",
      "\u001b[1m5498/5498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 662us/step\n",
      "Epoch 1/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9379 - loss: 0.1896 - precision_14: 0.8327 - recall_14: 0.6448 - val_auc_14: 0.9338 - val_loss: 0.1922 - val_precision_14: 0.8798 - val_recall_14: 0.5812\n",
      "Epoch 2/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9360 - loss: 0.1876 - precision_14: 0.8380 - recall_14: 0.6239 - val_auc_14: 0.9344 - val_loss: 0.1903 - val_precision_14: 0.8683 - val_recall_14: 0.6105\n",
      "Epoch 3/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9378 - loss: 0.1896 - precision_14: 0.8467 - recall_14: 0.6303 - val_auc_14: 0.9342 - val_loss: 0.1923 - val_precision_14: 0.8484 - val_recall_14: 0.6201\n",
      "Epoch 4/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9396 - loss: 0.1859 - precision_14: 0.8360 - recall_14: 0.6432 - val_auc_14: 0.9256 - val_loss: 0.2051 - val_precision_14: 0.8284 - val_recall_14: 0.6399\n",
      "Epoch 5/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9371 - loss: 0.1835 - precision_14: 0.8608 - recall_14: 0.6274 - val_auc_14: 0.9341 - val_loss: 0.1928 - val_precision_14: 0.8906 - val_recall_14: 0.5766\n",
      "Epoch 6/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9382 - loss: 0.1838 - precision_14: 0.8569 - recall_14: 0.6273 - val_auc_14: 0.9322 - val_loss: 0.1965 - val_precision_14: 0.8925 - val_recall_14: 0.5584\n",
      "Epoch 7/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9401 - loss: 0.1849 - precision_14: 0.8393 - recall_14: 0.6323 - val_auc_14: 0.9283 - val_loss: 0.2013 - val_precision_14: 0.8937 - val_recall_14: 0.5483\n",
      "Epoch 8/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9368 - loss: 0.1889 - precision_14: 0.8544 - recall_14: 0.6233 - val_auc_14: 0.9333 - val_loss: 0.1926 - val_precision_14: 0.8313 - val_recall_14: 0.6454\n",
      "Epoch 9/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_14: 0.9409 - loss: 0.1788 - precision_14: 0.8491 - recall_14: 0.6523 - val_auc_14: 0.9282 - val_loss: 0.2047 - val_precision_14: 0.8808 - val_recall_14: 0.5382\n",
      "Epoch 10/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9384 - loss: 0.1869 - precision_14: 0.8484 - recall_14: 0.6345 - val_auc_14: 0.9341 - val_loss: 0.1941 - val_precision_14: 0.8349 - val_recall_14: 0.6191\n",
      "Epoch 11/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9392 - loss: 0.1861 - precision_14: 0.8459 - recall_14: 0.6338 - val_auc_14: 0.9287 - val_loss: 0.2022 - val_precision_14: 0.8931 - val_recall_14: 0.5493\n",
      "Epoch 12/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9429 - loss: 0.1793 - precision_14: 0.8614 - recall_14: 0.6316 - val_auc_14: 0.9343 - val_loss: 0.1921 - val_precision_14: 0.8817 - val_recall_14: 0.5918\n",
      "Epoch 13/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9467 - loss: 0.1745 - precision_14: 0.8572 - recall_14: 0.6532 - val_auc_14: 0.9355 - val_loss: 0.1894 - val_precision_14: 0.8314 - val_recall_14: 0.6687\n",
      "Epoch 14/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9422 - loss: 0.1773 - precision_14: 0.8465 - recall_14: 0.6507 - val_auc_14: 0.9350 - val_loss: 0.1902 - val_precision_14: 0.8724 - val_recall_14: 0.5842\n",
      "Epoch 15/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_14: 0.9398 - loss: 0.1826 - precision_14: 0.8631 - recall_14: 0.6184 - val_auc_14: 0.9335 - val_loss: 0.1935 - val_precision_14: 0.8281 - val_recall_14: 0.6677\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - auc_14: 0.9250 - loss: 0.2049 - precision_14: 0.8036 - recall_14: 0.6230\n",
      "\u001b[32mpredicting using dense model of hidden 64\u001b[0m\n",
      "\u001b[1m5498/5498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 658us/step\n",
      "losses:  [0.22293533384799957, 0.20843593776226044, 0.21237555146217346, 0.19048428535461426, 0.20556487143039703]\n",
      "aucs:  [0.9176623821258545, 0.9270730018615723, 0.9156595468521118, 0.936776876449585, 0.9277210235595703]\n",
      "precisions:  [0.8507326245307922, 0.8592188954353333, 0.8443855047225952, 0.8222043514251709, 0.8258633613586426]\n",
      "recalls:  [0.5455079078674316, 0.5785932540893555, 0.5791388750076294, 0.6285362839698792, 0.6422857046127319]\n",
      "f1s:  [0.649023221525986, 0.697282233284901, 0.7028301886792453, 0.7257307008344352, 0.7410491991098773]\n",
      "roc_aucs:  [0.9193449962586011, 0.9261911754580113, 0.930456354348995, 0.9368556462976225, 0.9362648682817949]\n",
      "Average Loss: 0.20795919597148896\n",
      "Average AUC: 0.9249785661697387\n",
      "Average Precision: 0.8404809474945069\n",
      "Average Recall: 0.5948124051094055\n",
      "Average F1 Score: 0.703183108686889\n",
      "Average ROC AUC Score: 0.929822608129005\n",
      "Epoch 1/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - auc_15: 0.7025 - loss: 0.4240 - precision_15: 0.0000e+00 - recall_15: 0.0000e+00 - val_auc_15: 0.8943 - val_loss: 0.2709 - val_precision_15: 0.0000e+00 - val_recall_15: 0.0000e+00\n",
      "Epoch 2/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.8763 - loss: 0.2880 - precision_15: 0.0055 - recall_15: 2.2393e-05 - val_auc_15: 0.9070 - val_loss: 0.2533 - val_precision_15: 0.8082 - val_recall_15: 0.4333\n",
      "Epoch 3/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.8866 - loss: 0.2707 - precision_15: 0.6816 - recall_15: 0.4628 - val_auc_15: 0.9061 - val_loss: 0.2496 - val_precision_15: 0.8099 - val_recall_15: 0.4679\n",
      "Epoch 4/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_15: 0.8886 - loss: 0.2639 - precision_15: 0.6420 - recall_15: 0.5793 - val_auc_15: 0.9090 - val_loss: 0.2396 - val_precision_15: 0.7624 - val_recall_15: 0.5923\n",
      "Epoch 5/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_15: 0.9004 - loss: 0.2529 - precision_15: 0.7339 - recall_15: 0.5843 - val_auc_15: 0.9111 - val_loss: 0.2371 - val_precision_15: 0.7724 - val_recall_15: 0.5802\n",
      "Epoch 6/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9069 - loss: 0.2426 - precision_15: 0.7668 - recall_15: 0.5725 - val_auc_15: 0.9099 - val_loss: 0.2377 - val_precision_15: 0.7779 - val_recall_15: 0.5356\n",
      "Epoch 7/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9101 - loss: 0.2315 - precision_15: 0.7798 - recall_15: 0.6006 - val_auc_15: 0.9102 - val_loss: 0.2334 - val_precision_15: 0.8044 - val_recall_15: 0.5281\n",
      "Epoch 8/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9098 - loss: 0.2344 - precision_15: 0.7665 - recall_15: 0.5963 - val_auc_15: 0.9118 - val_loss: 0.2433 - val_precision_15: 0.6892 - val_recall_15: 0.6951\n",
      "Epoch 9/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_15: 0.9088 - loss: 0.2347 - precision_15: 0.7698 - recall_15: 0.5886 - val_auc_15: 0.9131 - val_loss: 0.2307 - val_precision_15: 0.7287 - val_recall_15: 0.6615\n",
      "Epoch 10/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9100 - loss: 0.2300 - precision_15: 0.7659 - recall_15: 0.5866 - val_auc_15: 0.9154 - val_loss: 0.2244 - val_precision_15: 0.7763 - val_recall_15: 0.6108\n",
      "Epoch 11/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_15: 0.9131 - loss: 0.2248 - precision_15: 0.7751 - recall_15: 0.6088 - val_auc_15: 0.9094 - val_loss: 0.2330 - val_precision_15: 0.7936 - val_recall_15: 0.5572\n",
      "Epoch 12/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9129 - loss: 0.2251 - precision_15: 0.8029 - recall_15: 0.5551 - val_auc_15: 0.9168 - val_loss: 0.2184 - val_precision_15: 0.7936 - val_recall_15: 0.5998\n",
      "Epoch 13/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9110 - loss: 0.2266 - precision_15: 0.7963 - recall_15: 0.5752 - val_auc_15: 0.9173 - val_loss: 0.2158 - val_precision_15: 0.8387 - val_recall_15: 0.5657\n",
      "Epoch 14/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9161 - loss: 0.2192 - precision_15: 0.8184 - recall_15: 0.5796 - val_auc_15: 0.9179 - val_loss: 0.2182 - val_precision_15: 0.7793 - val_recall_15: 0.6108\n",
      "Epoch 15/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9152 - loss: 0.2195 - precision_15: 0.8117 - recall_15: 0.5986 - val_auc_15: 0.9076 - val_loss: 0.2284 - val_precision_15: 0.8047 - val_recall_15: 0.5271\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - auc_15: 0.9112 - loss: 0.2180 - precision_15: 0.8218 - recall_15: 0.5463\n",
      "\u001b[32mpredicting using dense model of hidden 64\u001b[0m\n",
      "\u001b[1m5498/5498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 678us/step\n",
      "Epoch 1/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_15: 0.9165 - loss: 0.2147 - precision_15: 0.8249 - recall_15: 0.5828 - val_auc_15: 0.9059 - val_loss: 0.2331 - val_precision_15: 0.8778 - val_recall_15: 0.4649\n",
      "Epoch 2/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9156 - loss: 0.2157 - precision_15: 0.8308 - recall_15: 0.5876 - val_auc_15: 0.9209 - val_loss: 0.2156 - val_precision_15: 0.8521 - val_recall_15: 0.5401\n",
      "Epoch 3/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9198 - loss: 0.2120 - precision_15: 0.8325 - recall_15: 0.5894 - val_auc_15: 0.9070 - val_loss: 0.2294 - val_precision_15: 0.8621 - val_recall_15: 0.4609\n",
      "Epoch 4/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_15: 0.9208 - loss: 0.2075 - precision_15: 0.8371 - recall_15: 0.5908 - val_auc_15: 0.9177 - val_loss: 0.2175 - val_precision_15: 0.7873 - val_recall_15: 0.6143\n",
      "Epoch 5/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9138 - loss: 0.2163 - precision_15: 0.8193 - recall_15: 0.5845 - val_auc_15: 0.9178 - val_loss: 0.2175 - val_precision_15: 0.7772 - val_recall_15: 0.6419\n",
      "Epoch 6/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9253 - loss: 0.2058 - precision_15: 0.8419 - recall_15: 0.6005 - val_auc_15: 0.9197 - val_loss: 0.2100 - val_precision_15: 0.8742 - val_recall_15: 0.5401\n",
      "Epoch 7/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9193 - loss: 0.2107 - precision_15: 0.8308 - recall_15: 0.5921 - val_auc_15: 0.9211 - val_loss: 0.2140 - val_precision_15: 0.8139 - val_recall_15: 0.6294\n",
      "Epoch 8/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9180 - loss: 0.2113 - precision_15: 0.8377 - recall_15: 0.5835 - val_auc_15: 0.9227 - val_loss: 0.2066 - val_precision_15: 0.8252 - val_recall_15: 0.6153\n",
      "Epoch 9/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9248 - loss: 0.2034 - precision_15: 0.8317 - recall_15: 0.6089 - val_auc_15: 0.9224 - val_loss: 0.2139 - val_precision_15: 0.7817 - val_recall_15: 0.6269\n",
      "Epoch 10/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9244 - loss: 0.2028 - precision_15: 0.8294 - recall_15: 0.5878 - val_auc_15: 0.9163 - val_loss: 0.2298 - val_precision_15: 0.7054 - val_recall_15: 0.6700\n",
      "Epoch 11/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9204 - loss: 0.2104 - precision_15: 0.8454 - recall_15: 0.5720 - val_auc_15: 0.9193 - val_loss: 0.2117 - val_precision_15: 0.8221 - val_recall_15: 0.6163\n",
      "Epoch 12/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9198 - loss: 0.2061 - precision_15: 0.8414 - recall_15: 0.5976 - val_auc_15: 0.9182 - val_loss: 0.2126 - val_precision_15: 0.8268 - val_recall_15: 0.5888\n",
      "Epoch 13/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9242 - loss: 0.2036 - precision_15: 0.8462 - recall_15: 0.5831 - val_auc_15: 0.9230 - val_loss: 0.2068 - val_precision_15: 0.8358 - val_recall_15: 0.5948\n",
      "Epoch 14/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9281 - loss: 0.1994 - precision_15: 0.8327 - recall_15: 0.6063 - val_auc_15: 0.9187 - val_loss: 0.2103 - val_precision_15: 0.8798 - val_recall_15: 0.5321\n",
      "Epoch 15/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9213 - loss: 0.2095 - precision_15: 0.8271 - recall_15: 0.5939 - val_auc_15: 0.9247 - val_loss: 0.2093 - val_precision_15: 0.7835 - val_recall_15: 0.6369\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - auc_15: 0.9215 - loss: 0.2165 - precision_15: 0.7816 - recall_15: 0.6398\n",
      "\u001b[32mpredicting using dense model of hidden 64\u001b[0m\n",
      "\u001b[1m5498/5498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 657us/step\n",
      "Epoch 1/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_15: 0.9220 - loss: 0.2037 - precision_15: 0.8396 - recall_15: 0.6004 - val_auc_15: 0.9252 - val_loss: 0.2063 - val_precision_15: 0.8911 - val_recall_15: 0.5537\n",
      "Epoch 2/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9238 - loss: 0.2036 - precision_15: 0.8434 - recall_15: 0.5892 - val_auc_15: 0.9254 - val_loss: 0.2083 - val_precision_15: 0.8806 - val_recall_15: 0.5316\n",
      "Epoch 3/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9224 - loss: 0.1984 - precision_15: 0.8327 - recall_15: 0.6127 - val_auc_15: 0.9254 - val_loss: 0.2098 - val_precision_15: 0.8140 - val_recall_15: 0.6351\n",
      "Epoch 4/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9175 - loss: 0.2115 - precision_15: 0.8431 - recall_15: 0.5828 - val_auc_15: 0.9259 - val_loss: 0.2047 - val_precision_15: 0.8642 - val_recall_15: 0.5772\n",
      "Epoch 5/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9217 - loss: 0.2073 - precision_15: 0.8427 - recall_15: 0.5961 - val_auc_15: 0.9202 - val_loss: 0.2253 - val_precision_15: 0.9164 - val_recall_15: 0.4625\n",
      "Epoch 6/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9206 - loss: 0.2069 - precision_15: 0.8543 - recall_15: 0.5694 - val_auc_15: 0.9274 - val_loss: 0.2033 - val_precision_15: 0.8375 - val_recall_15: 0.6116\n",
      "Epoch 7/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9233 - loss: 0.2027 - precision_15: 0.8510 - recall_15: 0.6019 - val_auc_15: 0.9244 - val_loss: 0.2112 - val_precision_15: 0.8685 - val_recall_15: 0.5311\n",
      "Epoch 8/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_15: 0.9175 - loss: 0.2096 - precision_15: 0.8494 - recall_15: 0.5724 - val_auc_15: 0.9247 - val_loss: 0.2098 - val_precision_15: 0.8333 - val_recall_15: 0.6008\n",
      "Epoch 9/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9265 - loss: 0.2013 - precision_15: 0.8703 - recall_15: 0.5960 - val_auc_15: 0.9268 - val_loss: 0.2023 - val_precision_15: 0.8756 - val_recall_15: 0.5836\n",
      "Epoch 10/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9258 - loss: 0.2006 - precision_15: 0.8504 - recall_15: 0.5817 - val_auc_15: 0.9272 - val_loss: 0.2019 - val_precision_15: 0.8737 - val_recall_15: 0.5871\n",
      "Epoch 11/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9261 - loss: 0.1959 - precision_15: 0.8468 - recall_15: 0.6041 - val_auc_15: 0.9288 - val_loss: 0.1993 - val_precision_15: 0.8584 - val_recall_15: 0.6037\n",
      "Epoch 12/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9272 - loss: 0.1979 - precision_15: 0.8546 - recall_15: 0.5980 - val_auc_15: 0.9272 - val_loss: 0.2093 - val_precision_15: 0.8677 - val_recall_15: 0.5694\n",
      "Epoch 13/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_15: 0.9264 - loss: 0.1992 - precision_15: 0.8581 - recall_15: 0.6013 - val_auc_15: 0.9286 - val_loss: 0.2024 - val_precision_15: 0.8230 - val_recall_15: 0.6341\n",
      "Epoch 14/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9220 - loss: 0.2010 - precision_15: 0.8554 - recall_15: 0.5957 - val_auc_15: 0.9236 - val_loss: 0.2178 - val_precision_15: 0.7519 - val_recall_15: 0.6660\n",
      "Epoch 15/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_15: 0.9268 - loss: 0.1981 - precision_15: 0.8468 - recall_15: 0.5994 - val_auc_15: 0.9306 - val_loss: 0.1977 - val_precision_15: 0.8728 - val_recall_15: 0.5954\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - auc_15: 0.9371 - loss: 0.1875 - precision_15: 0.8693 - recall_15: 0.6248\n",
      "\u001b[32mpredicting using dense model of hidden 64\u001b[0m\n",
      "\u001b[1m5498/5498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 658us/step\n",
      "Epoch 1/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9317 - loss: 0.1916 - precision_15: 0.8555 - recall_15: 0.6334 - val_auc_15: 0.9258 - val_loss: 0.2056 - val_precision_15: 0.8629 - val_recall_15: 0.5797\n",
      "Epoch 2/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_15: 0.9272 - loss: 0.1975 - precision_15: 0.8435 - recall_15: 0.6066 - val_auc_15: 0.9277 - val_loss: 0.2002 - val_precision_15: 0.8536 - val_recall_15: 0.6125\n",
      "Epoch 3/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_15: 0.9290 - loss: 0.1900 - precision_15: 0.8415 - recall_15: 0.6083 - val_auc_15: 0.9241 - val_loss: 0.2129 - val_precision_15: 0.9025 - val_recall_15: 0.5120\n",
      "Epoch 4/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_15: 0.9285 - loss: 0.1932 - precision_15: 0.8697 - recall_15: 0.6088 - val_auc_15: 0.9299 - val_loss: 0.1958 - val_precision_15: 0.8499 - val_recall_15: 0.6315\n",
      "Epoch 5/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_15: 0.9295 - loss: 0.1905 - precision_15: 0.8426 - recall_15: 0.6206 - val_auc_15: 0.9272 - val_loss: 0.1990 - val_precision_15: 0.8232 - val_recall_15: 0.6444\n",
      "Epoch 6/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9301 - loss: 0.1896 - precision_15: 0.8447 - recall_15: 0.6206 - val_auc_15: 0.9264 - val_loss: 0.2055 - val_precision_15: 0.8940 - val_recall_15: 0.5334\n",
      "Epoch 7/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_15: 0.9327 - loss: 0.1885 - precision_15: 0.8624 - recall_15: 0.6148 - val_auc_15: 0.9289 - val_loss: 0.2015 - val_precision_15: 0.8765 - val_recall_15: 0.5692\n",
      "Epoch 8/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9320 - loss: 0.1897 - precision_15: 0.8524 - recall_15: 0.6207 - val_auc_15: 0.9297 - val_loss: 0.1977 - val_precision_15: 0.8659 - val_recall_15: 0.5981\n",
      "Epoch 9/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9294 - loss: 0.1888 - precision_15: 0.8557 - recall_15: 0.6128 - val_auc_15: 0.9242 - val_loss: 0.2066 - val_precision_15: 0.8890 - val_recall_15: 0.5543\n",
      "Epoch 10/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9289 - loss: 0.1923 - precision_15: 0.8584 - recall_15: 0.6051 - val_auc_15: 0.9268 - val_loss: 0.2098 - val_precision_15: 0.7455 - val_recall_15: 0.6987\n",
      "Epoch 11/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9330 - loss: 0.1914 - precision_15: 0.8506 - recall_15: 0.6188 - val_auc_15: 0.9287 - val_loss: 0.2020 - val_precision_15: 0.8700 - val_recall_15: 0.5498\n",
      "Epoch 12/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9344 - loss: 0.1836 - precision_15: 0.8692 - recall_15: 0.6168 - val_auc_15: 0.9290 - val_loss: 0.2004 - val_precision_15: 0.8238 - val_recall_15: 0.6474\n",
      "Epoch 13/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9328 - loss: 0.1860 - precision_15: 0.8554 - recall_15: 0.6276 - val_auc_15: 0.9281 - val_loss: 0.2012 - val_precision_15: 0.8841 - val_recall_15: 0.5583\n",
      "Epoch 14/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9338 - loss: 0.1857 - precision_15: 0.8724 - recall_15: 0.6183 - val_auc_15: 0.9294 - val_loss: 0.1957 - val_precision_15: 0.8544 - val_recall_15: 0.6255\n",
      "Epoch 15/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_15: 0.9355 - loss: 0.1839 - precision_15: 0.8452 - recall_15: 0.6285 - val_auc_15: 0.9277 - val_loss: 0.2051 - val_precision_15: 0.7900 - val_recall_15: 0.6688\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - auc_15: 0.9203 - loss: 0.2186 - precision_15: 0.7865 - recall_15: 0.6421\n",
      "\u001b[32mpredicting using dense model of hidden 64\u001b[0m\n",
      "\u001b[1m5498/5498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 660us/step\n",
      "Epoch 1/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_15: 0.9311 - loss: 0.1982 - precision_15: 0.8374 - recall_15: 0.6281 - val_auc_15: 0.9271 - val_loss: 0.2128 - val_precision_15: 0.7811 - val_recall_15: 0.6542\n",
      "Epoch 2/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9310 - loss: 0.1958 - precision_15: 0.8517 - recall_15: 0.6207 - val_auc_15: 0.9278 - val_loss: 0.2024 - val_precision_15: 0.7990 - val_recall_15: 0.6517\n",
      "Epoch 3/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9271 - loss: 0.1975 - precision_15: 0.8453 - recall_15: 0.6235 - val_auc_15: 0.9300 - val_loss: 0.2011 - val_precision_15: 0.8372 - val_recall_15: 0.6124\n",
      "Epoch 4/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_15: 0.9330 - loss: 0.1930 - precision_15: 0.8529 - recall_15: 0.6244 - val_auc_15: 0.9269 - val_loss: 0.2045 - val_precision_15: 0.8850 - val_recall_15: 0.5366\n",
      "Epoch 5/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9366 - loss: 0.1863 - precision_15: 0.8765 - recall_15: 0.6298 - val_auc_15: 0.9213 - val_loss: 0.2157 - val_precision_15: 0.7978 - val_recall_15: 0.5879\n",
      "Epoch 6/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_15: 0.9294 - loss: 0.1957 - precision_15: 0.8549 - recall_15: 0.6012 - val_auc_15: 0.9255 - val_loss: 0.2096 - val_precision_15: 0.7848 - val_recall_15: 0.6413\n",
      "Epoch 7/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9356 - loss: 0.1873 - precision_15: 0.8787 - recall_15: 0.6259 - val_auc_15: 0.9283 - val_loss: 0.2030 - val_precision_15: 0.8182 - val_recall_15: 0.6124\n",
      "Epoch 8/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9311 - loss: 0.1941 - precision_15: 0.8583 - recall_15: 0.6059 - val_auc_15: 0.9307 - val_loss: 0.1996 - val_precision_15: 0.8273 - val_recall_15: 0.6109\n",
      "Epoch 9/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_15: 0.9350 - loss: 0.1890 - precision_15: 0.8614 - recall_15: 0.6382 - val_auc_15: 0.9297 - val_loss: 0.2030 - val_precision_15: 0.8454 - val_recall_15: 0.6158\n",
      "Epoch 10/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9347 - loss: 0.1950 - precision_15: 0.8532 - recall_15: 0.6238 - val_auc_15: 0.9294 - val_loss: 0.2030 - val_precision_15: 0.8815 - val_recall_15: 0.5595\n",
      "Epoch 11/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9359 - loss: 0.1834 - precision_15: 0.8595 - recall_15: 0.6434 - val_auc_15: 0.9294 - val_loss: 0.2013 - val_precision_15: 0.8504 - val_recall_15: 0.6004\n",
      "Epoch 12/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9305 - loss: 0.1955 - precision_15: 0.8641 - recall_15: 0.6123 - val_auc_15: 0.9299 - val_loss: 0.2022 - val_precision_15: 0.8235 - val_recall_15: 0.6462\n",
      "Epoch 13/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9356 - loss: 0.1872 - precision_15: 0.8583 - recall_15: 0.6363 - val_auc_15: 0.9311 - val_loss: 0.1959 - val_precision_15: 0.8370 - val_recall_15: 0.6398\n",
      "Epoch 14/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9367 - loss: 0.1845 - precision_15: 0.8557 - recall_15: 0.6446 - val_auc_15: 0.9331 - val_loss: 0.1941 - val_precision_15: 0.8545 - val_recall_15: 0.6203\n",
      "Epoch 15/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_15: 0.9360 - loss: 0.1864 - precision_15: 0.8598 - recall_15: 0.6388 - val_auc_15: 0.9307 - val_loss: 0.2020 - val_precision_15: 0.8466 - val_recall_15: 0.6079\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - auc_15: 0.9273 - loss: 0.1978 - precision_15: 0.8392 - recall_15: 0.6044\n",
      "\u001b[32mpredicting using dense model of hidden 64\u001b[0m\n",
      "\u001b[1m5498/5498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 668us/step\n",
      "losses:  [0.22402271628379822, 0.21181288361549377, 0.19006045162677765, 0.21296857297420502, 0.19762200117111206]\n",
      "aucs:  [0.9133710861206055, 0.9238768219947815, 0.932701587677002, 0.9229534268379211, 0.9301908016204834]\n",
      "precisions:  [0.8140610456466675, 0.79175865650177, 0.8690783977508545, 0.7940566539764404, 0.8476027250289917]\n",
      "recalls:  [0.5256869792938232, 0.6427717804908752, 0.606370210647583, 0.6603448390960693, 0.6145251393318176]\n",
      "f1s:  [0.6443997382262404, 0.7115910092551785, 0.712339762506197, 0.7331899333189933, 0.7207094852075105]\n",
      "roc_aucs:  [0.9088444902950172, 0.9269466909042372, 0.9320485494861752, 0.9307241415369878, 0.9339417167256103]\n",
      "Average Loss: 0.20729732513427734\n",
      "Average AUC: 0.9246187448501587\n",
      "Average Precision: 0.8233114957809449\n",
      "Average Recall: 0.6099397897720337\n",
      "Average F1 Score: 0.7044459857028239\n",
      "Average ROC AUC Score: 0.9265011177896056\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from colorama import init\n",
    "from termcolor import colored\n",
    "\n",
    "# Define the L2 regularizers\n",
    "k = .0001\n",
    "kernel_regularizer = l2(0.0001*k)\n",
    "bias_regularizer = l2(0.00001*k)\n",
    "\n",
    "# Define the Dense model with different regularization strengths for kernel and bias\n",
    "class DenseModel:\n",
    "    def __init__(self, input_dim, hidden_dim=64):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.model = self.build_model()\n",
    "        self.THRESHOLD = 0.5\n",
    "\n",
    "    def build_model(self):\n",
    "        input_layer = Input(shape=(self.input_dim,))\n",
    "        x = Dense(self.hidden_dim, activation='relu')(input_layer)\n",
    "        x = Dense(self.hidden_dim // 2, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(x)\n",
    "        x = Dense(self.hidden_dim // 4, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(x)\n",
    "        x = Dense(self.hidden_dim // 8, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(x)\n",
    "        x = Dense(self.hidden_dim // 16, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(x)\n",
    "        x = Dense(self.hidden_dim // 32, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(x)\n",
    "        output_layer = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "        model = Model(input_layer, output_layer)\n",
    "\n",
    "        # Compile the model with Binary Crossentropy loss\n",
    "        model.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(), metrics=[AUC(), Precision(), Recall()])\n",
    "        return model\n",
    "\n",
    "    def fit(self, X_train, y_train, epochs=10, verbose=0, batch_size=32, validation_split=0.3, validation_data=None):\n",
    "        if validation_data is not None:\n",
    "            self.model.fit(X_train, y_train, epochs=epochs, verbose=verbose, batch_size=batch_size, validation_data=validation_data, validation_split=validation_split)\n",
    "            return \n",
    "        self.model.fit(X_train, y_train, epochs=epochs, verbose=verbose, batch_size=batch_size, validation_split=validation_split)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        print(colored(f'predicting using dense model of hidden {self.hidden_dim}', 'green'))\n",
    "        return self.model.predict(X_test)\n",
    "    \n",
    "    def f1max(self, *args, **kwargs):\n",
    "        print(self.summary())\n",
    "        if args:\n",
    "            print(f\"iter: {args[0]}, epochs: {args[1]}, splits: {args[2]}\")\n",
    "        print(kwargs)\n",
    "        \n",
    "    def summary(self):\n",
    "        self.model.summary()\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        return self.model.evaluate(X_test, y_test)\n",
    "\n",
    "    def save(self, path):\n",
    "        self.model.save(path)\n",
    "\n",
    "# Example usage\n",
    "# Assuming xult and yult are your feature matrix and target vector\n",
    "for i in range(2):\n",
    "    dense_model = DenseModel(input_dim=xult.shape[1])\n",
    "    ktrain(dense_model, xult, yult,epochs=15,batch_size=32,splits=5,random_state=i)\n",
    "    ens.add_model(dense_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "[[9951  138]\n",
      " [ 482 1158]]\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "[[9996  102]\n",
      " [ 499 1132]]\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "[[9952   82]\n",
      " [ 548 1147]]\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "[[9939   74]\n",
      " [ 516 1200]]\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "[[9980   68]\n",
      " [ 490 1191]]\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [0.9210959352011003, 0.9419434180226909, 0.9479755556770696, 0.9541671002521898, 0.9570931332104411]\n",
      "precisions:  [0.8935185185185185, 0.9173419773095624, 0.9332790886899919, 0.9419152276295133, 0.9459888800635425]\n",
      "recalls:  [0.7060975609756097, 0.6940527283874923, 0.6766961651917404, 0.6993006993006993, 0.7085068411659726]\n",
      "f1s:  [0.7721241903060085, 0.7874436159440302, 0.7909885057471264, 0.8008517263485667, 0.8027189160831185]\n",
      "roc_aucs:  [0.8369176469607759, 0.8371890119750558, 0.8392642411766587, 0.8453140661712663, 0.847257595357054]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 0.9444550284726982\n",
      "Average Precision: 0.9264087384422257\n",
      "Average Recall: 0.6969307990043029\n",
      "Average F1 Score: 0.7908253908857701\n",
      "Average ROC AUC Score: 0.8411885123281622\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "[[9951  138]\n",
      " [ 482 1158]]\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "[[9996  102]\n",
      " [ 499 1132]]\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "[[9952   82]\n",
      " [ 548 1147]]\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "[[9939   74]\n",
      " [ 516 1200]]\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "[[9980   68]\n",
      " [ 490 1191]]\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [0.9210959352011003, 0.9419434180226909, 0.9479755556770696, 0.9541671002521898, 0.9570931332104411]\n",
      "precisions:  [0.8935185185185185, 0.9173419773095624, 0.9332790886899919, 0.9419152276295133, 0.9459888800635425]\n",
      "recalls:  [0.7060975609756097, 0.6940527283874923, 0.6766961651917404, 0.6993006993006993, 0.7085068411659726]\n",
      "f1s:  [0.7721241903060085, 0.7874436159440302, 0.7909885057471264, 0.8008517263485667, 0.8027189160831185]\n",
      "roc_aucs:  [0.8369176469607759, 0.8371890119750558, 0.8392642411766587, 0.8453140661712663, 0.847257595357054]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 0.9444550284726982\n",
      "Average Precision: 0.9264087384422257\n",
      "Average Recall: 0.6969307990043029\n",
      "Average F1 Score: 0.7908253908857701\n",
      "Average ROC AUC Score: 0.8411885123281622\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, precision_score, recall_score\n",
    "\n",
    "class XGBRFClassifierModel:\n",
    "    def __init__(self, objective='binary:logistic', eval_metric='auc', n_estimators=600, max_depth=5, subsample=0.9,\n",
    "                 colsample_bynode=0.9, reg_alpha=0.1, reg_lambda=1.0, min_child_weight=1, random_state=42, model_path='xgbrf_model.json', **kwargs):\n",
    "        self.model = xgb.XGBRFClassifier(objective=objective, eval_metric=eval_metric, n_estimators=n_estimators,\n",
    "                                         max_depth=max_depth, subsample=subsample, colsample_bynode=colsample_bynode, reg_alpha=reg_alpha,\n",
    "                                         reg_lambda=reg_lambda, min_child_weight=min_child_weight, random_state=random_state, **kwargs)\n",
    "        self.model_path = model_path\n",
    "        self.THRESHOLD = 0.5\n",
    "        self.load_model()\n",
    "\n",
    "    def fit(self, X_train, y_train, verbose=0, **kwargs):\n",
    "        self.model.fit(X_train, y_train, verbose=verbose, xgb_model=self.model_path if self.model_exists() else None)\n",
    "        self.save_model()\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        print(colored('predicting using xgbrf model', 'green'))\n",
    "        return self.model.predict(X_test).reshape(-1, 1)\n",
    "\n",
    "    def predict_proba(self, X_test):\n",
    "        return self.model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        y_pred = self.predict(X_test)\n",
    "        y_pred_proba = self.predict_proba(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        print(cm)\n",
    "        # Assuming loss is not directly available, using log loss as a proxy\n",
    "        loss = -1  # Placeholder, as XGBoost does not directly provide loss in this context\n",
    "        return [loss, auc, precision, recall]\n",
    "\n",
    "    def summary(self):\n",
    "        print(self.model)\n",
    "\n",
    "    def save_model(self):\n",
    "        self.model.save_model(self.model_path)\n",
    "\n",
    "    def load_model(self):\n",
    "        if self.model_exists():\n",
    "            self.model.load_model(self.model_path)\n",
    "            \n",
    "    def f1max(self, *args, **kwargs):\n",
    "        print(self.summary())\n",
    "        if args:\n",
    "            print(f\"iter: {args[0]}, epochs: {args[1]}, splits: {args[2]}\")\n",
    "        print(kwargs)\n",
    "\n",
    "    def model_exists(self):\n",
    "        try:\n",
    "            with open(self.model_path, 'r'):\n",
    "                return True\n",
    "        except FileNotFoundError:\n",
    "            return False\n",
    "    def save(self, path):\n",
    "        self.model.save_model(path)\n",
    "\n",
    "for i in range(2):\n",
    "    if i%2==0:\n",
    "        xgbrf_model = XGBRFClassifierModel(model_path=f'xgbrf_model{i}.json')\n",
    "    else:\n",
    "        xgbrf_model = XGBRFClassifierModel(eval_metric='logloss', model_path=f'xgbrf_model{i}.json')\n",
    "    ktrain(xgbrf_model, xult, yult, epochs=10, batch_size=32, splits=5, random_state=5)\n",
    "    ens.add_model(xgbrf_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6660, number of negative: 40256\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002964 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7988\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.141956 -> initscore=-1.799140\n",
      "[LightGBM] [Info] Start training from score -1.799140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "[[9930   96]\n",
      " [ 475 1228]]\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6728, number of negative: 40188\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002941 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7988\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.143405 -> initscore=-1.787291\n",
      "[LightGBM] [Info] Start training from score -1.787291\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "[[10014    80]\n",
      " [  433  1202]]\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6714, number of negative: 40202\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002981 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7988\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.143107 -> initscore=-1.789722\n",
      "[LightGBM] [Info] Start training from score -1.789722\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "[[9998   82]\n",
      " [ 480 1169]]\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6737, number of negative: 40179\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003008 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7988\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.143597 -> initscore=-1.785730\n",
      "[LightGBM] [Info] Start training from score -1.785730\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "[[10009    94]\n",
      " [  455  1171]]\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6613, number of negative: 40303\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002955 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7986\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.140954 -> initscore=-1.807388\n",
      "[LightGBM] [Info] Start training from score -1.807388\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "[[9896   83]\n",
      " [ 522 1228]]\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [0.9609951589168221, 0.9639713300480075, 0.957503314899843, 0.9619178306006557, 0.9566103674860064]\n",
      "precisions:  [0.9274924471299094, 0.9375975039001561, 0.9344524380495604, 0.9256916996047431, 0.9366895499618612]\n",
      "recalls:  [0.721080446271286, 0.7351681957186544, 0.7089144936325046, 0.7201722017220172, 0.7017142857142857]\n",
      "f1s:  [0.8248959312474822, 0.8254209620072005, 0.8254734912010018, 0.8240533524304001, 0.8249082938176613]\n",
      "roc_aucs:  [0.8638578316078848, 0.8643636159433792, 0.8644035361030599, 0.8634322745303706, 0.864027685755837]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 0.960199600390267\n",
      "Average Precision: 0.932384727729246\n",
      "Average Recall: 0.7174099246117496\n",
      "Average F1 Score: 0.8249504061407492\n",
      "Average ROC AUC Score: 0.8640169887881063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6689, number of negative: 40227\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002938 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7988\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142574 -> initscore=-1.794074\n",
      "[LightGBM] [Info] Start training from score -1.794074\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "[[9969   86]\n",
      " [ 459 1215]]\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6689, number of negative: 40227\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002984 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7988\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142574 -> initscore=-1.794074\n",
      "[LightGBM] [Info] Start training from score -1.794074\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "[[9968   87]\n",
      " [ 489 1185]]\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6699, number of negative: 40217\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002945 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7986\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142787 -> initscore=-1.792332\n",
      "[LightGBM] [Info] Start training from score -1.792332\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "[[9957  108]\n",
      " [ 467 1197]]\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6623, number of negative: 40293\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008595 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7988\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.141167 -> initscore=-1.805629\n",
      "[LightGBM] [Info] Start training from score -1.805629\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "[[9900   89]\n",
      " [ 499 1241]]\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6752, number of negative: 40164\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002891 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7988\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.143917 -> initscore=-1.783132\n",
      "[LightGBM] [Info] Start training from score -1.783132\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "[[10049    69]\n",
      " [  453  1158]]\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [0.9616655586627195, 0.961420193713548, 0.960195090087508, 0.9576006020415561, 0.9590938962452864]\n",
      "precisions:  [0.9338970023059185, 0.9316037735849056, 0.9172413793103448, 0.9330827067669173, 0.9437652811735942]\n",
      "recalls:  [0.7258064516129032, 0.7078853046594982, 0.7193509615384616, 0.7132183908045977, 0.7188081936685289]\n",
      "f1s:  [0.8251275624384568, 0.8254778210465065, 0.8237316898892462, 0.8255105696882837, 0.8250850187936281]\n",
      "roc_aucs:  [0.8639908472150043, 0.8641603918120614, 0.8638922076316599, 0.8640138115259689, 0.8640441772782103]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 0.9599950681501236\n",
      "Average Precision: 0.9319180286283361\n",
      "Average Recall: 0.7170138604567978\n",
      "Average F1 Score: 0.8249865323712242\n",
      "Average ROC AUC Score: 0.864020287092581\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, precision_score, recall_score\n",
    "\n",
    "class LGBMClassifierModel:\n",
    "    def __init__(self, eval_metric='logloss', model_path='lgbm_model.txt', **kwargs):\n",
    "        self.model = lgb.LGBMClassifier(objective='binary', metric=eval_metric, )\n",
    "        self.model_path = model_path\n",
    "        self.THRESHOLD = 0.5\n",
    "        self.init_model = None\n",
    "        self.load_model()\n",
    "\n",
    "    def fit(self, X_train, y_train, verbose=0, **kwargs):\n",
    "        self.model.fit(X_train, y_train,   init_model=self.init_model)\n",
    "        self.save_model()\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        ret = self.model.predict(X_test).astype(float)\n",
    "        # All ret values multiplied by 1.1\n",
    "        # ret *= 1.1\n",
    "        print(colored('predicting using lgbm model', 'green'))\n",
    "        return ret.reshape(-1, 1)\n",
    "\n",
    "    def predict_proba(self, X_test):\n",
    "        return self.model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        y_pred = self.predict(X_test)\n",
    "        y_pred_proba = self.predict_proba(X_test)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        print(cm)\n",
    "        # Assuming loss is not directly available, using log loss as a proxy\n",
    "        loss = -1  # Placeholder, as LightGBM does not directly provide loss in this context\n",
    "        return [loss, auc, precision, recall]\n",
    "\n",
    "    def summary(self):\n",
    "        print(self.model)\n",
    "\n",
    "    def save_model(self):\n",
    "        self.model.booster_.save_model(self.model_path)\n",
    "\n",
    "    def load_model(self):\n",
    "        if self.model_exists():\n",
    "            self.init_model = self.model_path\n",
    "\n",
    "    def f1max(self, *args, **kwargs):\n",
    "        print(self.summary())\n",
    "        if args:\n",
    "            print(f\"iter: {args[0]}, epochs: {args[1]}, splits: {args[2]}\")\n",
    "        print(kwargs)\n",
    "\n",
    "    def model_exists(self):\n",
    "        try:\n",
    "            with open(self.model_path, 'r'):\n",
    "                return True\n",
    "        except FileNotFoundError:\n",
    "            return False\n",
    "\n",
    "    def save(self, path):\n",
    "        self.model.booster_.save_model(path)\n",
    "\n",
    "# Example usage\n",
    "# Assuming xult and yult are your feature matrix and target vector\n",
    "# Split the data into training and test sets\n",
    "\n",
    "for i in range(2):\n",
    "    # Initialize the LightGBM classifier model\n",
    "    if i % 2 == 0:\n",
    "        lgbm_model = LGBMClassifierModel(model_path=f'lgbm_model{i}.txt')\n",
    "    else:\n",
    "        lgbm_model = LGBMClassifierModel(eval_metric='auc', model_path=f'lgbm_model{i}.txt')\n",
    "    # Fit the model on training data\n",
    "    ktrain(lgbm_model, xult, yult, epochs=10, batch_size=32, splits=5, random_state=i)\n",
    "    ens.add_model(lgbm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6660, number of negative: 40256\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7988\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.141956 -> initscore=-1.799140\n",
      "[LightGBM] [Info] Start training from score -1.799140\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9875  151]\n",
      " [ 484 1219]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6728, number of negative: 40188\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007948 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7988\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.143405 -> initscore=-1.787291\n",
      "[LightGBM] [Info] Start training from score -1.787291\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9977  117]\n",
      " [ 465 1170]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6714, number of negative: 40202\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007999 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7988\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.143107 -> initscore=-1.789722\n",
      "[LightGBM] [Info] Start training from score -1.789722\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9973  107]\n",
      " [ 495 1154]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6737, number of negative: 40179\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008070 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7988\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.143597 -> initscore=-1.785730\n",
      "[LightGBM] [Info] Start training from score -1.785730\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9962  141]\n",
      " [ 455 1171]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6613, number of negative: 40303\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007918 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7986\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.140954 -> initscore=-1.807388\n",
      "[LightGBM] [Info] Start training from score -1.807388\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9855  124]\n",
      " [ 549 1201]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [0.9238306884777207, 0.9252098470099718, 0.917881598515695, 0.926131174852281, 0.9169020085035717]\n",
      "precisions:  [0.8897810218978102, 0.9090909090909091, 0.9151467089611419, 0.8925304878048781, 0.9064150943396226]\n",
      "recalls:  [0.7157956547269524, 0.7155963302752294, 0.6998180715585203, 0.7201722017220172, 0.6862857142857143]\n",
      "f1s:  [0.795512108420351, 0.7939736683282295, 0.795290747123864, 0.7948872921003738, 0.7950016735468035]\n",
      "roc_aucs:  [0.8505288597672931, 0.848105360012652, 0.848440516322956, 0.8482010727525959, 0.8491036735555632]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 0.9219910634718479\n",
      "Average Precision: 0.9025928444188723\n",
      "Average Recall: 0.7075335945136867\n",
      "Average F1 Score: 0.7949330979039244\n",
      "Average ROC AUC Score: 0.848875896482212\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6689, number of negative: 40227\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011018 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7988\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142574 -> initscore=-1.794074\n",
      "[LightGBM] [Info] Start training from score -1.794074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9922  133]\n",
      " [ 479 1195]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6689, number of negative: 40227\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009840 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7988\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142574 -> initscore=-1.794074\n",
      "[LightGBM] [Info] Start training from score -1.794074\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9926  129]\n",
      " [ 504 1170]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6699, number of negative: 40217\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7986\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142787 -> initscore=-1.792332\n",
      "[LightGBM] [Info] Start training from score -1.792332\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9929  136]\n",
      " [ 483 1181]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6623, number of negative: 40293\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007798 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7988\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.141167 -> initscore=-1.805629\n",
      "[LightGBM] [Info] Start training from score -1.805629\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9877  112]\n",
      " [ 531 1209]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6752, number of negative: 40164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007873 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7988\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.143917 -> initscore=-1.783132\n",
      "[LightGBM] [Info] Start training from score -1.783132\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[10014   104]\n",
      " [  474  1137]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [0.9218370348982627, 0.9281688467312695, 0.9250135238736673, 0.9204447881175041, 0.9190672350558874]\n",
      "precisions:  [0.8998493975903614, 0.9006928406466512, 0.8967350037965072, 0.915215745647237, 0.9161966156325544]\n",
      "recalls:  [0.7138590203106332, 0.6989247311827957, 0.7097355769230769, 0.6948275862068966, 0.7057728119180633]\n",
      "f1s:  [0.793642289490133, 0.7949674853069343, 0.7951189914380098, 0.794508275661269, 0.7956048884404081]\n",
      "roc_aucs:  [0.848282228663262, 0.8486939888986318, 0.8472881436649518, 0.8478616740075867, 0.8481104398222146]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 0.9229062857353183\n",
      "Average Precision: 0.9057379206626622\n",
      "Average Recall: 0.7046239453082931\n",
      "Average F1 Score: 0.7947683860673509\n",
      "Average ROC AUC Score: 0.8480472950113294\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6659, number of negative: 40257\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007841 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7988\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.141935 -> initscore=-1.799315\n",
      "[LightGBM] [Info] Start training from score -1.799315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9896  129]\n",
      " [ 507 1197]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6699, number of negative: 40217\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007994 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7988\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142787 -> initscore=-1.792332\n",
      "[LightGBM] [Info] Start training from score -1.792332\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9937  128]\n",
      " [ 485 1179]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6664, number of negative: 40252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008091 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7988\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142041 -> initscore=-1.798440\n",
      "[LightGBM] [Info] Start training from score -1.798440\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9907  123]\n",
      " [ 508 1191]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6701, number of negative: 40215\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007941 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7988\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142830 -> initscore=-1.791983\n",
      "[LightGBM] [Info] Start training from score -1.791983\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9920  147]\n",
      " [ 479 1183]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6729, number of negative: 40187\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008451 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7987\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.143427 -> initscore=-1.787117\n",
      "[LightGBM] [Info] Start training from score -1.787117\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9999   96]\n",
      " [ 483 1151]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [0.9197144462786694, 0.9208976687588368, 0.9243220603052527, 0.9252978569457081, 0.9241069387938209]\n",
      "precisions:  [0.9027149321266968, 0.9020657995409335, 0.906392694063927, 0.8894736842105263, 0.9230152365677626]\n",
      "recalls:  [0.7024647887323944, 0.7085336538461539, 0.7010005885815186, 0.7117930204572804, 0.704406364749082]\n",
      "f1s:  [0.7953477969134422, 0.7958927450452874, 0.795018255941581, 0.7948272017837236, 0.793715358483819]\n",
      "roc_aucs:  [0.8486603093643711, 0.8483133544026372, 0.848091021456441, 0.8492204298034808, 0.8480123419529367]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 0.9228677942164577\n",
      "Average Precision: 0.9047324693019693\n",
      "Average Recall: 0.7056396832732859\n",
      "Average F1 Score: 0.7949602716335706\n",
      "Average ROC AUC Score: 0.8484594913959734\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6689, number of negative: 40227\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008010 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7988\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142574 -> initscore=-1.794074\n",
      "[LightGBM] [Info] Start training from score -1.794074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9945  110]\n",
      " [ 507 1167]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6697, number of negative: 40219\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7987\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142744 -> initscore=-1.792680\n",
      "[LightGBM] [Info] Start training from score -1.792680\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9936  127]\n",
      " [ 459 1207]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6664, number of negative: 40252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008088 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7988\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142041 -> initscore=-1.798440\n",
      "[LightGBM] [Info] Start training from score -1.798440\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9905  125]\n",
      " [ 496 1203]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6688, number of negative: 40228\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008008 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7987\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142553 -> initscore=-1.794248\n",
      "[LightGBM] [Info] Start training from score -1.794248\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9920  134]\n",
      " [ 497 1178]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6714, number of negative: 40202\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008004 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7987\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.143107 -> initscore=-1.789722\n",
      "[LightGBM] [Info] Start training from score -1.789722\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9957  123]\n",
      " [ 508 1141]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [0.9169240919268989, 0.9306412220060439, 0.9275016621706393, 0.9173629861434818, 0.917392034133241]\n",
      "precisions:  [0.9138606108065779, 0.9047976011994003, 0.9058734939759037, 0.8978658536585366, 0.9026898734177216]\n",
      "recalls:  [0.6971326164874552, 0.7244897959183674, 0.7080635668040024, 0.7032835820895522, 0.6919345057610673]\n",
      "f1s:  [0.7962593348433541, 0.7960748373829268, 0.7938869717205217, 0.793196701159958, 0.7937540663630449]\n",
      "roc_aucs:  [0.8484262551544689, 0.8491992315200596, 0.8474025921712595, 0.8477363693926393, 0.8470196499336549]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 0.9219643992760609\n",
      "Average Precision: 0.905017486611628\n",
      "Average Recall: 0.704980813412089\n",
      "Average F1 Score: 0.7946343822939612\n",
      "Average ROC AUC Score: 0.8479568196344165\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6688, number of negative: 40228\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009087 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7988\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142553 -> initscore=-1.794248\n",
      "[LightGBM] [Info] Start training from score -1.794248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9933  121]\n",
      " [ 506 1169]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6712, number of negative: 40204\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007981 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7987\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.143064 -> initscore=-1.790070\n",
      "[LightGBM] [Info] Start training from score -1.790070\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9975  103]\n",
      " [ 473 1178]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6704, number of negative: 40212\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003265 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7987\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142894 -> initscore=-1.791461\n",
      "[LightGBM] [Info] Start training from score -1.791461\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9930  140]\n",
      " [ 480 1179]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6647, number of negative: 40269\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008216 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7988\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.141679 -> initscore=-1.801416\n",
      "[LightGBM] [Info] Start training from score -1.801416\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9886  127]\n",
      " [ 515 1201]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6701, number of negative: 40215\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007979 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7987\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142830 -> initscore=-1.791983\n",
      "[LightGBM] [Info] Start training from score -1.791983\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9936  131]\n",
      " [ 482 1180]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [0.9243630959980286, 0.923855405727512, 0.920574872816146, 0.9207488307158735, 0.9194530520363144]\n",
      "precisions:  [0.9062015503875969, 0.9195940671350508, 0.8938589840788476, 0.9043674698795181, 0.9000762776506483]\n",
      "recalls:  [0.697910447761194, 0.7135069654754694, 0.7106690777576854, 0.6998834498834499, 0.7099879663056559]\n",
      "f1s:  [0.795238414893379, 0.7957490695484507, 0.7952092068873227, 0.7961665061913612, 0.7938084373462175]\n",
      "roc_aucs:  [0.8484905326041424, 0.8482268865192373, 0.8493366443373319, 0.8487827645236419, 0.847835705465498]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 0.9217990514587748\n",
      "Average Precision: 0.9048196698263323\n",
      "Average Recall: 0.7063915814366909\n",
      "Average F1 Score: 0.7952343269733462\n",
      "Average ROC AUC Score: 0.8485345066899704\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, precision_score, recall_score\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, precision_score, recall_score\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, precision_score, recall_score\n",
    "\n",
    "class LGBMRandomForestClassifierModel:\n",
    "    def __init__(self, eval_metric='logloss', model_path='lgbm_rf_model.txt', bagging_freq=1, bagging_fraction=0.8, feature_fraction=0.8, **kwargs):\n",
    "        self.model_path = model_path\n",
    "        self.model = lgb.LGBMClassifier(boosting_type='rf', objective='binary', metric=eval_metric,\n",
    "                                        bagging_freq=bagging_freq, bagging_fraction=bagging_fraction,\n",
    "                                        feature_fraction=feature_fraction, **kwargs)\n",
    "        self.THRESHOLD = 0.5\n",
    "        self.load_model()  # Load the saved model if available\n",
    "\n",
    "    def fit(self, X_train, y_train, verbose=0, **kwargs):\n",
    "        # Train model from scratch\n",
    "        self.model.fit(X_train, y_train)\n",
    "        self.save_model()  # Save model state after training\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        print(colored('predicting using lgbm_rf model', 'green'))\n",
    "        ret = self.model.predict(X_test).astype(float)\n",
    "        return ret.reshape(-1, 1)\n",
    "\n",
    "    def predict_proba(self, X_test):\n",
    "        return self.model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        y_pred = self.predict(X_test)\n",
    "        y_pred_proba = self.predict_proba(X_test)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        print(cm)\n",
    "        loss = -1  # Placeholder for loss\n",
    "        return [loss, auc, precision, recall]\n",
    "\n",
    "    def summary(self):\n",
    "        print(self.model)\n",
    "\n",
    "    def save_model(self):\n",
    "        self.model.booster_.save_model(self.model_path)\n",
    "\n",
    "    def f1max(self, *args, **kwargs):\n",
    "        print(self.summary())\n",
    "        if args:\n",
    "            print(f\"iter: {args[0]}, epochs: {args[1]}, splits: {args[2]}\")\n",
    "        print(kwargs)\n",
    "\n",
    "    def load_model(self):\n",
    "        if self.model_exists():\n",
    "            # Load the booster and convert to LGBMClassifier\n",
    "            booster = lgb.Booster(model_file=self.model_path)\n",
    "            self.model._Booster = booster  # Inject the booster into the LGBMClassifier\n",
    "\n",
    "    def model_exists(self):\n",
    "        try:\n",
    "            with open(self.model_path, 'r'):\n",
    "                return True\n",
    "        except FileNotFoundError:\n",
    "            return False\n",
    "\n",
    "# Assuming xult and yult are your feature matrix and target vector\n",
    "# Split the data into training and test sets\n",
    "\n",
    "# yyyyyyy.shape \n",
    "for i in range(5):\n",
    "    # Initialize the LightGBM classifier model\n",
    "    if i % 2 == 0:\n",
    "        lgbm_rf_model = LGBMRandomForestClassifierModel(model_path=f'lgbm_rf_model{i}.txt')\n",
    "    else:\n",
    "        lgbm_rf_model = LGBMRandomForestClassifierModel(eval_metric='auc', model_path=f'lgbm_rf_model{i}.txt')\n",
    "    # Fit the model on training data\n",
    "    ktrain(lgbm_rf_model, xult, yult, epochs=1, batch_size=32, splits=5, random_state=i)\n",
    "    ens.add_model(lgbm_rf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "Percentage of predictions greater than 0.5: 11.55%\n",
      "Percentage of predictions less than or equal to 0.5: 88.45%\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "Percentage of predictions greater than 0.5: 11.62%\n",
      "Percentage of predictions less than or equal to 0.5: 88.38%\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "Percentage of predictions greater than 0.5: 11.70%\n",
      "Percentage of predictions less than or equal to 0.5: 88.30%\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "Percentage of predictions greater than 0.5: 11.67%\n",
      "Percentage of predictions less than or equal to 0.5: 88.33%\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "Percentage of predictions greater than 0.5: 11.72%\n",
      "Percentage of predictions less than or equal to 0.5: 88.28%\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "Percentage of predictions greater than 0.5: 11.68%\n",
      "Percentage of predictions less than or equal to 0.5: 88.32%\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "Percentage of predictions greater than 0.5: 11.69%\n",
      "Percentage of predictions less than or equal to 0.5: 88.31%\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "Percentage of predictions greater than 0.5: 11.71%\n",
      "Percentage of predictions less than or equal to 0.5: 88.29%\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "Percentage of predictions greater than 0.5: 11.72%\n",
      "Percentage of predictions less than or equal to 0.5: 88.28%\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "Percentage of predictions greater than 0.5: 11.73%\n",
      "Percentage of predictions less than or equal to 0.5: 88.27%\n",
      "\u001b[32mPredicting with encoding_dim 512...\u001b[0m\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 931us/step\n",
      "Percentage of predictions greater than 0.5: 9.97%\n",
      "Percentage of predictions less than or equal to 0.5: 90.03%\n",
      "\u001b[32mPredicting with encoding_dim 256...\u001b[0m\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 761us/step\n",
      "Percentage of predictions greater than 0.5: 8.57%\n",
      "Percentage of predictions less than or equal to 0.5: 91.43%\n",
      "\u001b[32mpredicting using dense model of hidden 64\u001b[0m\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668us/step\n",
      "Percentage of predictions greater than 0.5: 11.67%\n",
      "Percentage of predictions less than or equal to 0.5: 88.33%\n",
      "\u001b[32mpredicting using dense model of hidden 64\u001b[0m\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657us/step\n",
      "Percentage of predictions greater than 0.5: 10.11%\n",
      "Percentage of predictions less than or equal to 0.5: 89.89%\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "Percentage of predictions greater than 0.5: 10.35%\n",
      "Percentage of predictions less than or equal to 0.5: 89.65%\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "Percentage of predictions greater than 0.5: 10.35%\n",
      "Percentage of predictions less than or equal to 0.5: 89.65%\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "Percentage of predictions greater than 0.5: 10.58%\n",
      "Percentage of predictions less than or equal to 0.5: 89.42%\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "Percentage of predictions greater than 0.5: 10.61%\n",
      "Percentage of predictions less than or equal to 0.5: 89.39%\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Percentage of predictions greater than 0.5: 10.96%\n",
      "Percentage of predictions less than or equal to 0.5: 89.04%\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Percentage of predictions greater than 0.5: 10.79%\n",
      "Percentage of predictions less than or equal to 0.5: 89.21%\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Percentage of predictions greater than 0.5: 10.87%\n",
      "Percentage of predictions less than or equal to 0.5: 89.13%\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Percentage of predictions greater than 0.5: 10.76%\n",
      "Percentage of predictions less than or equal to 0.5: 89.24%\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Percentage of predictions greater than 0.5: 10.86%\n",
      "Percentage of predictions less than or equal to 0.5: 89.14%\n"
     ]
    }
   ],
   "source": [
    "ens.save(testx, 'finals.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
