{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "##load saved bm.keras and optimize it and then also train on test data and train data then upload final \n",
    "#default ml libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sklearn as sk\n",
    "#tf libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, ConfusionMatrixDisplay, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import kfold from sklearn\n",
    "from sklearn.model_selection import KFold\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test.csv file\n",
    "DEV = True\n",
    "loaddata = pd.read_csv('train.csv')\n",
    "testdata = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  person_age  person_income person_home_ownership  person_emp_length  \\\n",
      "0   0          37          35000                  RENT                0.0   \n",
      "1   1          22          56000                   OWN                6.0   \n",
      "2   2          29          28800                   OWN                8.0   \n",
      "3   3          30          70000                  RENT               14.0   \n",
      "4   4          22          60000                  RENT                2.0   \n",
      "\n",
      "  loan_intent loan_grade  loan_amnt  loan_int_rate  loan_percent_income  \\\n",
      "0   EDUCATION          B       6000          11.49                 0.17   \n",
      "1     MEDICAL          C       4000          13.35                 0.07   \n",
      "2    PERSONAL          A       6000           8.90                 0.21   \n",
      "3     VENTURE          B      12000          11.11                 0.17   \n",
      "4     MEDICAL          A       6000           6.92                 0.10   \n",
      "\n",
      "  cb_person_default_on_file  cb_person_cred_hist_length  loan_status  \n",
      "0                         N                          14            0  \n",
      "1                         N                           2            0  \n",
      "2                         N                          10            0  \n",
      "3                         N                           5            0  \n",
      "4                         N                           3            0  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      id  person_age  person_income person_home_ownership  person_emp_length  \\\n",
      "0  58645          23          69000                  RENT                3.0   \n",
      "1  58646          26          96000              MORTGAGE                6.0   \n",
      "2  58647          26          30000                  RENT                5.0   \n",
      "3  58648          33          50000                  RENT                4.0   \n",
      "4  58649          26         102000              MORTGAGE                8.0   \n",
      "\n",
      "         loan_intent loan_grade  loan_amnt  loan_int_rate  \\\n",
      "0    HOMEIMPROVEMENT          F      25000          15.76   \n",
      "1           PERSONAL          C      10000          12.68   \n",
      "2            VENTURE          E       4000          17.19   \n",
      "3  DEBTCONSOLIDATION          A       7000           8.90   \n",
      "4    HOMEIMPROVEMENT          D      15000          16.32   \n",
      "\n",
      "   loan_percent_income cb_person_default_on_file  cb_person_cred_hist_length  \n",
      "0                 0.36                         N                           2  \n",
      "1                 0.10                         Y                           4  \n",
      "2                 0.13                         Y                           2  \n",
      "3                 0.14                         N                           7  \n",
      "4                 0.15                         Y                           4  \n"
     ]
    }
   ],
   "source": [
    "train = loaddata.copy()\n",
    "print(train.head())\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "test = testdata.copy()\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_age(age):\n",
    "    if age <= 25:\n",
    "        return 0\n",
    "    elif age <= 35:\n",
    "        return 0.1\n",
    "    elif age <= 45:\n",
    "        return 0.2\n",
    "    elif age <= 55:\n",
    "        return 0.3\n",
    "    else:\n",
    "        return 0.4\n",
    "    \n",
    "def categorize_income(income, quantiles):\n",
    "    if income <= quantiles['q20']:\n",
    "        return 0\n",
    "    elif income <= quantiles['q40']:\n",
    "        return 0.1\n",
    "    elif income <= quantiles['q60']:\n",
    "        return 0.2\n",
    "    elif income <= quantiles['q80']:\n",
    "        return 0.3\n",
    "    else:\n",
    "        return 0.4\n",
    "\n",
    "\n",
    "def categorize_loan_amount(loan_amount, quantiles):\n",
    "    if loan_amount <= quantiles['q20']:\n",
    "        return 0\n",
    "    elif loan_amount <= quantiles['q40']:\n",
    "        return 1\n",
    "    elif loan_amount <= quantiles['q60']:\n",
    "        return 2\n",
    "    elif loan_amount <= quantiles['q80']:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "def calculate_quantiles(data, column):\n",
    "    quantiles = {}\n",
    "    for q in [0.2, 0.4, 0.6, 0.8]:\n",
    "        quantiles[f'q{int(q*100)}'] = data[column].quantile(q)\n",
    "    return quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2110/381903121.py:54: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test['person_home_ownership'] = test['person_home_ownership'].replace({'RENT': 0, 'MORTGAGE': 1, 'OWN': 2, 'OTHER': 3}).astype('category')\n",
      "/tmp/ipykernel_2110/381903121.py:55: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test['loan_intent'] = test['loan_intent'].replace({'EDUCATION': 0, 'MEDICAL': 1, 'PERSONAL': 2, 'VENTURE': 3, 'DEBTCONSOLIDATION': 4, 'HOMEIMPROVEMENT': 5}).astype('category')\n",
      "/tmp/ipykernel_2110/381903121.py:56: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test['loan_grade'] = test['loan_grade'].replace({'A':6, 'B':5, 'C':4, 'D':3, 'E':2, 'F':1, 'G':0}).astype('category')\n",
      "/tmp/ipykernel_2110/381903121.py:57: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test['cb_person_default_on_file'] = test['cb_person_default_on_file'].replace({'N': 0, 'Y': 1}).astype('category')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, ..., 3136, 3137, 3138, 3139, 3140]\n",
       "Length: 3141\n",
       "Categories (3141, int64): [0, 1, 2, 3, ..., 3137, 3138, 3139, 3140]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature engineering\n",
    "test[\"loantoincome\"] = ((test[\"loan_amnt\"] / test[\"person_income\"])).astype('Float64')\n",
    "test[\"loan_percent_incometoincome\"] = ((test[\"loan_percent_income\"] / test[\"person_income\"])).astype('Float64')\n",
    "test['person_age_to_person_income'] = (test['person_age'] / test['person_income']).astype(str).astype('Float64')\n",
    "test['person_emp_length_to_person_age'] = (test['person_emp_length'] / test['person_age']).astype('Float64')\n",
    "test['loan_int_rate_to_loan_amnt'] = (test['loan_int_rate'] / test['loan_amnt']).astype('Float64')\n",
    "\n",
    "\n",
    "\n",
    "test['income_to_age'] = test['person_income'] / test['person_age']\n",
    "test['loan_to_income'] = test['loan_amnt'] / test['person_income']\n",
    "test['rate_to_loan'] = test['loan_int_rate'] / test['loan_amnt']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test['log_income'] = (np.log1p(test['person_income'])).astype('Float64')\n",
    "test['age_credit_history_interaction'] = (test['person_age'] * test['cb_person_cred_hist_length']).astype('float64')\n",
    "test['high_loan_to_income'] = (test['loan_percent_income'] > 0.5).astype('float64')\n",
    "test['is_new_credit_user'] = (test['cb_person_cred_hist_length'] < 2).astype('float64')\n",
    "test['high_interest_rate'] = (test['loan_int_rate'] > test['loan_int_rate'].mean()).astype('float64')\n",
    "test['loan_to_employment'] = test['loan_amnt'] / (test['person_emp_length'] + 1)\n",
    "test['rate_to_grade'] = test.groupby('loan_grade')['loan_int_rate'].transform('mean')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test['age_category'] = test['person_age'].apply(categorize_age).astype('category')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test['person_home_ownership'] = test['person_home_ownership'].replace({'RENT': 0, 'MORTGAGE': 1, 'OWN': 2, 'OTHER': 3}).astype('category')\n",
    "test['loan_intent'] = test['loan_intent'].replace({'EDUCATION': 0, 'MEDICAL': 1, 'PERSONAL': 2, 'VENTURE': 3, 'DEBTCONSOLIDATION': 4, 'HOMEIMPROVEMENT': 5}).astype('category')\n",
    "test['loan_grade'] = test['loan_grade'].replace({'A':6, 'B':5, 'C':4, 'D':3, 'E':2, 'F':1, 'G':0}).astype('category')\n",
    "test['cb_person_default_on_file'] = test['cb_person_default_on_file'].replace({'N': 0, 'Y': 1}).astype('category')\n",
    "test[\"person_home_ownership_income\"] = pd.Series(pd.factorize((test[\"person_home_ownership\"].astype(str) + test[\"person_income\"].astype(str)).to_numpy())[0]).astype('category')\n",
    "\n",
    "test['person_home_ownership_income'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete all files that start with lgbm and xgb \n",
    "\n",
    "for item in os.listdir():\n",
    "    if item.startswith(\"lgbm\") or item.startswith(\"xgb\"):\n",
    "        os.remove(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2110/2567601764.py:9: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train['person_home_ownership'] = train['person_home_ownership'].replace({'RENT': 0, 'MORTGAGE': 1, 'OWN': 2, 'OTHER': 3}).astype('category')\n",
      "/tmp/ipykernel_2110/2567601764.py:10: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train['loan_intent'] = train['loan_intent'].replace({'EDUCATION': 0, 'MEDICAL': 1, 'PERSONAL': 2, 'VENTURE': 3, 'DEBTCONSOLIDATION': 4, 'HOMEIMPROVEMENT': 5}).astype('category')\n",
      "/tmp/ipykernel_2110/2567601764.py:11: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train['loan_grade'] = train['loan_grade'].replace({'A':6, 'B':5, 'C':4, 'D':3, 'E':2, 'F':1, 'G':0}).astype('category')\n",
      "/tmp/ipykernel_2110/2567601764.py:12: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train['cb_person_default_on_file'] = train['cb_person_default_on_file'].replace({'N': 0, 'Y': 1}).astype('category')\n",
      "/tmp/ipykernel_2110/2567601764.py:20: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  train['rate_to_grade'] = train.groupby('loan_grade')['loan_int_rate'].transform('mean').astype('float64')\n",
      "/tmp/ipykernel_2110/2567601764.py:26: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  train['normalized_loan_amount'] = train.groupby('loan_intent')['loan_amnt'].transform(lambda x: (x - x.mean()) / x.std()).astype('float64')\n",
      "/tmp/ipykernel_2110/2567601764.py:27: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  test['normalized_loan_amount'] = test.groupby('loan_intent')['loan_amnt'].transform(lambda x: (x - x.mean()) / x.std()).astype('float64')\n",
      "/tmp/ipykernel_2110/2567601764.py:152: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  train['normalized_income'] = train.groupby('age_category')['person_income'].transform(lambda x: ((x.astype('float64') - x.mean().astype('float64')) / x.std().astype('float64'))).astype('float64')\n",
      "/tmp/ipykernel_2110/2567601764.py:157: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  test['normalized_income'] = test.groupby('age_category')['person_income'].transform(lambda x: ((x.astype('float64') - x.mean().astype('float64')) / x.std().astype('float64'))).astype('float64')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05, 0.14, 0.26, 0.35, 0.16, ..., 0.1, 0.5, 0.2, 0.0, 0.4]\n",
       "Length: 42\n",
       "Categories (42, float64): [0.00, 0.01, 0.02, 0.03, ..., 0.53, 0.54, 0.55, 0.56]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature engineering\n",
    "train[\"loantoincome\"] = ((train[\"loan_amnt\"] / train[\"person_income\"])).astype('Float64')\n",
    "train[\"loan_percent_incometoincome\"] = ((train[\"loan_percent_income\"] / train[\"person_income\"])).astype('Float64')\n",
    "train['person_age_to_person_income'] = (train['person_age'] / train['person_income']).astype(str).astype('Float64')\n",
    "train['person_emp_length_to_person_age'] = (train['person_emp_length'] / train['person_age']).astype('Float64')\n",
    "train['loan_int_rate_to_loan_amnt'] = (train['loan_int_rate'] / train['loan_amnt']).astype('Float64')\n",
    "train['income_to_age'] = train['person_income'] / train['person_age']\n",
    "train['rate_to_loan'] = train['loan_int_rate'] / train['loan_amnt']\n",
    "train['person_home_ownership'] = train['person_home_ownership'].replace({'RENT': 0, 'MORTGAGE': 1, 'OWN': 2, 'OTHER': 3}).astype('category')\n",
    "train['loan_intent'] = train['loan_intent'].replace({'EDUCATION': 0, 'MEDICAL': 1, 'PERSONAL': 2, 'VENTURE': 3, 'DEBTCONSOLIDATION': 4, 'HOMEIMPROVEMENT': 5}).astype('category')\n",
    "train['loan_grade'] = train['loan_grade'].replace({'A':6, 'B':5, 'C':4, 'D':3, 'E':2, 'F':1, 'G':0}).astype('category')\n",
    "train['cb_person_default_on_file'] = train['cb_person_default_on_file'].replace({'N': 0, 'Y': 1}).astype('category')\n",
    "train[\"person_home_ownership_income\"] = pd.Series(pd.factorize((train[\"person_home_ownership\"].astype(str) + train[\"person_income\"].astype(str)).to_numpy())[0]).astype('category')\n",
    "train['log_income'] = np.log1p(train['person_income']).astype('float64')\n",
    "train['age_credit_history_interaction'] = (train['person_age'] * train['cb_person_cred_hist_length']).astype('float64')\n",
    "train['high_loan_to_income'] = (train['loan_percent_income'] > 0.5).astype('float64')\n",
    "train['is_new_credit_user'] = (train['cb_person_cred_hist_length'] < 2).astype('float64')\n",
    "train['high_interest_rate'] = (train['loan_int_rate'] > train['loan_int_rate'].mean()).astype('float64')\n",
    "train['loan_to_employment'] = (train['loan_amnt'] / (train['person_emp_length'] + 1)).astype('float64')\n",
    "train['rate_to_grade'] = train.groupby('loan_grade')['loan_int_rate'].transform('mean').astype('float64')\n",
    "train['age_category'] = train['person_age'].apply(categorize_age).astype('category')\n",
    "train['age_to_credit_history'] = (train['person_age'] / (train['cb_person_cred_hist_length'] + 1)).astype('float64')\n",
    "test['age_to_credit_history'] = (test['person_age'] / (test['cb_person_cred_hist_length'] + 1)).astype('float64')\n",
    "train['income_to_loan'] = (train['person_income'] / train['loan_amnt']).astype('float64')\n",
    "test['income_to_loan'] = (test['person_income'] / test['loan_amnt']).astype('float64')\n",
    "train['normalized_loan_amount'] = train.groupby('loan_intent')['loan_amnt'].transform(lambda x: (x - x.mean()) / x.std()).astype('float64')\n",
    "test['normalized_loan_amount'] = test.groupby('loan_intent')['loan_amnt'].transform(lambda x: (x - x.mean()) / x.std()).astype('float64')\n",
    "train['log_loan_amnt'] = np.log1p(train['loan_amnt']).astype('float64')\n",
    "test['log_loan_amnt'] = np.log1p(test['loan_amnt']).astype('float64')\n",
    "train['income_home_mismatch'] = ((train['person_income'] > train['person_income'].quantile(0.8)) & (train['person_home_ownership'] == 0)).astype('float64')\n",
    "test['income_home_mismatch'] = ((test['person_income'] > test['person_income'].quantile(0.8)) & (test['person_home_ownership'] == 0)).astype('float64')\n",
    "train['default_grade_interaction'] = ((train['cb_person_default_on_file'].astype('float64')*10 +  train['loan_grade'].astype('float64'))/16).astype('category')\n",
    "test['default_grade_interaction'] = ((test['cb_person_default_on_file'].astype('float64')*10 +  test['loan_grade'].astype('float64'))/16).astype('category')\n",
    "train['age_interest_interaction'] = (train['person_age'].astype('float64') * train['loan_int_rate'].astype('float64')).astype('float64')   \n",
    "test['age_interest_interaction'] = (test['person_age'] * test['loan_int_rate']).astype('float64')   \n",
    "train['credit_history_to_age'] = (train['cb_person_cred_hist_length'].astype('float64') / train['person_age'].astype('float64')).astype('float64')\n",
    "test['credit_history_to_age'] = (test['cb_person_cred_hist_length'].astype('float64') / test['person_age'].astype('float64')).astype('float64') \n",
    "train['rate_to_credit_history'] = (train['loan_int_rate'].astype('float64') / (train['cb_person_cred_hist_length'].astype('float64') + 1)).astype('float64')\n",
    "test['rate_to_credit_history'] = (test['loan_int_rate'].astype('float64') / (test['cb_person_cred_hist_length'].astype('float64') + 1)).astype('float64')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "loanseventryfivequantile = train['loan_amnt'].quantile(0.75)\n",
    "train['high_loan_amount'] = (train['loan_amnt'] > loanseventryfivequantile).astype('category')\n",
    "test['high_loan_amount'] = (test['loan_amnt'] > loanseventryfivequantile).astype('category')\n",
    "\n",
    "\n",
    "personninetyquantile = train['person_income'].quantile(0.9)\n",
    "train['age_income_mismatch'] = ((train['person_age'] < 30) & (train['person_income'] > personninetyquantile)).astype('category')\n",
    "test['age_income_mismatch'] = ((test['person_age'] < 30) & (test['person_income'] > personninetyquantile)).astype('category')\n",
    "\n",
    "\n",
    "\n",
    "# Define the custom function to categorize loan interest rates\n",
    "def calculate_quantiles(data, column):\n",
    "    quantiles = {}\n",
    "    for q in [0.2, 0.4, 0.6, 0.8]:\n",
    "        quantiles[f'q{int(q*100)}'] = data[column].quantile(q)\n",
    "    return quantiles\n",
    "def categorize_loan_int_rate(rate, quantiles):\n",
    "    if rate <= quantiles['q20']:\n",
    "        return 0\n",
    "    elif rate <= quantiles['q40']:\n",
    "        return 1\n",
    "    elif rate <= quantiles['q60']:\n",
    "        return 2\n",
    "    elif rate <= quantiles['q80']:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "loan_int_rate_quantiles = calculate_quantiles(train, 'loan_int_rate')\n",
    "\n",
    "###########################################3\n",
    "train['loan_int_rate_category'] = train['loan_int_rate'].apply(categorize_loan_int_rate, args=(loan_int_rate_quantiles,)).astype('category')\n",
    "train['default_rate_interaction'] = train['cb_person_default_on_file'].astype('float64') * 10 + train['loan_int_rate_category'].astype('float64')\n",
    "\n",
    "test['loan_int_rate_category'] = test['loan_int_rate'].apply(categorize_loan_int_rate, args=(loan_int_rate_quantiles,)).astype('category')\n",
    "test['default_rate_interaction'] = test['cb_person_default_on_file'].astype('float64') * 10 + test['loan_int_rate_category'].astype('float64')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train['intent_grade_interaction'] = (train['loan_intent'].astype('float64')*10 + train['loan_grade'].astype('float64')).astype('category')\n",
    "test['intent_grade_interaction'] = (test['loan_intent'].astype('float64')*10 + test['loan_grade'].astype('float64')).astype('category')\n",
    "\n",
    "\n",
    "\n",
    "train['home_ownership_intent'] = (train['person_home_ownership'].astype('float64')*10   + train['loan_intent'].astype('float64')).astype('category')\n",
    "test['home_ownership_intent'] = (test['person_home_ownership'].astype('float64')*10   + test['loan_intent'].astype('float64')).astype('category')\n",
    "###########################################3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "loan_amount_quantiles = calculate_quantiles(train, 'loan_amnt')\n",
    "train['loan_amount_category'] = train['loan_amnt'].apply(categorize_loan_amount, args=(loan_amount_quantiles,)).astype('category')\n",
    "test['loan_amount_category'] = test['loan_amnt'].apply(categorize_loan_amount, args=(loan_amount_quantiles,)).astype('category')\n",
    "\n",
    "\n",
    "\n",
    "train['risk_score'] = train['loan_percent_income'] * train['loan_int_rate'] * (6 - train['loan_grade'].astype('float64'))\n",
    "test['risk_score'] = test['loan_percent_income'] * test['loan_int_rate'] * (6 - test['loan_grade'].astype('float64'))\n",
    "train['loan_intent_grade'] = ((train['loan_intent'].astype('float64') * 10 + train['loan_grade'].astype('float64'))/100).astype('category')\n",
    "test['loan_intent_grade'] = ((test['loan_intent'].astype('float64') * 10 + test['loan_grade'].astype('float64'))/100).astype('category')\n",
    "income_quantiles = calculate_quantiles(train, 'person_income')\n",
    "train['income_category'] = train['person_income'].apply(categorize_income, args=(income_quantiles,)).astype('category')\n",
    "test['income_category'] = test['person_income'].apply(categorize_income, args=(income_quantiles,)).astype('category')\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train['creditworthiness_score'] = (train['person_income'].astype('float64') / (train['loan_amnt'].astype('float64') * train['loan_int_rate'].astype('float64'))) * (train['cb_person_cred_hist_length'].astype('float64') + 1).astype('float64')\n",
    "train['age_to_employment'] = (train['person_age'].astype('float64') / (train['person_emp_length'].astype('float64') + 1)).astype('float64')\n",
    "train['intent_home_match'] = ((train['loan_intent'].astype('float64') == 5) & (train['person_home_ownership'].astype('float64') == 2)).astype('float64')\n",
    "train['normalized_income'] = train.groupby('age_category')['person_income'].transform(lambda x: ((x.astype('float64') - x.mean().astype('float64')) / x.std().astype('float64'))).astype('float64')\n",
    "train['rate_to_age'] = (train['loan_int_rate'].astype('float64') / train['person_age'].astype('float64')).astype('float64')\n",
    "test['creditworthiness_score'] = (test['person_income'].astype('float64') / (test['loan_amnt'].astype('float64') * test['loan_int_rate'].astype('float64'))) * (test['cb_person_cred_hist_length'].astype('float64') + 1).astype('float64')\n",
    "test['age_to_employment'] = (test['person_age'].astype('float64') / (test['person_emp_length'].astype('float64') + 1)).astype('float64')\n",
    "test['intent_home_match'] = ((test['loan_intent'].astype('float64') == 5) & (test['person_home_ownership'].astype('float64') == 2)).astype('float64')\n",
    "test['normalized_income'] = test.groupby('age_category')['person_income'].transform(lambda x: ((x.astype('float64') - x.mean().astype('float64')) / x.std().astype('float64'))).astype('float64')\n",
    "test['rate_to_age'] = (test['loan_int_rate'].astype('float64') / test['person_age'].astype('float64')).astype('float64')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train['home_ownership_loan_interaction'] = (train['person_home_ownership'].astype('float64')*10  + train['loan_amount_category'].astype('float64')).astype('category')\n",
    "test['home_ownership_loan_interaction'] = (test['person_home_ownership'].astype('float64')*10  + test['loan_amount_category'].astype('float64')).astype('category')\n",
    "\n",
    "\n",
    "# more feature engineering\n",
    "\n",
    "train['loan_intent_grade'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABfYAAAPdCAYAAADIxjniAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdeVxU1f8/8NeAzLBvypqKiCa4pH5QETdcEDTUTMtMU1RyCzSlcslS0cpy30Url0q/uVuJqbikqViJSy5JmqiloiaCOyBzfn/4mxuXGWCGbZjh9Xw85qFz7pl73+dyzj1nzsycqxBCCBARERERERERERERkUmwMHYARERERERERERERESkP07sExERERERERERERGZEE7sExERERERERERERGZEE7sExERERERERERERGZEE7sExERERERERERERGZEE7sExERERERERERERGZEE7sExERERERERERERGZEE7sExERERERERERERGZEE7sExERERERERERERGZEE7sExGVkdWrV0OhUODy5cvGDqXEzKksRBXNoEGDUKtWLWOHUSTNdeDYsWPGDoWMwJT6AVNpU+Zs6tSpUCgUxg6jUjKltkqF47XMcJcvX4ZCocDq1auNHQoRlTL2b7pxYp+IyMw9evQIU6dOxU8//WTsUIjIBCxdurTM3xAfOXIEU6dORUZGRpkeh8hQO3bswNSpU412/HXr1mH+/Pllegxjl5H088knn2Dbtm3GDoNKiO3NMOUxBiEqbay3ZEyc2CciMnOPHj1CXFxciSb2BwwYgMePH8PHx6f0AiOiCqm8Jvbj4uI4sU9l4vPPP0dKSkqxXrtjxw7ExcWVckT6K6+JfWOWkfTDiX3zUJL2VpJrmakq6RjEx8cHjx8/xoABA0ovKKIicGK/fHBOQjdO7BMePXpk7BCIqIKztLSEtbU1f1ZP7DOI8mGbqHisrKygUqmMHQYA1g8iY1Or1Xjy5ImxwyiWinQtMxUKhQLW1tawtLQ0digmh/0VPX36FNnZ2cYOo0Cck9CNE/sVnGZ9yvPnz6NPnz5wdHRE1apV8fbbb2sNUL755hsEBgbCxsYGrq6u6Nu3L/7++29Znvbt26Nhw4ZITk5Gu3btYGtri/fffx8AcOzYMYSHh6NatWqwsbGBr68vhgwZInv9w4cP8c4776BGjRpQqVSoV68eZs+eDSGELJ9CoUBMTAy2bduGhg0bQqVSoUGDBti5c6fB52D27Nlo1aoVqlatChsbGwQGBmLTpk1a+R4/fozRo0ejWrVqcHBwQI8ePXDt2jUoFAqtnz9eu3YNQ4YMgYeHhxTbypUrDY6NyFBLly5FgwYNoFKp4O3tjejoaK1vrP7888949dVXUbNmTahUKtSoUQNjx47F48ePZfkGDRoEe3t7XLt2DT179oS9vT3c3Nzw7rvvIjc3F8CzdSbd3NwAAHFxcVAoFFptYt++fWjbti3s7Ozg7OyMl156CX/88YfsWLrWs6tVqxa6deuGQ4cOoUWLFrC2tkbt2rXx1VdfaZU7IyMDY8eORa1ataBSqVC9enUMHDgQ//77r5Tn1q1biIqKgoeHB6ytrdG4cWOsWbNGth/NupmzZ8/GkiVLULt2bdja2iIsLAx///03hBCYPn06qlevDhsbG7z00ktIT0/XiufHH3+Uyuzg4ICIiAicPXu24D+ciWCf8ewN/Pz589GgQQNYW1vDw8MDw4cPx927d2X5NPX3p59+QrNmzWBjY4NGjRpJv2zZsmULGjVqBGtrawQGBuLEiROy12va36VLlxAeHg47Ozt4e3tj2rRpWuUrDkPLoU87/P333xESEgIbGxtUr14dH330EVatWiVr27Vq1cLZs2dx4MAB6XrRvn172X6ysrIQGxsLNzc32NnZ4eWXX8bt27f1LtvUqVPx3nvvAQB8fX2l42hiePr0KaZPnw4/Pz+oVCrUqlUL77//PrKysvQ/gTCsPQDm2ybKchzl4OAACwsLWFhYwNnZucz7NH3lX5c6b9+xYsUKqW41b94cv/32m+x1S5YsAQCpXhry5rGw+vHdd98hIiIC3t7eUKlU8PPzw/Tp02Vla9++PRISEnDlyhXp2HnLkZWVhSlTpqBOnTrSuRw3bpxBbaOoMupbR4tD37atz7kC/jvf586dQ4cOHWBra4vnnnsOM2fONDg2Q4+puZ7a2tqiTp06Ups6cOAAgoKCYGNjg3r16mHPnj2y12uuSxcvXsSgQYPg7OwMJycnDB48WDapplAo8PDhQ6xZs0b6Gw0aNMjgcmmU9/hTX3nbTKtWraRrZ3x8vFZefeu/5vq5du1aqcyaa+e1a9cQFRUl/Z19fX0xcuRI2URWRkYGxowZI7WBOnXq4LPPPoNarZbylNc1pbjXMg1N/+fm5ibVyUmTJsnynDhxAl27doWjoyPs7e3RqVMnHD16VJZH8z7g0KFDGD16NNzc3ODs7Izhw4cjOzsbGRkZGDhwIFxcXODi4oJx48ZpXTP0GdcUNQa5dOkSXn31Vbi6usLW1hYtW7ZEQkKC7Di61tg3pM6q1WosWLBAGgO6ubmhS5cusvsL6XstK+lYU/M3fOWVV2BjYwOFQoGGDRuiTZs2lXKMX1HnhUqj3up7nG7dumH37t1o0qQJrK2tUb9+fWzZskUrr6HXsfnz50v1+dy5cwCARYsWoUGDBrC1tYWLiwuaNWuGdevWyY5jyPXj8OHDJXr/kHdfnJPIR1CFNmXKFAFANGrUSHTv3l0sXrxYvPHGGwKAGDBggJTvo48+EgqFQrz22mti6dKlIi4uTlSrVk3UqlVL3L17V8oXEhIiPD09hZubmxg1apRYvny52LZtm7h586ZwcXERzz//vJg1a5b4/PPPxaRJk0RAQID0WrVaLTp27CgUCoV48803xeLFi0X37t0FADFmzBhZ3ABE48aNhZeXl5g+fbqYP3++qF27trC1tRX//vuvQeegevXq4q233hKLFy8Wc+fOFS1atBAAxPbt22X5+vTpI52XJUuWiD59+ojGjRsLAGLKlClSvrS0NFG9enVRo0YNMW3aNLFs2TLRo0cPAUDMmzfPoNiICrNq1SoBQKSmpgoh/mvPoaGhYtGiRSImJkZYWlqK5s2bi+zsbOl1o0aNEi+++KL45JNPxPLly0VUVJSwtLQUr7zyimz/kZGRwtraWjRo0EAMGTJELFu2TPTu3VsAEEuXLhVCCPHgwQOxbNkyAUC8/PLL4uuvvxZff/21OHXqlBBCiMTERFGlShXx/PPPi5kzZ0rXDhcXFyluXWURQggfHx9Rr1494eHhId5//32xePFi8b///U8oFApx5swZKd/9+/dFw4YNhaWlpRg6dKhYtmyZmD59umjevLk4ceKEEEKIR48eiYCAAGFlZSXGjh0rFi5cKNq2bSsAiPnz50v7Sk1NFQBEkyZNRP369cXcuXPFBx98IJRKpWjZsqV4//33RatWrcTChQvF6NGjhUKhEIMHD5adt6+++kooFArRpUsXsWjRIvHZZ5+JWrVqCWdnZ1n5TBH7DCHefPNNUaVKFTF06FARHx8vxo8fL+zs7LTamab+enl5ialTp4p58+aJ5557Ttjb24tvvvlG1KxZU3z66afi008/FU5OTqJOnToiNzdXer2m/dWtW1cMGDBALF68WHTr1k0AEB9++KFBMUdGRgofH58SlaOodvjPP/8IV1dXUbVqVREXFydmz54t/P39pX5SU/e3bt0qqlevLvz9/aXrxe7du4UQ/10HmjZtKjp27CgWLVok3nnnHWFpaSn69Omjd3lPnTolXn/9danf1RznwYMH0vkAIF555RWxZMkSMXDgQAFA9OzZ06Dzqm97EMK820RpjaM0f/9ff/1VVK9eXTg6OgoAwt/fXzRq1EgAEBYWFmXap+krf5vS9B1NmzYVderUEZ999pmYOXOmqFatmqhevboU75EjR0Tnzp0FAKlefv3113oft6D6IYQQPXv2FH369BGzZs0Sy5YtE6+++qoAIN59913p9bt37xZNmjQR1apVk469detWIYQQubm5IiwsTNja2ooxY8aI5cuXi5iYGFGlShXx0ksv6R1jYWU0pI4WRdP+8tK3betzroR4dr69vb1FjRo1xNtvvy2WLl0qOnbsKACIHTt2GBRvcY753nvviUWLFon69esLS0tL8e233wpPT08xdepUMX/+fPHcc88JJycnce/ePa3z0rRpU9GrVy+xdOlS8eabbwoAYty4cVK+r7/+WqhUKtG2bVvpb3TkyBG9ylIRxp/60pxPd3d3ERMTIxYuXCjatGkjAIgvv/xSymdI/QcgAgIChJubm4iLixNLliwRJ06cENeuXRPe3t7SPuLj48WHH34oAgICpOv8w4cPxQsvvCCqVq0q3n//fREfHy8GDhwoFAqFePvtt6VjlNc1pbjXMiGe9bWOjo6iatWqYuLEiWL58uVi3LhxolGjRlKeM2fOCDs7O6mv+fTTT4Wvr69QqVTi6NGjUj5NnWrSpIno0qWLWLJkiRgwYIBUb9u0aSP69esnli5dKo2F1qxZIyuLPuOawsYgaWlpwsPDQzg4OIhJkyaJuXPnisaNGwsLCwuxZcsWrXO0atUq2XnUt84OGjRIABBdu3YV8+fPF7NnzxYvvfSSWLRokWx/+lzLSjrWPHPmjHBychL169cXoaGhAoCws7MTAMTQoUMr3Ri/os4LlUa91YePj494/vnnhbOzs5gwYYKYO3euaNSokbCwsJCOJ4Th17H69euL2rVri08//VTMmzdPXLlyRaxYsUKq48uXLxcLFiwQUVFRYvTo0dLrDb1+lPT9Q959cU5CjhP7FZxmINajRw9Z+ltvvSUAiFOnTonLly8LS0tL8fHHH8vynD59WlSpUkWWHhISIgCI+Ph4Wd6tW7cKAOK3334rMJZt27YJAOKjjz6Spb/yyitCoVCIixcvSmkAhFKplKWdOnVKAJB1ivp49OiR7Hl2drZo2LCh6Nixo5SWnJyssyPRdMx5L+BRUVHCy8tLqyPp27evcHJy0joeUXHl7Xhu3bollEqlCAsLkw3YFi9eLACIlStXSmm66uCMGTOEQqEQV65ckdI0g8pp06bJ8jZt2lQEBgZKz2/fvq3VDjSaNGki3N3dxZ07d6S0U6dOCQsLCzFw4ECdZdHw8fERAMTBgweltFu3bgmVSiXeeecdKW3y5MkCgM7Bi1qtFkIIMX/+fAFAfPPNN9K27OxsERwcLOzt7aU3xZpO1M3NTWRkZEh5J06cKA0cc3JypPTXX39dKJVK8eTJEyHEsw7d2dlZDB06VBZHWlqacHJy0ko3NZW9z/j5558FALF27VpZ+s6dO7XSNfU370TJrl27BABhY2Mja2vLly8XAMT+/fulNE37GzVqlJSmVqtFRESEUCqV4vbt23rHnf+Ne3HKUVQ7HDVqlFAoFNLAVQgh7ty5I1xdXbXadoMGDURISIhWnJrrQGhoqNR2hRBi7NixwtLSUtYmizJr1iyt4wohxMmTJwUA8eabb8rS3333XQFA7Nu3T+9j6NMehBBm3SaEKL1xlObv36dPH+Hu7q7Vp/Xt21dYW1uXeZ+mj4Imw6pWrSrS09Ol9O+++04AED/88IOUFh0drTUhra+C6ocQus/D8OHDha2trdRHCSFERESE1gd9Qjyb6LWwsBA///yzLD0+Pl4AEIcPH9Y7zoLKaEgdLUr+iX1D2ra+50pzvr/66ispLSsrS3h6eorevXvrHWtxjrlu3Top7fz589IHW3knMzR9St4JRs15GTJkiOxYL7/8sqhataoszc7OTkRGRhpUDiEqzvhTH5rzOWfOHCktKytLGp9qJnwNqf+av8XZs2dleQcOHCgsLCx0Xqc1fdr06dOFnZ2d+PPPP2XbJ0yYICwtLcXVq1eFEOV3TSnJtaxdu3bCwcFB9rfLW1Yhnn2gpVQqxV9//SWlXb9+XTg4OIh27dpJaZo6FR4eLnt9cHCwUCgUYsSIEVLa06dPRfXq1WXjCEPGNQWNQcaMGSMAyOrA/fv3ha+vr6hVq5ZUvwua2Nenzu7bt08AkE1e5j9vhlzLSjrW7NSpk2jUqJF48uSJbEzTqlUrUbduXSFE5RnjC1Gx54VKWm/1oalPmzdvltIyMzOFl5eXaNq0qZRm6HXM0dFR3Lp1S5b3pZdeEg0aNCg0HkOvH6Xx/oFzErpxKR4TER0dLXs+atQoAM9uxrNlyxao1Wr06dMH//77r/Tw9PRE3bp1sX//ftlrVSoVBg8eLEtzdnYGAGzfvh05OTk6Y9ixYwcsLS0xevRoWfo777wDIQR+/PFHWXpoaCj8/Pyk5y+88AIcHR1x6dIl/QsOwMbGRvr/3bt3kZmZibZt2+L48eNSuuanXG+99ZbstZrzpCGEwObNm9G9e3cIIWTnKzw8HJmZmbL9EpWWPXv2IDs7G2PGjIGFxX+X3qFDh8LR0VH2c7y8df7hw4f4999/0apVKwghdP5Ec8SIEbLnbdu21aud3bhxAydPnsSgQYPg6uoqpb/wwgvo3LkzduzYUeQ+6tevj7Zt20rP3dzcUK9ePdnxN2/ejMaNG+Pll1/Wer3m58g7duyAp6cnXn/9dWmblZUVRo8ejQcPHuDAgQOy17366qtwcnKSngcFBQEA3njjDVSpUkWWnp2djWvXrgEAEhMTkZGRgddff13W/i0tLREUFKR1vTRVlbXP2LhxI5ycnNC5c2dZ2QIDA2Fvb69Vtvr16yM4OFh6rqlHHTt2RM2aNbXSdcUSExMj/V/zc+Ps7Gyt5RcMUZxyFNUOd+7cieDgYDRp0kRKc3V1Rf/+/Q2Ob9iwYbKlBNq2bYvc3FxcuXLF4H3lp7nuxMbGytLfeecdACjWT5cLaw8AzLpNAKU7jgKe/Wy4YcOGyM7OxuDBg5Geni6No548eQI7Ozuj9Gn6eO211+Di4iLbN6C7bReXrvoByM/D/fv38e+//6Jt27Z49OgRzp8/X+R+N27ciICAAPj7+8vqaceOHQGgVPovQ+uoofsG9Gvbhpwre3t7vPHGG9JzpVKJFi1alKid6HPMvn37Ss/r1asHZ2dnBAQESP0FUHjfoaue37lzB/fu3TMo7qJUxPFnflWqVMHw4cOl50qlEsOHD8etW7eQnJwMwPD6HxISgvr160vP1Wo1tm3bhu7du6NZs2ZaMWj6tI0bN6Jt27ZwcXGRHSc0NBS5ubk4ePCg7HXlcU3Rpajj3r59GwcPHsSQIUNk4xngv7Lm5uZi9+7d6NmzJ2rXri1t9/LyQr9+/XDo0CGt+hgVFSXr/4OCgiCEQFRUlJRmaWmJZs2ayc6BoeMaXXbs2IEWLVqgTZs2Upq9vT2GDRuGy5cvS8uHFKaoOrt582YoFApMmTJF67V537MA+o9TijvWTE9Px759+9CnTx/cv39fWqrrjTfeQHh4OC5cuIBr165VmjE+YJrzQqVRb/Py9vaWvad2dHTEwIEDceLECaSlpQEw/DrWu3dvaeleDWdnZ/zzzz86l/gCinf9KMv3D5V9TqJK0VmoIqhbt67suZ+fHywsLHD58mVYWFhACKGVR8PKykr2/LnnnoNSqZSlhYSEoHfv3oiLi8O8efPQvn179OzZE/369ZNu2HPlyhV4e3vDwcFB9tqAgABpe175BxEA4OLiorU+cFG2b9+Ojz76CCdPnpStW5f3onDlyhVYWFjA19dX9to6derInt++fRsZGRlYsWIFVqxYofN4t27dMig+In1o2ke9evVk6UqlErVr15a1n6tXr2Ly5Mn4/vvvtdpLZmam7Llm7ce89G1nBcUEPGvXu3btwsOHD2FnZ1fgPvRp53/99Rd69+5dZCx169aVvenUxJE31oKOq+lQa9SooTNdE8+FCxcAQHojmJ+jo2OhcZqKytpnXLhwAZmZmXB3d9e5Pf/1vbj1SMPCwkI2mAWA559/HgBkaz8aqqTlALTP3ZUrV2RvLDXy95P6yH88zeSCof27Lpr+PH9cnp6ecHZ2Ltbgv7D2ADw73+baJoDSHUcBzyY99+3bBwCyNz4a7u7uRunT9FGWdVdDV/0AgLNnz+KDDz7Avn37tN7s5j8Puly4cAF//PGH1vnRKI3xq6F11NB969u2DTlX1atX11qz3MXFBb///rtB8ZX0mE5OTnr3HUDhdbE0xyIVcfyZn7e3t9ZYM29f2rJlS4Prf/5r2e3bt3Hv3j00bNiw0FguXLiA33//Xe/jlMc1RZeijquZzCqsvLdv38ajR48KfB+gVqvx999/o0GDBgUet7BxU95zYOi4RpcrV67IPjjLG6tme2Hl1afO/vXXX/D29pZ94UlXHIaMU4o71rx48SKEEPjwww/x4YcfSvn69Okj/f/WrVto2LBhpRjjA6Y5L1TSeptfnTp1tPqfvNdLT09Pg69j+c8VAIwfPx579uxBixYtUKdOHYSFhaFfv35o3bo1gNK5fpTm9bKyz0lwYt9E5W3MarUaCoUCP/74o867v9vb28ue5/2kM+/+Nm3ahKNHj+KHH37Arl27MGTIEMyZMwdHjx7V2oc+CroTvTDg5ls///wzevTogXbt2mHp0qXw8vKClZUVVq1apXXjDn1obhbyxhtvIDIyUmeeF154weD9EpWW3NxcdO7cGenp6Rg/fjz8/f1hZ2eHa9euYdCgQbIb3gAFt7PyUhrtvDSPW1Q8mvP39ddfw9PTUytf3k/WzUll6TPUajXc3d2xdu1andvzD3CLW4/KWmmVo6ziLY/jGXJzwZLu25zbRGmPozSaNGmCkydP4quvvoKXl5ds29ixY6X/V7Q+rTzqrq76kZGRgZCQEDg6OmLatGnw8/ODtbU1jh8/jvHjx2udB13UajUaNWqEuXPn6tye/01kRVVU2zb0XJXG37S0jmlILMbuZ/KraG01P0Prv652qO9xOnfujHHjxuncrplA06ho4+CKNP7OG4uh45qyUNp1Vt9xSknfs7z77rsIDw/HV199ha+//lrW7+af5OV4Rn/mPC9k6HVMVz0ICAhASkoKtm/fjp07d2Lz5s1YunQpJk+ejLi4uGLFVZbXLVO4JgJlNydhnjMYZujChQuyT9IuXrwItVqNWrVqwdLSEkII+Pr6ajVSQ7Vs2RItW7bExx9/jHXr1qF///749ttv8eabb8LHxwd79uzB/fv3ZZ/Oan6e6uPjU6Jj67J582ZYW1tj165d0ifEALBq1SpZPh8fH6jVaqSmpso+ob548aIsn5ubGxwcHJCbm4vQ0NBSj5eoIJr2kZKSIvuGb3Z2NlJTU6X6ePr0afz5559Ys2YNBg4cKOVLTEws9rELGnjmjSm/8+fPo1q1aoV+W19ffn5+OHPmTKF5fHx88Pvvv0OtVss+IS/t64vmZ6Du7u5mfQ2orH2Gn58f9uzZg9atWxf7Tb0h1Go1Ll26JDuPf/75JwCgVq1axd5vWZTDx8dHq08EtPtJoGwn1Ys6hqY/v3DhgvTtGAC4efMmMjIyilVvCmsPwLPzba5torTHUQBgZ2cn1ctq1arJrqXZ2dn4+++/y7RPK2tlUf9/+ukn3LlzB1u2bEG7du2k9NTUVL2P7+fnh1OnTqFTp04ljrGw9ldWdVTftm3IuSotxjimPkqjLhpz/Kmv69eva/1CNH9fWtL67+bmBkdHxyLHo35+fnjw4EGpjhHLo0/NT/O3Lqy8bm5usLW1LfB9gIWFRal9YGjIuKaw61NBsWq2l0acu3btQnp6eoHf2i+LcYoumr+hlZUVQkNDcejQIQCAh4eHrH6eP3++UozxK/q8UHnVW80vOfIeT9f1sjSuY3Z2dnjttdfw2muvITs7G7169cLHH3+MiRMnluv1o7SY85wE19g3EUuWLJE9X7RoEQCga9eu6NWrFywtLREXF6f1iZQQAnfu3Cly/3fv3tV6rWYdXs3PnF588UXk5uZi8eLFsnzz5s2DQqFA165dDSqTPiwtLaFQKJCbmyulXb58Gdu2bZPlCw8PBwAsXbpUlq45T3n317t3b2zevFlno759+3YpRU4kFxoaCqVSiYULF8ra2pdffonMzExEREQA+O/T3bx5hBBYsGBBsY9ta2sL4Nk30vLy8vJCkyZNsGbNGtm2M2fOYPfu3XjxxReLfcy8evfujVOnTmHr1q1a2zTlfPHFF5GWlob169dL254+fYpFixbB3t4eISEhpRJLeHg4HB0d8cknn+hcN9JcrgGVtc/o06cPcnNzMX36dK1tT58+1WoDpSFv+YQQWLx4MaysrNCpU6di77MsyhEeHo6kpCScPHlSSktPT9f57Tk7O7syOVf5jwFoX5c015358+fL0jXf0tRcKw1RWHsAYNZtorTHUQDQpUsXHDt2DFZWVlp92vz588u8TytrBdXNktB1HrKzs7XOt+b4upbm6dOnD65du4bPP/9ca9vjx4/x8OFDveMprP2VVR3Vt20bcq5KizGOqY/SuBYbc/ypr6dPn2L58uXS8+zsbCxfvhxubm4IDAwEUPL6b2FhgZ49e+KHH37AsWPHtLZryt2nTx8kJSVh165dWnkyMjLw9OlTg8oGlM01pShubm5o164dVq5ciatXr8q2acpqaWmJsLAwfPfdd7LlA2/evIl169ahTZs2pbYslCHjmoLq/Ysvvohff/0VSUlJUtrDhw+xYsUK1KpVS3ZPheLq3bs3hBA6v5Gc9z0LULrjFF3c3d3Rvn17LF++HDdu3JDSNWMazXuWyjLGr+jzQuVVb69fvy57T33v3j189dVXaNKkifTN79K4juWvK0qlEvXr14cQAjk5OeV6/Sgt5jwnwW/sm4jU1FT06NEDXbp0QVJSEr755hv069cPjRs3BgB89NFHmDhxIi5fvoyePXvCwcEBqamp2Lp1K4YNG4Z333230P2vWbMGS5cuxcsvvww/Pz/cv38fn3/+ORwdHaXOq3v37ujQoQMmTZqEy5cvo3Hjxti9eze+++47jBkzRnZDlNISERGBuXPnokuXLujXrx9u3bqFJUuWoE6dOrK1MwMDA9G7d2/Mnz8fd+7cQcuWLXHgwAHp08u8n2h++umn2L9/P4KCgjB06FDUr18f6enpOH78OPbs2YP09PRSLweRm5sbJk6ciLi4OHTp0gU9evRASkoKli5diubNm0s3fvP394efnx/effddXLt2DY6Ojti8eXOJ1p6zsbFB/fr1sX79ejz//PNwdXVFw4YN0bBhQ8yaNQtdu3ZFcHAwoqKi8PjxYyxatAhOTk6YOnVqqZT9vffew6ZNm/Dqq69iyJAhCAwMRHp6Or7//nvEx8ejcePGGDZsGJYvX45BgwYhOTkZtWrVwqZNm3D48GHMnz9faw3H4nJ0dMSyZcswYMAA/O9//0Pfvn3h5uaGq1evIiEhAa1bt9YapJqiytpnhISEYPjw4ZgxYwZOnjyJsLAwWFlZ4cKFC9i4cSMWLFiAV155pdSOZ21tjZ07dyIyMhJBQUH48ccfkZCQgPfff79EPysvi3KMGzcO33zzDTp37oxRo0bBzs4OX3zxBWrWrIn09HRZPxkYGIhly5bho48+Qp06deDu7l7gGpDFpZmsmTRpEvr27QsrKyt0794djRs3RmRkJFasWCEtj/Hrr79izZo16NmzJzp06GDwsYpqD35+fmbbJspiHDV+/HgcO3YM165dw86dO9GwYUPUqVMH586dw8WLF8u8Tytrmro5evRohIeHw9LSUnaj1OJo1aoVXFxcEBkZidGjR0OhUODrr7/W+RPxwMBArF+/HrGxsWjevDns7e3RvXt3DBgwABs2bMCIESOwf/9+tG7dGrm5uTh//jw2bNiAXbt26bwpqCFlLMs6qm/bNuRclRZjHFMfgYGB2LNnD+bOnQtvb2/4+vrqXKu5MMYcf+rL29sbn332GS5fvoznn38e69evx8mTJ7FixQppTfDSqP+ffPIJdu/ejZCQEAwbNgwBAQG4ceMGNm7ciEOHDsHZ2Rnvvfcevv/+e3Tr1g2DBg1CYGAgHj58iNOnT2PTpk24fPkyqlWrZlD5yuKaoo+FCxeiTZs2+N///odhw4bB19cXly9fRkJCgvQh/0cffYTExES0adMGb731FqpUqYLly5cjKysLM2fOLLVYDBnXFDQGmTBhAv7v//4PXbt2xejRo+Hq6oo1a9YgNTUVmzdv1loTuzg6dOiAAQMGYOHChbhw4QK6dOkCtVqNn3/+GR06dEBMTEyZjFMKsmTJErRp0waNGjWCv78/AOCXX36Bh4cHqlSpgo4dO1aaMX5Fnxcqr3r7/PPPIyoqCr/99hs8PDywcuVK3Lx5U/bLhdK4joWFhcHT0xOtW7eGh4cH/vjjDyxevBgRERHS+/Lyun6UFrOekxBUoU2ZMkUAEOfOnROvvPKKcHBwEC4uLiImJkY8fvxYlnfz5s2iTZs2ws7OTtjZ2Ql/f38RHR0tUlJSpDwhISGiQYMGWsc5fvy4eP3110XNmjWFSqUS7u7uolu3buLYsWOyfPfv3xdjx44V3t7ewsrKStStW1fMmjVLqNVqWT4AIjo6Wus4Pj4+IjIy0qBz8OWXX4q6desKlUol/P39xapVq6TzktfDhw9FdHS0cHV1Ffb29qJnz54iJSVFABCffvqpLO/NmzdFdHS0qFGjhrCyshKenp6iU6dOYsWKFQbFRlSYVatWCQAiNTVVSlu8eLHw9/cXVlZWwsPDQ4wcOVLcvXtX9rpz586J0NBQYW9vL6pVqyaGDh0qTp06JQCIVatWSfkiIyOFnZ2d1nF1tY8jR46IwMBAoVQqBQAxZcoUaduePXtE69athY2NjXB0dBTdu3cX586dK7IsPj4+IiIiQuv4ISEhIiQkRJZ2584dERMTI5577jmhVCpF9erVRWRkpPj333+lPDdv3hSDBw8W1apVE0qlUjRq1EhWXiGESE1NFQDErFmzZOn79+8XAMTGjRt1xv3bb79p5Q8PDxdOTk7C2tpa+Pn5iUGDBmld80wN+4xnVqxYIQIDA4WNjY1wcHAQjRo1EuPGjRPXr1+X7VtX/dUVi656p2l/f/31lwgLCxO2trbCw8NDTJkyReTm5hoUb2RkpPDx8SnVcuhqhydOnBBt27YVKpVKVK9eXcyYMUMsXLhQABBpaWlSvrS0NBERESEcHBwEAGk/hbUnAGL//v0GlXv69OniueeeExYWFrLrS05OjoiLixO+vr7CyspK1KhRQ0ycOFE8efLEoP0b0h6EMN82UVrjqLz9gGYc5ezsLAAIAEKpVIqQkJBy6dOKkr9NFdR3CCG0+sSnT5+KUaNGCTc3N6FQKAw6dkH1QwghDh8+LFq2bClsbGyEt7e3GDdunNi1a5dW23nw4IHo16+fdG7zliM7O1t89tlnokGDBkKlUgkXFxcRGBgo4uLiRGZmpt5xFlZGfetoUXT93fRt2/qeq4LOd0HX1MKU9Jj69ima83L79m1ZPl3jrPPnz4t27doJGxsbAUDvtl+Rxp9F0ZzPY8eOieDgYGFtbS18fHzE4sWLtfLqW/8Lun4KIcSVK1fEwIEDhZubm1CpVKJ27doiOjpaZGVlSXnu378vJk6cKOrUqSOUSqWoVq2aaNWqlZg9e7bIzs4WQpTfNaUk1zIhhDhz5ox4+eWXhbOzs7C2thb16tUTH374oSzP8ePHRXh4uLC3txe2traiQ4cO4siRI7I8BfX/BdXnguqIPuOagsYgQgjx119/iVdeeUUqT4sWLcT27dtlx9Cco+LW2adPn4pZs2YJf39/oVQqhZubm+jatatITk6W8uh7LSvpWFNT5oEDBwo7OzsBQLi7uwsvLy9hY2NT6cb4FXleqKT1Vh+a+rRr1y7xwgsvSOch//tfIUp+HVu+fLlo166dqFq1qlCpVMLPz0+89957WmONklw/ivP+gXMSuimEMPJXEahQU6dORVxcHG7fvm3wtwMIOHnyJJo2bYpvvvkG/fv3N3Y4RERlin1G+Rk0aBA2bdqEBw8eGDuUEhkzZgyWL1+OBw8eGP1m3KWN7aHkOI4iorLUvn17/Pvvv0Wue0xU2XFMUzLmMJ6pVasWGjZsiO3btxs7FKpguMY+mY3Hjx9rpc2fPx8WFhayG2ERERFVRvn7yTt37uDrr79GmzZtzG5SnwzHcRQRERGZOo5nqLLhGvtkFLm5uUXeEMLe3h729vZ673PmzJlITk5Ghw4dUKVKFfz444/48ccfMWzYsAp3R24iItJfWfQZ5SE9PR3Z2dkFbre0tCzRWvyGCg4ORvv27REQEICbN2/iyy+/xL179/Dhhx+W2jEePHhQ5K8Y3NzcSvRBgr7HMGeVdRxlrDZV0dpyQTIzM3VOaOSlubleRT5Gabp9+7bsZov5KZVKuLq6lmNElYOptBlj4fkheqaij2fKow9hP1U+7x/MmkEL91C5K2jdOlOnWZOqsEf+NQKLsnv3btG6dWvh4uIirKyshJ+fn5g6darIyckpm0IQEVUw7DPKT0HrteYVEhJSaMyGrgFdUhMnThR169YVNjY2wtbWVrRp00YkJiaW6jE0dbCwR951McvyGObaHoSovOMoY7WpitaWCxIZGVlkvTCFY5QmHx+fQmPNv/4ulQ5920xh96UwZ6ZyTaGKw1zHNBV9PFMefYi+xyhoLXlzUB7vH8wZ19gno3jy5AkOHTpUaJ7atWujdu3a5RQRERFVVKbaZyQnJ+Pu3bsFbrexsUHr1q3LMaKyd+nSJVy6dKnQPG3atIG1tXWFPkZFZ6ptoqSM1aZMpS2fO3cO169fLzRPaGhohT9GaTp8+HChvzBwcXFBYGBgOUZUOZhKmzEWnh+iZyr6eKY8+hD2UxzblxQn9omIiIiIiIiIiIiITEilXmNfrVbj+vXrcHBwgEKhMHY4RHoTQuD+/fvw9vaGhQXvgZ0f2zaZKrbtorF9k6li+y4c2zaZKrbtorF9k6li+y4c2zaZKrNq28ZaA6gi+Pvvv4tcx4kPPiry4++//zZ2M6qQ2Lb5MPUH23bB2L75MPUH27dubNt8mPqDbbtgbN98mPqjNNv3J598Ipo1aybs7e2Fm5ubeOmll8T58+dleR4/fizeeust4erqKuzs7ESvXr1EWlqaLM+VK1fEiy++KGxsbISbm5t49913tdaR379/v2jatKlQKpXCz89PrFq1SiuexYsXCx8fH6FSqUSLFi3EL7/8ondZ2Lb5MPWHOfTdlfob+w4ODgCAv//+G46OjkaOpvTk5ORg9+7dCAsLg5WVlbHDMQmmds7u3buHGjVqSHWY5Ipq26b29y4My1IxFbcsbNtFq0ztOy+Wy/TkLxvbd+EKa9vmXE8KU1nLDZhW2dm2i2aufTfjLl/GiLss2veBAwcQHR2N5s2b4+nTp3j//fcRFhaGc+fOwc7ODgAwduxYJCQkYOPGjXByckJMTAx69eqFw4cPAwByc3MREREBT09PHDlyBDdu3MDAgQNhZWWFTz75BACQmpqKiIgIjBgxAmvXrsXevXvx5ptvwsvLC+Hh4QCA9evXIzY2FvHx8QgKCsL8+fMRHh6OlJQUuLu7F1kWc23bhTHHMgHmWa7CymROfXelntjX/FTI0dHR7Cb2bW1t4ejoaDYNsqyZ6jnjz910K6ptm+rfWxeWpWIqaVnYtgtWmdp3XiyX6SmobGzfuhXWts25nhSmspYbMM2ys20XzFz7bsZdvowZd2m27507d8qer169Gu7u7khOTka7du2QmZmJL7/8EuvWrUPHjh0BAKtWrUJAQACOHj2Kli1bYvfu3Th37hz27NkDDw8PNGnSBNOnT8f48eMxdepUKJVKxMfHw9fXF3PmzAEABAQE4NChQ5g3b540sT937lwMHToUgwcPBgDEx8cjISEBK1euxIQJE/Q+L+bWtgtjjmUCzLNc+pTJHPruSj2xT0REREREREREZAyZmZkAAFdXVwBAcnIycnJyEBoaKuXx9/dHzZo1kZSUhJYtWyIpKQmNGjWCh4eHlCc8PBwjR47E2bNn0bRpUyQlJcn2ockzZswYAEB2djaSk5MxceJEabuFhQVCQ0ORlJSkM9asrCxkZWVJz+/duwfg2QRqTk6OVn5Nmq5tpsocywSYZ7kKK5M5lZMT+0REREREREREROVIrVZjzJgxaN26NRo2bAgASEtLg1KphLOzsyyvh4cH0tLSpDx5J/U12zXbCstz7949PH78GHfv3kVubq7OPOfPn9cZ74wZMxAXF6eVvnv3btja2hZYzsTExAK3mSpzLBNgnuXSVaZHjx4ZIZKywYn9ItSakKCVdvnTCCNEQkRlTVd7B9jmiUxRw6m7kJX7308r2Y6JTF/+dg2wbROZE/bdVNlER0fjzJkzOHTokLFD0cvEiRMRGxsrPdesUx4WFlbgUjyJiYno3LmzbCmUhlN36dz/manhpR90KSuoTKbOHMtVWJk0vzYxB5zYJyIiIiIiIiIiKicxMTHYvn07Dh48iOrVq0vpnp6eyM7ORkZGhuxb+zdv3oSnp6eU59dff5Xt7+bNm9I2zb+atLx5HB0dYWNjA0tLS1haWurMo9lHfiqVCiqVSivdysqq0Mng/Nvzf0ivUffD3VppFfUDvqLKbKrMsVy6ymROZbQwdgBERERERERERETmTgiBmJgYbN26Ffv27YOvr69se2BgIKysrLB3714pLSUlBVevXkVwcDAAIDg4GKdPn8atW7ekPImJiXB0dET9+vWlPHn3ocmj2YdSqURgYKAsj1qtxt69e6U8RFTx8Rv7REREREREREREZSw6Ohrr1q3Dd999BwcHB2lNfCcnJ9jY2MDJyQlRUVGIjY2Fq6srHB0dMWrUKAQHB6Nly5YAgLCwMNSvXx8DBgzAzJkzkZaWhg8++ADR0dHSN+pHjBiBxYsXY9y4cRgyZAj27duHDRs2ICHhv+VnY2NjERkZiWbNmqFFixaYP38+Hj58iMGDB5f/iSGiYuE39omIiIiITNCMGTPQvHlzODg4wN3dHT179kRKSoosz5MnTxAdHY2qVavC3t4evXv31vrZ/dWrVxEREQFbW1u4u7vjvffew9OnT2V5fvrpJ/zvf/+DSqVCnTp1sHr1aq14lixZglq1asHa2hpBQUFaywQQERFVdsuWLUNmZibat28PLy8v6bF+/Xopz7x589CtWzf07t0b7dq1g6enJ7Zs2SJtt7S0xPbt22FpaYng4GC88cYbGDhwIKZNmybl8fX1RUJCAhITE9G4cWPMmTMHX3zxBcLD/1vH/rXXXsPs2bMxefJkNGnSBCdPnsTOnTu1bqhLRBUXv7FPRERERGSCDhw4gOjoaDRv3hxPnz7F+++/j7CwMJw7dw52dnYAgLFjxyIhIQEbN26Ek5MTYmJi0KtXLxw+fBgAkJubi4iICHh6euLIkSO4ceMGBg4cCCsrK3zyyScAgNTUVERERGDEiBFYu3Yt9u7dizfffBNeXl7SBMH69esRGxuL+Ph4BAUFYf78+QgPD0dKSgrc3d2Nc4KIiIgqGCFEkXmsra2xZMkSLFmypMA8Pj4+2LFjR6H7ad++PU6cOFFonpiYGMTExBQZExFVTJzYL4ZaExK00irqDT2IiIiIyDzt3LlT9nz16tVwd3dHcnIy2rVrh8zMTHz55ZdYt24dOnbsCABYtWoVAgICcPToUbRs2RK7d+/GuXPnsGfPHnh4eKBJkyaYPn06xo8fj6lTp0KpVCI+Ph6+vr6YM2cOACAgIACHDh3CvHnzpIn9uXPnYujQodLP9+Pj45GQkICVK1diwoQJ5XhWiIiIiIgqB07sExERERGZgczMTACAq6srACA5ORk5OTkIDQ2V8vj7+6NmzZpISkpCy5YtkZSUhEaNGsl+dh8eHo6RI0fi7NmzaNq0KZKSkmT70OQZM2YMACA7OxvJycmYOHGitN3CwgKhoaFISkrSGWtWVhaysrKk5/fu3QMA5OTkICcnR5ZX81xlof0tx/x5zYmmbOZcxoKYUtlNIUYiIiIyT5zYJyIiIiIycWq1GmPGjEHr1q3RsGFDAEBaWhqUSiWcnZ1leT08PKSb9aWlpWmtpat5XlSee/fu4fHjx7h79y5yc3N15jl//rzOeGfMmIG4uDit9N27d8PW1lbna6Y3U2ulFbUMgTlITEw0dghGYwplf/TokbFDICIiokqKE/tERERERCYuOjoaZ86cwaFDh4wdil4mTpyI2NhY6fm9e/dQo0YNhIWFwdHRUZY3JycHiYmJ+PCYBbLUCtm2M1PDYa405e7cuTOsrKyMHU65MqWya35tQkRERFTeOLFPRERERGTCYmJisH37dhw8eBDVq1eX0j09PZGdnY2MjAzZt/Zv3rwJT09PKc+vv/4q29/NmzelbZp/NWl58zg6OsLGxgaWlpawtLTUmUezj/xUKhVUKpVWupWVVYETuVlqBbJy5RP7dT/crTOvOd3/qrBzYu5MoewVPT4iIiIyXxbGDoCIiIiIiAwnhEBMTAy2bt2Kffv2wdfXV7Y9MDAQVlZW2Lt3r5SWkpKCq1evIjg4GAAQHByM06dP49atW1KexMREODo6on79+lKevPvQ5NHsQ6lUIjAwUJZHrVZj7969Uh4iIiIiIipdnNgnIgDP1rpt3rw5HBwc4O7ujp49eyIlJUWW58mTJ4iOjkbVqlVhb2+P3r17a3077+rVq4iIiICtrS3c3d3x3nvv4enTp7I8P/30E/73v/9BpVKhTp06WL16tVY8S5YsQa1atWBtbY2goCCtbxMSERFVdtHR0fjmm2+wbt06ODg4IC0tDWlpaXj8+DEAwMnJCVFRUYiNjcX+/fuRnJyMwYMHIzg4GC1btgQAhIWFoX79+hgwYABOnTqFXbt24YMPPkB0dLT0jfoRI0bg0qVLGDduHM6fP4+lS5diw4YNGDt2rBRLbGwsPv/8c6xZswZ//PEHRo4ciYcPH2Lw4MHlf2KIiIiIiCoBTuwTEQDgwIEDiI6OxtGjR5GYmIicnByEhYXh4cOHUp6xY8fihx9+wMaNG3HgwAFcv34dvXr1krbn5uYiIiIC2dnZOHLkCNasWYPVq1dj8uTJUp7U1FRERESgQ4cOOHnyJMaMGYM333wTu3btkvKsX78esbGxmDJlCo4fP47GjRsjPDxc9m1CIiKiym7ZsmXIzMxE+/bt4eXlJT3Wr18v5Zk3bx66deuG3r17o127dvD09MSWLVuk7ZaWlti+fTssLS0RHByMN954AwMHDsS0adOkPL6+vkhISEBiYiIaN26MOXPm4IsvvkB4+H/r27/22muYPXs2Jk+ejCZNmuDkyZPYuXOn1g11iYiIiIiodHCN/VJSa0KCVpo5re1J5m/nzp2y56tXr4a7uzuSk5PRrl07ZGZm4ssvv8S6devQsWNHAMCqVasQEBCAo0ePomXLlti9ezfOnTuHPXv2wMPDA02aNMH06dMxfvx4TJ06FUqlEvHx8fD19cWcOXMAAAEBATh06BDmzZsnTRDMnTsXQ4cOlb7lFx8fj4SEBKxcuRITJkzQij0rKwtZWVnSc81NzHJycpCTk6OVX5OWf5vKUug8N7r2UVEUVBZTxLKYR9mJqPwIobvfysva2hpLlizBkiVLCszj4+ODHTt2FLqf9u3b48SJE4XmiYmJQUxMTJExERERERFRyXFin4h0yszMBAC4uroCAJKTk5GTk4PQ0FApj7+/P2rWrImkpCS0bNkSSUlJaNSokezbeeHh4Rg5ciTOnj2Lpk2bIikpSbYPTZ4xY8YAALKzs5GcnIyJEydK2y0sLBAaGoqkpCSdsc6YMQNxcXFa6bt374atrW2BZUxMTJQ9n9lCd76iJjsqgvxlMWWVuSyPHj0qo0iIiIiIiIiIyJxwYp+ItKjVaowZMwatW7dGw4YNAQBpaWlQKpVwdnaW5fXw8EBaWpqUJ/9P7jXPi8pz7949PH78GHfv3kVubq7OPOfPn9cZ78SJExEbGys9v3fvHmrUqIGwsDA4Ojpq5c/JyUFiYiI6d+4MKysrKb3h1F1aeQHgzNRwnekVQUFlMUUsy3+/NiEiIiIiIiIiKgwn9olIS3R0NM6cOYNDhw4ZOxS9qFQq6QZ/eVlZWRU6qdr0433IylXkSVHozGcKk8xFldWUVOaymEu5iYiIiIiIiKhs8ea5RCQTExOD7du3Y//+/ahevbqU7unpiezsbGRkZMjy37x5E56enlKemzdvam3XbCssj6OjI2xsbFCtWjVYWlrqzKPZBxERERERERERUWXGiX0iAvDsBnwxMTHYunUr9u3bB19fX9n2wMBAWFlZYe/evVJaSkoKrl69iuDgYABAcHAwTp8+jVu3bkl5EhMT4ejoiPr160t58u5Dk0ezD6VSicDAQFketVqNvXv3SnmIiIiIiIiIiIgqM07sExGAZ8vvfPPNN1i3bh0cHByQlpaGtLQ0PH78GADg5OSEqKgoxMbGYv/+/UhOTsbgwYMRHByMli1bAgDCwsJQv359DBgwAKdOncKuXbvwwQcfIDo6WloqZ8SIEbh06RLGjRuH8+fPY+nSpdiwYQPGjh0rxRIbG4vPP/8ca9aswR9//IGRI0fi4cOHGDx4cPmfGCIiIiKicjRjxgw0b94cDg4OcHd3R8+ePZGSkiLL8+TJE0RHR6Nq1aqwt7dH7969tX7xevXqVURERMDW1hbu7u5477338PTpU1men376Cf/73/+gUqlQp04drF69WiueJUuWoFatWrC2tkZQUBB+/fXXUi8zERERGY4T+0QEAFi2bBkyMzPRvn17eHl5SY/169dLeebNm4du3bqhd+/eaNeuHTw9PbFlyxZpu6WlJbZv3w5LS0sEBwfjjTfewMCBAzFt2jQpj6+vLxISEpCYmIjGjRtjzpw5+OKLLxAe/t8Nal977TXMnj0bkydPRpMmTXDy5Ens3LlT64a6RERERETm5sCBA4iOjsbRo0eRmJiInJwchIWF4eHDh1KesWPH4ocffsDGjRtx4MABXL9+Hb169ZK25+bmIiIiAtnZ2Thy5AjWrFmD1atXY/LkyVKe1NRUREREoEOHDjh58iTGjBmDN998E7t27ZLyrF+/HrGxsZgyZQqOHz+Oxo0bIzw8XPYLXSIiIjIO3jyXiAA8W4qnKNbW1liyZAmWLFlSYB4fHx/s2LGj0P20b98eJ06cKDRPTEwMYmJiioyJiIiIiMic7Ny5U/Z89erVcHd3R3JyMtq1a4fMzEx8+eWXWLduHTp27AgAWLVqFQICAnD06FG0bNkSu3fvxrlz57Bnzx54eHigSZMmmD59OsaPH4+pU6dCqVQiPj4evr6+mDNnDgAgICAAhw4dwrx586Qv3cydOxdDhw6VfjkbHx+PhIQErFy5EhMmTNAZf1ZWFrKysqTn9+7dAwDk5OQgJydHK78mTWUhdKZXVJr4Knqc+TFuw49JRFRRcWKfiIiIiIiIqILKzMwEALi6ugIAkpOTkZOTg9DQUCmPv78/atasiaSkJLRs2RJJSUlo1KiR7Bev4eHhGDlyJM6ePYumTZsiKSlJtg9NnjFjxgAAsrOzkZycjIkTJ0rbLSwsEBoaiqSkpALjnTFjBuLi4rTSd+/eDVtb2wJfN72ZWva8qC8LVRSJiYnGDqFYGHfRHj16VG7HIiIqDk7sExEREREREVVAarUaY8aMQevWrdGwYUMAQFpaGpRKJZydnWV5PTw8kJaWJuXJv4yl5nlRee7du4fHjx/j7t27yM3N1Znn/PnzBcY8ceJExMbGSs/v3buHGjVqICwsDI6Ojlr5c3JykJiYiA+PWSBLrZDSz0wN18pbkWji7ty5M6ysrIwdjt4Yt/40vzYhIqqoOLFPREREREREVAFFR0fjzJkzOHTokLFD0ZtKpYJKpdJKt7KyKnRCNkutQFauQpbfFBRVroqKcet3LCKiiow3zyUiIiIiIiKqYGJiYrB9+3bs378f1atXl9I9PT2RnZ2NjIwMWf6bN2/C09NTynPz5k2t7ZptheVxdHSEjY0NqlWrBktLS515NPsgIiIi4+HEPhEREREREVEFIYRATEwMtm7din379sHX11e2PTAwEFZWVti7d6+UlpKSgqtXryI4OBgAEBwcjNOnT+PWrVtSnsTERDg6OqJ+/fpSnrz70OTR7EOpVCIwMFCWR61WY+/evVIeIiIiMh4uxUNERERERERUQURHR2PdunX47rvv4ODgIK2J7+TkBBsbGzg5OSEqKgqxsbFwdXWFo6MjRo0aheDgYLRs2RIAEBYWhvr162PAgAGYOXMm0tLS8MEHHyA6OlpaJmfEiBFYvHgxxo0bhyFDhmDfvn3YsGEDEhISpFhiY2MRGRmJZs2aoUWLFpg/fz4ePnyIwYMHl/+JISIiIhmDv7F/8OBBdO/eHd7e3lAoFNi2bZtsuxACkydPhpeXF2xsbBAaGooLFy7I8qSnp6N///5wdHSEs7MzoqKi8ODBA1me33//HW3btoW1tTVq1KiBmTNnasWyceNG+Pv7w9raGo0aNcKOHTsMLQ4RERERERFRhbFs2TJkZmaiffv28PLykh7r16+X8sybNw/dunVD79690a5dO3h6emLLli3SdktLS2zfvh2WlpYIDg7GG2+8gYEDB2LatGlSHl9fXyQkJCAxMRGNGzfGnDlz8MUXXyA8/L+b1r722muYPXs2Jk+ejCZNmuDkyZPYuXOn1g11iYiIqPwZ/I39hw8fonHjxhgyZAh69eqltX3mzJlYuHAh1qxZA19fX3z44YcIDw/HuXPnYG1tDQDo378/bty4gcTEROTk5GDw4MEYNmwY1q1bB+DZncfDwsIQGhqK+Ph4nD59GkOGDIGzszOGDRsGADhy5Ahef/11zJgxA926dcO6devQs2dPHD9+HA0bNizJOSEiIiIiIiIyCiFEkXmsra2xZMkSLFmypMA8Pj4+RX75rX379jhx4kSheWJiYhATE1NkTERERFS+DJ7Y79q1K7p27apzmxAC8+fPxwcffICXXnoJAPDVV1/Bw8MD27ZtQ9++ffHHH39g586d+O2339CsWTMAwKJFi/Diiy9i9uzZ8Pb2xtq1a5GdnY2VK1dCqVSiQYMGOHnyJObOnStN7C9YsABdunTBe++9BwCYPn06EhMTsXjxYsTHxxfrZBARERERERGR8dWakKCVdvnTCCNEQkREVDGV6hr7qampSEtLQ2hoqJTm5OSEoKAgJCUloW/fvkhKSoKzs7M0qQ8AoaGhsLCwwC+//IKXX34ZSUlJaNeuHZRKpZQnPDwcn332Ge7evQsXFxckJSUhNjZWdvzw8HCtpYHyysrKQlZWlvT83r17AICcnBzk5OTofI3KsuhvSxSkoH2WNc1xjXV8U2Rq58xU4iQiIiIiIiIiIqLSV6oT+5qb+uRfb8/Dw0PalpaWBnd3d3kQVarA1dVVlsfX11drH5ptLi4uSEtLK/Q4usyYMQNxcXFa6bt374atra3O18xsUeDuimTsNf8TExONenxTZCrn7NGjR8YOgYhMxIwZM7BlyxacP38eNjY2aNWqFT777DPUq1dPyvPkyRO88847+Pbbb5GVlYXw8HAsXbpU1s9evXoVI0eOxP79+2Fvb4/IyEjMmDEDVar8N5T46aefEBsbi7Nnz6JGjRr44IMPMGjQIFk8S5YswaxZs5CWlobGjRtj0aJFaNGiBJ0tERERERERUSVUqhP7Fd3EiRNl3/K/d+8eatSogbCwMDg6Oup8TcOpu4p9vDNTw4vOVAZycnKQmJiIzp07w8rKyigxmBpTO2eaX5sQERXlwIEDiI6ORvPmzfH06VO8//77CAsLw7lz52BnZwcAGDt2LBISErBx40Y4OTkhJiYGvXr1wuHDhwEAubm5iIiIgKenJ44cOYIbN25g4MCBsLKywieffALg2a/2IiIiMGLECKxduxZ79+7Fm2++CS8vL+kmfOvXr0dsbCzi4+MRFBSE+fPnIzw8HCkpKVof+hMRERERERFRwUp1Yt/T0xMAcPPmTXh5eUnpN2/eRJMmTaQ8t27dkr3u6dOnSE9Pl17v6emJmzdvyvJonheVR7NdF5VKBZVKpZVuZWVV4GRuVq6iwP0VxdgTxIWVi3QzlXNmCjESUcWwc+dO2fPVq1fD3d0dycnJaNeuHTIzM/Hll19i3bp16NixIwBg1apVCAgIwNGjR9GyZUvs3r0b586dw549e+Dh4YEmTZpg+vTpGD9+PKZOnQqlUon4+Hj4+vpizpw5AICAgAAcOnQI8+bNkyb2586di6FDh2Lw4MEAgPj4eCQkJGDlypWYMGGCzvgNXUZPk6ayEDrTTZWpLRmnL3MtF6BdNnMsIxERERERGU+pTuz7+vrC09MTe/fulSby7927h19++QUjR44EAAQHByMjIwPJyckIDAwEAOzbtw9qtRpBQUFSnkmTJiEnJ0eawExMTES9evXg4uIi5dm7dy/GjBkjHT8xMRHBwcGlWSQiIiKzkpmZCQBwdXUFACQnJyMnJ0d2fxx/f3/UrFkTSUlJaNmyJZKSktCoUSPZ0jzh4eEYOXIkzp49i6ZNmyIpKUm2D00eTT+dnZ2N5ORkTJw4UdpuYWGB0NBQJCUlFRhvcZbRA4DpzdSy58ZeHq+0mMqScYYy13IB/5WNy+gREREREVFpMnhi/8GDB7h48aL0PDU1FSdPnoSrqytq1qyJMWPG4KOPPkLdunXh6+uLDz/8EN7e3ujZsyeAZ9/g69KlC4YOHYr4+Hjk5OQgJiYGffv2hbe3NwCgX79+iIuLQ1RUFMaPH48zZ85gwYIFmDdvnnTct99+GyEhIZgzZw4iIiLw7bff4tixY1ixYkUJTwkREZF5UqvVGDNmDFq3bo2GDRsCeHbvGqVSCWdnZ1ne/PfH0XVfG822wvLcu3cPjx8/xt27d5Gbm6szz/nz5wuM2dBl9DRLq314zAJZ6v9+dWes5fFKi6ktGacvcy0XoF02LqNHRERERESlycLQFxw7dgxNmzZF06ZNAQCxsbFo2rQpJk+eDAAYN24cRo0ahWHDhqF58+Z48OABdu7cCWtra2kfa9euhb+/Pzp16oQXX3wRbdq0kU3IOzk5Yffu3UhNTUVgYCDeeecdTJ48GcOGDZPytGrVCuvWrcOKFSvQuHFjbNq0Cdu2bZMmKoiIiEguOjoaZ86cwbfffmvsUPSmUqng6OgoewD/LZ2m6wEAWWoFsnL/exSW31QeRZXbVB/mWi5dZSMiIqLK7eDBg+jevTu8vb2hUCiwbds22XYhBCZPngwvLy/Y2NggNDQUFy5ckOVJT09H//794ejoCGdnZ0RFReHBgweyPL///jvatm0La2tr1KhRAzNnztSKZePGjfD394e1tTUaNWpkNr9wJapMDP7Gfvv27SGEKHC7QqHAtGnTMG3atALzuLq6Yt26dYUe54UXXsDPP/9caJ5XX30Vr776auEBExEREWJiYrB9+3YcPHgQ1atXl9I9PT2RnZ2NjIwM2bf28963xtPTE7/++qtsf/re+8bR0RE2NjawtLSEpaWlwffHISIiIiIyFw8fPkTjxo0xZMgQ9OrVS2v7zJkzsXDhQqxZs0ZaBSM8PBznzp2TvjDbv39/3LhxA4mJicjJycHgwYMxbNgwaZ7t3r17CAsLQ2hoKOLj43H69GkMGTIEzs7O0hdmjxw5gtdffx0zZsxAt27dsG7dOvTs2RPHjx/nF2aJTEiprrFPREREFYsQAqNGjcLWrVvx008/wdfXV7Y9MDAQVlZW2Lt3L3r37g0ASElJwdWrV6X71gQHB+Pjjz/GrVu34O7uDuDZuuGOjo6oX7++lCf/t3zy3vtGqVQiMDAQe/fulZbnU6vV2Lt3L2JiYsqs/Bq1JiRopV3+NKLMj0tEREREpNG1a1d07dpV5zYhBObPn48PPvgAL730EgDgq6++goeHB7Zt24a+ffvijz/+wM6dO/Hbb7+hWbNmAIBFixbhxRdfxOzZs+Ht7Y21a9ciOzsbK1euhFKpRIMGDXDy5EnMnTtXmthfsGABunTpgvfeew8AMH36dCQmJmLx4sWIj4/XGV9WVhaysrKk55plBnNycpCTk6OVX5OWf5vKsuAvCxe0j4qioDKZOnMsV2FlMqdycmKfiIjIjEVHR2PdunX47rvv4ODgIK2J7+TkBBsbGzg5OSEqKgqxsbFwdXWFo6MjRo0aheDgYLRs2RIAEBYWhvr162PAgAGYOXMm0tLS8MEHHyA6OhoqlQoAMGLECCxevBjjxo3DkCFDsG/fPmzYsAEJCf9NqMfGxiIyMhLNmjVDixYtMH/+fDx8+BCDBw8u/xNDRERERFSBpKamIi0tDaGhoVKak5MTgoKCkJSUhL59+yIpKQnOzs7SpD4AhIaGwsLCAr/88gtefvllJCUloV27dlAqlVKe8PBwfPbZZ7h79y5cXFyQlJQku4+VJk/+pYHymjFjBuLi4rTSd+/eDVtb2wJfl5iYKHs+s0WBWbVU1OWB8pfJXJhjuXSV6dGjR0aIpGxwYp+IiMiMLVu2DMCzpfTyWrVqFQYNGgQAmDdvHiwsLNC7d29kZWUhPDwcS5culfJaWlpi+/btGDlyJIKDg2FnZ4fIyEjZsnu+vr5ISEjA2LFjsWDBAlSvXh1ffPEFwsP/u2nta6+9htu3b2Py5MlIS0tDkyZNsHPnTq0b6hKRfg4ePIhZs2YhOTkZN27cwNatW6VfxADPvvk3ZcoUfP7558jIyEDr1q2xbNky1K1bV8qTnp6OUaNG4YcffpCuAwsWLIC9vb2U5/fff0d0dDR+++03uLm5YdSoURg3bpwslo0bN+LDDz/E5cuXUbduXXz22Wd48cUXy/wcEBERmQvNF3Dyj409PDykbWlpadIvaDWqVKkCV1dXWZ78v9LV7DMtLQ0uLi5IS0sr9Di6TJw4UfZhwL1791CjRg2EhYVJ98HKKycnB4mJiejcubPsXkMNp+4q8Bj5nZkaXnSmclRQmUydOZarsDJpfm1iDjixT0REZMYKuy+OhrW1NZYsWYIlS5YUmMfHx6fIb8y0b98eJ06cKDRPTExMuSy9Q1QZcJ1eIiIiKi8qlUr6tW5eVlZWhU4G59+elavQ+5h1P9ytlVYRltMsqsymyhzLpatM5lRGTuwTEREREZmgyrJOr+a5ysJ01+QtDnNc71ZfplR2U4iRiEyDp6cnAODmzZvw8vKS0m/evIkmTZpIeW7duiV73dOnT5Geni693tPTEzdv3pTl0TwvKo9mOxGZBk7sExERERGZGXNcp3d6M7W+xa+wa/IWhzmud6svUyi7Oa3TS0TG5evrC09PT+zdu1eayL937x5++eUXjBw5EgAQHByMjIwMJCcnIzAwEACwb98+qNVqBAUFSXkmTZqEnJwc6ZvJiYmJqFevHlxcXKQ8e/fuxZgxY6TjJyYmIjg4uJxKS0SlgRP7RASA6/QSERGZE3Nap1ezRuqHxyyQpdbv5/sVbU3e4jDH9W71ZUplN6d1eomo7D148AAXL16UnqempuLkyZNwdXVFzZo1MWbMGHz00UeoW7eutIyet7e39N48ICAAXbp0wdChQxEfH4+cnBzExMSgb9++8Pb2BgD069cPcXFxiIqKwvjx43HmzBksWLAA8+bNk4779ttvIyQkBHPmzEFERAS+/fZbHDt2DCtWrCjX80FEJcOJfSICwHV6iYiIqPwUZ53eLLVC73V5K/pksCHMcb1bfZlC2St6fERUsRw7dgwdOnSQnms+5I6MjMTq1asxbtw4PHz4EMOGDUNGRgbatGmDnTt3Su+5AWDt2rWIiYlBp06dpC/ULVy4UNru5OSE3bt3Izo6GoGBgahWrRomT54svecGgFatWmHdunX44IMP8P7776Nu3brYtm0b33MTmRhO7BMRgMqzTq8mHdB/rd56k7ZrpVWUbwKa0hq0RWFZzKPsRFQxcJ1eIiKiiqd9+/YQouD3oQqFAtOmTcO0adMKzOPq6ip9ea4gL7zwAn7++edC87z66qt49dVXCw+YiCo0TuwTUZHMcZ1ewLC1evOraGv3msIatPqqzGXhOr1EVFq4Ti8RERERkXnjxD4RFcmc1ukFirdWb34V6Rv7prIGbVFYFq7TS0SG4Tq9ROaL978iIiKionBin4hMXnHW6QUMW6tX174rElNYg1Zflbks5lJuIiofXKe3YLUmJGilXf40wgiREBUP739FREREReHEPhEViev0EhERVTxcp5fIfPH+V7pVpPsRmer9oRi34cckIqqoOLFPREXiOr1ERERERBVDZb7/VUW7zxVguveHYtxF4/2viKii48Q+EQHgOr1ERERERKagMt//qqLc5wow3ftDMW798f5XRFTRcWKfiABwnV4iIiIiIiq5srz/VUWciDbV+0Mxbv2ORURUkXFin4gAcJ1eIiIiIiJTwPtfEREREQBYGDsAIiIiIiIiItJP3vtfaWjuf6W5L1Xe+19p6Lr/1cGDB2U3CC3o/ld58f5XREREFQMn9omIiIiIiIgqkAcPHuDkyZM4efIkgP/uf3X16lUoFArp/lfff/89Tp8+jYEDBxZ4/6tff/0Vhw8f1nn/K6VSiaioKJw9exbr16/HggULZOvjv/3229i5cyfmzJmD8+fPY+rUqTh27BhiYmLK+5QQERFRPlyKpwzVmpCgM/3ypxHlHAkRERERERGZCt7/ioiIiIrCiX0iIiIiIiKiCoT3vyIiIqKicCkeIiIiIiIiIiIiIiITwm/sExEREREREVGFp2u5Wy51S0RElRUn9o2AgxEiIiIiIiIiIiIiKi4uxUNEREREREREREREZEL4jX0iIiIiIiIiIiKq8HStggFwJQyqnPiNfSIiIiIiIiIiIiIiE8KJfSIiIiIiIiIiIiIiE8KJfSIiIiIiIiIiIiIiE8KJfSIiIiIiIiIiIiIiE8Kb5xIRERERkdnTdbM93miPiIiIiEwVJ/aJiIqBkwNERERERERERGQsXIqHiIiIiIiIiIiIiMiE8Bv7REREVCnxlzdERESmT1d/DrBPJ6ooGk7dhaxchbHDIDJL/MY+EREREREREREREZEJ4Tf2Kwh+a5CIiIiIiIiIiIiI9MGJfSIiIiIiqpS4hAcRERERmSpO7FdgfKNBRERERERERERUOK6EQZURJ/aJiIiIiIiIyKxwko+IiMwdJ/aJiIiIiIjy4IQgEREREVV0FsYOoKSWLFmCWrVqwdraGkFBQfj111+NHRIRlRK2byLzxLZNZL7YvonME9s2kfky5/Zda0KC1oPInJj0N/bXr1+P2NhYxMfHIygoCPPnz0d4eDhSUlLg7u5u7PDKDL9BRJWBKbZv3heDqGim2LaJSD/m3r45BqfKypzaNtsxkZw5tW+iysikJ/bnzp2LoUOHYvDgwQCA+Ph4JCQkYOXKlZgwYYJW/qysLGRlZUnPMzMzAQDp6enIycnReYwqTx+WQeSlr867G6T/qywEPmiqRpNJW5ClVmjl/WVip/IMzSTk5OTg0aNHuHPnDqysrIwdTpHu378PABBCGDmSsmNI+za0bWv+3lVyLJCro42Utjt37pTZvk2t7haGZWHbLo2+u6Ttuyzba0mYU/vIy1zLBWiXje27+H13effbhsg7Bi+Owsbl5tw+imJKZWfbNn7fXVIFteOi3jebUj3Ni3Hrj+3btN5366u4bR4w3fZTFHMsV2FlMqu2LUxUVlaWsLS0FFu3bpWlDxw4UPTo0UPna6ZMmSIA8MGH2Tz+/vvvcmht5c/Q9s22zYe5Pdi2/8P2zYe5Pdi+n2Hb5sPcHmzb/2H75sPcHmzfz7Bt82FuD3No2yb7jf1///0Xubm58PDwkKV7eHjg/PnzOl8zceJExMbGSs/VajXS09NRtWpVKBQV59PDkrp37x5q1KiBv//+G46OjsYOxySY2jkTQuD+/fvw9vY2dihlwtD2bWjbNrW/d2FYloqpuGVh29ZWmdt3XiyX6clfNrZvOUPatjnXk8JU1nIDplV2tm1tlaXvZtzlyxhxs33LVZa2XRhzLBNgnuUqrEzm1LZNdmK/OFQqFVQqlSzN2dnZOMGUA0dHR7NpkOXFlM6Zk5OTsUOoMIrbtk3p710UlqViKk5Z2Lbl2L7lWC7Tk7dsbN//KU7bNud6UpjKWm7AdMrOti1X2fpuxl2+yjtutu//VLa2XRhzLBNgnuUqqEzm0rYtjB1AcVWrVg2Wlpa4efOmLP3mzZvw9PQ0UlREVBrYvonME9s2kfli+yYyT2zbROaL7ZvI9JnsxL5SqURgYCD27t0rpanVauzduxfBwcFGjIyISortm8g8sW0TmS+2byLzxLZNZL7YvolMn0kvxRMbG4vIyEg0a9YMLVq0wPz58/Hw4UPpbt6VlUqlwpQpU7R+IkUF4zmreMqyfZvT35tlqZjMqSylraz7bnM99yyX6THnshWkrNp3ZTyXQOUtN1C5y14Rse/WjXGXL1ONu6Lj+27DmGOZAPMslzmWSReFEEIYO4iSWLx4MWbNmoW0tDQ0adIECxcuRFBQkLHDIqJSwPZNZJ7YtonMF9s3kXli2yYyX2zfRKbL5Cf2iYiIiIiIiIiIiIgqE5NdY5+IiIiIiIiIiIiIqDLixD4RERERERERERERkQnhxD4RERERERERERERkQnhxD4RERERERERERERkQnhxL6Jmjp1KhQKhezh7+8vbX/y5Amio6NRtWpV2Nvbo3fv3rh586YRIy5/Bw8eRPfu3eHt7Q2FQoFt27bJtgshMHnyZHh5ecHGxgahoaG4cOGCLE96ejr69+8PR0dHODs7IyoqCg8ePCjHUlBZWLJkCWrVqgVra2sEBQXh119/NXZIBiuqfpuKGTNmoHnz5nBwcIC7uzt69uyJlJQUY4dVLMuWLcMLL7wAR0dHODo6Ijg4GD/++KOxw6pUzKFt52dObaQwn376KRQKBcaMGWPsUErs2rVreOONN1C1alXY2NigUaNGOHbsmLHDqnAMba8bN26Ev78/rK2t0ahRI+zYsUO2XZ9xXUVQ2uXesmULwsLCULVqVSgUCpw8ebIMoy++0ix3Tk4Oxo8fj0aNGsHOzg7e3t4YOHAgrl+/XtbFoDJgan23ufTLptTvsl81HmP01eUxB1Pe5bp8+TKioqLg6+sLGxsb+Pn5YcqUKcjOzjbZMuWVlZWFJk2alMk4xFjlSkhIQFBQEGxsbODi4oKePXuWZrFKlyCTNGXKFNGgQQNx48YN6XH79m1p+4gRI0SNGjXE3r17xbFjx0TLli1Fq1atjBhx+duxY4eYNGmS2LJliwAgtm7dKtv+6aefCicnJ7Ft2zZx6tQp0aNHD+Hr6yseP34s5enSpYto3LixOHr0qPj5559FnTp1xOuvv17OJaHS9O233wqlUilWrlwpzp49K4YOHSqcnZ3FzZs3jR2aQYqq36YiPDxcrFq1Spw5c0acPHlSvPjii6JmzZriwYMHxg7NYN9//71ISEgQf/75p0hJSRHvv/++sLKyEmfOnDF2aJWCubTt/MypjRTk119/FbVq1RIvvPCCePvtt40dTomkp6cLHx8fMWjQIPHLL7+IS5cuiV27domLFy8aO7QKxdD2evjwYWFpaSlmzpwpzp07Jz744ANhZWUlTp8+LeXRZ1xnbGVR7q+++krExcWJzz//XAAQJ06cKKfS6K+0y52RkSFCQ0PF+vXrxfnz50VSUpJo0aKFCAwMLM9iUSkwxb7bHPplU+p32a8aj7H66rKegzFGuX788UcxaNAgsWvXLvHXX3+J7777Tri7u4t33nnHZMuU1+jRo0XXrl1LfRxirHJt2rRJuLi4iGXLlomUlBRx9uxZsX79+lIrV2njxL6JmjJlimjcuLHObRkZGcLKykps3LhRSvvjjz8EAJGUlFROEVYs+Sc+1Wq18PT0FLNmzZLSMjIyhEqlEv/3f/8nhBDi3LlzAoD47bffpDw//vijUCgU4tq1a+UWO5WuFi1aiOjoaOl5bm6u8Pb2FjNmzDBiVCVjyhP7+d26dUsAEAcOHDB2KKXCxcVFfPHFF8YOo1Iwx7ati7m1kfv374u6deuKxMREERISUuEnGIoyfvx40aZNG2OHUeEZ2l779OkjIiIiZGlBQUFi+PDhQgj9xnUVQWmXO6/U1NQKO7FfluXW+PXXXwUAceXKldIJmsqFOfTdptYvm1q/y37VeIzRV5fHHExFGYPMnDlT+Pr6lqQoEmOWaceOHcLf31+cPXu21MchxihXTk6OeO6550zqPTyX4jFhFy5cgLe3N2rXro3+/fvj6tWrAIDk5GTk5OQgNDRUyuvv74+aNWsiKSnJWOFWKKmpqUhLS5OdIycnJwQFBUnnKCkpCc7OzmjWrJmUJzQ0FBYWFvjll1/KPWYquezsbCQnJ8v+7hYWFggNDWXbqCAyMzMBAK6urkaOpGRyc3Px7bff4uHDhwgODjZ2OGavMrVtc2kjGtHR0YiIiJD97UzZ999/j2bNmuHVV1+Fu7s7mjZtis8//9zYYVUoxWmvSUlJWnUkPDxcyq/PuM7YyqLcpqC8yp2ZmQmFQgFnZ+dSiZvKnrn03abWL5tav8t+1TiM1VeX9RxMRRqDZGZmlsp1w5hlunnzJoYOHYqvv/4atra2JS5LXsYq1/Hjx3Ht2jVYWFigadOm8PLyQteuXXHmzJlSLV9p4sS+iQoKCsLq1auxc+dOLFu2DKmpqWjbti3u37+PtLQ0KJVKrYGth4cH0tLSjBNwBaM5Dx4eHrL0vOcoLS0N7u7usu1VqlSBq6srz6OJ+vfff5Gbm1vo352MR61WY8yYMWjdujUaNmxo7HCK5fTp07C3t4dKpcKIESOwdetW1K9f39hhmb3K0rbNoY3k9e233+L48eOYMWOGsUMpNZcuXcKyZctQt25d7Nq1CyNHjsTo0aOxZs0aY4dWYRSnvaalpRU5ZtOk6bvP8lYW5TYF5VHuJ0+eYPz48Xj99dfh6OhYOoFTmTOHvtvU+mVT7HfZrxqHsfrqsp6DqShjkIsXL2LRokUYPnx4scqRl7HKJITAoEGDMGLECNkHMaXFWOW6dOkSgGf3Nf3ggw+wfft2uLi4oH379khPTy95wcpAFWMHQMXTtWtX6f8vvPACgoKC4OPjgw0bNsDGxsaIkRERFU90dDTOnDmDQ4cOGTuUYqtXrx5OnjyJzMxMbNq0CZGRkThw4AAn96lUmEMb0fj777/x9ttvIzExEdbW1sYOp9So1Wo0a9YMn3zyCQCgadOmOHPmDOLj4xEZGWnk6IjMT05ODvr06QMhBJYtW2bscKiSMaV+2VT7XfarZG6uXbuGLl264NVXX8XQoUONHU6xLVq0CPfv38fEiRONHUqpUqvVAIBJkyahd+/eAIBVq1ahevXq2LhxY6l8GFPa+I19M+Hs7Iznn38eFy9ehKenJ7Kzs5GRkSHLc/PmTXh6ehonwApGcx5u3rwpS897jjw9PXHr1i3Z9qdPnyI9PZ3n0URVq1YNlpaWhf7dyThiYmKwfft27N+/H9WrVzd2OMWmVCpRp04dBAYGYsaMGWjcuDEWLFhg7LDMXmVo2+bSRjSSk5Nx69Yt/O9//0OVKlVQpUoVHDhwAAsXLkSVKlWQm5tr7BCLxcvLS+uDvICAAGm5RCpee/X09CxyzKZJ03ef5a0sym0KyrLcmkn9K1euIDExkd/WNzGm3nebWr9sqv0u+1XjMFZfXdZzMMYeg1y/fh0dOnRAq1atsGLFihKVRcNYZdq3bx+SkpKgUqlQpUoV1KlTBwDQrFmzUvnQzVjl8vLyAgDZdUelUqF27doV9rrDiX0z8eDBA/z111/w8vJCYGAgrKyssHfvXml7SkoKrl69yrWe/z9fX194enrKztG9e/fwyy+/SOcoODgYGRkZSE5OlvLs27cParUaQUFB5R4zlZxSqURgYKDs765Wq7F37162DSMRQiAmJgZbt27Fvn374Ovra+yQSpVarUZWVpaxwzB75ty2zbWNdOrUCadPn8bJkyelR7NmzdC/f3+cPHkSlpaWxg6xWFq3bo2UlBRZ2p9//gkfHx8jRVTxFKe9BgcHy/IDQGJiopRfn3GdsZVFuU1BWZVbM6l/4cIF7NmzB1WrVi2bAlCZMdW+21T7ZVPtd9mvGoex+uqynoMx5hjk2rVraN++PQIDA7Fq1SpYWJTOdKyxyrRw4UKcOnVKup7s2LEDALB+/Xp8/PHHJluuwMBAqFQq2XUnJycHly9frrjXHaPeupeK7Z133hE//fSTSE1NFYcPHxahoaGiWrVq4tatW0IIIUaMGCFq1qwp9u3bJ44dOyaCg4NFcHCwkaMuX/fv3xcnTpwQJ06cEADE3LlzxYkTJ8SVK1eEEEJ8+umnwtnZWXz33Xfi999/Fy+99JLw9fUVjx8/lvbRpUsX0bRpU/HLL7+IQ4cOibp164rXX3/dWEWiUvDtt98KlUolVq9eLc6dOyeGDRsmnJ2dRVpamrFDM0hR9dtUjBw5Ujg5OYmffvpJ3LhxQ3o8evTI2KEZbMKECeLAgQMiNTVV/P7772LChAlCoVCI3bt3Gzu0SsFc2nZ+5tRGihISEiLefvttY4dRIr/++quoUqWK+Pjjj8WFCxfE2rVrha2trfjmm2+MHVqFUlR7HTBggJgwYYKU//Dhw6JKlSpi9uzZ4o8//hBTpkwRVlZW4vTp01IefcZ1xlYW5b5z5444ceKESEhIEADEt99+K06cOCFu3LhR7uUrSGmXOzs7W/To0UNUr15dnDx5UnZtzMrKMkoZqXhMse82p37ZFPpd9qvGY6y+uqznYIxRrn/++UfUqVNHdOrUSfzzzz+ya4eplim/1NRUAUCcOHGiVMpkzHK9/fbb4rnnnhO7du0S58+fF1FRUcLd3V2kp6eXWtlKEyf2TdRrr70mvLy8hFKpFM8995x47bXXxMWLF6Xtjx8/Fm+99ZZwcXERtra24uWXX65QA/zysH//fgFA6xEZGSmEEEKtVosPP/xQeHh4CJVKJTp16iRSUlJk+7hz5454/fXXhb29vXB0dBSDBw8W9+/fN0JpqDQtWrRI1KxZUyiVStGiRQtx9OhRY4dksKLqt6nQVQYAYtWqVcYOzWBDhgwRPj4+QqlUCjc3N9GpUydO6pczc2jb+ZlTGymKKUww6OOHH34QDRs2FCqVSvj7+4sVK1YYO6QKqbD2GhISotWfbdiwQTz//PNCqVSKBg0aiISEBNl2fcZ1FUFpl3vVqlU6rxFTpkwph9LorzTLrZk80PXYv39/OZWISoup9d3m1C+bSr/LftV4jNFXl8ccTHmXq6C+ujS/a23scVVZTOwLYZxyZWdni3feeUe4u7sLBwcHERoaKs6cOVOq5SpNCiGEKO1fARARERERERERERERUdngGvtERERERERERERERCaEE/tERERERERERERERCaEE/tERERERERERERERCaEE/tERERERERERERERCaEE/tERERERERERERERCaEE/tERERERERERERERCaEE/tERERERERERERERCaEE/tERERERERERGRUBw8eRPfu3eHt7Q2FQoFt27aV6fGmTp0KhUIhe/j7+5fpMYmIShMn9omIiIiIiIiIyKgePnyIxo0bY8mSJeV2zAYNGuDGjRvS49ChQ+V2bCKikqpi7ACIiIiIiIiIiKhy69q1K7p27Vrg9qysLEyaNAn/93//h4yMDDRs2BCfffYZ2rdvX+xjVqlSBZ6ensV+PRGRMfEb+0REREREREREVKHFxMQgKSkJ3377LX7//Xe8+uqr6NKlCy5cuFDsfV64cAHe3t6oXbs2+vfvj6tXr5ZixEREZUshhBDGDoKIiIiIiIiIiAgAFAoFtm7dip49ewIArl69itq1a+Pq1avw9vaW8oWGhqJFixb45JNPDD7Gjz/+iAcPHqBevXq4ceMG4uLicO3aNZw5cwYODg6lVRQiojLDpXiIiIiIiIiIiKjCOn36NHJzc/H888/L0rOyslC1alUAwPnz5xEQEFDofsaPH49PP/0UAGTL/rzwwgsICgqCj48PNmzYgKioqFIuARFR6ePEPhERERERERERVVgPHjyApaUlkpOTYWlpKdtmb28PAKhduzb++OOPQvej+RBAF2dnZzz//PO4ePFiyQMmIioHnNgnIiIiIiIiIqIKq2nTpsjNzcWtW7fQtm1bnXmUSiX8/f2LfYwHDx7gr7/+woABA4q9DyKi8sSJfSIiIiIiIiIiMqoHDx7Ivi2fmpqKkydPwtXVFc8//zz69++PgQMHYs6cOWjatClu376NvXv34oUXXkBERITBx3v33XfRvXt3+Pj44Pr165gyZQosLS3x+uuvl2axiIjKDG+eS0RERERERERERvXTTz+hQ4cOWumRkZFYvXo1cnJy8NFHH+Grr77CtWvXUK1aNbRs2RJxcXFo1KiRwcfr27cvDh48iDt37sDNzQ1t2rTBxx9/DD8/v9IoDhFRmePEPhERERERERERERGRCbEwdgBERERERERERERERKQ/TuwTEREREREREREREZkQTuwTEREREREREREREZkQTuwTEREREREREREREZkQTuwTEREREREREREREZkQTuwTEREREREREREREZkQTuwTEREREREREREREZkQTuwTEREREREREREREZkQTuwTEREREREREREREZkQTuwTEREREREREREREZkQTuwTEREREREREREREZkQTuwTEREREREREREREZkQTuwTEREREREREREREZkQTuwTEREREREREREREZkQTuwTEREREREREREREZkQTuwTEREREREREREREZkQTuwTEREREREREREREZkQTuxTuVAoFJg6daqxwyCq8FavXg2FQoHLly8bOxQionIzaNAg1KpVy9hhFElzjT527JixQ6EyZkr9sam0H6rcTKlNUeF4zTEfHNeYl59++gkKhQI//fST3q8xpA60b98e7du3L36ABpo6dSoUCkW5Ha+4NOd906ZNRjk+J/aJiMhsLF26FKtXrzZ2GERk4ngtocpix44dRv3yzbp16zB//nyjHZ+osjJ22yeiyuHIkSOYOnUqMjIyjB1KiVXUMQsn9qlcPH78GB988IGxwyAiM8fJOCIqDbyWkCn5/PPPkZKSUqzX7tixA3FxcaUckf4q6ptkInNXkrZfkmsOEZmu3bt3Y/fu3Qa95siRI4iLi+PEfhnixL6ZePTokbFDKJS1tTWqVKli7DCIiIhKrKL3uURUuVhZWUGlUhk7DAC8PhLpS61W48mTJ8YOo1gq0jWHKh9z7GdM5XqgVCqhVCqNHQblw4n9cqBZF+r8+fPo06cPHB0dUbVqVbz99ttajfebb75BYGAgbGxs4Orqir59++Lvv/+W5Wnfvj0aNmyI5ORktGvXDra2tnj//fcBAMeOHUN4eDiqVasGGxsb+Pr6YsiQIbLXP3z4EO+88w5q1KgBlUqFevXqYfbs2RBCyPIpFArExMRg27ZtaNiwIVQqFRo0aICdO3cafA7yr7GvOScXL17EoEGD4OzsDCcnJwwePFjnhfqbb75BixYtYGtrCxcXF7Rr107rk8KlS5eiQYMGUKlU8Pb2RnR0tNangppz9/vvvyMkJAS2traoU6eOtBbWgQMHEBQUBBsbG9SrVw979uzRiuXatWsYMmQIPDw8pHOycuVKg88Jkb70qds///wzXn31VdSsWRMqlQo1atTA2LFj8fjxY1m+QYMGwd7eHteuXUPPnj1hb28PNzc3vPvuu8jNzTUoLkOPefXqVXTr1g329vZ47rnnsGTJEgDA6dOn0bFjR9jZ2cHHxwfr1q2TvV6z7t/hw4cRGxsLNzc32NnZ4eWXX8bt27elfLVq1cLZs2dx4MABKBQKKBSKcl0DkCoG9rnP3hzMnz8fDRo0gLW1NTw8PDB8+HDcvXtXlq9WrVro1q0bfvrpJzRr1gw2NjZo1KiRtC7nli1b0KhRI1hbWyMwMBAnTpyQvV7Tti9duoTw8HDY2dnB29sb06ZN0ypfcRhajkOHDqFFixawtrZG7dq18dVXX2ntU9P/29jYoHr16vjoo4+watUq2brP+lxLsrKyCr0ekXmqqP1x/vWuL1++DIVCgdmzZ2PFihXw8/ODSqVC8+bN8dtvv8lep+mLNXXdkLVsC7s+fvfdd4iIiIC3tzdUKhX8/Pwwffp0Wdnat2+PhIQEXLlyRTp23nJkZWVhypQpqFOnjnQux40bh6ysLIPOD1VcFbVN5a3brVq1kvr4+Ph4rbz61lNNP7927VqpzJo+/tq1a4iKipLai6+vL0aOHIns7Gzp9RkZGRgzZow0nqhTpw4+++wzqNVqKU95tf3iXnM0NGM0Nzc36X33pEmTZHlOnDiBrl27wtHREfb29ujUqROOHj0qy6N5j3Do0CGMHj0abm5ucHZ2xvDhw5GdnY2MjAwMHDgQLi4ucHFxwbhx47TGJ/qONUyZPvXr0aNHGD58OKpWrQpHR0cMHDjQ4HNgyBgcMO9x+IIFC6QxtJubG7p06SJbw76o64E+803//PMPevbsCTs7O7i7u2Ps2LEl6h/1GdvqWmN/0aJFaNCggTRX16xZM+n9/NSpU/Hee+8BAHx9faVrTUnvtWJI3Tl37hw6dOgAW1tbPPfcc5g5c6bW/q5cuYIePXrIzuWuXbtk9ysoaswCPPvbf/zxx6hevTqsra3RqVMnXLx4sURl1Qe/Ql2O+vTpg1q1amHGjBk4evQoFi5ciLt370pvPD/++GN8+OGH6NOnD958803cvn0bixYtQrt27XDixAk4OztL+7pz5w66du2Kvn374o033oCHhwdu3bqFsLAwuLm5YcKECXB2dsbly5exZcsW6XVCCPTo0QP79+9HVFQUmjRpgl27duG9997DtWvXMG/ePFnMhw4dwpYtW/DWW2/BwcEBCxcuRO/evXH16lVUrVq1VM6Jr68vZsyYgePHj+OLL76Au7s7PvvsMylPXFwcpk6dilatWmHatGlQKpX45ZdfsG/fPoSFhQF4dsGIi4tDaGgoRo4ciZSUFCxbtgy//fYbDh8+DCsrK2l/d+/eRbdu3dC3b1+8+uqrWLZsGfr27Yu1a9dizJgxGDFiBPr164dZs2bhlVdewd9//w0HBwcAwM2bN9GyZUvpQuzm5oYff/wRUVFRuHfvHsaMGVPic0KUl751e+PGjXj06BFGjhyJqlWr4tdff8WiRYvwzz//YOPGjbJ95ubmIjw8HEFBQZg9ezb27NmDOXPmwM/PDyNHjtQ7NkOP2bVrV7Rr1w4zZ87E2rVrERMTAzs7O0yaNAn9+/dHr169EB8fj4EDByI4OBi+vr6yfYwaNQouLi6YMmUKLl++jPnz5yMmJgbr168HAMyfPx+jRo2Cvb299ObAw8PD4HNO5qEy97nDhw/H6tWrMXjwYIwePRqpqalYvHgxTpw4odUnXrx4Ef369cPw4cPxxhtvYPbs2ejevTvi4+Px/vvv46233gIAzJgxA3369EFKSgosLP77Xkhubi66dOmCli1bYubMmdi5cyemTJmCp0+fYtq0aQb9zUpajldeeQVRUVGIjIzEypUrMWjQIAQGBqJBgwYAnr1R6tChAxQKBSZOnAg7Ozt88cUXWt861OdaUtT1iMxPRe6PC7Ju3Trcv38fw4cPh0KhwMyZM9GrVy9cunQJVlZWGD58OK5fv47ExER8/fXXxTqGrusj8GzCzd7eHrGxsbC3t8e+ffswefJk3Lt3D7NmzQIATJo0CZmZmfjnn3+k66G9vT2AZ2+Oe/TogUOHDmHYsGEICAjA6dOnMW/ePPz555/Ytm1bic8PGVdFb1N3797Fiy++iD59+uD111/Hhg0bMHLkSCiVSmny0NB6um/fPmzYsAExMTGoVq0aatWqhevXr6NFixbIyMjAsGHD4O/vj2vXrmHTpk149OgRlEolHj16hJCQEFy7dg3Dhw9HzZo1ceTIEUycOBE3btzQWhqiPNq+LkUdF3j2AXvbtm1hZWWFYcOGoVatWvjrr7/www8/4OOPPwYAnD17Fm3btoWjoyPGjRsHKysrLF++HO3bt5e+iJfXqFGj4Onpibi4OBw9ehQrVqyAs7Mzjhw5gpo1a+KTTz7Bjh07MGvWLDRs2BADBw6UXmvIWMMUFVW/NGJiYuDs7IypU6dKbfHKlSvSTUENUdQYHDDvcXhUVBRWr16Nrl274s0338TTp0/x888/4+jRo2jWrJmUT9f1QN/5psePH6NTp064evUqRo8eDW9vb3z99dfYt2+fQX+rvIoztv38888xevRovPLKK9IHOL///jt++eUX9OvXD7169cKff/6J//u//8O8efNQrVo1AICbm1ux4zSk7ty9exddunRBr1690KdPH2zatAnjx49Ho0aN0LVrVwDPPvzp2LEjbty4gbfffhuenp5Yt24d9u/fLztuYWMWjU8//RQWFhZ49913kZmZiZkzZ6J///745Zdfil1evQgqc1OmTBEARI8ePWTpb731lgAgTp06JS5fviwsLS3Fxx9/LMtz+vRpUaVKFVl6SEiIACDi4+Nlebdu3SoAiN9++63AWLZt2yYAiI8++kiW/sorrwiFQiEuXrwopQEQSqVSlnbq1CkBQCxatEj/E/D/9zVlyhTpueacDBkyRJbv5ZdfFlWrVpWeX7hwQVhYWIiXX35Z5ObmyvKq1WohhBC3bt0SSqVShIWFyfIsXrxYABArV66U0jTnbt26dVLa+fPnBQBhYWEhjh49KqXv2rVLABCrVq2S0qKiooSXl5f4999/ZbH07dtXODk5iUePHhlwVoi0rVq1SgAQqampBtVtXXVvxowZQqFQiCtXrkhpkZGRAoCYNm2aLG/Tpk1FYGCgQbEaesxPPvlESrt7966wsbERCoVCfPvtt1K6pj3mvV5ozkloaKjU7oUQYuzYscLS0lJkZGRIaQ0aNBAhISEGlYPMS2Xvc3/++WcBQKxdu1aWvnPnTq10Hx8fAUAcOXJEStP0fTY2NrJ2vHz5cgFA7N+/X0rTtO1Ro0ZJaWq1WkRERAilUilu376td9yRkZHCx8enROU4ePCglHbr1i2hUqnEO++8I6WNGjVKKBQKceLECSntzp07wtXVVbruahR0LTHkekSmzZT64/ztJzU1VQAQVatWFenp6VL6d999JwCIH374QUqLjo4WxX1LWND1UQjd52H48OHC1tZWPHnyREqLiIiQxa7x9ddfCwsLC/Hzzz/L0uPj4wUAcfjw4WLFTMZjSm1KU7fnzJkjpWVlZYkmTZoId3d3kZ2dLYQwrJ5q3m+ePXtWlnfgwIHCwsJC53hC089Mnz5d2NnZiT///FO2fcKECcLS0lJcvXpVCFF+bb8k15x27doJBwcH2d8ub1mFEKJnz55CqVSKv/76S0q7fv26cHBwEO3atZPSNHUqPDxc9vrg4GChUCjEiBEjpLSnT5+K6tWry/p2Q8Yapqqo+qU5h4GBgVK9FkKImTNnCgDiu+++0/tY+ozBhRBmPQ7ft2+fACBGjx6ttS1vHS3oeqDvfNP8+fMFALFhwwYpz8OHD0WdOnW0xutFMWRsGxISImtDL730kmjQoEGh+581a5bWOFtfmjqlUZy689VXX0lpWVlZwtPTU/Tu3VtKmzNnjgAgtm3bJqU9fvxY+Pv7a53LgsYs+/fvFwBEQECAyMrKktIXLFggAIjTp08bXHZDcCmechQdHS17PmrUKADPblyzZcsWqNVq9OnTB//++6/08PT0RN26dbU+LVKpVBg8eLAsTfPJ1Pbt25GTk6Mzhh07dsDS0hKjR4+Wpb/zzjsQQuDHH3+UpYeGhsLPz096/sILL8DR0RGXLl3Sv+CFGDFihOx527ZtcefOHdy7dw8AsG3bNqjVakyePFn2DUEA0ifHe/bsQXZ2NsaMGSPLM3ToUDg6OiIhIUH2Ont7e/Tt21d6Xq9ePTg7OyMgIED26b/m/5qyCiGwefNmdO/eHUII2d8pPDwcmZmZOH78eElPCZHEkLptY2Mj/f/hw4f4999/0apVKwghtJbPAHS3PUPbtaHHfPPNN6X/Ozs7o169erCzs0OfPn2kdE171BXLsGHDZN8Yadu2LXJzc3HlyhWD4qbKobL2uRs3boSTkxM6d+4sK1tgYCDs7e21yla/fn0EBwdLzzV9X8eOHVGzZk2tdF2xxMTESP/XfMMoOztb53J2ZVmOtm3bSs/d3NxQr149Wbw7d+5EcHAwmjRpIqW5urqif//+BsfH61HlUtH744K89tprcHFxke0b0N2Oi0vX9RGQn4f79+/j33//Rdu2bfHo0SOcP3++yP1u3LgRAQEB8Pf3l10DOnbsCABa1wAyLabQpqpUqYLhw4dLz5VKJYYPH45bt24hOTkZgOH1NCQkBPXr15eeq9VqbNu2Dd27d5d9k1dD089s3LgRbdu2hYuLi+w4oaGhyM3NxcGDB2WvK4+2r0tRx719+zYOHjyIIUOGyMYYwH9lzc3Nxe7du9GzZ0/Url1b2u7l5YV+/frh0KFD0lyBRlRUlKxPDgoKghACUVFRUpqlpSWaNWsmOweGjjVMjb71C3g2rsn764SRI0eiSpUq2LFjh8HHLWwMDsCsx+GbN2+GQqHAlClTtLbl/+VD/uuBIfNNO3bsgJeXF1555RXp9ba2thg2bJjeseZXnLGts7Mz/vnnH51LbpUFQ+uOvb093njjDem5UqlEixYttN4fPPfcc+jRo4eUZm1tjaFDhxoc3+DBg2X3ICivay+X4ilHdevWlT338/ODhYUFLl++DAsLCwghtPJo5P8J2HPPPad104qQkBD07t0bcXFxmDdvHtq3b4+ePXuiX79+0s/Mr1y5Am9vb2lpGY2AgABpe175O1wAcHFxKbU15/LvXzMQuHv3LhwdHfHXX3/BwsJCdsHLTxNzvXr1ZOlKpRK1a9fWKlP16tW1LqpOTk6oUaOGVpomFuDZQCQjIwMrVqzAihUrdMZy69atAuMkMpQhdfvq1auYPHkyvv/+e632mZmZKXuuWesvr+K065Ie08nJqcD2qCuWwq4XRPlV1j73woULyMzMhLu7u87t+fup/MfU9H1F9YkaFhYWsjfeAPD8888DQInWzyxpOQDtc3flyhXZhxgaderUMTg+Xo8ql4reHxekPOqprusj8GwpjQ8++AD79u3TmoTLfx50uXDhAv74448Cf67PMbdpM4U25e3tDTs7O1la3v6tZcuWBtfT/MtM3r59G/fu3UPDhg0LjeXChQv4/fff9T6Osfqooo6rmdwqrLy3b9/Go0ePtOoG8Gz8pFar8ffff0vL7Ok6bmFjmbznwNCxhqnRt34B2uNme3t7eHl5FWssV9gYHHh23s11HP7XX3/B29sbrq6uRebVdT3Qd77pypUrqFOnjtb7aF3tRl/FuW6MHz8ee/bsQYsWLVCnTh2EhYWhX79+aN26dbHjKIyhdUfXXIOLiwt+//136fmVK1fg5+enlc+U3h9wYt+I8lYctVoNhUKBH3/8EZaWllp586/dlPebC3n3t2nTJhw9ehQ//PADdu3ahSFDhmDOnDk4evSo1j70oSsWAKVyU7zy2L8hxywqFs2Nid544w1ERkbqzPvCCy+UQoREhsnNzUXnzp2Rnp6O8ePHw9/fH3Z2drh27RoGDRoku6kWUHBdN8YxDbkGGON6QeajsvS5arUa7u7uWLt2rc7t+ScFSqNtloXSKkdZxWvs80MVkzH648KURz3VdX3MyMhASEgIHB0dMW3aNPj5+cHa2hrHjx/H+PHjtc6DLmq1Go0aNcLcuXN1bs8/YUfmqaK1qfwMrae62ou+x+ncuTPGjRunc7vmAwcNY/VRFe24utLzxmLoWIOKJ/+EqTmPww2Rv1zGnm8qTvkDAgKQkpKC7du3Y+fOndi8eTOWLl2KyZMnIy4urtRjNLTuVJb3B5zYL0cXLlyQfSp38eJFqNVq1KpVC5aWlhBCwNfXV6tjNlTLli3RsmVLfPzxx1i3bh369++Pb7/9Fm+++SZ8fHywZ88e3L9/X/bJpeYnsT4+PiU6dmnz8/ODWq3GuXPnZD+dz0sTc0pKiuxbg9nZ2UhNTUVoaGipxOLm5gYHBwfk5uaW2j6JCqNv3T59+jT+/PNPrFmzRnYzqMTExDKLzRjH1IehN3ci81VZ+1w/Pz/s2bMHrVu3LvYEgiHUajUuXbokO49//vknAKBWrVrF3m9ZlMPHxwcXL17USteVxmsJ5VWR++OSKou6/tNPP+HOnTvYsmUL2rVrJ6WnpqbqfXw/Pz+cOnUKnTp1Yns0Q6bQpq5fv46HDx/KvrWfv38raT11c3ODo6Mjzpw5U2g+Pz8/PHjwoFTfgxqjXWn+1oWV183NDba2tkhJSdHadv78eVhYWJTaB3vlPWYqb/rWL+DZuLlDhw7S8wcPHuDGjRt48cUXDT5uYWNw4Nl5N+dx+K5du5Cenq7Xt/bzMmS+ycfHB2fOnIEQQtaWdbWbsmZnZ4fXXnsNr732GrKzs9GrVy98/PHHmDhxIqytrUv1WlOadUfDx8cH586d0zqXpvT+gGvsl6MlS5bIni9atAgA0LVrV/Tq1QuWlpaIi4vT+jRHCIE7d+4Uuf+7d+9qvVYzGZ6VlQUAePHFF5Gbm4vFixfL8s2bNw8KhUK6M3RF0bNnT1hYWGDatGla38jQlDU0NBRKpRILFy6Ulf/LL79EZmYmIiIiSiUWS0tL9O7dG5s3b9bZOd6+fbtUjkOkoW/d1nwynDePEAILFiwos9iMcUx92NnZISMjw6gxUMVQWfvcPn36IDc3F9OnT9fa9vTp0zJpH3nLJ4TA4sWLYWVlhU6dOhV7n2VRjvDwcCQlJeHkyZNSWnp6us5v6vFaQnlV5P64pDSTlqVZ33Wdh+zsbCxdulTn8XUtzdOnTx9cu3YNn3/+uda2x48f4+HDh6UWL5U/U2hTT58+xfLly6Xn2dnZWL58Odzc3BAYGAig5PXUwsICPXv2xA8//IBjx45pbdeUu0+fPkhKSsKuXbu08mRkZODp06cGlQ0om7ZfFDc3N7Rr1w4rV67E1atXZds0ZbW0tERYWBi+++472TIwN2/exLp169CmTRs4OjqWSjzGGDOVJ33rFwCsWLFCtlb9smXL8PTp02KNVQsbgwMw63F47969IYTQ+W31or61bch804svvojr169j06ZNUtqjR48KXMKnrOT/WymVStSvXx9CCKk+lea1pjTqTn7h4eG4du0avv/+eyntyZMnOq/rBY1ZjI3f2C9Hqamp6NGjB7p06YKkpCR888036NevHxo3bgwA+OijjzBx4kRcvnwZPXv2hIODA1JTU7F161YMGzYM7777bqH7X7NmDZYuXYqXX34Zfn5+uH//Pj7//HM4OjpKn7R2794dHTp0wKRJk3D58mU0btwYu3fvxnfffYcxY8bIbhZSEdSpUweTJk3C9OnT0bZtW/Tq1QsqlQq//fYbvL29MWPGDLi5uWHixImIi4tDly5d0KNHD6SkpGDp0qVo3ry57GYZJfXpp59i//79CAoKwtChQ1G/fn2kp6fj+PHj2LNnD9LT00vtWET61m1/f3/4+fnh3XffxbVr1+Do6IjNmzeX6VpuxjimPgIDA7Fs2TJ89NFHqFOnDtzd3aUbmFHlUln73JCQEAwfPhwzZszAyZMnERYWBisrK1y4cAEbN27EggULZDfaKilra2vs3LkTkZGRCAoKwo8//oiEhAS8//77JfoJe1mUY9y4cfjmm2/QuXNnjBo1CnZ2dvjiiy9Qs2ZNpKeny76Fw2sJ5VWR++OS0kxQjh49GuHh4bC0tETfvn1LtM9WrVrBxcUFkZGRGD16NBQKBb7++mudkxqBgYFYv349YmNj0bx5c9jb26N79+4YMGAANmzYgBEjRmD//v1o3bo1cnNzcf78eWzYsAG7du3SeTNIMg2m0Ka8vb3x2Wef4fLly3j++eexfv16nDx5EitWrJDWcS6NevrJJ59g9+7dCAkJwbBhwxAQEIAbN25g48aNOHToEJydnfHee+/h+++/R7du3TBo0CAEBgbi4cOHOH36NDZt2oTLly+jWrVqBpWvLNq+PhYuXIg2bdrgf//7H4YNGwZfX19cvnwZCQkJ0gfvH330ERITE9GmTRu89dZbqFKlCpYvX46srCzMnDmz1GIp7zGTMRRVvzSys7PRqVMn9OnTR2qLbdq0kd1QVF9FjcH9/PzMdhzeoUMHDBgwAAsXLsSFCxfQpUsXqNVq/Pzzz+jQoQNiYmIKfb2+801Dhw7F4sWLMXDgQCQnJ8PLywtff/01bG1tS71MhQkLC4Onpydat24NDw8P/PHHH1i8eDEiIiKkX0lorjWTJk1C3759YWVlhe7du2vdw0QfpVF38hs+fDgWL16M119/HW+//Ta8vLywdu1aWFtbA4DW+wNdYxajE1TmpkyZIgCIc+fOiVdeeUU4ODgIFxcXERMTIx4/fizLu3nzZtGmTRthZ2cn7OzshL+/v4iOjhYpKSlSnpCQENGgQQOt4xw/fly8/vrrombNmkKlUgl3d3fRrVs3cezYMVm++/fvi7Fjxwpvb29hZWUl6tatK2bNmiXUarUsHwARHR2tdRwfHx8RGRlp0DkAIKZMmaJ1Tm7fvi3Lt2rVKgFApKamytJXrlwpmjZtKlQqlXBxcREhISEiMTFRlmfx4sXC399fWFlZCQ8PDzFy5Ehx9+5dWZ6Czp2Pj4+IiIjQGXf+c3Dz5k0RHR0tatSoIaysrISnp6fo1KmTWLFihR5ngqhwutqAPnX73LlzIjQ0VNjb24tq1aqJoUOHilOnTgkAYtWqVVK+yMhIYWdnp3VcTZs0REmPqW971JyT3377TZZv//79AoDYv3+/lJaWliYiIiKEg4ODACBCQkIMKhOZPva5z6xYsUIEBgYKGxsb4eDgIBo1aiTGjRsnrl+/Ltu3vn1famqqACBmzZolpWna9l9//SXCwsKEra2t8PDwEFOmTBG5ubkGxRsZGSl8fHxKtRwhISFa14ATJ06Itm3bCpVKJapXry5mzJghFi5cKACItLQ0KV9B1xJDrkdk2kypP87ffnS1V438Y/KnT5+KUaNGCTc3N6FQKAw6dkHXRyGEOHz4sGjZsqWwsbER3t7eYty4cWLXrl1a7eTBgweiX79+wtnZWQCQlSM7O1t89tlnokGDBtJ7gMDAQBEXFycyMzP1jpMqBlNqU5q6fezYMREcHCysra2Fj4+PWLx4sVZefetpQf28EEJcuXJFDBw4ULi5uQmVSiVq164toqOjRVZWlpTn/v37YuLEiaJOnTpCqVSKatWqiVatWonZs2eL7OxsIUT5tf2SXHOEEOLMmTPi5ZdfFs7OzsLa2lrUq1dPfPjhh7I8x48fF+Hh4cLe3l7Y2tqKDh06iCNHjsjyFNQnFzTXUFAd0WesYcoKq1+ac3jgwAExbNgw4eLiIuzt7UX//v3FnTt3DDqOIWNwIcx3HP706VMxa9Ys4e/vL5RKpXBzcxNdu3YVycnJRR5PCP3nm65cuSJ69OghbG1tRbVq1cTbb78tdu7cafB41JCxbf6x9fLly0W7du1E1apVhUqlEn5+fuK9997T6qOnT58unnvuOWFhYaFzvq8gBV2/S1J3dL3nuHTpkoiIiBA2NjbCzc1NvPPOO2Lz5s0CgDh69KiUr6Axi+Zcbdy4UbZfzbUxb19VFhRC8C5fZW3q1KmIi4vD7du3Df4knYiIiPTHPrf8DBo0CJs2bcKDBw+MHUqJjBkzBsuXL8eDBw/K/caLRERU8bRv3x7//vuvXmuTE9EzHIOTOZk/fz7Gjh2Lf/75B88995yxwykU19gnIiIiokrh8ePHsud37tzB119/jTZt2nBSn4iIiIioksn//uDJkydYvnw56tatW+En9QGusU8lkJubW+QNY+3t7WFvb19OERFRaUhPT0d2dnaB2y0tLUu0djYRGc5U+9yKdj0JDg5G+/btERAQgP/H3p3HRVH/fwB/AXLDcqiAJCIeeZ+oSN6KoJJlknmU4Z1+wULKqzwgK9LySk06FKw0075qJX5VxFtRkzTFg9QwKwVNRTw5P78//O3Esgvs4rK7s7yejwcP3ZnPzrxndt4zn/nMzGeys7OxatUq5ObmYvbs2QaLgUhbxsofU8tbIn3htl0+rh/S5N69exU+nWnu24Uc6+EPHz6s8EWv7u7usLGxMVBE/7pz545aY3ppXl5eBorm8Ut569Wrh7Zt2+LOnTv45ptvcP78eaxdu9ZgMTwJNuxTpf3555/w8/Mrt8zcuXMRExNjmICISC8GDx6Mffv2lTne19cXly9fNlxARCTbY66p7U8GDBiA77//Hp9//jksLCzQvn17rFq1Ct27dzdYDETaMlb+mFreEukLt+3ycf2QJh9//DFiY2PLLZOZmWmgaIxDjvXw7777DqNHjy63zJ49e9CzZ0/DBFTCG2+8gTVr1pRbxpC9xoeEhODLL7/E2rVrUVRUhObNm2P9+vUYOnSowWJ4Euxjnyrt0aNHKm9S16RBgwZo0KCBgSIiIn1IS0vD7du3yxxvb2+PLl26GDAiIpLrMZf7E6LKM1b+MG/JXHHbLh/XD2ny+++/4/fffy+3TNeuXWFnZ2egiAxPjvXwa9eu4cyZM+WW8ff3h5ubm4Ei+tfZs2dx9erVcssEBQUZKBr5Y8M+EREREREREREREZGM8OW5REREREREREREREQyUq372C8uLsbVq1fh7OwMCwsLY4dDpDUhBO7evQtvb29YWvL6XGnMbZIr5nbFmN8kV8zv8jG3Sa6Y2xVjfpNcMb/Lx9wmuTKn3K7WDftXr16Fj4+PscMgqrQ///wTdevWNXYYJoe5TXLH3C4b85vkjvmtGXOb5I65XTbmN8kd81sz5jbJnTnkdrVu2Hd2dgbw+IdUKBQq4woKCrBz504EBwfD2traGOGZFa5P/crNzYWPj4+0DZOqsnJbrtsh4zYsY8bN3K5YecduQL7bnb5U9+UHTHcdML/LVzq3TfV3LA9jrnqmGC9zu2LmfOyWc+wA468I87t8FeW2XMk9Lypi7ssHVLyM5pTb1bphX/mokEKh0Niw7+DgAIVCYbYbuiFxfVYNPu6mWVm5LdftkHEblinEzdwuW3nHbsA0fj9jqu7LD5j+OmB+a1Y6t039d9SEMVc9U46XuV02cz52yzl2gPFri/mtWUW5LVdyz4uKmPvyAdovoznktrw7EiIiIiIiIiIiIiIiqmaq9R372mgZswN5RapXcC5/GGqkaIjIVNSfkaQ2jPsGItNR+vjN/CQiHruJzJOm3AaY30SmoKz81IQ5S6Q7NuwTERERERERERGR0fACPJHu2BUPERERERERERFRFdu/fz8GDhwIb29vWFhYYMuWLSrjhRCYM2cO6tSpA3t7ewQFBeHChQsqZW7duoWXX34ZCoUCrq6uGDt2LO7du6dS5tSpU+jWrRvs7Ozg4+ODBQsWqMWyceNGNG3aFHZ2dmjVqhW2bdum9+UloqrFhn0iIiIiIiIiIqIqdv/+fbRp0wYrVqzQOH7BggX45JNPEB8fj6NHj8LR0REhISF49OiRVObll1/GmTNnkJycjK1bt2L//v2YMGGCND43NxfBwcHw9fVFWloaPvroI8TExODzzz+Xyhw+fBjDhw/H2LFjceLECQwaNAiDBg1Cenp61S08Eekdu+IhIiIiIiIiIiKqYv3790f//v01jhNCYMmSJZg1axaef/55AMBXX30FT09PbNmyBcOGDcO5c+ewfft2/Pzzz+jQoQMAYNmyZRgwYAA+/vhjeHt7Y+3atcjPz8fq1athY2ODFi1a4OTJk1i0aJF0AWDp0qXo168fpk6dCgCYN28ekpOTsXz5csTHx2uMLy8vD3l5edLn3NxcAEBBQQEKCgo0fsfWSlRiLf2rrOlWJeU8jTFvQzD35QMqXkZzWnY27BMRERERERGRydPlRZxEcpOZmYmsrCwEBQVJw1xcXBAQEIDU1FQMGzYMqampcHV1lRr1ASAoKAiWlpY4evQoXnjhBaSmpqJ79+6wsbGRyoSEhGD+/Pm4ffs23NzckJqaiujoaJX5h4SEqHUNVFJcXBxiY2PVhu/cuRMODg4av7Ogk7ZLr5kxuwdKTk422rwNwdyXDyh7GR88eGDgSKoOG/aJiIiIiIiIiIiMKCsrCwDg6empMtzT01Mal5WVBQ8PD5XxNWrUgLu7u0oZPz8/tWkox7m5uSErK6vc+Wgyc+ZMlYsBubm58PHxQXBwMBQKhcbvtIzZUeb0tJEeE/JE36+MgoICJCcno2/fvrC2tjb4/KuauS8fUPEyKp82MQds2CciIiIiIiIiIqIy2drawtbWVm24tbV1mQ3EeUUWTzRPYzY8l7dc5sDclw8oexnNabn58lwiIiIiIjMUExMDCwsLlb+mTZtK4x89eoSIiAjUrFkTTk5OCAsLQ3Z2tso0rly5gtDQUDg4OMDDwwNTp05FYWGhSpm9e/eiffv2sLW1RaNGjZCYmGiIxSMiIjIrXl5eAKB2LM7OzpbGeXl54fr16yrjCwsLcevWLZUymqZRch5llVGOJyJ5YMM+EREREZGZatGiBa5duyb9HTx4UBo3ZcoU/PTTT9i4cSP27duHq1evYvDgwdL4oqIihIaGIj8/H4cPH8aaNWuQmJiIOXPmSGUyMzMRGhqKXr164eTJk4iKisK4ceOwY8eTPXovZy1jdqD+jCS1PyIiovL4+fnBy8sLKSkp0rDc3FwcPXoUgYGBAIDAwEDk5OQgLS1NKrN7924UFxcjICBAKrN//36VF4QmJyejSZMmcHNzk8qUnI+yjHI+RCQP7IqHiIiIiMhM1ahRQ+Pdd3fu3MGqVauwbt069O7dGwCQkJCAZs2a4ciRI+jcuTN27tyJs2fPYteuXfD09ETbtm0xb948TJ8+HTExMbCxsUF8fDz8/PywcOFCAECzZs1w8OBBLF68GCEhZfeLm5eXh7y8POmzsq/TgoIC6U/5WV9srYTaMH1OXzktW0v1+eh7XvpSFeu5KplivKYUCxGZvnv37uHixYvS58zMTJw8eRLu7u6oV68eoqKi8N5776Fx48bw8/PD7Nmz4e3tjUGDBgF4fJzt168fxo8fj/j4eBQUFCAyMhLDhg2Dt7c3AGDEiBGIjY3F2LFjMX36dKSnp2Pp0qVYvHixNN833ngDPXr0wMKFCxEaGor169fj+PHj+Pzzzw26PojoybBhn4iIiIjITF24cAHe3t6ws7NDYGAg4uLiUK9ePaSlpaGgoABBQUFS2aZNm6JevXpITU1F586dkZqailatWqm8XC8kJASTJk3CmTNn0K5dO6SmpqpMQ1kmKiqq3Lji4uIQGxurNnznzp1wcHCQPicnJ1dyydUt6KQ+bNu2bXqbvtK8DsUah1fFvPRFn+vZEEwp3gcPHhg7BCKSkePHj6NXr17SZ+XLaMPDw5GYmIhp06bh/v37mDBhAnJyctC1a1ds374ddnZ20nfWrl2LyMhI9OnTB5aWlggLC8Mnn3wijXdxccHOnTsREREBf39/1KpVC3PmzMGECROkMs888wzWrVuHWbNm4e2330bjxo2xZcsWtGzZ0gBrgYj0hQ37RERERERmKCAgAImJiWjSpAmuXbuG2NhYdOvWDenp6cjKyoKNjQ1cXV1VvuPp6YmsrCwAQFZWlkqjvnK8clx5ZXJzc/Hw4UPY29trjG3mzJlSYwbw+I59Hx8fBAcHQ6FQoKCgAMnJyejbt6/eXnDWMka9e6D0mLKfKtCVMubZxy2RV6z+skB9zktfqmI9VyVTjFf5tAkRkTZ69uwJITQ/2QUAFhYWePfdd/Huu++WWcbd3R3r1q0rdz6tW7fGgQMHyi0zZMgQDBkypPyAiciksWGfiMiE1Z+RBFsrgQWdHjdI5BU9bii4/GGokSMjIiJT179/f+n/rVu3RkBAAHx9fbFhw4YyG9wNxdbWFra2tmrDra2tVRpsS39+EspjaOn56VtesYXW89LU974xjvH6XM+GYErxmkocREREVP3w5blERERERNWAq6srnn76aVy8eBFeXl7Iz89HTk6OSpns7GypT34vLy9kZ2erjVeOK6+MQqEw+sUDIiIiIiJzxoZ9IiIiIqJq4N69e7h06RLq1KkDf39/WFtbIyUlRRqfkZGBK1euIDAwEAAQGBiI06dP4/r161KZ5ORkKBQKNG/eXCpTchrKMsppEBERERFR1WBXPEREREREZuitt97CwIED4evri6tXr2Lu3LmwsrLC8OHD4eLigrFjxyI6Ohru7u5QKBSYPHkyAgMD0blzZwBAcHAwmjdvjpEjR2LBggXIysrCrFmzEBERIXWjM3HiRCxfvhzTpk3DmDFjsHv3bmzYsAFJSepdzBARGZupdH9FRESkD2zYJyIiIiIyQ3/99ReGDx+Omzdvonbt2ujatSuOHDmC2rVrAwAWL14MS0tLhIWFIS8vDyEhIfj000+l71tZWWHr1q2YNGkSAgMD4ejoiPDwcJUX+vn5+SEpKQlTpkzB0qVLUbduXXz55ZcICTG9F8USEREREZkTNuwTEREREZmh9evXlzvezs4OK1aswIoVK8os4+vri23btpU7nZ49e+LEiROVipGIiIiIiCqHfewTEREREREREREREckIG/aJiIiIiIiIiIiIiGSEDftERERERERERERERDLChn0iIiIiIiIiIiIiIhlhwz4RERERERERERERkYzUMHYARERERERERETGUH9Gksbhlz8MNXAkREREuuEd+0REREREREREREREMsI79omIiIiIiGRI053GvMuYiIiIqHpgwz4REREREZmVsrrWMCZTjInInDHniIjI3LErHiIiIjMWFxeHjh07wtnZGR4eHhg0aBAyMjJUyjx69AgRERGoWbMmnJycEBYWhuzsbJUyV65cQWhoKBwcHODh4YGpU6eisLBQpczevXvRvn172NraolGjRkhMTFSLZ8WKFahfvz7s7OwQEBCAY8eO6X2ZiYiIiIiIiMwdG/aJiIjM2L59+xAREYEjR44gOTkZBQUFCA4Oxv3796UyU6ZMwU8//YSNGzdi3759uHr1KgYPHiyNLyoqQmhoKPLz83H48GGsWbMGiYmJmDNnjlQmMzMToaGh6NWrF06ePImoqCiMGzcOO3bskMp89913iI6Oxty5c/HLL7+gTZs2CAkJwfXr1w2zMoiIiIiIiIjMBLviISIiMmPbt29X+ZyYmAgPDw+kpaWhe/fuuHPnDlatWoV169ahd+/eAICEhAQ0a9YMR44cQefOnbFz506cPXsWu3btgqenJ9q2bYt58+Zh+vTpiImJgY2NDeLj4+Hn54eFCxcCAJo1a4aDBw9i8eLFCAkJAQAsWrQI48ePx+jRowEA8fHxSEpKwurVqzFjxgyN8efl5SEvL0/6nJubCwAoKChAQUGBWnnlMFtLoXG4uVMuZ3VZXk1MdR2YWjxERERERCRvbNgnItKTsvrx5EvsyJTcuXMHAODu7g4ASEtLQ0FBAYKCgqQyTZs2Rb169ZCamorOnTsjNTUVrVq1gqenp1QmJCQEkyZNwpkzZ9CuXTukpqaqTENZJioqCgCQn5+PtLQ0zJw5UxpvaWmJoKAgpKamlhlvXFwcYmNj1Ybv3LkTDg4OZX5vXodilc/btm0rs6w5Sk5ONnYIRmdq6+DBgwfGDoGIzEhMTIza8bFJkyY4f/48gMfd7L355ptYv3498vLyEBISgk8//VTlWH7lyhVMmjQJe/bsgZOTE8LDwxEXF4caNf5tJti7dy+io6Nx5swZ+Pj4YNasWRg1apRBlpGIiIjKx4Z9IiKiaqK4uBhRUVHo0qULWrZsCQDIysqCjY0NXF1dVcp6enoiKytLKlOyIUA5XjmuvDK5ubl4+PAhbt++jaKiIo1llI0QmsycORPR0dHS59zcXPj4+CA4OBgKhUKtfEFBAZKTkzH7uCXyii2k4ekxIWXOw5wol79v376wtrY2djhGYarrQPm0CZmXkhf1ba0EFnQyYjBU7bRo0QK7du2SPpdskJ8yZQqSkpKwceNGuLi4IDIyEoMHD8ahQ4cA/NvNnpeXFw4fPoxr167h1VdfhbW1NT744AMA/3azN3HiRKxduxYpKSkYN24c6tSpIz2NR0RERMbDhn0iIqJqIiIiAunp6Th48KCxQ9Gara0tbG1t1YZbW1uX22ibV2yBvCILlfLVSUXrpzowtXVgSrEQkXmoUaMGvLy81IYbsps9c6bpaVw+iUtERKaEDftEpBU+7kskb5GRkdi6dSv279+PunXrSsO9vLyQn5+PnJwclbv2s7OzpcYCLy8vHDt2TGV62dnZ0jjlv8phJcsoFArY29vDysoKVlZWGstoapQgIjIEdqNHcnbhwgV4e3vDzs4OgYGBiIuLQ7169QzWzV5ZKvt+HG3eRWJrJSosU5VKx2iq73XRFuPXbvpERKaKDftEpDU+7mvaeFcRaSKEwOTJk7F582bs3bsXfn5+KuP9/f1hbW2NlJQUhIWFAQAyMjJw5coVBAYGAgACAwPx/vvv4/r16/Dw8ADwuP9yhUKB5s2bS2VK92OfnJwsTcPGxgb+/v5ISUnBoEGDADzuGiglJQWRkZFVtvxERETmKCAgAImJiWjSpAmuXbuG2NhYdOvWDenp6QbrZs/e3l5jbJV9P44270YxdndXZb2zx9Te66Irxq8Z349DRKZOp4b9uLg4bNq0CefPn4e9vT2eeeYZzJ8/H02aNJHKGPKu3RUrVuCjjz5CVlYW2rRpg2XLlqFTJ3ZsSVRV+Liv/rARngwlIiIC69atww8//ABnZ2fpZN3FxQX29vZwcXHB2LFjER0dDXd3dygUCkyePBmBgYHo3LkzACA4OBjNmzfHyJEjsWDBAmRlZWHWrFmIiIiQusmZOHEili9fjmnTpmHMmDHYvXs3NmzYgKSkf7f16OhohIeHo0OHDujUqROWLFmC+/fvY/To0VW+HphzRCR3ZT1dQNVT//79pf+3bt0aAQEB8PX1xYYNG8pscDeUyr4fp/S7UVrG7DBIvLoo/c4eU32vi7YYf/n4fhwiMnU6Nezv27cPERER6NixIwoLC/H2228jODgYZ8+ehaOjIwDD3bX73XffITo6GvHx8QgICMCSJUsQEhKCjIwM6W5CItIvuT/uq89HNXV5DFjT/DR9v6xytpaPyyr/fdJpGopcH+01ZtxVMc+VK1cCAHr27KkyPCEhQbpgvnjxYlhaWiIsLEzlorySlZUVtm7dikmTJiEwMBCOjo4IDw/Hu+++K5Xx8/NDUlISpkyZgqVLl6Ju3br48ssvVS7KDR06FDdu3MCcOXOQlZWFtm3bYvv27Wp3AxIREZFuXF1d8fTTT+PixYvo27evQbrZK0tl349TenzJd+WYirLiN7X3uuiK8Zc9XSIiU6ZTw/727dtVPicmJsLDwwNpaWno3r27Qe/aXbRoEcaPHy/d5RcfH4+kpCSsXr0aM2bM0Bi/Ln39KT+XbEgrPY60J9cGPlNljPVoTo/76uNRTV0eA9b0yK6m71dUbl6HYr1M09Dk+mivMeKuisd9haj4IpSdnR1WrFiBFStWlFnG19e3wu2pZ8+eOHHiRLllIiMj2fUOERGRnt27dw+XLl3CyJEjDdbNHhERERnXE/Wxf+fOHQCAu7s7ABjsrt38/HykpaVh5syZ0nhLS0sEBQUhNTW1zHgr09dfyYY0JVNoKJMruTbwmRpj9PVnDo/76vNRTV0eDS79yG5Z3y+rnK2lwLwOxZh93BJ5xRZPPE1DkeujvcaMm4/7EhERkTbeeustDBw4EL6+vrh69Srmzp0LKysrDB8+3KDd7BEREZHxVLphv7i4GFFRUejSpQtatmwJAAa7a/f27dsoKirSWOb8+fNlxqxLX3/Khp2SDWlKxmwokyu5NvCZKlNo/JPz4776eFRTl0eDNc1L0/crKpdXbCF9fpJpGppcH+01RtxyXE9ERKRf7EuftPHXX39h+PDhuHnzJmrXro2uXbviyJEjqF27NgDDdbNHRERExlPphv2IiAikp6fj4MGD+oynSlWmr7+SDWkly1PlyLWBz9SYwjrk475ERERERMaxfv36cscbsps9ItKfmJgYtZ4mmjRpIt3E+ujRI7z55ptYv369ykW7kje+XrlyBZMmTcKePXvg5OSE8PBwxMXFoUaNf5sA9+7di+joaJw5cwY+Pj6YNWuW9P4tIpKPSjXsR0ZGYuvWrdi/fz/q1q0rDffy8jLIXbtWVlawsrLSWEY5jaqk6S6ayx+GVvl8iYyJj/sSERERERERVa0WLVpg165d0ueSDfJTpkxBUlISNm7cCBcXF0RGRmLw4ME4dOgQAKCoqAihoaHw8vLC4cOHce3aNbz66quwtrbGBx98AADIzMxEaGgoJk6ciLVr1yIlJQXjxo1DnTp1+EQOkczo1LAvhMDkyZOxefNm7N27F35+firjDXXXro2NDfz9/ZGSkoJBgwYBeNw1UEpKCl/IR1RF+LgvERERkekrqysf3ohERCQPNWrU0HjT6p07d7Bq1SqsW7cOvXv3BgAkJCSgWbNmOHLkCDp37oydO3fi7Nmz2LVrFzw9PdG2bVvMmzcP06dPR0xMDGxsbBAfHw8/Pz8sXLgQANCsWTMcPHgQixcvLvfcOy8vD3l5edJnZRfBBQUFKCgo0PgdWytR6fWgnLahKedpjHkbgrkvH1DxMprTsuvUsB8REYF169bhhx9+gLOzs9QnvouLC+zt7Q161250dDTCw8PRoUMHdOrUCUuWLMH9+/cxevRofa0bIiqBj/sSERHJS1xcHDZt2oTz58/D3t4ezzzzDObPn48mTZpIZXr27Il9+/apfO+1115DfHy89JmP9BMRERnOhQsX4O3tDTs7OwQGBiIuLg716tVDWloaCgoKEBQUJJVt2rQp6tWrh9TUVHTu3Bmpqalo1aqVStc8ISEhmDRpEs6cOYN27dohNTVVZRrKMlFRUeXGFRcXp9ZNEADs3LkTDg4OGr+zoJMOC65BRe0HVSk5Odlo8zYEc18+oOxlfPDggYEjqTo6NeyvXLkSwOMTgJISEhKkiruh7todOnQobty4gTlz5iArKwtt27bF9u3b1V6oS0RERERUHe3btw8RERHo2LEjCgsL8fbbbyM4OBhnz56Fo6OjVG78+PEqdfGSJ+fV9ZF+dr1JRETGEBAQgMTERDRp0gTXrl1DbGwsunXrhvT0dGRlZcHGxkal62sA8PT0lG68zcrKUmsXU36uqExubi4ePnwIe3t7jbHNnDkT0dHR0ufc3Fz4+PggODgYCoVC43daxuzQfuE1SI8xfD2ioKAAycnJ6Nu3r0m831DfzH35gIqXUfm0iTnQuSueihjyrt3IyEh2vUNEREREpMH27dtVPicmJsLDwwNpaWno3r27NNzBwaHM91RV1SP9FT3O/6SPiT/po/+aaIql5HxsLYXKv6ZGU/xyexzfFOM1pViISP769+8v/b9169YICAiAr68vNmzYUGaDu6HY2tpKPW2UZG1tXWYDcV6RxRPN05gNz+Utlzkw9+UDyl5Gc1ruSr08l4ioOimrr1oiIiI5uXPnDgDA3d1dZfjatWvxzTffwMvLCwMHDsTs2bOlu/ar6pF+bR/nr+xj4k/66L8mmm5M0jSfeR2K9T9zPSjvxiq5PY5vSvGa0+P8RGR6XF1d8fTTT+PixYvo27cv8vPzkZOTo3LXfnZ2tnSB3svLC8eOHVOZRnZ2tjRO+a9yWMkyCoXC6BcPiEg3bNgnIiIiIjJzxcXFiIqKQpcuXdCyZUtp+IgRI+Dr6wtvb2+cOnUK06dPR0ZGBjZt2gSg6h7pr+hxfk2PUGt6nL+sR/Sf9NF/TTTNq+R8bC0F5nUoxuzjlsgrfrI7FKuCpvjl9ji+KcZrTo/zE5HpuXfvHi5duoSRI0fC398f1tbWSElJQVhYGAAgIyMDV65cQWBgIAAgMDAQ77//Pq5fvw4PDw8Ajy+GKhQKNG/eXCpT+mJvcnKyNA0ikg827BMRVUPsO5iIqHqJiIhAeno6Dh48qDJ8woQJ0v9btWqFOnXqoE+fPrh06RIaNmxYZfFo+zh/yc+aHuevqkf/NdE0L03zySu2qJL5P6nyGsLl9ji+KcVrKnEQkXl46623MHDgQPj6+uLq1auYO3curKysMHz4cLi4uGDs2LGIjo6Gu7s7FAoFJk+ejMDAQHTu3BkAEBwcjObNm2PkyJFYsGABsrKyMGvWLEREREjH3YkTJ2L58uWYNm0axowZg927d2PDhg1ISuKT6kRyw4Z9IqIqxq58iIjImCIjI7F161bs378fdevWLbdsQEAAAODixYto2LAhH+knIiIyoL/++gvDhw/HzZs3Ubt2bXTt2hVHjhxB7dq1AQCLFy+GpaUlwsLCkJeXh5CQEHz66afS962srLB161ZMmjQJgYGBcHR0RHh4ON59912pjJ+fH5KSkjBlyhQsXboUdevWxZdffinbF94TVWds2CciIiIiMkNCCEyePBmbN2/G3r174efnV+F3Tp48CQCoU6cOAD7ST0REZEjr168vd7ydnR1WrFiBFStWlFnG19e33PeqAEDPnj1x4sSJSsVIRKbD0tgBEBERERGR/kVEROCbb77BunXr4OzsjKysLGRlZeHhw4cAgEuXLmHevHlIS0vD5cuX8eOPP+LVV19F9+7d0bp1awCqj/T/+uuv2LFjh8ZH+n///XdMmzYN58+fx6effooNGzZgypQpRlt2IiIiIiJzxzv2iYiIiIjM0MqVKwE8viuvpISEBIwaNQo2NjbYtWsXlixZgvv378PHxwdhYWGYNWuWVJaP9BMRVaxlzA61d2vw/VVERFTV2LBPRERERGSGhBDljvfx8cG+ffsqnI4pP9LP99gQERERUXXFrniIiIiIiIiIiIiIiGSEd+wTERERERERERGRWdHlyT52n0VyxIZ9IiIiIiIiM6epcePCvGAjREJERKQdQ3a5p5yXrZXAgk6P352R8f6zBps/UWWwKx4iIiIiIiIiIiIiIhnhHftERERERERERBUoffew8s5eIiIiY2DDPhEREREREQEou9sD9j1MREREZFrYsE9EREREREREpEeaLpLxAhkREekTG/aJiP6fIV/MQ0RERGRsLWN2SC8IzCuyMHY4RERERKQDvjyXiIiIiIiIiIiIiEhG2LBPRERERERERERERCQj7IqHiMhEsCsgIiIiIiIiIiLSBhv2iYhIL0pfmLC1EljQyUjBEBERERGZGL5Ql4iI9Ild8RARERERERERERERyQjv2CciIqJqiXfNERERERERkVzxjn0iIiIiIiIiIiIiIhlhwz4RERERERERERERkYywYZ+IiIiIiIiIiIiISEbYxz4RERERERGVi+8lISIiIjItbNgnompJ08mpOTLH5Sxrmdi4QERERERERETVBRv2iYiIiIiIKmCOF8uJiIiISL7YsE9ERAD4iD0RERHphnUHoqrD/CIiooqwYZ+ISIZ41yARERERERGR6eIFOqpqbNgnIiKd8cICEREREdGTY72ayHQZOz95YYAqwoZ9IiIiov/HlzMTEREZR8uYHcgrsjB2GCaNjXxE8vekecz9AJXEhn0iIiqTKd6hQERERERERERU3VkaO4AntWLFCtSvXx92dnYICAjAsWPHjBJH/RlJan9E9GRMJb+JSL+Y20Tmi/lNPC8yT8xt08WcoyfF/CaSL1k37H/33XeIjo7G3Llz8csvv6BNmzYICQnB9evXjR0aET0h5jeReWJuE5kv5jeVRVPDIxsf5YO5TWS+mN9E8ibrrngWLVqE8ePHY/To0QCA+Ph4JCUlYfXq1ZgxY4aRoyOiJ8H8Nh/a9pdq7H4BlQ0MtlYCCzo9jjvj/Wf1Ms2SjL2cxibX3OZvSVQxueY3GQ/3rfLA3JYfXd8ZVLq+zjysPpjfRPIm24b9/Px8pKWlYebMmdIwS0tLBAUFITU1VeN38vLykJeXJ32+c+cOAODWrVsoKChQKVtQUIAHDx6gRoElioor9wKfRm9tqNT3qtrRmX3UhgXEpVTpfJTr8+bNm7C2ttbq+5pi0hS7nOiynstb1rt37wIAhBBPHJMp0jW/tc3tktthjcL7VbgE+lWjWODBg+In2h8Zg65xa9pn6nKQetJ9rnJeJePW1zRLunnzZpnlmdvqdDl2A/o5fmvL2Md5TceJyhxvzY0h1kFZx3Meu/V37Nb0O5r6sVuOx2tTjLm8fautpcCsdsVo+84m5BkwXua2+Ry79c0Uc6g8pfNLmVOl46+qOo6+z+d1Oebz2K2uqs67SzL1Y7cmxsjrss4RtV1/uuSssY6lhqRcxrL2DeaU27Jt2P/nn39QVFQET09PleGenp44f/68xu/ExcUhNjZWbbifn1+VxGiqai2U73wMFbsp0GZZ7969CxcXl6oPxsB0ze/qkNsjjB1AJTFudcxtHrv1pTodE+WC+c1jtxyPe3KL2RjxMrd57C6P3HKoNEPGb4p1F+Y3j92aGDqvDZ0bct9vaUObZTSH3JZtw35lzJw5E9HR0dLn4uJi3Lp1CzVr1oSFhepVqtzcXPj4+ODPP/+EQqEwdKhmh+tTv4QQuHv3Lry9vY0diknQNrfluh0ybsMyZtzMbXW6HLsB+W53+lLdlx8w3XXA/FZVUW6b6u9YHsZc9UwxXua2uup07JZz7ADjrwjzW5WuuS1Xcs+Lipj78gEVL6M55bZsG/Zr1aoFKysrZGdnqwzPzs6Gl5eXxu/Y2trC1tZWZZirq2u581EoFGa7oRsD16f+yP2qYnl0zW9dc1uu2yHjNixjxc3cVlWZYzcg3+1OX6r78gOmuQ6Y3//SNrdN8XesCGOueqYWL3NbVXU8dss5doDxl4f5/a/K5rZcyT0vKmLuyweUv4zmktuWxg6gsmxsbODv74+UlH/7SSsuLkZKSgoCAwONGBkRPSnmN5F5Ym4TmS/mN5F5Ym4TmS/mN5H8yfaOfQCIjo5GeHg4OnTogE6dOmHJkiW4f/++9DZvIpIv5jeReWJuE5kv5jeReWJuE5kv5jeRvMm6YX/o0KG4ceMG5syZg6ysLLRt2xbbt29Xe/FHZdja2mLu3LlqjxlR5XB9kq6qIr/luh0ybsOSa9xyUZXHboC/X3VffoDrwJj0md9y/B0Zc9WTW7zmgsfussk5doDxU9XntxyZ+3Zl7ssHVI9lVLIQQghjB0FERERERERERERERNqRbR/7RERERERERERERETVERv2iYiIiIiIiIiIiIhkhA37REREREREREREREQywoZ9IiIiIiIiIiIiIiIZYcN+GVasWIH69evDzs4OAQEBOHbsmLFDkqX9+/dj4MCB8Pb2hoWFBbZs2WLskKiaMmROV7TdCyEwZ84c1KlTB/b29ggKCsKFCxdUyty6dQsvv/wyFAoFXF1dMXbsWNy7d0+lzKlTp9CtWzfY2dnBx8cHCxYsUItl48aNaNq0Kezs7NCqVSts27atzLjj4uLQsWNHODs7w8PDA4MGDUJGRoZKmUePHiEiIgI1a9aEk5MTwsLCkJ2drVLmypUrCA0NhYODAzw8PDB16lQUFhaqlNm7dy/at28PW1tbNGrUCImJiWrxaPubrVy5Eq1bt4ZCoYBCoUBgYCD+97//mXTMVDWq0/qPiYmBhYWFyl/Tpk2l8dps93JiqP0qGV9F27Yp0Mf2aEgVxTtq1Ci1dd6vXz/jBPv/9FUnIePQ9XhcUX3V0DmlS/xffPEFunXrBjc3N7i5uSEoKEitvKFzTJf4ExMT1WKzs7NTKWPK679nz55q8VtYWCA0NFQqY4r7ODI+uR3LK8Pcj6X6aAcwC4LUrF+/XtjY2IjVq1eLM2fOiPHjxwtXV1eRnZ1t7NBkZ9u2beKdd94RmzZtEgDE5s2bjR0SVUOGzumKtvsPP/xQuLi4iC1btohff/1VPPfcc8LPz088fPhQKtOvXz/Rpk0bceTIEXHgwAHRqFEjMXz4cGn8nTt3hKenp3j55ZdFenq6+Pbbb4W9vb347LPPpDKHDh0SVlZWYsGCBeLs2bNi1qxZwtraWpw+fVpj3CEhISIhIUGkp6eLkydPigEDBoh69eqJe/fuSWUmTpwofHx8REpKijh+/Ljo3LmzeOaZZ6TxhYWFomXLliIoKEicOHFCbNu2TdSqVUvMnDlTKvP7778LBwcHER0dLc6ePSuWLVsmrKysxPbt26UyuvxmP/74o0hKShK//fabyMjIEG+//bawtrYW6enpJhsz6V91W/9z584VLVq0ENeuXZP+bty4IY2vaLuXG0PsV8k0VLRtmwJ9bI+mFG94eLjo16+fyjq/deuWUWJV0kedhIxD1+OxNvVVQ+aUrvGPGDFCrFixQpw4cUKcO3dOjBo1Sri4uIi//vpLKmPIHNM1/oSEBKFQKFRiy8rKUiljyuv/5s2bKrGnp6cLKysrkZCQIJUxxX0cGZ/cjuWVYe7H0idtBzAXbNjXoFOnTiIiIkL6XFRUJLy9vUVcXJwRo5I/NuyTsRgzp0tv98XFxcLLy0t89NFH0rCcnBxha2srvv32WyGEEGfPnhUAxM8//yyV+d///icsLCzE33//LYQQ4tNPPxVubm4iLy9PKjN9+nTRpEkT6fNLL70kQkNDVeIJCAgQr732mlaxX79+XQAQ+/btk+K0trYWGzdulMqcO3dOABCpqalCiMcVJEtLS5UTgpUrVwqFQiHFOm3aNNGiRQuVeQ0dOlSEhIRIn5/0N3NzcxNffvmlrGKmJ1Pd1v/cuXNFmzZtNI7TZruXs6rar5JpKG/bNkWV2R6NqayG/eeff94o8WirMnUSMg5dj8cV1VcNnVNPWp8oLCwUzs7OYs2aNdIwQ+aYrvEnJCQIFxeXMqcnt/W/ePFi4ezsrNJwKYd9HBmX3I7llVUdjqW6tAOYC3bFU0p+fj7S0tIQFBQkDbO0tERQUBBSU1ONGBkRVYap5XRmZiaysrJU4nFxcUFAQIAUT2pqKlxdXdGhQwepTFBQECwtLXH06FGpTPfu3WFjYyOVCQkJQUZGBm7fvi2VKTkfZRltl/vOnTsAAHd3dwBAWloaCgoKVKbZtGlT1KtXTyX2Vq1awdPTU2Weubm5OHPmjFZxPclvVlRUhPXr1+P+/fsIDAyURcz05Krr+r9w4QK8vb3RoEEDvPzyy7hy5QoA7XLVnOhrv0qmo6xtWw602R5N0d69e+Hh4YEmTZpg0qRJuHnzprFDUlGZOgkZXmWOxxXVsQyZU/qoTzx48AAFBQXStqpkiByrbPz37t2Dr68vfHx88Pzzz0v1X0B+63/VqlUYNmwYHB0dVYab+j6OTItcj+UVMedjaWXaAcwFG/ZL+eeff1BUVKTSwAMAnp6eyMrKMlJURFRZppbTynmWF09WVhY8PDxUxteoUQPu7u4qZTRNo+Q8yiqjzXIXFxcjKioKXbp0QcuWLaXp2djYwNXVtdzYKxtXbm4uHj58WKnf7PTp03BycoKtrS0mTpyIzZs3o3nz5iYdM+lPdVz/AQEBSExMxPbt27Fy5UpkZmaiW7duuHv3rlbbvTnR136VTEN527YcaLM9mpp+/frhq6++QkpKCubPn499+/ahf//+KCoqMnZoACpfJyHDq8zxuKL6qiFzSh/1ienTp8Pb21ulMclQOVaZ+Js0aYLVq1fjhx9+wDfffIPi4mI888wz+OuvvwDIa/0fO3YM6enpGDdunMpwU9/HkemR47G8IuZ6LH2SdgBzUcPYARARkemJiIhAeno6Dh48aOxQtNKkSROcPHkSd+7cwffff4/w8HDs27fP2GERVZn+/ftL/2/dujUCAgLg6+uLDRs2wN7e3oiRET2Z8rbtsWPHGjEy8zVs2DDp/61atULr1q3RsGFD7N27F3369DFiZI/JrU5C1deHH36I9evXY+/evSovoDXlHAsMDERgYKD0+ZlnnkGzZs3w2WefYd68eUaMTHerVq1Cq1at0KlTJ5Xhprz+iQzFXI+lbAfgHftqatWqBSsrK7U3JWdnZ8PLy8tIURFRZZlaTivnWV48Xl5euH79usr4wsJC3Lp1S6WMpmmUnEdZZSpa7sjISGzduhV79uxB3bp1VWLPz89HTk5OubFXNi6FQgF7e/tK/WY2NjZo1KgR/P39ERcXhzZt2mDp0qUmHTPpD9c/4OrqiqeffhoXL17Uars3J/rar5JpKrlty4E226Opa9CgAWrVqmUS6/xJ6iRkeJU5HldUXzVkTj1JfeLjjz/Ghx9+iJ07d6J169bllq2qHNNHfcja2hrt2rWTYpPL+r9//z7Wr1+v1QVgU9rHkWkyh2N5SeZ8LH2SdgBzwYb9UmxsbODv74+UlBRpWHFxMVJSUlSuZBORPJhaTvv5+cHLy0slntzcXBw9elSKJzAwEDk5OUhLS5PK7N69G8XFxQgICJDK7N+/HwUFBVKZ5ORkNGnSBG5ublKZkvNRlilruYUQiIyMxObNm7F79274+fmpjPf394e1tbXKNDMyMnDlyhWV2E+fPq3SgJacnAyFQoHmzZtrFZc+frPi4mLk5eXJKmaqPK7/x/3jXrp0CXXq1NFquzcn+tqvkmkquW3LgTbbo6n766+/cPPmTaOuc33UScjwKnM8rqiOZcicqmx9YsGCBZg3bx62b9+u8i6XslRVjumjPlRUVITTp09Lsclh/QPAxo0bkZeXh1deeaXC+ZjCPo5Mmzkcy4HqeSzVpR3AbBj55b0maf369cLW1lYkJiaKs2fPigkTJghXV1eRlZVl7NBk5+7du+LEiRPixIkTAoBYtGiROHHihPjjjz+MHRpVI4bO6Yq2+w8//FC4urqKH374QZw6dUo8//zzws/PTzx8+FCaRr9+/US7du3E0aNHxcGDB0Xjxo3F8OHDpfE5OTnC09NTjBw5UqSnp4v169cLBwcH8dlnn0llDh06JGrUqCE+/vhjce7cOTF37lxhbW0tTp8+rTHuSZMmCRcXF7F3715x7do16e/BgwdSmYkTJ4p69eqJ3bt3i+PHj4vAwEARGBgojS8sLBQtW7YUwcHB4uTJk2L79u2idu3aYubMmVKZ33//XTg4OIipU6eKc+fOiRUrVggrKyuxfft2qYwuv9mMGTPEvn37RGZmpjh16pSYMWOGsLCwEDt37jTZmEn/qtv6f/PNN8XevXtFZmamOHTokAgKChK1atUS169fF0JUvN3LjSH2q2QaKtq2TYE+tkdTiffu3bvirbfeEqmpqSIzM1Ps2rVLtG/fXjRu3Fg8evTIKPEKoZ86CRlHRcfjkSNHihkzZkjltamvGjKndI3/ww8/FDY2NuL7779X2Vbv3r0rhBAGzzFd44+NjRU7duwQly5dEmlpaWLYsGHCzs5OnDlzRmUZTXX9K3Xt2lUMHTpUbbip7uPI+OR2LK8Mcz+WPmk7gLlgw34Zli1bJurVqydsbGxEp06dxJEjR4wdkizt2bNHAFD7Cw8PN3ZoVM0YMqcr2u6Li4vF7Nmzhaenp7C1tRV9+vQRGRkZKtO4efOmGD58uHBychIKhUKMHj1aOkFQ+vXXX0XXrl2Fra2teOqpp8SHH36oFsuGDRvE008/LWxsbESLFi1EUlJSmXFrihmASEhIkMo8fPhQ/Oc//xFubm7CwcFBvPDCC+LatWsq07l8+bLo37+/sLe3F7Vq1RJvvvmmKCgoUFtHbdu2FTY2NqJBgwYq81DS9jcbM2aM8PX1FTY2NqJ27dqiT58+0sHcVGOmqlGd1v/QoUNFnTp1hI2NjXjqqafE0KFDxcWLF6Xx2mz3cmKo/SoZX0XbtinQx/ZoKvE+ePBABAcHi9q1awtra2vh6+srxo8fb/SLovqqk5BxlHc87tGjh9q5YEX1VUPnlC7x+/r6atxW586dK4QQRskxXeKPioqSynp6eooBAwaIX375RWV6prz+hRDi/PnzAoBK/V/JVPdxZHxyO5ZXhrkfS/XRDmAOLIQQQj/3/hMRERERERERERERUVVjH/tERERERERERERERDLChn0iIiIiIiIiIiIiIhlhwz4RERERERERERERkYywYZ+IiIiIiIiIiIiISEbYsE9EREREREREREREJCNs2CciIiIiIiIiIiIikhE27BMRERERERERERERyQgb9omqwP79+zFw4EB4e3vDwsICW7Zs0XkaQgh8/PHHePrpp2Fra4unnnoK77//vv6DJSIiIiIiIiIiIlmpYewAiMzR/fv30aZNG4wZMwaDBw+u1DTeeOMN7Ny5Ex9//DFatWqFW7du4datW3qOlIiIiIiIiIiIiOTGQgghjB0EkTmzsLDA5s2bMWjQIGlYXl4e3nnnHXz77bfIyclBy5YtMX/+fPTs2RMAcO7cObRu3Rrp6elo0qSJcQInIiIiIiIiIiIik8SueIiMIDIyEqmpqVi/fj1OnTqFIUOGoF+/frhw4QIA4KeffkKDBg2wdetW+Pn5oX79+hg3bhzv2CciIiIiIiIiIiI27BMZ2pUrV5CQkICNGzeiW7duaNiwId566y107doVCQkJAIDff/8df/zxBzZu3IivvvoKiYmJSEtLw4svvmjk6ImIiIiIiIiIiMjY2Mc+kYGdPn0aRUVFePrpp1WG5+XloWbNmgCA4uJi5OXl4auvvpLKrVq1Cv7+/sjIyGD3PERERERERERERNUYG/aJDOzevXuwsrJCWloarKysVMY5OTkBAOrUqYMaNWqoNP43a9YMwOM7/tmwT0REREREREREVH2xYZ/IwNq1a4eioiJcv34d3bp101imS5cuKCwsxKVLl9CwYUMAwG+//QYA8PX1NVisREREREREREREZHoshBDC2EEQmZt79+7h4sWLAB435C9atAi9evWCu7s76tWrh1deeQWHDh3CwoUL0a5dO9y4cQMpKSlo3bo1QkNDUVxcjI4dO8LJyQlLlixBcXExIiIioFAosHPnTiMvHRERERERERERERkTG/aJqsDevXvRq1cvteHh4eFITExEQUEB3nvvPXz11Vf4+++/UatWLXTu3BmxsbFo1aoVAODq1auYPHkydu7cCUdHR/Tv3x8LFy6Eu7u7oReHiIiIiIiIiIiITAgb9omIiIiIiIiIiIiIZMTS2AEQEREREREREREREZH22LBPRERERERERERERCQjbNgnIiIiIiIiIiIiIpIRNuwTEREREREREREREckIG/aJiIiIiIiIiIiIiGSEDftERERERERERERERDLChn0iIiIiIiIiIiIiIhlhwz4RERERERERERERkYywYZ+IiIiIiIiIiIiISEbYsE9EREREREREREREJCNs2CciIiIiIiIiIiIikhE27BMRERERERERERERyQgb9omIiIiIiIiIiIiIZIQN+0REREREREREREREMsKGfSIiIiIiIiIiIiIiGWHDPhERERERERERERGRjLBhn4iIiIiIiIiIiIhIRtiwT0REREREREREREQkI2zYN5DExERYWFjg8uXLxg6FiMjo9u7dCwsLC+zdu9fYoRBVCVM47vfs2RM9e/Y02vyJ5EpT/uozn5TTP378eIVlzTmPR40ahfr16xs7DKO5fPkyLCwskJiYaOxQDComJgYWFhb4559/yi1Xv359jBo1qlLzqF+/Pp599tlKfVefcZij6rrdkn6YQv24utKUu8r9MckbG/bJKK5evYqYmBicPHnS2KEQycrhw4cRExODnJycKpvH2bNnERMTwwoXERFRGUy5LmuIuoKxbdu2DTExMcYOQyvr1q3DkiVLjB0GVQOmvF8iInn44IMPsGXLFmOHQTpgw76BjBw5Eg8fPoSvr6+xQzEJV69eRWxsLCsdRDo6fPgwYmNjq7xhPzY2lg37RDK3c+dO7Ny509hhEJmF0vlkqLpsZfLYEHUFffjiiy+QkZFRqe9u27YNsbGxeo6oapTVsO/r64uHDx9i5MiRhg9KBjIyMvDFF18YOwxZMcR+idstPQm2i5mWWbNm4eHDhyrD2LAvPzWMHUB1YWVlBSsrK2OHQUQm6P79+3B0dDR2GERkZmxsbIwdApFBFRYWori4uEq2fWPlk6nksRACjx49gr29vd6maW1trbdp6UNVLGN5LCwsYGdnZ5B5yZGtra2xQyANuN3Sk2C7mO6q8thUo0YN1Khhfs3C1a19hXfsG0jpvsSU/f4dPHgQnTp1gp2dHRo0aICvvvpK7bs5OTmYMmUK6tevD1tbW9StWxevvvqqSr+E169fx9ixY+Hp6Qk7Ozu0adMGa9asUZmOsk+tjz/+GCtWrECDBg3g4OCA4OBg/PnnnxBCYN68eahbty7s7e3x/PPP49atW2rx/O9//0O3bt3g6OgIZ2dnhIaG4syZM1qvi71796Jjx44AgNGjR8PCwkKtr6+NGzfC398f9vb2qFWrFl555RX8/fffWs8DAPLz8zFnzhz4+/vDxcUFjo6O6NatG/bs2aNW9ubNmxg5ciQUCgVcXV0RHh6OX3/9VWP/gefPn8eLL74Id3d32NnZoUOHDvjxxx91io2qL2U/dmfPnsWIESPg5uaGrl274tSpUxg1ahQaNGgAOzs7eHl5YcyYMbh586bKd6dOnQoA8PPzk3Kn5J3133zzjZQ77u7uGDZsGP7880+t40tMTMSQIUMAAL169ZLmUbIv/E8//RQtWrSAra0tvL29ERERobe7ArXJfW3WFfDvur548SJGjRoFV1dXuLi4YPTo0Xjw4IFe4iXShba5ozxG29vbo1OnTjhw4ECl+tku/R3luy02bNiA999/H3Xr1oWdnR369OmDixcvqn3/6NGjGDBgANzc3ODo6IjWrVtj6dKlKmV2794t1QlcXV3x/PPP49y5cypllLn422+/4ZVXXoGLiwtq166N2bNnQwiBP//8E88//zwUCgW8vLywcOFCtVjy8vIwd+5cNGrUCLa2tvDx8cG0adOQl5en0zqhf/3xxx/4z3/+gyZNmsDe3h41a9bEkCFDND6tderUKfTo0QP29vaoW7cu3nvvPSQkJGjsJ/dJ64lKjx49QkxMDJ5++mnY2dmhTp06GDx4MC5dugRAtV67ZMkSNGzYELa2tjh79iwA7etrZ86cQe/evVWWrbi4WK1cyXzSpi6rjby8PERHR6N27dpwdHTECy+8gBs3bpQ5X6Vly5ahRYsWcHBwgJubGzp06IB169YBqLiuUFhYiHnz5knrq379+nj77bfVckl5rrJjxw506NAB9vb2+Oyzz9CjRw+0adNG4/I0adIEISEhWi9/6T72S/6mn3/+uRRjx44d8fPPP6t8b8WKFQAgLV/JPoKLi4uxZMkStGjRAnZ2dvD09MRrr72G27dva7WMAJCQkIDevXvDw8MDtra2aN68OVauXKlxOf73v/+hR48ecHZ2hkKhQMeOHaXfo2fPnkhKSsIff/whxalc5rL6KtdlvyrnOk5OTk65sWvq216XfREArc61K+P333/HkCFD4O7uDgcHB3Tu3BlJSUkqZbQ9F9V2u6+Ioc6xNW23o0aNgpOTE/7++28MGjQITk5OqF27Nt566y0UFRWpfL+4uBhLly5Fq1atYGdnh9q1a6Nfv34q7xzRdT+1d+9eKYdbtWolnbds2rRJmo+/vz9OnDihtjw8tzes0u1ix48fR0hICGrVqgV7e3v4+flhzJgxOk2zZ8+eaNmyJc6ePYtevXrBwcEBTz31FBYsWKBWVpv65ODBg9G+fXuV7w0cOBAWFhYq28bRo0dhYWGB//3vfzrF+80336BTp07SMbx79+4qT+aVd2zKyclBVFQUfHx8YGtri0aNGmH+/Plq9Rbl/tXFxUVq39J0zlG6j30LCwvcv38fa9askfYh2r5jpKx36GnaZ2RlZWH06NGoW7cubG1tUadOHTz//POVqlMq9z+XLl3CgAED4OzsjJdfflmrmM2F+V2akZGLFy/ixRdfxNixYxEeHo7Vq1dj1KhR8Pf3R4sWLQAA9+7dQ7du3XDu3DmMGTMG7du3xz///IMff/wRf/31F2rVqoWHDx+iZ8+euHjxIiIjI+Hn54eNGzdi1KhRyMnJwRtvvKEy37Vr1yI/Px+TJ0/GrVu3sGDBArz00kvo3bs39u7di+nTp+PixYtYtmwZ3nrrLaxevVr67tdff43w8HCEhIRg/vz5ePDgAVauXImuXbvixIkTWr0Aq1mzZnj33XcxZ84cTJgwAd26dQMAPPPMMwAe7+xHjx6Njh07Ii4uDtnZ2Vi6dCkOHTqEEydOwNXVVav1m5ubiy+//BLDhw/H+PHjcffuXaxatQohISE4duwY2rZtC+Bx5WLgwIE4duwYJk2ahKZNm+KHH35AeHi42jTPnDmDLl264KmnnsKMGTPg6OiIDRs2YNCgQfjvf/+LF154QavYiIYMGYLGjRvjgw8+gBACycnJ+P333zF69Gh4eXnhzJkz+Pzzz3HmzBkcOXIEFhYWGDx4MH777Td8++23WLx4MWrVqgUAqF27NgDg/fffx+zZs/HSSy9h3LhxuHHjBpYtW4bu3btrnTvdu3fH66+/jk8++QRvv/02mjVrBgDSvzExMYiNjUVQUBAmTZqEjIwMrFy5Ej///DMOHTr0RHffaZv72qyrkl566SX4+fkhLi4Ov/zyC7788kt4eHhg/vz5lY6VSFfa5s7KlSsRGRmJbt26YcqUKbh8+TIGDRoENzc31K1bVy+xfPjhh7C0tMRbb72FO3fuYMGCBXj55Zdx9OhRqUxycjKeffZZ1KlTB2+88Qa8vLxw7tw5bN26VapX7Nq1C/3790eDBg0QExODhw8fYtmyZejSpQt++eUXtTrB0KFD0axZM3z44YdISkrCe++9B3d3d3z22Wfo3bs35s+fj7Vr1+Ktt95Cx44d0b17dwCPj9PPPfccDh48iAkTJqBZs2Y4ffo0Fi9ejN9++42PC1fSzz//jMOHD2PYsGGoW7cuLl++jJUrV6Jnz544e/YsHBwcAAB///23dKF35syZcHR0xJdffqnxblp91BMBoKioCM8++yxSUlIwbNgwvPHGG7h79y6Sk5ORnp6Ohg0bSmUTEhLw6NEjTJgwAba2tnB3d9e6vpaVlYVevXqhsLBQKvf5559XeFdcRXVZbU2ePBlubm6YO3cuLl++jCVLliAyMhLfffddmd/54osv8Prrr+PFF1/EG2+8gUePHuHUqVM4evQoRowYUWFdYdy4cVizZg1efPFFvPnmmzh69Cji4uJw7tw5bN68WWVeGRkZGD58OF577TWMHz8eTZo0gZOTE8aPH4/09HS0bNlSKvvzzz/jt99+w6xZs3RaB5qsW7cOd+/exWuvvQYLCwssWLAAgwcPxu+//w5ra2u89tpruHr1KpKTk/H111+rff+1116T6hSvv/46MjMzsXz5cpw4cUKtrqJpGYHH++IWLVrgueeeQ40aNfDTTz/hP//5D4qLixERESF9PzExEWPGjEGLFi0wc+ZMuLq64sSJE9i+fTtGjBiBd955B3fu3MFff/2FxYsXAwCcnJzKXHZd96tyruPoGrsu+yJAu3PtysjOzsYzzzyDBw8e4PXXX0fNmjWxZs0aPPfcc/j++++l/Yu256JKFW33FTHUOXZZioqKEBISgoCAAHz88cfYtWsXFi5ciIYNG2LSpElSubFjxyIxMRH9+/fHuHHjUFhYiAMHDuDIkSPo0KEDAN32UxcvXsSIESPw2muv4ZVXXsHHH3+MgQMHIj4+Hm+//Tb+85//AADi4uLw0ksvISMjA5aWj+9v5bm9cV2/fh3BwcGoXbs2ZsyYAVdXV1y+fBmbNm3SeVq3b99Gv379MHjwYLz00kv4/vvvMX36dLRq1Qr9+/cHoH19slu3bvjhhx+Qm5sLhUIBIQQOHToES0tLHDhwAM899xwA4MCBA7C0tESXLl20jjM2NhYxMTF45pln8O6778LGxgZHjx7F7t27ERwcLJXTdGx68OABevTogb///huvvfYa6tWrh8OHD2PmzJm4du2a1OWbEALPP/88Dh48iIkTJ6JZs2bYvHmzxvat0r7++muMGzcOnTp1woQJEwBApc6lL2FhYThz5gwmT56M+vXr4/r160hOTsaVK1ek45wudcrCwkKEhISga9eu+Pjjj6U6bLUhyCASEhIEAJGZmSmEEMLX11cAEPv375fKXL9+Xdja2oo333xTGjZnzhwBQGzatEltmsXFxUIIIZYsWSIAiG+++UYal5+fLwIDA4WTk5PIzc0VQgiRmZkpAIjatWuLnJwcqezMmTMFANGmTRtRUFAgDR8+fLiwsbERjx49EkIIcffuXeHq6irGjx+vEkdWVpZwcXFRG16en3/+WQAQCQkJKsPz8/OFh4eHaNmypXj48KE0fOvWrQKAmDNnjtbzKCwsFHl5eSrDbt++LTw9PcWYMWOkYf/9738FALFkyRJpWFFRkejdu7dajH369BGtWrWS1okQj3+HZ555RjRu3Fjr2Kj6mjt3rgAghg8frjL8wYMHamW//fZbtf3ERx99pLIvUbp8+bKwsrIS77//vsrw06dPixo1aqgNL8/GjRsFALFnzx6V4devXxc2NjYiODhYFBUVScOXL18uAIjVq1drPY89e/aozEOX3Nd2XSnXdcl8F0KIF154QdSsWVPrWIkqo+RxX9vcycvLEzVr1hQdO3ZUOR4nJiYKAKJHjx46xdCjRw+V7yjzrlmzZirHx6VLlwoA4vTp00KIx8dPPz8/4evrK27fvq0yTWXdQwgh2rZtKzw8PMTNmzelYb/++quwtLQUr776qjRMmYsTJkyQhhUWFoq6desKCwsL8eGHH0rDb9++Lezt7UV4eLg07OuvvxaWlpbiwIEDKrHEx8cLAOLQoUM6rRd6TNO+NDU1VQAQX331lTRs8uTJwsLCQpw4cUIadvPmTeHu7q5yPNJnPXH16tUCgFi0aJHaOOU2qKzXKhQKcf36dZUy2tbXoqKiBABx9OhRadj169eFi4uL2rG2dD6VVZfVhnL/EBQUpJJTU6ZMEVZWVir19NLzff7550WLFi3KnX5ZdYWTJ08KAGLcuHEqw9966y0BQOzevVsapjxX2b59u0rZnJwcYWdnJ6ZPn64y/PXXXxeOjo7i3r175cZWUnh4uPD19ZU+K3/TmjVrilu3bknDf/jhBwFA/PTTT9KwiIgIoelU9sCBAwKAWLt2rcrw7du3qw0vaxmF0JwfISEhokGDBtLnnJwc4ezsLAICAlTqLkKo7itDQ0NVlrP08pbchnTdr8qxjqNt7L6+virHAm33RcrvanOurY3ScSj3GyWPSXfv3hV+fn6ifv360nFe23NRXbb7ihjiHFvTdhseHi4AiHfffVelbLt27YS/v7/0effu3QKAeP3119Wmq8yZyuynDh8+LA3bsWOHACDs7e3FH3/8IQ3/7LPP1M5veG5veCXrx5s3bxYAxM8///xE0+zRo4da3SUvL094eXmJsLAwaZi29UllHm3btk0IIcSpU6cEADFkyBAREBAgfe+5554T7dq10zrOCxcuCEtLS/HCCy+onA8IoXrMKOvYNG/ePOHo6Ch+++03leEzZswQVlZW4sqVK0IIIbZs2SIAiAULFkhlCgsLRbdu3dRyV7k/LsnR0VFln6et0uf3SqX3Gbdv3xYAxEcffVTmtHSpUyr3PzNmzNA5ZnPBrniMqHnz5tKVdODxnTRNmjTB77//Lg3773//izZt2mi8Wqy8K3Xbtm3w8vLC8OHDpXHW1tZ4/fXXce/ePezbt0/le0OGDIGLi4v0OSAgAADwyiuvqPSvFRAQgPz8fOnxvOTkZOTk5GD48OH4559/pD8rKysEBARo7OJGV8ePH8f169fxn//8R6XvvtDQUDRt2lTtEcfyWFlZSf2SFhcX49atWygsLESHDh3wyy+/SOW2b98Oa2trjB8/XhpmaWmpcjcOANy6dQu7d+/GSy+9hLt370rLf/PmTYSEhODChQs6P8pI1dfEiRNVPpe8O/DRo0f4559/0LlzZwBQ2V7LsmnTJhQXF+Oll15SyU8vLy80btxYL/m5a9cu5OfnIyoqSrrTBQDGjx8PhUKhU36Wpkvu67quSq/rbt264ebNm8jNza10vES60DZ3jh8/jps3b2L8+PEqx+OXX34Zbm5ueotn9OjRKv12K+siyvrHiRMnkJmZiaioKLU7+JR1j2vXruHkyZMYNWoU3N3dpfGtW7dG3759sW3bNrX5jhs3Tvq/lZUVOnToACEExo4dKw13dXVVqwtt3LgRzZo1Q9OmTVX2b7179wYAvezfqqOS+9KCggLcvHkTjRo1gqurq1o9KTAwUOXuUnd3d7XHnPVZT/zvf/+LWrVqYfLkyWrjSj+VFRYWJt2NDuhWX9u2bRs6d+6MTp06Sd+vXbu2wR7hnjBhgsrydOvWDUVFRfjjjz/K/I6rqyv++usvnbroUFLmZXR0tMrwN998EwDUjuN+fn5qXeu4uLjg+eefx7fffgshBIDHd+p+9913GDRokF76tB06dKjKPq/0Pqo8GzduhIuLC/r27auyHfr7+8PJyUltO9S0jIBqfty5cwf//PMPevTogd9//x137twB8Hibv3v3LmbMmKHW53jp7VQbldmvyrmOo2vs2u6LlLQ5166Mbdu2oVOnTujatas0zMnJCRMmTMDly5el7sC0PRdVepLtviL6PMcuj6bftHTbhoWFBebOnav23ZJtG4D2+6nmzZsjMDBQ+qxs2+jduzfq1aunNlwZD8/tjU9Zx9y6dSsKCgqeaFpOTk545ZVXpM82Njbo1KlTpeqT7dq1g5OTE/bv3w/g8Z35yu6wf/nlFzx48ABCCBw8eFBlH1ORLVu2oLi4GHPmzFE5HwDUjxmajk0bN25Et27d4ObmphJ/UFAQioqKpHi3bduGGjVqqDwpY2VlpbFOZQz29vawsbHB3r171brIU6pMnbLk8lY37IrHiEoeaJTc3NxUNu5Lly4hLCys3On88ccfaNy4sdrOQdl1RumTg9LzVTby+/j4aByujOfChQsAIO34SlMoFOXGqQ1lrMrHYEtq2rQpDh48qNP01qxZg4ULF+L8+fMqBws/Pz+VedapU0ftcZ1GjRqpfL548SKEEJg9ezZmz56tcX7Xr1/HU089pVOMVD2V3AaBx5XL2NhYrF+/HtevX1cZpzyBLM+FCxcghEDjxo01jtfHC+rKyk8bGxs0aNCg3IaIyk4bUM99XddV6X2e8qTp9u3betlvEVVE29xR/lv6+FOjRg2tuzDRRnk5AUDqw7xkNxullZezzZo1w44dO9ReXKWp/mFnZyd1FVJyeMl3Zly4cAHnzp1TabwtqfR+gLTz8OFDxMXFISEhAX///bfUSAuo7kv/+OMPlUYTpdLbqT7riZcuXUKTJk20eqFb6eOpLvW1P/74Q2rsKUnTdl0VKspFTaZPn45du3ahU6dOaNSoEYKDgzFixAitugL4448/YGlpqfbbeXl5wdXVVe04XnrdKr366qv47rvvcODAAXTv3h27du1CdnY2Ro4cWWEM2qjMelG6cOEC7ty5Aw8PD43jS+8vylrGQ4cOYe7cuUhNTVXrs/7OnTtwcXHRal+pC33sV+VUx9E1dm33RWVNXzkPbbaj8pS13yh57q3cJrQ5Fy0rXl22e21iBvR3jq2Jsr/8kjS1bXh7e6tcuNIUqy77qcq2bfDc3vh69OiBsLAwxMbGYvHixejZsycGDRqEESNG6Pzy7Lp166o1jru5ueHUqVPSZ23rk1ZWVggMDMSBAwcAPG7Y79atG7p27YqioiIcOXIEnp6euHXrlk4N+5cuXYKlpSWaN29eYVlN+4gLFy7g1KlTFcavbN8q3e2boeo2FbG1tcX8+fPx5ptvwtPTE507d8azzz6LV199FV5eXgB0r1PWqFFDb12WyhEb9o2orLeBlzyxMuR8K4pH+UKOr7/+Wkq4kkztbdrffPMNRo0ahUGDBmHq1Knw8PCAlZUV4uLipIq4LpTL/9Zbb5X5YrCyKpZEpZXuv/ell17C4cOHMXXqVLRt2xZOTk4oLi5Gv379NL7Er7Ti4mLp5T2acrm8/lzlRtd1Zax9LZGpMqX6hzaxFBcXo1WrVli0aJHGsqVP3kk7kydPRkJCAqKiohAYGAgXFxdYWFhg2LBhWh13SjNWPbH08VRO9bXK5GKzZs2QkZGBrVu3Yvv27fjvf/+LTz/9FHPmzEFsbKxW89X2bvKy3jUQEhICT09PfPPNN+jevTu++eYbeHl5ISgoSKvpVuRJ9lHFxcXw8PDA2rVrNY4v3SCiaRkvXbqEPn36oGnTpli0aBF8fHxgY2ODbdu2YfHixZXKj6oi5zpOVcdu7HWj67moseN9UmXFX1na7qeetG1DDscKc2VhYYHvv/8eR44cwU8//YQdO3ZgzJgxWLhwIY4cOaLT+au+65Ndu3bF+++/j0ePHuHAgQN455134OrqipYtW+LAgQPw9PQEAJ0a9nWh6dhUXFyMvn37Ytq0aRq/8/TTT1dJLNoqK2dLv0AbAKKiojBw4EBs2bIFO3bswOzZsxEXF4fdu3ejXbt2OtcpbW1t1W50rk5MqyWW1DRs2BDp6enllvH19cWpU6dQXFyssjGfP39eGq+vWADAw8PjiSvuZSW9MtaMjAy1q3MZGRk6Lcv333+PBg0aYNOmTSrzK/3on6+vL/bs2YMHDx6o3LV/8eJFlXINGjQA8PjOZ32duBABj+8cSUlJQWxsLObMmSMNV16pLqms3GnYsCGEEPDz83vig7o2+anMBwDIz89HZmbmE+WFtrmvy7oiMhXa5o6y3MWLF9GrVy+pXGFhIS5fvozWrVsbJF7l8T49Pb3MvC65TKWdP38etWrV0kuXHMp4fv31V/Tp06dS3VuQZt9//z3Cw8OxcOFCadijR4+Qk5OjUs7X11etTgSo15P0WU9s2LAhjh49ioKCAp2fONOlvubr66vx+KFpuy7NmNuio6Mjhg4diqFDhyI/Px+DBw/G+++/j5kzZ8LOzq7c43hxcTEuXLgg3V0MPH4ZaE5Ojtb1bCsrK4wYMQKJiYmYP38+tmzZgvHjx+u9Ya885dWHdu3ahS5dulT4EuSy/PTTT8jLy8OPP/6ocjdw6Uf/S+4ry2sA1HZbMeR+VY603RcZIo6yfiPleED7c1F9MsQ59pNo2LAhduzYgVu3bpV5176+9lMV4bm96ejcuTM6d+6M999/H+vWrcPLL7+M9evXq3ThqA+61Ce7deuG/Px8fPvtt/j777+lBvzu3btLDftPP/201MCv7fyLi4tx9uxZtZdna/v9e/fuaVW3SUlJwb1791QujmhTtwEqX79RPmVUuh5Z1lP9DRs2xJtvvok333wTFy5cQNu2bbFw4UJ88803eq1TVgfV95KGTISFheHXX39Ve/s78O/VxwEDBiArKwvfffedNK6wsBDLli2Dk5MTevTooZdYQkJCoFAo8MEHH2jsA+3GjRtaT0tZKS2d9B06dICHhwfi4+ORl5cnDf/f//6Hc+fOITQ0VOt5KE8uSl6lPXr0KFJTU1XKhYSEoKCgAF988YU0rLi4GCtWrFAp5+HhgZ49e+Kzzz7DtWvX1Oany/ITlaRpWwUgvdm+pLJyZ/DgwbCyskJsbKzadIQQKt1aVKSseQQFBcHGxgaffPKJyjxWrVqFO3fu6JSfpWmb+7qsKyJToW3udOjQATVr1sQXX3yBwsJCqdzatWv18ii+ttq3bw8/Pz8sWbJEbT+gjL9OnTpo27Yt1qxZo1ImPT0dO3fuxIABA/QWz0svvYS///5b5Tit9PDhQ9y/f19v86pOrKys1Paly5YtU7uzKiQkBKmpqTh58qQ07NatW2p3ROuznhgWFoZ//vkHy5cvVxtX0d2rutTXBgwYgCNHjuDYsWMq48u627ukso6VVa308dzGxgbNmzeHEEJa72XFpszL0sdM5d2LuhzHR44cidu3b+O1117DvXv3VPo2NoSylvGll15CUVER5s2bp/adwsJCrX4vTXWNO3fuICEhQaVccHAwnJ2dERcXh0ePHqmMK/ldR0dHrbpVNOR+VY603RdVtQEDBuDYsWMq55T379/H559/jvr160vdbGh7LqpPhjjHfhJhYWEQQmh8uqhk2wagn/1UeXhub3y3b99WO6YrG7xLbqf6okt9MiAgANbW1pg/fz7c3d3RokULAI8b/I8cOYJ9+/bpfLf+oEGDYGlpiXfffVftyS9tnsx56aWXkJqaih07dqiNy8nJkc4dBgwYgMLCQqxcuVIaX1RUhGXLlmkVp6OjY6XqNr6+vrCyspL6+lf69NNPVT4/ePBA7ZjZsGFDODs7S7+7PuuU1QHv2DdxU6dOxffff48hQ4ZgzJgx8Pf3x61bt/Djjz8iPj4ebdq0wYQJE/DZZ59h1KhRSEtLQ/369fH999/j0KFDWLJkCZydnfUSi0KhwMqVKzFy5Ei0b98ew4YNQ+3atXHlyhUkJSWhS5cuGk/ANGnYsCFcXV0RHx8PZ2dnODo6IiAgAH5+fpg/fz5Gjx6NHj16YPjw4cjOzsbSpUtRv359TJkyRet4n332WWzatAkvvPACQkNDkZmZifj4eDRv3hz37t2Tyg0aNAidOnXCm2++iYsXL6Jp06b48ccfcevWLQCqVyxXrFiBrl27olWrVhg/fjwaNGiA7OxspKam4q+//sKvv/6qdXxESgqFAt27d8eCBQtQUFCAp556Cjt37kRmZqZaWX9/fwDAO++8g2HDhsHa2hoDBw5Ew4YN8d5772HmzJm4fPkyBg0aBGdnZ2RmZmLz5s2YMGEC3nrrLa3iadu2LaysrDB//nzcuXMHtra26N27Nzw8PDBz5kzExsaiX79+eO6555CRkYFPP/0UHTt2fKKTemXFqaLc12VdEZmK2rVra5U7NjY2iImJweTJk9G7d2+89NJLuHz5MhITE9GwYUOD3SFsaWmJlStXYuDAgWjbti1Gjx6NOnXq4Pz58zhz5ox0QvHRRx+hf//+CAwMxNixY/Hw4UMsW7YMLi4uiImJ0Vs8I0eOxIYNGzBx4kTs2bMHXbp0QVFREc6fP48NGzZgx44d6NChg97mV108++yz+Prrr+Hi4oLmzZsjNTUVu3btQs2aNVXKTZs2Dd988w369u2LyZMnw9HREV9++SXq1auHW7duSdulPuuJr776Kr766itER0fj2LFj6NatG+7fv49du3bhP//5D55//vlyv69tfW3atGn4+uuv0a9fP7zxxhtwdHTE559/Lj0NW57y6rJVKTg4GF5eXujSpQs8PT1x7tw5LF++HKGhoVKdv6y6Qps2bRAeHo7PP/8cOTk56NGjB44dO4Y1a9Zg0KBBKk8KVaRdu3Zo2bKl9DLC9u3bV8nylkW5jK+//jpCQkJgZWWFYcOGoUePHnjttdcQFxeHkydPIjg4GNbW1rhw4QI2btyIpUuX4sUXXyx32sHBwbCxscHAgQOlCxdffPEFPDw8VBoAFQoFFi9ejHHjxqFjx44YMWIE3Nzc8Ouvv+LBgwdYs2aNFOt3332H6OhodOzYEU5OThg4cKDGeRtqvypH2u6LqtqMGTPw7bffon///nj99dfh7u6ONWvWIDMzE//973+lJ+i1PRfVJ0OcYz+JXr16YeTIkfjkk09w4cIFqRvNAwcOoFevXoiMjNTrfqoiPLc3rjVr1uDTTz/FCy+8gIYNG+Lu3bv44osvoFAoquRCpi71SQcHB/j7++PIkSMYOHCgtH/p3r077t+/j/v37+vcsN+oUSO88847mDdvHrp164bBgwfD1tYWP//8M7y9vREXF1fu96dOnYoff/wRzz77LEaNGgV/f3/cv38fp0+fxvfff4/Lly+jVq1aGDhwILp06YIZM2bg8uXLaN68OTZt2qTVBWbg8TFr165dWLRoEby9veHn56fxvSKlubi4YMiQIVi2bBksLCzQsGFDbN26Ve3dNr/99hv69OmDl156Cc2bN0eNGjWwefNmZGdnY9iwYQD0W6esFgQZREJCggAgMjMzhRBC+Pr6itDQULVyPXr0ED169FAZdvPmTREZGSmeeuopYWNjI+rWrSvCw8PFP//8I5XJzs4Wo0ePFrVq1RI2NjaiVatWIiEhQWU6mZmZAoD46KOPVIbv2bNHABAbN27UGPPPP/+sVj4kJES4uLgIOzs70bBhQzFq1Chx/PhxndbJDz/8IJo3by5q1KghAKjE+91334l27doJW1tb4e7uLl5++WXx119/6TT94uJi8cEHHwhfX19ha2sr2rVrJ7Zu3SrCw8OFr6+vStkbN26IESNGCGdnZ+Hi4iJGjRolDh06JACI9evXq5S9dOmSePXVV4WXl5ewtrYWTz31lHj22WfF999/r1N8VD3NnTtXABA3btxQGf7XX3+JF154Qbi6ugoXFxcxZMgQcfXqVQFAzJ07V6XsvHnzxFNPPSUsLS1V9itCCPHf//5XdO3aVTg6OgpHR0fRtGlTERERITIyMnSK84svvhANGjQQVlZWAoDYs2ePNG758uWiadOmwtraWnh6eopJkyaJ27dv6zR95X6n5HSF0C73tV1XZa3r0vtjoqqgaTvTNnc++eQT6djVqVMncejQIeHv7y/69eunUwyl6xRlHe+V9YPS9YaDBw+Kvn37CmdnZ+Ho6Chat24tli1bplJm165dokuXLsLe3l4oFAoxcOBAcfbsWZUyZeVieHi4cHR01Bh3ixYtVIbl5+eL+fPnixYtWghbW1vh5uYm/P39RWxsrLhz5462q4RKuH37tlR3dHJyEiEhIeL8+fPC19dXhIeHq5Q9ceKE6Natm7C1tRV169YVcXFx4pNPPhEARFZWlkpZfdUTHzx4IN555x3h5+cnrK2thZeXl3jxxRfFpUuXhBBl12uVtK2vnTp1SvTo0UPY2dmJp556SsybN0+sWrVKLX811dHLq8uWp7w6duljY+n5fvbZZ6J79+6iZs2awtbWVjRs2FBMnTpVLQ/KqisUFBSI2NhYab36+PiImTNnikePHql8v6xzlZIWLFggAIgPPvhAq+UurXSdvLzftPQxvrCwUEyePFnUrl1bWFhYiNKntZ9//rnw9/cX9vb2wtnZWbRq1UpMmzZNXL16Vatl/PHHH0Xr1q2FnZ2dqF+/vpg/f75YvXq1xvrDjz/+KJ555hlpP9ipUyfx7bffSuPv3bsnRowYIVxdXQUAaZnL2vc+yX5VDnUcbWN/kn2RLufaFdEUx6VLl8SLL74oXF1dhZ2dnejUqZPYunWrShltz0V12e61UdXn2Jq227KO58rfuqTCwkLx0UcfiaZNmwobGxtRu3Zt0b9/f5GWliaVedL9FAARERGhMe7S65nn9oZVMs9/+eUXMXz4cFGvXj1ha2srPDw8xLPPPqtzfUFTvVEI9WOMELrVJ6dOnSoAiPnz56sMb9SokQAg1Ud0tXr1aikP3dzcRI8ePURycrI0vrxj0927d8XMmTNFo0aNhI2NjahVq5Z45plnxMcffyzy8/Olcjdv3hQjR44UCoVCuLi4iJEjR4oTJ06o5a6mHD1//rzo3r27sLe3FwDU9n/luXHjhggLCxMODg7Czc1NvPbaayI9PV1lvv/884+IiIgQTZs2FY6OjsLFxUUEBASIDRs2qE1PmzplWfuf6sRCCJm8jYXIwLZs2YIXXngBBw8eRJcuXYwdDhERVVPFxcWoXbs2Bg8erPHxYSJjiIqKwmeffYZ79+4ZtG91Mh1Lly7FlClTcPnyZZW+6IkMifsiIiKqztjHPhEe96lWkrIPMoVCYfBHi4mIqPp69OiRWj+bX331FW7duoWePXsaJyiq9krXk27evImvv/4aXbt2ZUNaNSWEwKpVq9CjRw826pPBcF9ERESkin3sk17l5+dLfdOXxcXFBfb29iY1j8mTJ+Phw4cIDAxEXl4eNm3ahMOHD+ODDz54oliJTMnDhw8r7FvP3d0dNjY2Jj0PInN25MgRTJkyBUOGDEHNmjXxyy+/YNWqVWjZsiWGDBkC4PELo0q/4LQkGxsbuLu7GypkqgYCAwPRs2dPNGvWDNnZ2Vi1ahVyc3Mxe/ZsnaZjiHqiMVWHY+D9+/fx448/Ys+ePTh9+jR++OEHtTK3bt1Cfn5+mdOwsrJC7dq1qzJMMlP62hcBQFZWVrnj7e3t4eLiUtlQ9Uqu59hET0JOxxI57U90VVRUVOHLap2cnODk5GSgiEiNcXsCInOj7Bu0vD9t+x815DzWrl0r2rdvLxQKhbCxsRHNmzdX60eYSO6UfRqW91e6z3tTnAeROcvMzBQDBw4Unp6eUl/8o0ePFtnZ2VIZX1/fcnNM1/6DiSoyc+ZM0bhxY2Fvby8cHBxE165dVfqD1ZYh6onGVB2Ogcp+ql1dXcXbb7+tsUyPHj3KXQel+zwm0pa+9kVCiApzVZd+pauaXM+xiZ6EnI4lctqf6Ep53C/vT9d3gZB+sY990qvbt28jLS2t3DItWrRAnTp1THoeRObo2rVrOHPmTLll/P394ebmZtLzIKruDh06pNYdQUlubm7w9/c3YERE2jH3OhyPgY+lpaXh9u3bZY63t7fn+6vI6Hbt2lXueG9vbzRv3txA0ZSP59hUHcnpWCKn/YmuHj16hIMHD5ZbpkGDBmjQoIGBIqLS2LBPRERERERERERERCQj1bqP/eLiYly9ehXOzs6wsLAwdjhEWhNC4O7du/D29oalJd+BXRpzm+SKuV0x5jfJFfO7fMxtkivmdsWY3yRXzO/yMbdJrswpt6t1w/7Vq1fh4+Nj7DCIKu3PP/9E3bp1jR2GyWFuk9wxt8vG/Ca5Y35rxtwmuWNul435TXLH/NaMuU1yZw65Xa0b9p2dnQE8/iEVCoXKuIKCAuzcuRPBwcGwtrY2RniVIte4AfnGboy4c3Nz4ePjI23DpMocc/tJVdflBuS17MztipWX33Ijp21TG1ye8jG/y6cpt81tmzIErjPdPek6Y25XrKJjN7fbyuO6ezIVrT/md/mY21WL66/yqlNuV+uGfeWjQgqFQmPjn4ODAxQKhawSSK5xA/KN3Zhx83E3zcwxt59UdV1uQJ7LztwuW3n5LTdy3DbLw+XRDvNbM025bW7blCFwnelOX+uMuV22io7d3G4rj+vuyWi7/pjfmjG3qxbXX+VVp9yWd0dCRERERERERERERETVTLW+Y18bLWN2IK9I9QrO5Q9DjRQNEekLc5uIqov6M5I0Duc+j+RG07bM7ZjIfJSunzO/iYi4b6Ty8Y59IiIiIiIiIiIiIiIZYcM+EREREREREREREZGMsGGfiIiIiIiIiIiIiEhG2LBPRACAuLg4dOzYEc7OzvDw8MCgQYOQkZGhUubRo0eIiIhAzZo14eTkhLCwMGRnZ6uUuXLlCkJDQ+Hg4AAPDw9MnToVhYWFKmX27t2L9u3bw9bWFo0aNUJiYqJaPCtWrED9+vVhZ2eHgIAAHDt2TO/LTEREREREREREJEds2CciAMC+ffsQERGBI0eOIDk5GQUFBQgODsb9+/elMlOmTMFPP/2EjRs3Yt++fbh69SoGDx4sjS8qKkJoaCjy8/Nx+PBhrFmzBomJiZgzZ45UJjMzE6GhoejVqxdOnjyJqKgojBs3Djt27JDKfPfdd4iOjsbcuXPxyy+/oE2bNggJCcH169cNszKIiIiIiIiIiIhMWA1jB0BEpmH79u0qnxMTE+Hh4YG0tDR0794dd+7cwapVq7Bu3Tr07t0bAJCQkIBmzZrhyJEj6Ny5M3bu3ImzZ89i165d8PT0RNu2bTFv3jxMnz4dMTExsLGxQXx8PPz8/LBw4UIAQLNmzXDw4EEsXrwYISEhAIBFixZh/PjxGD16NAAgPj4eSUlJWL16NWbMmGHAtUJERERERERERGR6nuiO/Q8//BAWFhaIioqShrGrDiLzcOfOHQCAu7s7ACAtLQ0FBQUICgqSyjRt2hT16tVDamoqACA1NRWtWrWCp6enVCYkJAS5ubk4c+aMVKbkNJRllNPIz89HWlqaShlLS0sEBQVJZUrLy8tDbm6uyh8AFBQUaPwDAFtLAVsr1b+yypvLX3nrxNz/5LTsREREREREREQVqfQd+z///DM+++wztG7dWmX4lClTkJSUhI0bN8LFxQWRkZEYPHgwDh06BODfrjq8vLxw+PBhXLt2Da+++iqsra3xwQcfAPi3q46JEydi7dq1SElJwbhx41CnTh3pjl5lVx3x8fEICAjAkiVLEBISgoyMDHh4eFR2sYgIQHFxMaKiotClSxe0bNkSAJCVlQUbGxu4urqqlPX09ERWVpZUpmSjvnK8clx5ZXJzc/Hw4UPcvn0bRUVFGsucP39eY7xxcXGIjY1VG75z5044ODho/M68DsVqw7Zt26axrDlJTk42dghGI4dlf/DggbFDICIiIiIiIiIZqFTD/r179/Dyyy/jiy++wHvvvScNN/WuOvLy8pCXlyd9Ln1Xb0nKz7aWQm06pnxHZck7U+VGrrEbI+6qnldERATS09Nx8ODBKp2PvsycORPR0dHS59zcXPj4+CA4OBgKhUKlbEFBAZKTkzH7uCXyii1UxqXHhBgkXmNQLnffvn1hbW1t7HAMSk7LrjwuERERUfUVExOjdtNKkyZNpJtcHj16hDfffBPr169HXl4eQkJC8Omnn6rcGHPlyhVMmjQJe/bsgZOTE8LDwxEXF4caNf5tAti7dy+io6Nx5swZ+Pj4YNasWRg1apTKfFesWIGPPvoIWVlZaNOmDZYtW4ZOnTpV3cITmTnmNxHpU6Ua9iMiIhAaGoqgoCCVhv2Kuuro3LlzmV11TJo0CWfOnEG7du3K7KpD2eWPsquOmTNnSuMr6qoDqF539crhztSyyDV2Q8ZdlXf1RkZGYuvWrdi/fz/q1q0rDffy8kJ+fj5ycnJU7trPzs6Gl5eXVKZ0l1jKrrhKlindPVd2djYUCgXs7e1hZWUFKysrjWWU0yjN1tYWtra2asOtra3LbMjNK7ZAXpFqw37j2Ts1lr38YajG4XJU3joxd3JY9qqKb//+/fjoo4+QlpaGa9euYfPmzRg0aJA0XgiBuXPn4osvvkBOTg66dOmClStXonHjxlKZW7duYfLkyfjpp59gaWmJsLAwLF26FE5OTlKZU6dOISIiAj///DNq166NyZMnY9q0aSqxbNy4EbNnz8bly5fRuHFjzJ8/HwMGDKiS5SYiIpKrFi1aYNeuXdLnkg12fEqeSN6Y30SkLzo37K9fvx6//PILfv75Z7VxptxVB1A97uqV052ppck1dmPEXRV39QohMHnyZGzevBl79+6Fn5+fynh/f39YW1sjJSUFYWFhAICMjAxcuXIFgYGBAIDAwEC8//77uH79ulQZSE5OhkKhQPPmzaUypS+OJScnS9OwsbGBv78/UlJSpIbH4uJipKSkIDIyUu/LTVQd3L9/H23atMGYMWMwePBgtfELFizAJ598gjVr1sDPzw+zZ89GSEgIzp49Czs7OwDAyy+/jGvXriE5ORkFBQUYPXo0JkyYgHXr1gF4vF8KDg5GUFAQ4uPjcfr0aYwZMwaurq6YMGECAODw4cMYPnw44uLi8Oyzz2LdunUYNGgQfvnlF6nbLyIiInrc0KfpphZTf0oe0O1JeeVwQP1pebk9yW0Mcn3q3VRUtP6qar3KNb8rm9vcPiuH+8bKM1ZuG4NODft//vkn3njjDSQnJ0sn+nKir7t65dDoLIc7U8si19gNGXdVzCciIgLr1q3DDz/8AGdnZ+lCm4uLC+zt7eHi4oKxY8ciOjoa7u7uUCgUmDx5MgIDA9G5c2cAQHBwMJo3b46RI0diwYIFyMrKwqxZsxARESHl3sSJE7F8+XJMmzYNY8aMwe7du7FhwwYkJSVJsURHRyM8PBwdOnRAp06dsGTJEty/f1+qdBCRbvr374/+/ftrHCeEwJIlSzBr1iw8//zzAICvvvoKnp6e2LJlC4YNG4Zz585h+/bt+Pnnn9GhQwcAwLJlyzBgwAB8/PHH8Pb2xtq1a5Gfn4/Vq1fDxsYGLVq0wMmTJ7Fo0SKpYX/p0qXo168fpk6dCgCYN28ekpOTsXz5csTHx2uMT9cTCDkx1MmOrZV6t4JVMV9zO3nT9/KYy3ohIsO4cOECvL29YWdnh8DAQMTFxaFevXom/5Q8ULkn5QH1p+Xl8KS8qZDrU++moqz1V1VPyss1vyub29w+nwz3jZVn6Nw2Bp0a9tPS0nD9+nW0b99eGlZUVIT9+/dj+fLl2LFjh8l21UFE5Vu5ciUAoGfPnirDExISpL74Fi9eLHXBUbK/PyUrKyts3boVkyZNQmBgIBwdHREeHo53331XKuPn54ekpCRMmTIFS5cuRd26dfHll19Kdw4AwNChQ3Hjxg3MmTMHWVlZaNu2LbZv3672lA4RPbnMzExkZWWpVP5dXFwQEBCA1NRUDBs2DKmpqXB1dZUa9QEgKCgIlpaWOHr0KF544QWkpqaie/fusLGxkcqEhIRg/vz5uH37Ntzc3JCamqry5JyyzJYtW8qMr7InEHJS1Sc7C8roKrWqTgrM7eRNX8tjTicQRFS1AgICkJiYiCZNmuDatWuIjY1Ft27dkJ6ebvJPyQO6PSkPlP20vCk/KW8q5PrUu6moaP1VxZPycs7vyuY2t8/K4b6x8oyR28aiU8N+nz59cPr0aZVho0ePRtOmTTF9+nT4+Piwqw4imRJC8x2dJdnZ2WHFihVYsWJFmWV8fX0rbCzq2bMnTpw4UW6ZyMhI5jORAShPADRV7EueHJTua7NGjRpwd3dXKVO6C6+SJxlubm5lnmQop6GJricQcmKok52WMTs0Dtf3SYG5nbzpe3nM6QSCiKpWyafsWrdujYCAAPj6+mLDhg2wt7c3YmTaqcyT8oD60/LmcCwxFLk+9W4qylp/VbFO5Zzflc1tbp9PhvvGyjNkbhuLTg37zs7Oan3gOjo6ombNmtJwdtVBRERE+lLZEwg5qeplKd2lYMn5VgVz+m0A/S2POa0TIjIsV1dXPP3007h48SL69u3Lp+SJzAjzm4iehKW+J7h48WI8++yzCAsLQ/fu3eHl5YVNmzZJ45VddVhZWSEwMBCvvPIKXn31VY1ddSQnJ6NNmzZYuHChxq46Pv74Y8yZMwdt27bFyZMn2VUHERGRjpSV9/Iq9l5eXrh+/brK+MLCQty6davCE4iS8yirDE8giIiIynbv3j1cunQJderUgb+/v/SUvJKmp+RPnz6tcuzW9JR8yWkoy2h6Sl5J+ZS8sgwRPTnmNxE9CZ3u2Ndk7969Kp/ZVQcREZF8+Pn5wcvLCykpKWjbti2Ax12GHD16FJMmTQLw+OQgJycHaWlp8Pf3BwDs3r0bxcXFCAgIkMq88847KCgokO5MTk5ORpMmTeDm5iaVSUlJkV7cpSzDEwj9qT8jqeJCRERk0t566y0MHDgQvr6+uHr1KubOnQsrKysMHz4cLi4ufEqeSMaY30SkT0/csE9ERESm7d69e7h48aL0OTMzEydPnoS7uzvq1auHqKgovPfee2jcuDH8/Pwwe/ZsGiFYlQABAABJREFUeHt7S++xadasGfr164fx48cjPj4eBQUFiIyMxLBhw+Dt7Q0AGDFiBGJjYzF27FhMnz4d6enpWLp0KRYvXizN94033kCPHj2wcOFChIaGYv369Th+/Dg+//xzg64PIiIiU/bXX39h+PDhuHnzJmrXro2uXbviyJEjqF27NoDHT8lbWloiLCwMeXl5CAkJwaeffip9X/mU/KRJkxAYGAhHR0eEh4drfEp+ypQpWLp0KerWravxKfkbN25gzpw5yMrKQtu2bfmUPNETYn4TkT6xYZ+IiMjMHT9+HL169ZI+K19GGx4ejsTEREybNg3379/HhAkTkJOTg65du2L79u2ws7OTvrN27VpERkaiT58+0snGJ598Io13cXHBzp07ERERAX9/f9SqVQtz5szBhAkTpDLPPPMM1q1bh1mzZuHtt99G48aNsWXLFrX39xAREVVn69evL3c8n5Inki/mNxHpExv2iYiIzFzPnj0hhChzvIWFBd59912VO31Kc3d3x7p168qdT+vWrXHgwIFyywwZMgRDhgwpP2AiIiIiIiIiKpfeX55LRERERERERERERERVhw37REREREREREREREQywq54iIiIiGSo/owkY4dARERERERERsI79omIiIiIiIiIiIiIZIQN+0REREREREREREREMsKGfSIiIiIiIiIiIiIiGWHDPhERERERERERERGRjLBhn4iIiIhIhuLi4tCxY0c4OzvDw8MDgwYNQkZGhkqZR48eISIiAjVr1oSTkxPCwsKQnZ2tUubKlSsIDQ2Fg4MDPDw8MHXqVBQWFqqU2bt3L9q3bw9bW1s0atQIiYmJavGsWLEC9evXh52dHQICAnDs2DG9LzMRERERET3Ghn0iIiIiIhnat28fIiIicOTIESQnJ6OgoADBwcG4f/++VGbKlCn46aefsHHjRuzbtw9Xr17F4MGDpfFFRUUIDQ1Ffn4+Dh8+jDVr1iAxMRFz5syRymRmZiI0NBS9evXCyZMnERUVhXHjxmHHjh1Sme+++w7R0dGYO3cufvnlF7Rp0wYhISG4fv26YVYGEREREVE1U8PYARARERERke62b9+u8jkxMREeHh5IS0tD9+7dcefOHaxatQrr1q1D7969AQAJCQlo1qwZjhw5gs6dO2Pnzp04e/Ysdu3aBU9PT7Rt2xbz5s3D9OnTERMTAxsbG8THx8PPzw8LFy4EADRr1gwHDx7E4sWLERISAgBYtGgRxo8fj9GjRwMA4uPjkZSUhNWrV2PGjBlqsefl5SEvL0/6nJubCwAoKChAQUGB9P+S/9paCbXpKMfRY6XXGVXsSdcZ1zUREREZCxv2iYiIiIjMwJ07dwAA7u7uAIC0tDQUFBQgKChIKtO0aVPUq1cPqamp6Ny5M1JTU9GqVSt4enpKZUJCQjBp0iScOXMG7dq1Q2pqqso0lGWioqIAAPn5+UhLS8PMmTOl8ZaWlggKCkJqaqrGWOPi4hAbG6s2fOfOnXBwcFAZlpycDABY0El9Otu2bStrdVRrynVG2qvsOnvw4IGeIyEiIiLSDhv2iYiIiIhkrri4GFFRUejSpQtatmwJAMjKyoKNjQ1cXV1Vynp6eiIrK0sqU7JRXzleOa68Mrm5uXj48CFu376NoqIijWXOnz+vMd6ZM2ciOjpa+pybmwsfHx8EBwdDoVAAeHwndHJyMvr27Qtra2u0jNmhNp30mJBy10t1U3qdUcWedJ0pnzYhIiIiMjQ27BMRERERyVxERATS09Nx8OBBY4eiFVtbW9ja2qoNt7a2VmtcVQ7LK7LQWJ7UaVqPVL7KrjOuZyIiIjIWvjyXiIiIiEjGIiMjsXXrVuzZswd169aVhnt5eSE/Px85OTkq5bOzs+Hl5SWVyc7OVhuvHFdeGYVCAXt7e9SqVQtWVlYayyinQURERERE+sWGfSIiIqJqqP6MJLU/khchBCIjI7F582bs3r0bfn5+KuP9/f1hbW2NlJQUaVhGRgauXLmCwMBAAEBgYCBOnz6N69evS2WSk5OhUCjQvHlzqUzJaSjLKKdhY2MDf39/lTLFxcVISUmRyhARERERkX6xKx4iIiIiIhmKiIjAunXr8MMPP8DZ2VnqE9/FxQX29vZwcXHB2LFjER0dDXd3dygUCkyePBmBgYHo3LkzACA4OBjNmzfHyJEjsWDBAmRlZWHWrFmIiIiQusqZOHEili9fjmnTpmHMmDHYvXs3NmzYgKSkfy8GRUdHIzw8HB06dECnTp2wZMkS3L9/H6NHjzb8iiEiIiIiqgbYsE9EREREJEMrV64EAPTs2VNleEJCAkaNGgUAWLx4MSwtLREWFoa8vDyEhITg008/lcpaWVlh69atmDRpEgIDA+Ho6Ijw8HC8++67Uhk/Pz8kJSVhypQpWLp0KerWrYsvv/wSISH/vrh26NChuHHjBubMmYOsrCy0bdsW27dvV3uhLhERERER6Qcb9omIiIiIZEgIUWEZOzs7rFixAitWrCizjK+vL7Zt21budHr27IkTJ06UWyYyMhKRkZEVxkRERERERE+OfewTEREREREREREREckIG/aJiIiIiIiIiIiIiGSEDftERERERERERERERDLChn0iAgDs378fAwcOhLe3NywsLLBlyxaV8UIIzJkzB3Xq1IG9vT2CgoJw4cIFlTK3bt3Cyy+/DIVCAVdXV4wdOxb37t1TKXPq1Cl069YNdnZ28PHxwYIFC9Ri2bhxI5o2bQo7Ozu0atWqwn5/iYiIiIiIiIiIqhM27BMRAOD+/fto06ZNmS/XW7BgAT755BPEx8fj6NGjcHR0REhICB49eiSVefnll3HmzBkkJydj69at2L9/PyZMmCCNz83NRXBwMHx9fZGWloaPPvoIMTEx+Pzzz6Uyhw8fxvDhwzF27FicOHECgwYNwqBBg5Cenl51C09ERERERERERCQjOjXsx8XFoWPHjnB2doaHhwcGDRqEjIwMlTKPHj1CREQEatasCScnJ4SFhSE7O1ulzJUrVxAaGgoHBwd4eHhg6tSpKCwsVCmzd+9etG/fHra2tmjUqBESExPV4lmxYgXq168POzs7BAQE4NixY7osDhGV0L9/f7z33nt44YUX1MYJIbBkyRLMmjULzz//PFq3bo2vvvoKV69ele7sP3fuHLZv344vv/wSAQEB6Nq1K5YtW4b169fj6tWrAIC1a9ciPz8fq1evRosWLTBs2DC8/vrrWLRokTSvpUuXol+/fpg6dSqaNWuGefPmoX379li+fLlB1gMRERERkTFpc97ds2dPWFhYqPxNnDhRpQzPu4lMD/ObiPRJp4b9ffv2ISIiAkeOHEFycjIKCgoQHByM+/fvS2WmTJmCn376CRs3bsS+fftw9epVDB48WBpfVFSE0NBQ5Ofn4/Dhw1izZg0SExMxZ84cqUxmZiZCQ0PRq1cvnDx5ElFRURg3bhx27Nghlfnuu+8QHR2NuXPn4pdffkGbNm0QEhKC69evP8n6ICINMjMzkZWVhaCgIGmYi4sLAgICkJqaCgBITU2Fq6srOnToIJUJCgqCpaUljh49KpXp3r07bGxspDIhISHIyMjA7du3pTIl56Mso5yPJnl5ecjNzVX5A4CCggKNfwBgaylga6XdX1nTkdtfeevE3P/ktOzGEBMTo3by0LRpU2m8IS/aExERVXfanHcDwPjx43Ht2jXpr2QXlzzvJjJNzG8i0qcauhTevn27yufExER4eHggLS0N3bt3x507d7Bq1SqsW7cOvXv3BgAkJCSgWbNmOHLkCDp37oydO3fi7Nmz2LVrFzw9PdG2bVvMmzcP06dPR0xMDGxsbBAfHw8/Pz8sXLgQANCsWTMcPHgQixcvRkhICABg0aJFGD9+PEaPHg0AiI+PR1JSElavXo0ZM2ZojD8vLw95eXnS59KNfyUpP9taCrXpGKvhRRslG7DkRq6xGyNuQ6+jrKwsAICnp6fKcE9PT2lcVlYWPDw8VMbXqFED7u7uKmX8/PzUpqEc5+bmhqysrHLno0lcXBxiY2PVhu/cuRMODg4avzOvQ3GZ0yvNnPr4T05ONnYIRiOHZX/w4IHR5t2iRQvs2rVL+lyjxr9VhClTpiApKQkbN26Ei4sLIiMjMXjwYBw6dAjAvycXXl5eOHz4MK5du4ZXX30V1tbW+OCDDwD8e3IxceJErF27FikpKRg3bhzq1KkjHduJiIio4vNuJQcHB3h5eWmchjHPu4mobMxvItInnRr2S7tz5w4AwN3dHQCQlpaGgoIClbttmzZtinr16iE1NRWdO3dGamoqWrVqpdJwFxISgkmTJuHMmTNo165dmXfsRkVFAQDy8/ORlpaGmTNnSuMtLS0RFBRU7l29+mr8k0MjnxwasMoi19gNGbcxG/9M0cyZMxEdHS19zs3NhY+PD4KDg6FQKFTKFhQUIDk5GbOPWyKv2EKr6afHyL/RUbncffv2hbW1tbHDMSg5LbvygrMx1KhRQ+PJgyEv2muiy0V5udHlwnDLmB1qw2yt9B7SE61TuV6gL4u+l8dc1gsRGV7p826ltWvX4ptvvoGXlxcGDhyI2bNnS+e1xjzv1vXYXdZNddxvVszcjr2GVtH6M8R6lVN+Vza3uX1WDveNlWcKuW0olW7YLy4uRlRUFLp06YKWLVsCeHzHrY2NDVxdXVXKlr6rV9PduMpx5ZXJzc3Fw4cPcfv2bRQVFWksc/78+TJj1lfjnyk38smpAas0ucZujLgN3finbOzLzs5GnTp1pOHZ2dlo27atVKb0I3uFhYW4deuW9H0vLy+17juUnysqU9bdCgBga2sLW1tbteHW1tZl/iZ5xRbIK9KuYV9O22NFylsn5k4Oy27M+C5cuABvb2/Y2dkhMDAQcXFxqFevnsEu2pelMhfl5UabC8MLOhkgEOjn5gW5XqAvi76WhxfliagyNJ13A8CIESPg6+sLb29vnDp1CtOnT0dGRgY2bdoEwLjn3ZU9dpe+qU4ON9SZCnM79hpaWeuvqo/dcsvvyuY2t88nw31j5Rkrtw2p0g37ERERSE9Px8GDB/UZT5XSV+OfqTcMAfJowCqLXGM3ZNyGXj9+fn7w8vJCSkqK1JCfm5uLo0ePYtKkSQCAwMBA5OTkIC0tDf7+/gCA3bt3o7i4GAEBAVKZd955BwUFBdIyJCcno0mTJnBzc5PKpKSkqDT2JScnIzAw0EBLS1T9BAQEIDExEU2aNMG1a9cQGxuLbt26IT093WAX7e3t7TXGpstFebnR5cKwpjv2DUXbGxrkeoG+LPpeHmM+kUNE8lXWefeECROk/7dq1Qp16tRBnz59cOnSJTRs2NDQYarQ9dhd1k11pnxDnakwt2OvoVW0/qr62C23/K5sbnP7rBzuGyvP2LltSJVq2I+MjMTWrVuxf/9+1K1bVxru5eWF/Px85OTkqDQAlLzb1svLS+0t29resatQKGBvbw8rKytYWVnpfFcvEZXt3r17uHjxovQ5MzMTJ0+ehLu7O+rVq4eoqCi89957aNy4Mfz8/DB79mx4e3tj0KBBAB53q9GvXz+MHz8e8fHxKCgoQGRkJIYNGwZvb28Aj+88iI2NxdixYzF9+nSkp6dj6dKlWLx4sTTfN954Az169MDChQsRGhqK9evX4/jx4/j8888Nuj6IqpP+/ftL/2/dujUCAgLg6+uLDRs2lNngbiiVuSgvN9osi7ZPGFUFXdezOf02gP6Wx5zWCREZRlnn3Zoob6S5ePEiGjZsaNTz7soeu0vfVMf9pvbM7dhraGWtv6pcp3LM78rmNrfPJ8N9Y+UZI7cNzVKXwkIIREZGYvPmzdi9e7faSzD9/f1hbW2NlJQUaVhGRgauXLki3W0bGBiI06dPq3TZkZycDIVCgebNm0tlSk5DWUY5DRsbG/j7+6uUKS4uRkpKCu/qJaqk48ePo127dmjXrh0AIDo6Gu3atcOcOXMAANOmTcPkyZMxYcIEdOzYEffu3cP27dthZ2cnTWPt2rVo2rQp+vTpgwEDBqBr164qDfIuLi7YuXMnMjMz4e/vjzfffBNz5sxRuSPhmWeewbp16/D555+jTZs2+P7777FlyxaVRxMNrf6MJLU/InPm6uqKp59+GhcvXlS5aF9S6Yv2le1mS3lyQURERI9VdN6tycmTJwFA6jaT591Epon5TUT6pNMd+xEREVi3bh1++OEHODs7S4/Xu7i4wN7eHi4uLhg7diyio6Ph7u4OhUKByZMnIzAwEJ07dwYABAcHo3nz5hg5ciQWLFiArKwszJo1CxEREdKVv4kTJ2L58uWYNm0axowZg927d2PDhg1ISvq3MS06Ohrh4eHo0KEDOnXqhCVLluD+/fvS27yJSDc9e/aEEKLM8RYWFnj33Xfx7rvvllnG3d0d69atK3c+rVu3xoEDB8otM2TIEAwZMqT8gImoyty7dw+XLl3CyJEjVS7ah4WFAdB80f7999/H9evX4eHhAUDzyUXp/iDZzRYREZG6is67L126hHXr1mHAgAGoWbMmTp06hSlTpqB79+5o3bo1AJ53E5kq5jcR6ZNODfsrV64E8LgBsKSEhASMGjUKALB48WJYWloiLCwMeXl5CAkJwaeffiqVtbKywtatWzFp0iQEBgbC0dER4eHhKo2Ffn5+SEpKwpQpU7B06VLUrVsXX375JUJC/u1HaujQobhx4wbmzJmDrKwstG3bFtu3b1frv5eIiIjK99Zbb2HgwIHw9fXF1atXMXfuXFhZWWH48OEGvWhP4BNBRERU4Xm3jY0Ndu3aJTXC+fj4ICwsDLNmzZLK8rybyDQxv4lIn3Rq2C/vbl4lOzs7rFixAitWrCizjK+vb4Vvce7ZsydOnDhRbpnIyEhERkZWGBMRERGV7a+//sLw4cNx8+ZN1K5dG127dsWRI0dQu3ZtAIa7aE9EREQVn3f7+Phg3759FU6H591Epof5TUT6VKmX5xIREZH5WL9+fbnjDXnRnoiIiIiIiIgqptPLc4mIiIiIiIiIiIiIyLjYsE9EREREREREREREJCNs2CciIiIiIiIiIiIikhE27BMRERERERERERERyQgb9omIiIiIiIiIiIiIZKSGsQOQo/ozktSGXf4w1AiREBEREREREREREVF1w4Z9IiIiIiqTphsaAN7UQEREREREZExs2CciIiIiIrPCJ2yJiIiIyNyxj30iIiIiIiIiIiIiIhlhwz4RERERERERERERkYywYZ+IiIiIiIiIiIiISEbYsE9EREREREREREREJCN8eS4REREREZk9vlCXiIiIiMwJ79gnIiIiIiIiIiIiIpIR3rFPRFQJvOuPiIjI+DQdj4mIiIiIqgPesU9EREREREREREREJCO8Y5+IiIjICFrG7MCCTo//zSuyMHY4REREREREJCO8Y5+IiIiIiIiIiIiISEbYsE9EREREREREREREJCPsioeIiIiIdFb6paW2VgILOhkpGCIiIiIiomqGd+wTEREREREREREREckI79gnItKT0nevKl3+MNTAkRARERERERERkTnjHftERERERERERERERDLChn0iIiIiIiIiIiIiIhmRfcP+ihUrUL9+fdjZ2SEgIADHjh0zdkhEpCfmkt/1ZySp/RFVZ+aS26RZy5gd3N9VY+ac35qO5zzGU3VhzrlNVN0xv4nkS9Z97H/33XeIjo5GfHw8AgICsGTJEoSEhCAjIwMeHh7GDo+InoC557emE3/2xU/Vgbnndlk05bytlRECIapCcszvqmiI5zt3yNzIMbeJSDvMbyJ5k3XD/qJFizB+/HiMHj0aABAfH4+kpCSsXr0aM2bMMGgsbKQj0i9Tym9D0aVxgfsXkqvqmNtE1QXzu3w8XyC5Ym4TmS/mN5G8ybZhPz8/H2lpaZj5f+zdeVwU9f8H8Bcg7HIIiAiIB+KR91GoiBceBBqW95Up4pUKFlIelCFoRZp5ZF5lgh3m0dfs0FTEKxU1UVNRSc0jD8BUQBEB4fP7o99OLrvALizsLvt6Ph48dGc+O/P+zM7nM5957+xMRIQ0zdzcHH5+fkhMTFT7ntzcXOTm5kqvMzMzAQD3799Hfn6+Utn8/Hw8fvwY1fLNUVBoVqYY7927V6b3lYci7nv37sHS0rLS118exhq7PuJ++PAhAEAIUSnrq2zatu/KbtuGoPHbm7UqLzMXmPN8Idq9uxW5WtT7WERvbUMzOMbUt7Btq9KmfVc275gEjcuqG3BVKxR4/LjQ6PsjheLqo01/ZUh9jq77DrZvZZq07aKfQbWn2RVci8qnrn2Upx0Y0zHPUJR3m7Ftq9L22F3c+Fwf59PGhm2+fErbfmzfysratrl/lg37xrIzpbZttIn9f/75BwUFBXB1dVWa7urqiosXL6p9T0xMDKKjo1Wme3p6VkiMzp9UyGKJJA8fPoSDg4O+w9A5bdt3ZbdtY/VqGd7Dfkw/2Lb/U9Xbd1napSErb31Moc9h+/5XVW/b5WEK7aAqYtv+j67aN9sCGQq273/x2G0Y2DfqTlVo20ab2C+LiIgIhIeHS68LCwtx//591KxZE2ZmylfKZWVloV69evj7779hb29f2aGWmbHGDRhv7PqIWwiBhw8fwt3dvVLWZ+hMoW2Xl6nWGzCuurNtq9KmfRsbY9o3NcH6lIztW5kmbbuq7VOVgdtMe+XdZmzbqrQ9dnO/LTtuu/IpbfuxfStj265c3H5lZ0pt22gT+87OzrCwsEBaWprS9LS0NLi5ual9j0wmg0wmU5rm6OhY4nrs7e2NsgEZa9yA8cZe2XEb+7eKJdG2fZtS2y4vU603YDx1Z9tWVpb2bWyMZd/UFOtTPLbv/2jTtqvaPlUZuM20V55txratrKzHbu63ZcdtVz4lbT+27/+wbesHt1/ZmULbNtd3AGVlZWUFLy8vJCT8d3/bwsJCJCQkwMfHR4+REVF5sX0TVU1s20RVF9s3UdXEtk1UdbF9Exk/o71iHwDCw8MRFBSE9u3bo2PHjli6dCmys7Olp3kTkfFi+yaqmti2iaoutm+iqoltm6jqYvsmMm5GndgfPnw47t69i8jISKSmpqJdu3bYuXOnyoM/ykImk2Hu3LkqPzMydMYaN2C8sRtr3Iauotq3qX5eplpvwLTrbogq8thtbKravsn6kK7bNz8D7XGbaY/brHQVfezmZ1B23Hblw+3HvJoh4/YrO1PadmZCCKHvIIiIiIiIiIiIiIiISDNGe499IiIiIiIiIiIiIiJTxMQ+EREREREREREREZERYWKfiIiIiIiIiIiIiMiIMLFPRERERERERERERGREmNgvxooVK9CgQQPI5XJ4e3vj+PHjFbKemJgYdOjQAdWrV4eLiwsGDBiAlJQUpTI9evSAmZmZ0t/kyZOVyty4cQOBgYGwsbGBi4sLZsyYgadPnyqV2b9/P1544QXIZDI0btwYcXFxKvFoU++oqCiVuJo1aybNf/LkCUJCQlCzZk3Y2dlh8ODBSEtL03vcDRo0UInbzMwMISEhAAx3e1PxtN2OW7ZsQbNmzSCXy9G6dWvs2LFDab4QApGRkahduzasra3h5+eHS5cuVWQVykTX9d66dSv8/f1Rs2ZNmJmZ4fTp0xUYfdnpst75+fmYNWsWWrduDVtbW7i7u2PMmDG4fft2RVeDTMTBgwfx8ssvw93dHWZmZti2bZvSfGPpbxRKqo8xtqfSPp9nTZ48GWZmZli6dGmlxWfKTHmMpIt+4/79+xg1ahTs7e3h6OiI8ePH49GjR0plzpw5g27dukEul6NevXpYuHBhRVetwmhyTlWZ5yakStfjVlOizbaLi4tTOZeVy+WVGK3h0OYYr8D2XX6aHH+K0iQHU1Wxbyw79o3/T5CKjRs3CisrK7Fu3TqRnJwsJk6cKBwdHUVaWprO1xUQECBiY2PFuXPnxOnTp8VLL70k6tevLx49eiSV8fX1FRMnThR37tyR/jIzM6X5T58+Fa1atRJ+fn7i1KlTYseOHcLZ2VlERERIZf766y9hY2MjwsPDxfnz58Xy5cuFhYWF2LlzZ5nrPXfuXNGyZUuluO7evSvNnzx5sqhXr55ISEgQJ06cEJ06dRKdO3fWe9zp6elKMcfHxwsAYt++fQa9vUk9bbfj4cOHhYWFhVi4cKE4f/68mDNnjrC0tBRnz56Vynz00UfCwcFBbNu2Tfzxxx/ilVdeEZ6eniInJ6eyqlWqiqj3V199JaKjo8UXX3whAIhTp05VUm00p+t6Z2RkCD8/P7Fp0yZx8eJFkZiYKDp27Ci8vLwqs1pUhe3YsUO8++67YuvWrQKA+OGHH5TmG0N/86yS6mOM7am0z0dh69atom3btsLd3V0sWbKkUmM0RaY+RtJFv9GnTx/Rtm1bcfToUfHbb7+Jxo0bi5EjR0rzMzMzhaurqxg1apQ4d+6c+O6774S1tbVYs2ZNZVVTpzQ5p6qscxNSVRHjVlOh7baLjY0V9vb2SueyqamplRy1YdD0GK/A9q0bpR1/1CktB1NVsW8sO/aN/2FiX42OHTuKkJAQ6XVBQYFwd3cXMTExFb7u9PR0AUAcOHBAmubr6yvefPPNYt+zY8cOYW5urrRTrlq1Stjb24vc3FwhhBAzZ84ULVu2VHrf8OHDRUBAgPRa23rPnTtXtG3bVu28jIwMYWlpKbZs2SJNu3DhggAgEhMT9Rp3UW+++aZo1KiRKCwsFEIY7vYm9bTdjsOGDROBgYFK07y9vcXrr78uhBCisLBQuLm5iY8//lian5GRIWQymfjuu+8qoAZlo+t6P+vq1asGm9ivyHorHD9+XAAQ169f103QRP+v6EmlsfQ3xdHkJNmY2lNx9bl586aoU6eOOHfunPDw8GBivxJwjPSfsvQb58+fFwDE77//LpX59ddfhZmZmbh165YQQoiVK1eKGjVqSGNXIYSYNWuWaNq0aQXXqHIUPaeqzHMTUlUZ47eqStttFxsbKxwcHCopOuOhyZiF7bv8NDn+qFNaDqaqYt9Yduwb/8Nb8RSRl5eHpKQk+Pn5SdPMzc3h5+eHxMTECl9/ZmYmAMDJyUlp+rfffgtnZ2e0atUKERERePz4sTQvMTERrVu3hqurqzQtICAAWVlZSE5Olso8WydFGUWdylrvS5cuwd3dHQ0bNsSoUaNw48YNAEBSUhLy8/OVltesWTPUr19fWp4+41bIy8vDN998g3HjxsHMzEyabqjbm5SVZTuW9tlcvXoVqampSmUcHBzg7e1tMJ9NRdTbGFRWvTMzM2FmZgZHR0edxE1UHGPob8rL2NtTYWEhRo8ejRkzZqBly5b6DsckcIxUMk36jcTERDg6OqJ9+/ZSGT8/P5ibm+PYsWNSme7du8PKykoqExAQgJSUFDx48KCSalNxip5TVda5Caky1XGrLpS1P3z06BE8PDxQr1499O/fX9p/qWTc78pPk+NPcUrKwVRF7BvLjn2jsmr6DsDQ/PPPPygoKFAa0AGAq6srLl68WKHrLiwsRFhYGLp06YJWrVpJ01999VV4eHjA3d0dZ86cwaxZs5CSkoKtW7cCAFJTU9XGq5hXUpmsrCzk5OTgwYMHWtfb29sbcXFxaNq0Ke7cuYPo6Gh069YN586dQ2pqKqysrFRO5F1dXUuNqaLjfta2bduQkZGBsWPHStMMdXuTqrK01+I+m2c/O8W04sroW0XU2xhURr2fPHmCWbNmYeTIkbC3t9dN4ETFMIb+pjyqQntasGABqlWrhjfeeEPfoZgMfY7FjYEm/UZqaipcXFyU5lerVg1OTk5KZTw9PVWWoZhXo0aNCom/Mqg7p6qscxNra+uKqJJRM9Vxqy6UZds1bdoU69atQ5s2bZCZmYlFixahc+fOSE5ORt26dSsjbKPF9l1+mhx/1CktB1MVsW8sO/aNypjYNyAhISE4d+4cDh06pDR90qRJ0v9bt26N2rVro3fv3rhy5QoaNWpU2WFK+vbtK/2/TZs28Pb2hoeHBzZv3mw0B70vv/wSffv2hbu7uzTNULc3EVWs/Px8DBs2DEIIrFq1St/hEBm1qtCekpKSsGzZMpw8eVLpV31EZNiKO6ciMgU+Pj7w8fGRXnfu3BnNmzfHmjVrMH/+fD1GRsZs9uzZWLBgQYllLly4UOblMwdDFa0q9428FU8Rzs7OsLCwQFpamtL0tLQ0uLm5Vdh6Q0ND8csvv2Dfvn2lflvk7e0NALh8+TIAwM3NTW28inkllbG3t4e1tbVO6u3o6IjnnnsOly9fhpubG/Ly8pCRkVHs8vQd9/Xr17Fnzx5MmDChxHKGur2pbO21uM/m2c9OMU3TZVa2iqi3MajIeiuSkNevX0d8fLzRXl1MxsUY+puyqCrt6bfffkN6ejrq16+PatWqoVq1arh+/TreeustNGjQQN/hVVkcI5VMk37Dzc0N6enpSvOfPn2K+/fvazUON0bFnVNV1rkJqTLVcasu6KI/tLS0xPPPPy+dy1Lx2L6L99Zbb+HChQsl/jVs2FCj448miuZgqiL2jWXHvlEZE/tFWFlZwcvLCwkJCdK0wsJCJCQkKH27oytCCISGhuKHH37A3r17VX4Sq87p06cBALVr1wbw7zdPZ8+eVepAFSfSLVq0kMo8WydFGUWddFHvR48e4cqVK6hduza8vLxgaWmptLyUlBTcuHFDWp6+446NjYWLiwsCAwNLLGeo25vKth1L+2w8PT3h5uamVCYrKwvHjh0zmM+mIuptDCqq3ook5KVLl7Bnzx7UrFmzYipAVIQx9DfaqkrtafTo0Thz5gxOnz4t/bm7u2PGjBnYtWuXvsOrsjhGKpkm/YaPjw8yMjKQlJQkldm7dy8KCwulZImPjw8OHjyI/Px8qUx8fDyaNm1qlLfhKe2cqrLOTUiVqY5bdUEX/WFBQQHOnj0rnctS8bjfFa9WrVpo1qxZiX9WVlYaHX80UTQHUxWxbyw79o1F6PfZvYZp48aNQiaTibi4OHH+/HkxadIk4ejoKFJTU3W+rilTpggHBwexf/9+cefOHenv8ePHQgghLl++LObNmydOnDghrl69Kn788UfRsGFD0b17d2kZT58+Fa1atRL+/v7i9OnTYufOnaJWrVoiIiJCKvPXX38JGxsbMWPGDHHhwgWxYsUKYWFhIXbu3Fnmer/11lti//794urVq+Lw4cPCz89PODs7i/T0dCGEEJMnTxb169cXe/fuFSdOnBA+Pj7Cx8dH73EL8e8Ts+vXry9mzZqlNN2QtzepV9p2HD16tJg9e7ZU/vDhw6JatWpi0aJF4sKFC2Lu3LnC0tJSnD17Virz0UcfCUdHR/Hjjz+KM2fOiP79+wtPT0+Rk5NT6fUrTkXU+969e+LUqVNi+/btAoDYuHGjOHXqlLhz506l1684uq53Xl6eeOWVV0TdunXF6dOnlfrh3NxcvdSRqpaHDx+KU6dOiVOnTgkAYvHixeLUqVPi+vXrQgjj6G+eVVJ9jLE9lfb5FOXh4SGWLFlSuUGaIFMfI+mi3+jTp494/vnnxbFjx8ShQ4dEkyZNxMiRI6X5GRkZwtXVVYwePVqcO3dObNy4UdjY2Ig1a9ZUen11obRzKiEq79yEVFXEuNVUaLvtoqOjxa5du8SVK1dEUlKSGDFihJDL5SI5OVlfVdCb0vrS2bNni9GjR0vl2b51o7Tjz82bN0XTpk3FsWPHhBCa5WCqKvaNZce+8T9M7Bdj+fLlon79+sLKykp07NhRHD16tELWA0DtX2xsrBBCiBs3boju3bsLJycnIZPJROPGjcWMGTNEZmam0nKuXbsm+vbtK6ytrYWzs7N46623RH5+vlKZffv2iXbt2gkrKyvRsGFDaR1lrffw4cNF7dq1hZWVlahTp44YPny4uHz5sjQ/JydHTJ06VdSoUUPY2NiIgQMHqiQI9RG3EELs2rVLABApKSlK0w15e1PxStqOvr6+IigoSKn85s2bxXPPPSesrKxEy5Ytxfbt25XmFxYWivfee0+4uroKmUwmevfurbKvGAJd1zs2NlZtfzR37txKqI3mdFnvq1evFtsP79u3r5JqRFXZvn371O5fiv3UWPobhZLqY4ztqbTPpygm9iuPKY+RdNFv3Lt3T4wcOVLY2dkJe3t7ERwcLB4+fKhU5o8//hBdu3YVMplM1KlTR3z00UeVVUWdK+2cSojKPTchVboet5oSbbZdWFiYVNbV1VW89NJL4uTJk3qIWv9K60uDgoKEr6+vynvYvsuntOOPYryoGBtqmoOpqtg3lh37xn+ZCSGELq78JyIiIiIiIiIiIiKiisd77BMRERERERERERERGREm9omIiIiIiIiIiIiIjAgT+0RERERERERERERERoSJfSIiIiIiIiIiIiIiI8LEPhERERERERERERGREWFin4iIiIiIiIiIiIjIiDCxT0RERERERERERERkRJjYJyIiIiIiIiIiIiIyIkzsExEREREREREREREZESb2iYiIiIiIiIiIiIiMCBP7RERERERERERERERGhIl9IiIiIiIiIiIiIiIjwsQ+EREREREREREREZERYWKfiIiIiIiIiIiIiMiIMLFPRERERERERERERGREmNgnIiIiIiIiIiIiIjIiTOwTERERERERERERERkRJvaJiIiIiIiIiIiIiIwIE/tEREREREREREREREaEiX0iIiIiIiIiIiIiIiPCxD4RERERERERERERkRFhYp+IiIiIiIiIiIiIyIgwsU9EREREREREREREZESY2CciIiIiIiIiIiIiMiJM7BMRERERERERERERGREm9omIiIiIiIiIiIiIjAgT+0RERERERERERERERoSJfSIiIiIiIiIiIiIiI8LEPhERERERERERERGREWFin4iIiIiIiIiIiIjIiDCxT0RERERERERERERkRJjYJyIiIiIiIiIiIiIyIkzsExEREREREREREREZESb2iYiIiIiIiIiIiIiMCBP7RERERERERERERERGhIl9IiIiIiIiIiIiIiIjwsR+GURFRcHMzAz//PNPieUaNGiAsWPHlmkdDRo0QL9+/cr0Xl3GQWTs4uLiYGZmhmvXruk7FCrG2LFj0aBBA32HQURGiGMcMgaKcwdt7N+/H2ZmZvj+++8rKCoiMhXqzod69OiBHj166HT5J06cKLWsLtdLpoHn85Xv2rVrMDMzQ1xcnL5DIQ0wsU8lWrlypVE05h07diAqKkpv69+wYQOWLl2qt/VT1cD9yHQ8fvwYUVFR2L9/v75DoUp25MgRREVFISMjo8LWcf78eURFRfEEiIiIqBS3b99GVFQUTp8+re9Q9MqQt0NljJ2IjIUht1XSDyb2K1BKSgq++OILfYdRrjiMKbEfHR2tt/UzIUu6wP3IdDx+/BjR0dFM7JugI0eOIDo6usIT+9HR0UzsExmIOXPmICcnR99hEJEat2/fRnR0tMklyXbv3o3du3dLrytrOxRdryYqY+xEhmv06NHIycmBh4eHvkMxCKbaZ1HxmNivQDKZDJaWlvoOw2DiUHj69Cny8vL0HUaJHj9+rO8QiIjISGRnZ+s7BKMihGCSk0xGdnY2qlWrBrlcru9Q9MYYxv5Ehqgi246VlRWsrKwqZNmGuN6iOBYxHhYWFpDL5Vrf0o7IVDCxXw4ZGRkYO3YsHB0d4eDggODgYKWEsLr7vp45cwa+vr6wtrZG3bp18f777yM2NrbYe4YdOnQIHTt2hFwuR8OGDfHVV19pHWfROBT3KDt8+DDCw8NRq1Yt2NraYuDAgbh7967S+5KTk3HgwAGYmZnBzMxM6X54GRkZCAsLQ7169SCTydC4cWMsWLAAhYWFUhnFvbkWLVqEpUuXolGjRpDJZDh//jwA4OLFixgyZAicnJwgl8vRvn17/PTTT0rx5+fnIzo6Gk2aNIFcLkfNmjXRtWtXxMfHA/j3/twrVqwAAClObTr9Hj16oFWrVkhKSkL37t1hY2ODd955BwDw448/IjAwEO7u7pDJZGjUqBHmz5+PgoICpfdv374d169fl9b97P3Cc3NzMXfuXDRu3BgymQz16tXDzJkzkZubq3GMpFsrV65Ey5YtIZPJ4O7ujpCQEJUrQH777TcMHToU9evXlz636dOnqwwAx44dCzs7O9y6dQsDBgyAnZ0datWqhbfffltpPylNaftReno6xo8fD1dXV8jlcrRt2xbr168vU/2PHTuGPn36wMHBATY2NvD19cXhw4eVyijuB/znn3/itddeg4ODA2rVqoX33nsPQgj8/fff6N+/P+zt7eHm5oZPPvlE6f2KewNv2rQJ77zzDtzc3GBra4tXXnkFf//9d6kxZmdn46233pL6l6ZNm2LRokUQQkhlfH190bZtW7Xvb9q0KQICAgAo90MrVqxAw4YNYWNjA39/f/z9998QQmD+/PmoW7curK2t0b9/f9y/f19lmb/++iu6desGW1tbVK9eHYGBgUhOTlYqo8n+cO3aNdSqVQsAEB0dLX3e+rydGGlO0TbOnz+PV199FTVq1EDXrl1x5swZjB07Fg0bNoRcLoebmxvGjRuHe/fuKb13xowZAABPT0/ps3/2+P/NN9/Ay8sL1tbWcHJywogRIzRqMwpxcXEYOnQoAKBnz57SOp79dYgmfaAmNB3TKJ4btGvXLrRv3x7W1tZYs2YNACA2Nha9evWCi4sLZDIZWrRogVWrVqmsSwiB999/H3Xr1oWNjQ169uyp0v4UNBmfEFWE4voHdffYj4+PR9euXeHo6Ag7Ozs0bdpUGn8WJzc3F/369YODgwOOHDmicVwbN26El5cXqlevDnt7e7Ru3RrLli1TKpORkYHp06ejQYMGkMlkqFu3LsaMGaP0TDFNxiK6GPtT1XP9+nVMnToVTZs2hbW1NWrWrImhQ4eqPf/V5nxZk7FZSfbv348OHToAAIKDg6Vj5rO/WN+yZYt0XHZ2dsZrr72GW7duab0Nnjx5gqioKDz33HOQy+WoXbs2Bg0ahCtXrgDQXdtJTk5Gr169lLafuuPfs/e612Q7aCI3N7fE/ELR9SosX74cLVu2hI2NDWrUqIH27dtjw4YNAEofOz19+hTz58+XtleDBg3wzjvvqJxrFzcW0fR8gvSn6D32FZ+lJrmyiji2VfT5ZEkqs89SZ+/evVL8jo6O6N+/Py5cuKBURtP+XtO8JJWumr4DMGbDhg2Dp6cnYmJicPLkSaxduxYuLi5YsGCB2vK3bt2STrIjIiJga2uLtWvXQiaTqS1/+fJlDBkyBOPHj0dQUBDWrVuHsWPHwsvLCy1btix3/NOmTUONGjUwd+5cXLt2DUuXLkVoaCg2bdoEAFi6dCmmTZsGOzs7vPvuuwAAV1dXAP9e0e7r64tbt27h9ddfR/369XHkyBFERETgzp07KrcTiY2NxZMnTzBp0iTIZDI4OTkhOTkZXbp0QZ06dTB79mzY2tpi8+bNGDBgAP73v/9h4MCBAP49mMfExGDChAno2LEjsrKycOLECZw8eRIvvvgiXn/9ddy+fRvx8fH4+uuvy7Qt7t27h759+2LEiBF47bXXpHrGxcXBzs4O4eHhsLOzw969exEZGYmsrCx8/PHHAIB3330XmZmZuHnzJpYsWQIAsLOzAwAUFhbilVdewaFDhzBp0iQ0b94cZ8+exZIlS/Dnn39i27ZtZYqXyi4qKgrR0dHw8/PDlClTkJKSglWrVuH333/H4cOHpV+3bNmyBY8fP8aUKVNQs2ZNHD9+HMuXL8fNmzexZcsWpWUWFBQgICAA3t7eWLRoEfbs2YNPPvkEjRo1wpQpUzSKq6T9KCcnBz169MDly5cRGhoKT09PbNmyBWPHjkVGRgbefPNNjeu/d+9e9O3bF15eXpg7dy7Mzc2lxNpvv/2Gjh07KpUfPnw4mjdvjo8++gjbt2/H+++/DycnJ6xZswa9evXCggUL8O233+Ltt99Ghw4d0L17d6X3f/DBBzAzM8OsWbOQnp6OpUuXws/PD6dPn4a1tbXaGIUQeOWVV7Bv3z6MHz8e7dq1w65duzBjxgzcunVL2j6jR4/GxIkTce7cObRq1Up6/++//44///wTc+bMUVrut99+i7y8PEybNg3379/HwoULMWzYMPTq1Qv79+/HrFmzcPnyZSxfvhxvv/021q1bJ73366+/RlBQEAICArBgwQI8fvwYq1atQteuXXHq1CmlL2FK2x9q1aqFVatWYcqUKRg4cCAGDRoEAGjTpo3GnyPp39ChQ9GkSRN8+OGHEEIgPj4ef/31F4KDg+Hm5obk5GR8/vnnSE5OxtGjR2FmZoZBgwbhzz//xHfffYclS5bA2dkZAKQvej744AO89957GDZsGCZMmIC7d+9i+fLl6N69O06dOgVHR8dS4+revTveeOMNfPrpp3jnnXfQvHlzAJD+1bQPLI22Y5qUlBSMHDkSr7/+OiZOnIimTZsCAFatWoWWLVvilVdeQbVq1fDzzz9j6tSpKCwsREhIiPT+yMhIvP/++3jppZfw0ksv4eTJk/D391e5klHb8QlRRSjaP6SnpyvNT05ORr9+/dCmTRvMmzcPMpkMly9fVvmS/Vk5OTno378/Tpw4gT179kgn9qWJj4/HyJEj0bt3b+kc5cKFCzh8+LA0fnj06BG6deuGCxcuYNy4cXjhhRfwzz//4KeffsLNmzfh7Oys9VikPGN/qnp+//13HDlyBCNGjEDdunVx7do1rFq1Cj169MD58+dhY2MDQLtjizZjs+I0b94c8+bNQ2RkJCZNmoRu3boBADp37gzg33PB4OBgdOjQATExMUhLS8OyZctw+PBhjY/LwL9jw379+iEhIQEjRozAm2++iYcPHyI+Ph7nzp1Do0aNpLLlaTupqano2bMnnj59KpX7/PPPix1za7odNFVafkGdL774Am+88QaGDBmCN998E0+ePMGZM2dw7NgxvPrqq6WOnSZMmID169djyJAheOutt3Ds2DHExMTgwoUL+OGHH5TWpW4sYmdnp9X5BBkGTXJlFXFsq6zzyeJUVp+lzp49e9C3b180bNgQUVFRyMnJwfLly9GlSxecPHlSil/T/l6hLP0GFSFIa3PnzhUAxLhx45SmDxw4UNSsWVN67eHhIYKCgqTX06ZNE2ZmZuLUqVPStHv37gknJycBQFy9elXpvQDEwYMHpWnp6elCJpOJt956S6t4i8YRGxsrAAg/Pz9RWFgoTZ8+fbqwsLAQGRkZ0rSWLVsKX19flWXOnz9f2Nraij///FNp+uzZs4WFhYW4ceOGEEKIq1evCgDC3t5epKenK5Xt3bu3aN26tXjy5Ik0rbCwUHTu3Fk0adJEmta2bVsRGBhYYh1DQkJEWXdnX19fAUCsXr1aZd7jx49Vpr3++uvCxsZGKe7AwEDh4eGhUvbrr78W5ubm4rffflOavnr1agFAHD58uEwxk+YU+/vVq1dFenq6sLKyEv7+/qKgoEAq89lnnwkAYt26ddI0dZ99TEyMMDMzE9evX5emBQUFCQBi3rx5SmWff/554eXlpVWsxe1HS5cuFQDEN998I03Ly8sTPj4+ws7OTmRlZWm0/MLCQtGkSRMREBCg1PYfP34sPD09xYsvvihNU/RzkyZNkqY9ffpU1K1bV5iZmYmPPvpImv7gwQNhbW2t1M/s27dPABB16tRRim/z5s0CgFi2bJk0LSgoSKne27ZtEwDE+++/rxT/kCFDhJmZmbh8+bIQQoiMjAwhl8vFrFmzlMq98cYbwtbWVjx69EgI8V8/VKtWLaX+LSIiQgAQbdu2Ffn5+dL0kSNHCisrK6mNP3z4UDg6OoqJEycqrSc1NVU4ODgoTdd0f7h7964AIObOnSvIuCjaxsiRI5Wmq+szvvvuO5Vj+ccff6xyzBdCiGvXrgkLCwvxwQcfKE0/e/asqFatmsr0kmzZskUAEPv27VOark0fWJqyjGl27typshx12y0gIEA0bNhQJe7AwEClvuudd94RAJT6Hk3HJ0QVobj+QTFdYcmSJQKAuHv3brHLUhxHt2zZIh4+fCh8fX2Fs7OzUpvTxJtvvins7e3F06dPiy0TGRkpAIitW7eqzFO0OU3HIroY+1PVo66vT0xMFADEV199JU3T9NiizdisNL///rsAIGJjY5Wm5+XlCRcXF9GqVSuRk5MjTf/ll18EABEZGanxOtatWycAiMWLF6vMU7QxXbSdsLAwAUAcO3ZMmpaeni4cHBxUjs2+vr5K5/nFbQdNaJNfKLre/v37i5YtW5a4/OLGTqdPnxYAxIQJE5Smv/322wKA2Lt3rzStuLGIpucTpD/Pns8LoXmurCKObZVxPlmayuizFPV9dh3t2rUTLi4u4t69e9K0P/74Q5ibm4sxY8ZI0zTt77XpN6hkvBVPOUyePFnpdbdu3XDv3j1kZWWpLb9z5074+PigXbt20jQnJyeMGjVKbfkWLVpI38AB/34r3bRpU/z111/lDx7ApEmTlH4W3K1bNxQUFOD69eulvnfLli3o1q0batSogX/++Uf68/PzQ0FBAQ4ePKhUfvDgwdK36gBw//597N27F8OGDcPDhw+l99+7dw8BAQG4dOmS9HMhR0dHJCcn49KlSzqptzoymQzBwcEq05+9ukERZ7du3fD48WNcvHix1OVu2bIFzZs3R7NmzZS2U69evQAA+/bt010lqFR79uxBXl4ewsLCYG7+X/c3ceJE2NvbY/v27dK0Zz/77Oxs/PPPP+jcuTOEEDh16pTKstX1B7pqqzt27ICbmxtGjhwpTbO0tMQbb7yBR48e4cCBAxot5/Tp07h06RJeffVV3Lt3T9ofs7Oz0bt3bxw8eFDlp7oTJkyQ/m9hYYH27dtDCIHx48dL0x0dHYvtm8aMGYPq1atLr4cMGYLatWtjx44dJdbXwsICb7zxhtL0t956C0II/PrrrwAABwcH9O/fH9999510i56CggJs2rQJAwYMgK2trdL7hw4dCgcHB+m1t7c3AOC1115DtWrVlKbn5eVJfVB8fDwyMjIwcuRIpXZsYWEBb29vte24IvcHMgxFP+Nn+4wnT57gn3/+QadOnQAAJ0+eLHV5W7duRWFhIYYNG6a0n7m5uaFJkyY6OV5o0weWRtsxjaenp9qfsz+73TIzM/HPP//A19cXf/31FzIzM5XinjZtmtK4JSwsTGV52o5PiCpC0f6hKMUVcz/++GOpt4jKzMyEv78/Ll68iP379yu1OU04OjoiOztbuoWlOv/73//Qtm1btVfMK9qctmOR8oz9qep5tq/Pz8/HvXv30LhxYzg6OiodIzU9tpRlbKatEydOID09HVOnTlV6RkZgYCCaNWum1THzf//7H5ydnTFt2jSVeUVv01WetrNjxw506tRJ6Re4tWrVKvbYrGtlyS84Ojri5s2b+P3337Ven+J8Ijw8XGn6W2+9BQAqn5G6sYi25xNkGDTJlVXEsa0yzye1pcs+q6g7d+7g9OnTGDt2LJycnKTpbdq0wYsvvqh0bq9pf69Qnrwk/Yu34imH+vXrK72uUaMGAODBgwewt7dXKX/9+nX4+PioTG/cuLFGy1es48GDB2UJt9TlPxt/aS5duoQzZ84oDTqeVfQnx56enkqvL1++DCEE3nvvPbz33nvFLqNOnTqYN28e+vfvj+eeew6tWrVCnz59MHr0aJ3etqJOnTpqH+KTnJyMOXPmYO/evSpf2CgSDiW5dOkSLly4oPF2ooqlODgobgGhYGVlhYYNGyodPG7cuIHIyEj89NNPKm2i6Gcvl8tVPmNdttXr16+jSZMmSok44L9ba2h60FN8ORYUFFRsmczMTKkvAFT7CQcHB8jlculnsM9Of/Ze4gpNmjRRem1mZobGjRurvaeqwvXr1+Hu7q70hQCgvr5jxozBpk2b8Ntvv6F79+7Ys2cP0tLSMHr0aJXlqqsLANSrV0/tdMXnp9huii/kiira31f0/kCGoehx7f79+4iOjsbGjRtV+nZNjxdCCJU2o6DpLXJKok0fqMmytBnTFN1eCocPH8bcuXORmJio8uD6zMxMODg4SHEV3Ta1atVS6q8A7ccnRBWhuP1dYfjw4Vi7di0mTJiA2bNno3fv3hg0aBCGDBmicqwPCwvDkydPcOrUqTLdinPq1KnYvHkz+vbtizp16sDf3x/Dhg1Dnz59pDJXrlzB4MGDS1yOtmOR8oz9qerJyclBTEwMYmNjcevWLaVnJj17jNT02KLt2KwsijtmAkCzZs1w6NAhjZd15coVNG3aVCnxV5zytJ3r169LicZnqatDRShLfmHWrFnYs2cPOnbsiMaNG8Pf3x+vvvoqunTpUur6rl+/DnNzc5X9w83NDY6OjqX2SwranE+QYdAkV1YRx7bKOp8sC132Wdosu3nz5ti1axeys7Nha2urcX+vUJ68JP2Lif1ysLCwUDv92R23qi6/sLAQL774ImbOnKl2/nPPPaf0uuh9/RRXJ7399tvFPpBGcYDu3r07rly5gh9//BG7d+/G2rVrsWTJEqxevVrpauLyUHffwYyMDPj6+sLe3h7z5s1Do0aNIJfLcfLkScyaNUujh/AVFhaidevWWLx4sdr5RQ8AZBgKCgrw4osv4v79+5g1axaaNWsGW1tb3Lp1C2PHjlX57ItrS4ZGEffHH39c7BV/ivv6K6irW0X3TdoICAiAq6srvvnmG3Tv3h3ffPMN3Nzc4Ofnp1K2uLhLq49iu3399ddwc3NTKVf0JM1Y9gcqn6LHjWHDhuHIkSOYMWMG2rVrBzs7OxQWFqJPnz4aHy/MzMzw66+/qt2HirZNY6PuOHvlyhX07t0bzZo1w+LFi1GvXj1YWVlhx44dWLJkSZkedqvt+ISoIpR2P2tra2scPHgQ+/btw/bt27Fz505s2rQJvXr1wu7du5X6gP79+2Pjxo346KOP8NVXX6kkH0rj4uKC06dPY9euXfj111/x66+/IjY2FmPGjFF5OKAulWfsT1XPtGnTEBsbi7CwMPj4+MDBwQFmZmYYMWJEmft6QPOxmTEx5rZTlnOE5s2bIyUlBb/88gt27tyJ//3vf1i5ciUiIyMRHR2t0XqL/uqhOMX1zdqcT5Bh0Nf5aGWdTxozbft7Q8otGKuqs/cYAQ8PD1y+fFllurpphqK4g2SjRo3w6NGjMh/sGjZsCODfKxA1WYaTkxOCg4MRHByMR48eoXv37oiKipIS+5oezLWxf/9+3Lt3D1u3blV6IOjVq1dVypa0nf744w/07t27QmIk7Xh4eAD498FJin0QAPLy8nD16lVpXzx79iz+/PNPrF+/HmPGjJHKlfQzdl0obh/x8PDAmTNnUFhYqHRCr7gdlKJepVE8mMve3r7SBqpFb6ElhMDly5dL/MWNh4cH9uzZg4cPHypdta+uvhYWFnj11VcRFxeHBQsWYNu2bZg4caJOk+uK7ebi4qKz7cb+oGp58OABEhISEB0djcjISGm6ulvIlXS8EELA09Oz3MnnkvoSoPQ+UBO6GNP8/PPPyM3NxU8//aR0tU7RnyMr4r506ZJS3Hfv3lW5mqe84xOiymJubo7evXujd+/eWLx4MT788EO8++672Ldvn9L+O2DAAPj7+2Ps2LGoXr06Vq1apfW6rKys8PLLL+Pll19GYWEhpk6dijVr1uC9995D48aN0ahRI5w7d67EZZR3LKLt2J+qlu+//x5BQUH45JNPpGlPnjxBRkaGUjlNjy26HJtpcswsepVtSkqKxuNv4N94jx07hvz8fK1/gadN2/Hw8FA79khJSSl1Pfocm9ra2mL48OEYPnw48vLyMGjQIHzwwQeIiIiAXC4v8TMqLCzEpUuXpCusASAtLQ0ZGRkaf0aVcT5Bla8yjm3axAIYT59V0rKLunjxIpydnaXbVmna35Pu8B77lSggIACJiYk4ffq0NO3+/fv49ttv9RdUKWxtbdU2wGHDhiExMRG7du1SmZeRkYGnT5+WuFwXFxf06NEDa9aswZ07d1Tm3717V/p/0dt72NnZoXHjxsjNzVWKU7FuXVEcyJ/9pjAvLw8rV65UKWtra6v2Z0XDhg3DrVu38MUXX6jMy8nJQXZ2ts7ipdL5+fnBysoKn376qdLn+uWXXyIzMxOBgYEA1H/2QggsW7asQuMrbj966aWXkJqaqvRk+KdPn2L58uWws7ODr6+vRsv38vJCo0aNsGjRIjx69Ehl/rPtTle++uorPHz4UHr9/fff486dO+jbt2+x73nppZdQUFCAzz77TGn6kiVLYGZmpvLe0aNH48GDB3j99dfx6NEjvPbaazqtQ0BAAOzt7fHhhx8iPz9fZX5ZtpuNjQ0A3fZZpD/q+gwAWLp0qUrZ4o5XgwYNgoWFBaKjo1WWI4RQe6ur4hS3Dk37QE3oYkyjbrtlZmYiNjZWJW5LS0ssX75cqay67Vve8QlRZbh//77KNMUv6Z4d3yqMGTMGn376KVavXo1Zs2Zpta6ifYe5ubn05bpiXYMHD8Yff/yBH374QeX9ijZX3rGINmN/qnosLCxUjm3Lly9HQUGB0jRNjy26HJsVd8xs3749XFxcsHr1aqV2+euvv+LChQtaHTMHDx6Mf/75R2VsC5R+Vao2beell17C0aNHcfz4caX5mhybK+J8WhNF+ygrKyu0aNECQgjpsy0utpdeegmA6nhA8Wt5bT6jij6foMpXGcc2TRlbn1VU7dq10a5dO6xfv15pvefOncPu3bultgho3t+T7vCK/Uo0c+ZMfPPNN3jxxRcxbdo02NraYu3atahfvz7u379vkFdwenl5YdWqVXj//ffRuHFjuLi4oFevXpgxYwZ++ukn9OvXD2PHjoWXlxeys7Nx9uxZfP/997h27ZrKPbiLWrFiBbp27YrWrVtj4sSJaNiwIdLS0pCYmIibN2/ijz/+APDvg1F69OgBLy8vODk54cSJE/j+++8RGhqqFCcAvPHGGwgICICFhQVGjBhRrrp37twZNWrUQFBQEN544w2YmZnh66+/Vjv48vLywqZNmxAeHo4OHTrAzs4OL7/8MkaPHo3Nmzdj8uTJ2LdvH7p06YKCggJcvHgRmzdvxq5du9C+fftyxUmaq1WrFiIiIhAdHY0+ffrglVdeQUpKClauXIkOHTpIA7hmzZqhUaNGePvtt3Hr1i3Y29vjf//7X4Xf5624/WjSpElYs2YNxo4di6SkJDRo0ADff/89Dh8+jKVLl6rci7445ubmWLt2Lfr27YuWLVsiODgYderUwa1bt7Bv3z7Y29vj559/1mmdnJyc0LVrVwQHByMtLQ1Lly5F48aNMXHixGLf8/LLL6Nnz5549913ce3aNbRt2xa7d+/Gjz/+iLCwMOmKB4Xnn38erVq1kh5W/cILL+i0Dvb29li1ahVGjx6NF154ASNGjECtWrVw48YNbN++HV26dFF7olYSa2trtGjRAps2bcJzzz0HJycntGrVCq1atdJp7FQ57O3t0b17dyxcuBD5+fmoU6cOdu/erfYXXorj1bvvvosRI0bA0tISL7/8Mho1aoT3338fERERuHbtGgYMGIDq1avj6tWr+OGHHzBp0iS8/fbbGsXTrl07WFhYYMGCBcjMzIRMJkOvXr3g4uKiUR+oCV2Mafz9/aUriRUn0l988QVcXFyUkhe1atXC22+/jZiYGPTr1w8vvfQSTp06hV9//VVlrKGL8QlRRZs3bx4OHjyIwMBAeHh4ID09HStXrkTdunXRtWtXte8JDQ1FVlYW3n33XTg4OOCdd97RaF0TJkzA/fv30atXL9StWxfXr1/H8uXL0a5dO+kK1xkzZuD777/H0KFDMW7cOHh5eeH+/fv46aefsHr1arRt21YnYxFNx/5U9fTr1w9ff/01HBwc0KJFCyQmJmLPnj2oWbOmUjlNjy26HJs1atQIjo6OWL16NapXrw5bW1t4e3vD09MTCxYsQHBwMHx9fTFy5EikpaVh2bJlaNCgAaZPn65x/ceMGYOvvvoK4eHhOH78OLp164bs7Gzs2bMHU6dORf/+/Ut8v6ZtZ+bMmfj666/Rp08fvPnmm7C1tcXnn38uXZVc1u1Qkfz9/eHm5oYuXbrA1dUVFy5cwGeffYbAwECpXylu7NS2bVsEBQXh888/l26je/z4caxfvx4DBgxAz549NY6jos8nqPJV1rFNE8bWZ6nz8ccfo2/fvvDx8cH48eORk5OD5cuXw8HBAVFRUVI5Tft70iFBWps7d64AIO7evas0PTY2VgAQV69eFUII4eHhIYKCgpTKnDp1SnTr1k3IZDJRt25dERMTIz799FMBQKSmpkrlPDw8RGBgoMq6fX19ha+vr1bxFo1DEefvv/+uVG7fvn0CgNi3b580LTU1VQQGBorq1asLAErrfvjwoYiIiBCNGzcWVlZWwtnZWXTu3FksWrRI5OXlCSGEuHr1qgAgPv74Y7WxXblyRYwZM0a4ubkJS0tLUadOHdGvXz/x/fffS2Xef/990bFjR+Ho6Cisra1Fs2bNxAcffCCtQwghnj59KqZNmyZq1aolzMzMhDa7tq+vr2jZsqXaeYcPHxadOnUS1tbWwt3dXcycOVPs2rVLZTs9evRIvPrqq8LR0VEAEB4eHtK8vLw8sWDBAtGyZUshk8lEjRo1hJeXl4iOjhaZmZkax0llU7RdCiHEZ599Jpo1ayYsLS2Fq6urmDJlinjw4IHS+86fPy/8/PyEnZ2dcHZ2FhMnThR//PGHACBiY2OlckFBQcLW1lZlvYp+Qhsl7UdpaWkiODhYODs7CysrK9G6dWulOLRx6tQpMWjQIFGzZk0hk8mEh4eHGDZsmEhISFCJv2g/V1x9i7YjRX/y3XffiYiICOHi4iKsra1FYGCguH79usoyn62rEP/2L9OnTxfu7u7C0tJSNGnSRHz88ceisLBQbZ0WLlwoAIgPP/xQZV5x/ZAixi1btihNL6mPDAgIEA4ODkIul4tGjRqJsWPHihMnTpS6fdTtD0eOHBFeXl7CyspKABBz585VWzcyLMW1jZs3b4qBAwcKR0dH4eDgIIYOHSpu376t9rOdP3++qFOnjjA3N1fpn/73v/+Jrl27CltbW2FrayuaNWsmQkJCREpKilZxfvHFF6Jhw4bCwsJC5ZilSR+oifKOaYQQ4qeffhJt2rQRcrlcNGjQQCxYsECsW7dOZbsUFBSI6OhoUbt2bWFtbS169Oghzp07p3aspcn4hKgiFNc/FD0GJCQkiP79+wt3d3dhZWUl3N3dxciRI8Wff/4plSnuGDVz5kwBQHz22WcaxfT9998Lf39/4eLiIqysrET9+vXF66+/Lu7cuaNU7t69eyI0NFTUqVNHWFlZibp164qgoCDxzz//SGU0GYvoYuxPVc+DBw+kfcfOzk4EBASIixcvlut8WQjNxmaa+PHHH0WLFi1EtWrVVMb6mzZtEs8//7yQyWTCyclJjBo1Sty8eVPrbfD48WPx7rvvCk9PT2FpaSnc3NzEkCFDxJUrV4QQums7Z86cEb6+vkIul4s6deqI+fPniy+//FLluKour1DSdiiJNvmFoutds2aN6N69u3Re0qhRIzFjxgyV8+Tixk75+fkiOjpa2q716tUTERER4smTJ0rvL2ksolDS+QTpj7o8m6a5soo+tlXE+aQmKrrPUtS36HbYs2eP6NKli7C2thb29vbi5ZdfFufPn1cqo2l/r02/QSUzE4JPJNC3sLAwrFmzBo8ePeJ93IioSti/fz969uyJLVu2YMiQIRW+vmXLlmH69Om4du2a0r26iahycUxDRES6xmMLVQaeTxCRMeI99itZTk6O0ut79+7h66+/RteuXTlIISIqAyEEvvzyS/j6+nIQTlSJOKYhIiJd47GF9IHnE0RkrHiP/Urm4+ODHj16oHnz5khLS8OXX36JrKwsvPfee1ovKzU1tcT51tbWcHBwKGuoRu/+/fvIy8srdr6FhQVq1apViRGRqaqMfdEU9/fs7Gz89NNP2LdvH86ePYsff/xR3yERVaicnBy1D9h+lpOTE6ysrCplHboc0xCRdgoKCkp92J6dnR3s7OwqKSIi3dDVsSUvL0/tg6qf5eDgAGtr6zLHWhnr0KfKGHfoG88nyFCwz6Iy0++dgExPRESEaNKkibC2thY2Njaia9euIj4+vkzLAlDiX9H7FZoaX1/fErdP0Xt6E1WUytgXDW1/L+5+g7qkuPefo6OjeOeddypsPUSGQnEvypL+yns/Sm3WocsxDRFpR3EMLOmPz24hY6SrY4tiLFrSX1mfV1WZ69Cnyhh36BvPJ8hQsM+isuI99o3Ynj17Spzv7u6OFi1aVFI0hicpKQkPHjwodr61tTW6dOlSiRGRqaqMfZH7O1HVd+fOHSQnJ5dYxsvLCzVq1DDodRBR+T158gSHDh0qsUzDhg3RsGHDSoqIyLA8ePAASUlJJZZp2bIlateubdDr0CeOCYgqD/ssKism9omIiIiIiIiIiIiIjIhJ32O/sLAQt2/fRvXq1WFmZqbvcIg0JoTAw4cP4e7uDnNzPgO7KLZtMlZs26Vj+yZjxfZdMrZtMlZs26Vj+yZjxfZdMrZtMlZVqW2bdGL/9u3bqFevnr7DICqzv//+G3Xr1tV3GAaHbZuMHdt28di+ydixfavHtk3Gjm27eGzfZOzYvtVj2yZjVxXatkkn9qtXrw7g3w/S3t5eZX5+fj52794Nf39/WFpaVnZ4Ro3brnxK235ZWVmoV6+etA+TsqrYto0xZsA449ZnzGzbpSutfeubMe7z5WWKdQa0rzfbd8mq4rG7vEyxzoDx1Zttu3SKbbN27VoMGDDAKD7XimZs+3lFMuRtwfZdMh67i8e6G3bdq1LbNunEvuKnQvb29sV2QjY2NrC3tzfYndFQcduVj6bbjz93U68qtm1jjBkwzrgNIWa27eKV1r71zRD2n8pminUGyl5vtm/1quKxu7xMsc6A8dabbbt4im1jjJ9rRTHW/bwiGMO2YPtWj8fu4rHuxlH3qtC2jftGQkREREREREREREREJsakr9gnMgQNZm9XmSazEFjYUQ/BmJhWUbuQW/DfN7TXPgrUYzREpCvq+lW2b6KqgcduItIUxwNEhoHHbqKKwyv2iQgAEBMTgw4dOqB69epwcXHBgAEDkJKSolTmyZMnCAkJQc2aNWFnZ4fBgwcjLS1NqcyNGzcQGBgIGxsbuLi4YMaMGXj69KlSmf379+OFF16ATCZD48aNERcXpxLPihUr0KBBA8jlcnh7e+P48eM6rzORKWDbJiIiIiIiIqp6mNgnIgDAgQMHEBISgqNHjyI+Ph75+fnw9/dHdna2VGb69On4+eefsWXLFhw4cAC3b9/GoEGDpPkFBQUIDAxEXl4ejhw5gvXr1yMuLg6RkZFSmatXryIwMBA9e/bE6dOnERYWhgkTJmDXrl1SmU2bNiE8PBxz587FyZMn0bZtWwQEBCA9Pb1yNgZRFcK2bbgazN6u8kdERERERESkCd6KRwP82RCZgp07dyq9jouLg4uLC5KSktC9e3dkZmbiyy+/xIYNG9CrVy8AQGxsLJo3b46jR4+iU6dO2L17N86fP489e/bA1dUV7dq1w/z58zFr1ixERUXBysoKq1evhqenJz755BMAQPPmzXHo0CEsWbIEAQEBAIDFixdj4sSJCA4OBgCsXr0a27dvx7p16zB79uxK3CpExs/Y23Zubi5yc3Ol11lZWQD+fShTfn6+2vfILITKtOLK6ppiPZqsT59x6pI2da5KtK23qW0fIiIiIiKqWEzsE5FamZmZAAAnJycAQFJSEvLz8+Hn5yeVadasGerXr4/ExER06tQJiYmJaN26NVxdXaUyAQEBmDJlCpKTk/H8888jMTFRaRmKMmFhYQCAvLw8JCUlISIiQppvbm4OPz8/JCYmqo1V28SfYprMXKidboiMNXFmjHHrM+bKWKcxtW3g31sJRUdHq0zfvXs3bGxs1L5H3TNKduzYUew6KkJ8fHypZQwhTl3SpM5Vkab1fvz4cQVHQkREREREpoSJfSJSUVhYiLCwMHTp0gWtWrUCAKSmpsLKygqOjo5KZV1dXZGamiqVeTbxp5ivmFdSmaysLOTk5ODBgwcoKChQW+bixYtq4y1L4g8A5rcvVHptDAk1Y02cGWPc+oi5ohN/xta2ASAiIgLh4eHS66ysLNSrVw/+/v6wt7dX+55WUbtUpp2LCih2HbqUn5+P+Ph4vPjii7C0tCyxrD7j1CVt6lyVaFtvxZfOREREREREusDEPhGpCAkJwblz53Do0CF9h6IRbRN/imTMeyfMkVv43222DDmhZqyJM2OMW58xV3Tiz9jaNgDIZDLIZDKV6ZaWlsV+Ps/ePu/Z8pWppPgUDCFOXdKkzlWRpvU2xW1DRKRr6p5Hw1vlEhGRqWJin4iUhIaG4pdffsHBgwdRt25dabqbmxvy8vKQkZGhdGVvWloa3NzcpDLHjx9XWl5aWpo0T/GvYtqzZezt7WFtbQ0LCwtYWFioLaNYRlFlSfwBQG6hmVJizRiSLsaaODPGuPURc0WuzxjbNhERERERERGpZ67vAIjIMAghEBoaih9++AF79+6Fp6en0nwvLy9YWloiISFBmpaSkoIbN27Ax8cHAODj44OzZ88iPT1dKhMfHw97e3u0aNFCKvPsMhRlFMuwsrKCl5eXUpnCwkIkJCRIZYhIc2zbRERERESGISoqCmZmZkp/zZo1k+Y/efIEISEhqFmzJuzs7DB48GCVC2Nu3LiBwMBA2NjYwMXFBTNmzMDTp0+Vyuzfvx8vvPACZDIZGjdujLi4OJVYVqxYgQYNGkAul8Pb21vlQh4iMnxM7BMRgH9v0fHNN99gw4YNqF69OlJTU5GamoqcnBwAgIODA8aPH4/w8HDs27cPSUlJCA4Oho+PDzp16gQA8Pf3R4sWLTB69Gj88ccf2LVrF+bMmYOQkBDpivrJkyfjr7/+wsyZM3Hx4kWsXLkSmzdvxvTp06VYwsPD8cUXX2D9+vW4cOECpkyZguzsbAQHB1f+hiEycmzbRERERESGo2XLlrhz54709+xtMqdPn46ff/4ZW7ZswYEDB3D79m0MGjRIml9QUIDAwEDk5eXhyJEjWL9+PeLi4hAZGSmVuXr1KgIDA9GzZ0+cPn0aYWFhmDBhAnbt+u/5Tps2bUJ4eDjmzp2LkydPom3btggICFC6kIeIDB8T+0QEAFi1ahUyMzPRo0cP1K5dW/rbtGmTVGbJkiXo168fBg8ejO7du8PNzQ1bt26V5ltYWOCXX36BhYUFfHx88Nprr2HMmDGYN2+eVMbT0xPbt29HfHw82rZti08++QRr165FQMB/97cfPnw4Fi1ahMjISLRr1w6nT5/Gzp07VR66SUSlY9smIiIyPgcPHsTLL78Md3d3mJmZYdu2bUrzhRCIjIxE7dq1YW1tDT8/P1y6dEmpzP379zFq1CjY29vD0dER48ePx6NHj5TKnDlzBt26dYNcLke9evWwcOFClVi2bNmCZs2aQS6Xo3Xr1tixY4fO60tkSqpVqwY3Nzfpz9nZGQCQmZmJL7/8EosXL0avXr3g5eWF2NhYHDlyBEePHgUA7N69G+fPn8c333yDdu3aoW/fvpg/fz5WrFiBvLw8AMDq1avh6emJTz75BM2bN0doaCiGDBmCJUuWSDEsXrwYEydORHBwMFq0aIHVq1fDxsYG69atq/wNQkRlxnvsExGAf08OSiOXy7FixQqsWLGi2DIeHh6lDvZ79OiBU6dOlVgmNDQUoaGhpcZERCVj2yYiIjI+2dnZaNu2LcaNG6d0ta7CwoUL8emnn2L9+vXw9PTEe++9h4CAAJw/fx5yuRwAMGrUKNy5cwfx8fHIz89HcHAwJk2ahA0bNgAAsrKy4O/vDz8/P6xevRpnz57FuHHj4OjoiEmTJgEAjhw5gpEjRyImJgb9+vXDhg0bMGDAAJw8eRKtWrWqvA1CVIVcunQJ7u7ukMvl8PHxQUxMDOrXr4+kpCTk5+fDz89PKtusWTPUr18fiYmJ6NSpExITE9G6dWulC2MCAgIwZcoUJCcn4/nnn0diYqLSMhRlwsLCAAB5eXlISkpCRESENN/c3Bx+fn5ITEwsNu7c3Fzk5uZKr7OysgAA+fn5yM/PVymvmCYzF2qnV2WKOppCXYsyhrobcmzaYmKfiIiIiIiIyID07dsXffv2VTtPCIGlS5dizpw56N+/PwDgq6++gqurK7Zt24YRI0bgwoUL2LlzJ37//Xe0b98eALB8+XK89NJLWLRoEdzd3fHtt98iLy8P69atg5WVFVq2bInTp09j8eLFUmJ/2bJl6NOnD2bMmAEAmD9/PuLj4/HZZ59h9erVauMrLvkHlD+ZIrNQvWChuGVqU7ayGUPiq7IY8raoiJi8vb0RFxeHpk2b4s6dO4iOjka3bt1w7tw5pKamwsrKCo6OjkrvcXV1RWpqKgAgNTVV5deuitellcnKykJOTg4ePHiAgoICtWUuXrxYbOwxMTGIjo5Wmb57927Y2NgU+7757QuVXpvSr37i4+P1HYLeGHLdHz9+rO8QdIaJfSIiIiIiIiIjcfXqVaSmpipdkevg4ABvb28kJiZixIgRSExMhKOjo5TUBwA/Pz+Ym5vj2LFjGDhwIBITE9G9e3dYWVlJZQICArBgwQI8ePAANWrUQGJiIsLDw5XWHxAQoHJroGcVl/wDyp/oWdhRdVpxSUJtyuqLISe+KpshbouKSP49+4VdmzZt4O3tDQ8PD2zevBnW1tY6X58uRUREKPUHWVlZqFevHvz9/WFvb69SPj8/H/Hx8XjvhDlyC82k6eeiAlTKVjWKur/44ouwtLTUdziVyhjq/uwXzsaOiX0iIiIiIiIiI6G4Klfd1bbPXrHr4uKiNL9atWpwcnJSKuPp6amyDMW8GjVqFHvlr2IZ6hSX/ANQ7kRPq6hdKtOKSxJqU7ayGUPiq7IY8raojOSfo6MjnnvuOVy+fBkvvvgi8vLykJGRoXTVflpaGtzc3AAAbm5uOH78uNIy0tLSpHmKfxXTni1jb28Pa2trWFhYwMLCQm0ZxTLUkclkkMlkKtMtLS1L/OxyC82QW2CmVN5UlLZtqjJDrruhxlUWTOwTERERERERkU4Ul/wDyp/oeTY5+Owyy1tWXww58VXZDHFbVEY8jx49wpUrVzB69Gh4eXnB0tISCQkJGDx4MAAgJSUFN27cgI+PDwDAx8cHH3zwAdLT06Uv7+Lj42Fvb48WLVpIZYr+OiU+Pl5ahpWVFby8vJCQkIABAwYAAAoLC5GQkMBnYREZGXN9B0BEREREREREmlFcUVvS1bZubm5IT09Xmv/06VPcv3+/1Kt6n11HcWVKuqqXiIr39ttv48CBA7h27RqOHDmCgQMHwsLCAiNHjoSDgwPGjx+P8PBw7Nu3D0lJSQgODoaPjw86deoEAPD390eLFi0wevRo/PHHH9i1axfmzJmDkJAQ6Qu1yZMn46+//sLMmTNx8eJFrFy5Eps3b8b06dOlOMLDw/HFF19g/fr1uHDhAqZMmYLs7GwEBwfrZbsQUdkwsU9ERERERERkJDw9PeHm5oaEhARpWlZWFo4dO6Z0VW9GRgaSkpKkMnv37kVhYSG8vb2lMgcPHlR6QGh8fDyaNm2KGjVqSGWeXY+ijGI9RKSdmzdvYuTIkWjatCmGDRuGmjVr4ujRo6hVqxYAYMmSJejXrx8GDx6M7t27w83NDVu3bpXeb2FhgV9++QUWFhbw8fHBa6+9hjFjxmDevHlSGU9PT2zfvh3x8fFo27YtPvnkE6xduxYBAf/dimr48OFYtGgRIiMj0a5dO5w+fRo7d+5UufUWERk23oqHiIiIiIiIyIA8evQIly9fll5fvXoVp0+fhpOTE+rXr4+wsDC8//77aNKkCTw9PfHee+/B3d1duq1G8+bN0adPH0ycOBGrV69Gfn4+QkNDMWLECLi7uwMAXn31VURHR2P8+PGYNWsWzp07h2XLlmHJkiXSet988034+vrik08+QWBgIDZu3IgTJ07g888/r9TtQVRVbNy4scT5crkcK1aswIoVK4ot4+HhUeqDoHv06IFTp06VWCY0NJS33iEyckzsExERERERERmQEydOoGfPntJrxcNog4KCEBcXh5kzZyI7OxuTJk1CRkYGunbtip07d0Iul0vv+fbbbxEaGorevXvD3NwcgwcPxqeffirNd3BwwO7duxESEgIvLy84OzsjMjISkyZNksp07twZGzZswJw5c/DOO++gSZMm2LZtG1q1alUJW4GIiIhKwsQ+ERERERERkQHp0aMHhBDFzjczM8O8efOUbr9RlJOTEzZs2FDietq0aYPffvutxDJDhw7F0KFDSw6YiIiIKh0T+0RE/6/B7O1qp1/7KLCSIyEiIiIiIiIiIioeH55LRERERERERERERGREmNgnIiIiIiIiIiIiIjIiWiX2Y2Ji0KFDB1SvXh0uLi4YMGAAUlJSlMo8efIEISEhqFmzJuzs7DB48GCkpaUplblx4wYCAwNhY2MDFxcXzJgxA0+fPlUqs3//frzwwguQyWRo3Lgx4uLiVOJZsWIFGjRoALlcDm9vbxw/flyb6hARERERERERERERGR2tEvsHDhxASEgIjh49ivj4eOTn58Pf3x/Z2dlSmenTp+Pnn3/Gli1bcODAAdy+fRuDBg2S5hcUFCAwMBB5eXk4cuQI1q9fj7i4OERGRkplrl69isDAQPTs2ROnT59GWFgYJkyYgF27dkllNm3ahPDwcMydOxcnT55E27ZtERAQgPT09PJsDyIiIiIiIiIiIiIig6bVw3N37typ9DouLg4uLi5ISkpC9+7dkZmZiS+//BIbNmxAr169AACxsbFo3rw5jh49ik6dOmH37t04f/489uzZA1dXV7Rr1w7z58/HrFmzEBUVBSsrK6xevRqenp745JNPAADNmzfHoUOHsGTJEgQEBAAAFi9ejIkTJyI4OBgAsHr1amzfvh3r1q3D7Nmzy71hiIiIiIiIiIiIiIgMkVaJ/aIyMzMBAE5OTgCApKQk5Ofnw8/PTyrTrFkz1K9fH4mJiejUqRMSExPRunVruLq6SmUCAgIwZcoUJCcn4/nnn0diYqLSMhRlwsLCAAB5eXlISkpCRESENN/c3Bx+fn5ITEwsNt7c3Fzk5uZKr7OysgAA+fn5yM/PVymvmCYzF2qnU/EU24jbqnQyC6E67f/3ueK2H7crERERERERERGR6SpzYr+wsBBhYWHo0qULWrVqBQBITU2FlZUVHB0dlcq6uroiNTVVKvNsUl8xXzGvpDJZWVnIycnBgwcPUFBQoLbMxYsXi405JiYG0dHRKtN3794NGxubYt83v32h0usdO3YUW5aUxcfH6zsEg7ewY/Hzitt+jx8/rqBoiIiIiIiIiIiIyNCVObEfEhKCc+fO4dChQ7qMp0JFREQgPDxcep2VlYV69erB398f9vb2KuXz8/MRHx+P906YI7fQTJp+LiqgUuI1Zopt9+KLL8LS0lLf4Ri0VlG7VKbJzAXmty8sdvspfm1CREREREREREREpkerh+cqhIaG4pdffsG+fftQt25dabqbmxvy8vKQkZGhVD4tLQ1ubm5SmbS0NJX5inkllbG3t4e1tTWcnZ1hYWGhtoxiGerIZDLY29sr/QGApaVlsX8AkFtohtyC//5KKs8/5W2n7xiM4e/ZfUv6+/8vkkrbvkRERGS6YmJi0KFDB1SvXh0uLi4YMGAAUlJSlMo8efIEISEhqFmzJuzs7DB48GCVMfSNGzcQGBgIGxsbuLi4YMaMGXj69KlSmf379+OFF16ATCZD48aNERcXpxLPihUr0KBBA8jlcnh7e+P48eM6rzMREREREf1Lq8S+EAKhoaH44YcfsHfvXnh6eirN9/LygqWlJRISEqRpKSkpuHHjBnx8fAAAPj4+OHv2LNLT06Uy8fHxsLe3R4sWLaQyzy5DUUaxDCsrK3h5eSmVKSwsREJCglSGiIiIiKgqO3DgAEJCQnD06FHEx8cjPz8f/v7+yM7OlspMnz4dP//8M7Zs2YIDBw7g9u3bGDRokDS/oKAAgYGByMvLw5EjR7B+/XrExcUhMjJSKnP16lUEBgaiZ8+eOH36NMLCwjBhwgTs2vXfrw43bdqE8PBwzJ07FydPnkTbtm0REBCgNOYnIiIiIiLd0epWPCEhIdiwYQN+/PFHVK9eXbonvoODA6ytreHg4IDx48cjPDwcTk5OsLe3x7Rp0+Dj44NOnToBAPz9/dGiRQuMHj0aCxcuRGpqKubMmYOQkBDIZDIAwOTJk/HZZ59h5syZGDduHPbu3YvNmzdj+/btUizh4eEICgpC+/bt0bFjRyxduhTZ2dkIDg7W1bYhIiIiIjJYO3fuVHodFxcHFxcXJCUloXv37sjMzMSXX36JDRs2oFevXgCA2NhYNG/eHEePHkWnTp2we/dunD9/Hnv27IGrqyvatWuH+fPnY9asWYiKioKVlRVWr14NT09PfPLJJwCA5s2b49ChQ1iyZAkCAv69ReXixYsxceJEaSy+evVqbN++HevWrcPs2bMrcasQEREREZkGrRL7q1atAgD06NFDaXpsbCzGjh0LAFiyZAnMzc0xePBg5ObmIiAgACtXrpTKWlhY4JdffsGUKVPg4+MDW1tbBAUFYd68eVIZT09PbN++HdOnT8eyZctQt25drF27VjpxAIDhw4fj7t27iIyMRGpqKtq1a4edO3eqPFCXiIiIiMgUZGZmAgCcnJwAAElJScjPz4efn59UplmzZqhfvz4SExPRqVMnJCYmonXr1kpj6ICAAEyZMgXJycl4/vnnkZiYqLQMRZmwsDAAQF5eHpKSkhARESHNNzc3h5+fHxITE9XGmpubi9zcXOm14vlB+fn5yM/PVymvmCYzF2qnV0WKulXlOqpjbPU2ljjpXw1mb1eZdu2jQD1EQkREVH5aJfaFEKWWkcvlWLFiBVasWFFsGQ8PD+zYsaPE5fTo0QOnTp0qsUxoaChCQ0NLjYmIiIiIqCorLCxEWFgYunTpglatWgEAUlNTYWVlBUdHR6Wyrq6u0i9vU1NTVS6MUbwurUxWVhZycnLw4MEDFBQUqC1z8eJFtfHGxMQgOjpaZfru3bthY2NTbD3nty9Uel3aOUVVEB8fr+8Q9MJY6v348WN9h0CViF8MEBGRIdEqsU9ERERERIYnJCQE586dw6FDh/QdikYiIiIQHh4uvc7KykK9evXg7+8Pe3t7lfL5+fmIj4/HeyfMkVtoJk0/FxWgUraqUNT5xRdfhKWlpb7DqTTGVm/Fr02IiIiIKhsT+0RERERERiw0NBS//PILDh48iLp160rT3dzckJeXh4yMDKWr9tPS0uDm5iaVOX78uNLy0tLSpHmKfxXTni1jb28Pa2trWFhYwMLCQm0ZxTKKkslk0vO1nmVpaVliMje30Ay5BWZK5au60rZJVWUs9TaGGImIiKhqMtd3AEREREREpD0hBEJDQ/HDDz9g79698PT0VJrv5eUFS0tLJCQkSNNSUlJw48YN+Pj4AAB8fHxw9uxZpKenS2Xi4+Nhb2+PFi1aSGWeXYaijGIZVlZW8PLyUipTWFiIhIQEqQwRkaFqMHu72j8iIiJDxyv2iYiIiIiMUEhICDZs2IAff/wR1atXl+6J7+DgAGtrazg4OGD8+PEIDw+Hk5MT7O3tMW3aNPj4+KBTp04AAH9/f7Ro0QKjR4/GwoULkZqaijlz5iAkJES6on7y5Mn47LPPMHPmTIwbNw579+7F5s2bsX37f4mv8PBwBAUFoX379ujYsSOWLl2K7OxsBAcHV/6GISKTwiQ8ERGZKib2iYiIiIiM0KpVqwAAPXr0UJoeGxuLsWPHAgCWLFkCc3NzDB48GLm5uQgICMDKlSulshYWFvjll18wZcoU+Pj4wNbWFkFBQZg3b55UxtPTE9u3b8f06dOxbNky1K1bF2vXrkVAwH/3tx8+fDju3r2LyMhIpKamol27dti5c6fKA3WJiIiIiEg3eCseIiKiKu7gwYN4+eWX4e7uDjMzM2zbtk1pvhACkZGRqF27NqytreHn54dLly4plbl//z5GjRoFe3t7ODo6Yvz48Xj06JFSmTNnzqBbt26Qy+WoV68eFi5cqBLLli1b0KxZM8jlcrRu3Ro7duzQeX1JM7ztgPETQqj9UyT1AUAul2PFihW4f/8+srOzsXXrVpX73nt4eGDHjh14/Pgx7t69i0WLFqFaNeXrf3r06IFTp04hNzcXV65cUVqHQmhoKK5fv47c3FwcO3YM3t7eFVFtIiIiIiICE/tE9P+Y+COqurKzs9G2bVusWLFC7fyFCxfi008/xerVq3Hs2DHY2toiICAAT548kcqMGjUKycnJiI+Plx7SOWnSJGl+VlYW/P394eHhgaSkJHz88ceIiorC559/LpU5cuQIRo4cifHjx+PUqVMYMGAABgwYgHPnzlVc5YmIiIiIiIiqICb2iQgAE39EVVnfvn3x/vvvY+DAgSrzhBBYunQp5syZg/79+6NNmzb46quvcPv2bekLvgsXLmDnzp1Yu3YtvL290bVrVyxfvhwbN27E7du3AQDffvst8vLysG7dOrRs2RIjRozAG2+8gcWLF0vrWrZsGfr06YMZM2agefPmmD9/Pl544QV89tlnlbIdiIiIiIiIiKoK3mOfiAD8m/jr27ev2nlFE38A8NVXX8HV1RXbtm3DiBEjpMTf77//jvbt2wMAli9fjpdeegmLFi2Cu7u7UuLPysoKLVu2xOnTp7F48WLpC4BnE38AMH/+fMTHx+Ozzz7D6tWr1caXm5uL3Nxc6XVWVhYAID8/H/n5+SrlFdNk5kKjbaNuGZVNEYMhxKINY4xbnzHrY51Xr15Famoq/Pz8pGkODg7w9vZGYmIiRowYgcTERDg6OkptGwD8/Pxgbm6OY8eOYeDAgUhMTET37t1hZWUllQkICMCCBQvw4MED1KhRA4mJiQgPD1daf0BAgMovhJ6lbfsGAJmFatuurG2rzf6jzzh1uX5jbOe6oG29TW37EBERERFRxWJin4hKZeiJv5iYGERHR6tM3717N2xsbIp93/z2hZpU36BuBRQfH6/vEMrEGOPWR8yPHz+u9HWmpqYCgMoDLl1dXaV5qampcHFxUZpfrVo1ODk5KZXx9PRUWYZiXo0aNZCamlrietQpS/te2FF1WmW3Y032H33Hqev1G2M71wVN662P9k1ERESGJSYmBlu3bsXFixdhbW2Nzp07Y8GCBWjatKlUpkePHjhw4IDS+15//XWlC91u3LiBKVOmYN++fbCzs0NQUBBiYmKUnpGzf/9+hIeHIzk5GfXq1cOcOXNUnpGzYsUKfPzxx0hNTUXbtm2xfPlydOyoZpBIRAaJiX0iKpWhJ/4iIiKUvgzIyspCvXr14O/vD3t7e5Xy+fn5iI+Px3snzJFbaFZi3QHgXFRAqWUqmiLmF198EZaWlvoOR2PGGLc+Y1ZcjU7/0bZ9A0CrqF0q0yqrHWuz/+gzTl2u3xjbuS5oW2+2byLSpaioKJUvvps2bYqLFy8CAJ48eYK33noLGzduRG5uLgICArBy5UqlcbauEoNEpLkDBw4gJCQEHTp0wNOnT/HOO+/A398f58+fh62trVRu4sSJmDdvnvT62QtaCgoKEBgYCDc3Nxw5cgR37tzBmDFjYGlpiQ8//BDAvxfnBQYGYvLkyfj222+RkJCACRMmoHbt2ggI+He8t2nTJoSHh2P16tXw9vbG0qVLERAQgJSUFJVzeyIyTEzsE5HRk8lkkMlkKtMtLS1LTLbkFpoht6D0xL4hJapKq5OhMsa49RGzPraRm5sbACAtLQ21a9eWpqelpaFdu3ZSmfT0dKX3PX36FPfv35fe7+bmhrS0NKUyitellVHMV6cs7Vtdu9bHZ1naOvUdp67Xb4ztXBc0rbcpbhsiqlgtW7bEnj17pNfPJuSnT5+O7du3Y8uWLXBwcEBoaCgGDRqEw4cPA9BdYpCItLNz506l13FxcXBxcUFSUhK6d+8uTbexsSl2jLx7926cP38ee/bsgaurK9q1a4f58+dj1qxZiIqKgpWVFVavXg1PT0988sknAIDmzZvj0KFDWLJkidR+Fy9ejIkTJyI4OBgAsHr1amzfvh3r1q3D7NmzK6L6RKRjTOwTUakMPfFHRGXn6ekJNzc3JCQkSO05KysLx44dw5QpUwAAPj4+yMjIQFJSEry8vAAAe/fuRWFhIby9vaUy7777LvLz86UEZnx8PJo2bYoaNWpIZRISEhAWFiatPz4+Hj4+PpVUWyIioqqjWrVqasfImZmZ+PLLL7Fhwwb06tULABAbG4vmzZvj6NGj6NSpk84Sg0RUPpmZmQAAJycnpenffvstvvnmG7i5ueHll1/Ge++9J121n5iYiNatWyv9AicgIABTpkxBcnIynn/+eSQmJirdSldRRjEOz8vLQ1JSEiIiIqT55ubm8PPzQ2JiotpYdfVsO1N47pCpPoMKMI66G3Js2mJin4hKxcQfkXF79OgRLl++LL2+evUqTp8+DScnJ9SvXx9hYWF4//330aRJE3h6euK9996Du7s7BgwYAODfE/k+ffpg4sSJWL16NfLz8xEaGooRI0bA3d0dAPDqq68iOjoa48ePx6xZs3Du3DksW7YMS5Yskdb75ptvwtfXF5988gkCAwOxceNGnDhxAp9//nmlbg8iIqKq4NKlS3B3d4dcLoePjw9iYmJQv359JCUlIT8/Xymp16xZM9SvXx+JiYno1KmTThKDxSku+QeUP5mi7sHvFUVdrHzwvO4Z8rao6JgKCwsRFhaGLl26oFWrVtL0V199FR4eHnB3d8eZM2cwa9YspKSkYOvWrQBQ7O1rFfNKKpOVlYWcnBw8ePAABQUFassobulVlK6ebWdIz7CraKb6DCrAsOtelZ59xcQ+EQFg4o+oKjtx4gR69uwpvVbcsz4oKAhxcXGYOXMmsrOzMWnSJGRkZKBr167YuXMn5HK59J5vv/0WoaGh6N27N8zNzTF48GB8+umn0nwHBwfs3r0bISEh8PLygrOzMyIjIzFp0iSpTOfOnbFhwwbMmTMH77zzDpo0aYJt27YpncgQERFR6by9vREXF4emTZvizp07iI6ORrdu3XDu3DmkpqbCysoKjo6OSu8p+nys8iYGra2t1cZWXPIPKH+iR92D3yuKuuQjHzxfcQxxW1R08i8kJATnzp3DoUOHlKY/O35u3bo1ateujd69e+PKlSto1KhRhcZUEl09284QnmFX0Uz1GVSAcdS9Kj37iol9IgLAxB9RVdajRw8IUfwVbmZmZpg3b57SA7qKcnJywoYNG0pcT5s2bfDbb7+VWGbo0KEYOnRoyQETERFRifr27Sv9v02bNvD29oaHhwc2b95cbMK9shSX/ANQ7kSPuge/VxR1yUc+eF73DHlbVGTyLzQ0FL/88gsOHjyIunXrllhW8Qv4y5cvo1GjRnBzc8Px48eVymh6i1t7e3tYW1vDwsICFhYWWt0GV1fPtjO0z7kimeozqADDrruhxlUWTOwTEQAm/krSYPZ2lWnXPgrUQyRERERERKocHR3x3HPP4fLly3jxxReRl5eHjIwMpav2n03Y6SIxWJzikn9A+RM96h78XlHUxckHz1ccQ9wWFRGPEALTpk3DDz/8gP3798PT07PU95w+fRoApOfd+fj44IMPPkB6ejpcXFwA/PuLB3t7e7Ro0UIqU/TXJM/e4tbKygpeXl5ISEiQfoVfWFiIhIQEhIaG6qKqRFQJzPUdABERERERERGV3aNHj3DlyhXUrl0bXl5esLS0REJCgjQ/JSUFN27ckJJ6Pj4+OHv2LNLT06Uy6hKDzy5DUYbPviIqu5CQEHzzzTfYsGEDqlevjtTUVKSmpiInJwcAcOXKFcyfPx9JSUm4du0afvrpJ4wZMwbdu3dHmzZtAAD+/v5o0aIFRo8ejT/++AO7du3CnDlzEBISIn2pNnnyZPz111+YOXMmLl68iJUrV2Lz5s2YPn26FEt4eDi++OILrF+/HhcuXMCUKVOQnZ2N4ODgyt8wRFQmvGKfiIiIiIiIyIi8/fbbePnll+Hh4YHbt29j7ty5sLCwwMiRI+Hg4IDx48cjPDwcTk5OsLe3x7Rp0+Dj44NOnToBUE4MLly4EKmpqWoTg5999hlmzpyJcePGYe/evdi8eTO2b1f9NSsRaWbVqlUA/v3F/LNiY2MxduxYWFlZYc+ePVi6dCmys7NRr149DB48GHPmzJHKWlhY4JdffsGUKVPg4+MDW1tbBAUFKf263tPTE9u3b8f06dOxbNky1K1bF2vXrkVAwH+3jho+fDju3r2LyMhIpKamol27dti5c6fKszWIyHAxsU9ERERERERkRG7evImRI0fi3r17qFWrFrp27YqjR4+iVq1aAIAlS5ZIz7zKzc1FQEAAVq5cKb1fV4lBItJOSbe/BYB69erhwIEDpS7Hw8Oj1Ac39+jRA6dOnSqxTGhoKG+9Q2TEmNgnIiIiIiKjpO45OACfhUNV38aNG0ucL5fLsWLFCqxYsaLYMrpKDBIREZF+8B77RERERERERERERERGhIl9IiIiIiIiIiIiIiIjwsQ+EREREREREREREZERYWKfiIiIiIiIiIiIiMiIMLFPRERERERERERERGREmNgnIiIiIiIiIiIiIjIi1fQdABERERERERHRsxrM3q7vEIiIiAwaE/tERERERERERGVQ3BcQ1z4KrORIiIjI1DCxT0REREQ6oS65wcQGERERERGR7vEe+0RERERERERERERERoSJfSIiIiIiIiIiIiIiI8LEPhERERERERERERGREWFin4iIiIiIiIiIiIjIiDCxT0RERERERERERERkRKrpOwAiImPUYPZ2lWnXPgrUQyRERERERKRr6sb7REREhoSJfSIiIiIiqlL4BTwRERERVXW8FQ8RERERERERERERkRHhFftERDpS3M91eYUgERERERERERHpEq/YJyIiIiIiIiIiIiIyIkzsExEREREREREREREZEd6Kh4iogvEBfkREREREREREpEtM7BMRERERUZXHL9qJiIiIqCrhrXiIiIiIiIiIiIiIiIwIr9gnItIDTa8aVJSTWQgs7Ai0itqF3AIzXmFIRESkA+qOxwCv5CciIiIiw2f0V+yvWLECDRo0gFwuh7e3N44fP67vkIhIR9i+iaomtm3SRoPZ29X+kWFi+yaqmti2iaoutm8i42XUif1NmzYhPDwcc+fOxcmTJ9G2bVsEBAQgPT1d36ERUTmxfWuPiS8yBmzbRFVXVWrfPKYS/acqtW0iUsb2TWTcjDqxv3jxYkycOBHBwcFo0aIFVq9eDRsbG6xbt07foRFROZli+67MJAITFqQvpti2iUxFVW/fPHaSqarqbZvIlLF9Exk3o73Hfl5eHpKSkhARESFNMzc3h5+fHxITE9W+Jzc3F7m5udLrzMxMAMD9+/eRn5+vUj4/Px+PHz9GtXxzFBSaSdPv3bunq2pUWYptd+/ePVhaWuo7HINW7Wm26rRCgcePC4vdfg8fPgQACCEqPD590LZ966ptGzLFPqGIufHbm1XLqHmfunLalD0W0VvLSJV1X7AHc54vRLt3tyL3/7d1eZfpHZOgdnp5l6ugz/6LbVuVtu0bUN+vVtaxW5v9R59x6nL9z9a5IuqkbpnlXa4u+hFt+wq2b2VV5dhd3HG2PBT7oamOp42t3mzbqopr39p+rsX1/8aipOOUse3nFcmQtwXbtzJdHbuLO3bq6nzOEBjyfl3RjKHuValtG21i/59//kFBQQFcXV2Vpru6uuLixYtq3xMTE4Po6GiV6Z6enlqt2/kTrYoTlcmrGpR5+PAhHBwcKjyWyqZt+9ZV2zZ0muwTuqaL/q5o3BXVh1alvplt+z+mduzWd5wVsX5javOVsf3Zvv9lKsfustB3P0Blw7b9n+La94QJEyokRkPFtlx1sH3/q6KP3WwzVNmqQts22sR+WURERCA8PFx6XVhYiPv376NmzZowM1O98icrKwv16tXD33//DXt7+8oM1ehx25VPadtPCIGHDx/C3d1dD9EZHlNo28YYM2CcceszZrZtVdq2b30zxn2+vEyxzoD29Wb7VmYKx+7yMsU6A8ZXb7ZtVera9/Xr19GuXTuj+VwrmrHt5xXJkLcF27cyHrs1x7obdt2rUts22sS+s7MzLCwskJaWpjQ9LS0Nbm5uat8jk8kgk8mUpjk6Opa6Lnt7e4PdGQ0dt135lLT9jP1bxZJo275NqW0bY8yAccatr5jZtpWVtX3rmzHu8+VlinUGtKs32/d/TOnYXV6mWGfAuOrNtq1MXfs2N//38X7G9LlWBm6P/xjqtmD7/g+P3dpj3Q237lWlbRvtw3OtrKzg5eWFhIT/7pFaWFiIhIQE+Pj46DEyIiovtm+iqoltm6jqYvsmqprYtomqLrZvIuNntFfsA0B4eDiCgoLQvn17dOzYEUuXLkV2djaCg4P1HRoRlRPbN1HVxLZNVHWxfRNVTWzbRFUX2zeRcTPqxP7w4cNx9+5dREZGIjU1Fe3atcPOnTtVHvxRVjKZDHPnzlX5qRGVjtuufLj9KrZ9G+P2NcaYAeOM2xhjNiYVfezWN1Pcf0yxzoDp1rskPHbrlinWGTDdehsyXbRtfq7KuD3+w22hXzx2VwzW3TTrrg9mQgih7yCIiIiIiIiIiIiIiEgzRnuPfSIiIiIiIiIiIiIiU8TEPhERERERERERERGREWFin4iIiIiIiIiIiIjIiDCxT0RERERERERERERkRJjYJyIiIiIiIiIiIiIyIiad2F+xYgUaNGgAuVwOb29vHD9+vMTyW7ZsQbNmzSCXy9G6dWvs2LGjkiI1TNpsv7i4OJiZmSn9yeXySozWcBw8eBAvv/wy3N3dYWZmhm3btpX6nv379+OFF16ATCZD48aNERcXV+FxVlXatvvyKO2zFkIgMjIStWvXhrW1Nfz8/HDp0iWlMvfv38eoUaNgb28PR0dHjB8/Ho8ePVIqc+bMGXTr1g1yuRz16tXDwoULVWLRtP+KiYlBhw4dUL16dbi4uGDAgAFISUlRKvPkyROEhISgZs2asLOzw+DBg5GWlqZU5saNGwgMDISNjQ1cXFwwY8YMPH36VKmMJvu1pp/XqlWr0KZNG9jb28Pe3h4+Pj749ddfDTpmMm66aN/GprQ6jx07VuVY36dPH/0EqyO66hOp/Kpy38r9DPjoo49gZmaGsLAwaVpVr7OpqcptuDimOFYoDvs501TV2n1UVJTKWLdZs2bSfF2dcxoCQ8plUCmEidq4caOwsrIS69atE8nJyWLixInC0dFRpKWlqS1/+PBhYWFhIRYuXCjOnz8v5syZIywtLcXZs2crOXLDoO32i42NFfb29uLOnTvSX2pqaiVHbRh27Ngh3n33XbF161YBQPzwww8llv/rr7+EjY2NCA8PF+fPnxfLly8XFhYWYufOnZUTcBWi7X5bXqV91h999JFwcHAQ27ZtE3/88Yd45ZVXhKenp8jJyZHK9OnTR7Rt21YcPXpU/Pbbb6Jx48Zi5MiR0vzMzEzh6uoqRo0aJc6dOye+++47YW1tLdasWSOV0ab/CggIELGxseLcuXPi9OnT4qWXXhL169cXjx49kspMnjxZ1KtXTyQkJIgTJ06ITp06ic6dO0vznz59Klq1aiX8/PzEqVOnxI4dO4Szs7OIiIiQymiyX2vzef30009i+/bt4s8//xQpKSninXfeEZaWluLcuXMGGzMZN120b2NTWp2DgoJEnz59lI719+/f10+wOqKLPpHKr6r3raa+nx0/flw0aNBAtGnTRrz55pvS9KpcZ1NT1dtwcUxxrFAcU+/nTFFVbPdz584VLVu2VBrr3r17V5qvi3NOQ2EouQwqnckm9jt27ChCQkKk1wUFBcLd3V3ExMSoLT9s2DARGBioNM3b21u8/vrrFRqnodJ2+8XGxgoHB4dKis54aJLYnzlzpmjZsqXStOHDh4uAgIAKjKxq0na/1aWin3VhYaFwc3MTH3/8sTQtIyNDyGQy8d133wkhhDh//rwAIH7//XepzK+//irMzMzErVu3hBBCrFy5UtSoUUPk5uZKZWbNmiWaNm0qvS5P/5Weni4AiAMHDkgxWlpaii1btkhlLly4IACIxMREIcS/gwBzc3OlL+9WrVol7O3tpTg12a/L+3nVqFFDrF271qhiJuNUlvZt7IpL7Pfv318v8VSWsvSJVH6m1rea0n728OFD0aRJExEfHy98fX2lxH5VrrMpMrU2rI4pjhVKYkr9nKmqiu1+7ty5om3btmrn6eqc0xDpM5dBpTPJW/Hk5eUhKSkJfn5+0jRzc3P4+fkhMTFR7XsSExOVygNAQEBAseWrsrJsPwB49OgRPDw8UK9ePfTv3x/JycmVEa7R476nG2XdbyvK1atXkZqaqhSPg4MDvL29pXgSExPh6OiI9u3bS2X8/Pxgbm6OY8eOSWW6d+8OKysrqUxAQABSUlLw4MEDqUxZ96HMzEwAgJOTEwAgKSkJ+fn5Sstr1qwZ6tevrxR369at4erqqrS+rKwsqd2XFlN5Pq+CggJs3LgR2dnZ8PHxMYqYqWrRpH1XVfv374eLiwuaNm2KKVOm4N69e/oOSafK0idS+Zhi32pK+1lISAgCAwNVjq9Vuc6mxhTbsCZMeawAmFY/Z4qqcru/dOkS3N3d0bBhQ4waNQo3btwAoLvzZGNQmbkMKp1JJvb/+ecfFBQUKDUmAHB1dUVqaqra96SmpmpVviory/Zr2rQp1q1bhx9//BHffPMNCgsL0blzZ9y8ebMyQjZqxe17WVlZyMnJ0VNUxqcs+21FUqyzpHhSU1Ph4uKiNL9atWpwcnJSKqNuGc+uo6z9V2FhIcLCwtClSxe0atVKWpaVlRUcHR1LjLusMSn267J8XmfPnoWdnR1kMhkmT56MH374AS1atDDomKlq0qR9V0V9+vTBV199hYSEBCxYsAAHDhxA3759UVBQoO/QdKKsfSKVj6n1raa0n23cuBEnT55ETEyMyryqWmdTZGptWFOmOlYATKufM1VVtd17e3sjLi4OO3fuxKpVq3D16lV069YNDx8+1Nk5pzGozFwGla6avgMg0+Dj4wMfHx/pdefOndG8eXOsWbMG8+fP12NkRFSckJAQnDt3DocOHdJ3KBpp2rQpTp8+jczMTHz//fcICgrCgQMH9B0WkckYMWKE9P/WrVujTZs2aNSoEfbv34/evXvrMTLdMLY+kYyTqexnf//9N958803Ex8dDLpfrOxwiqkSm0s9R1dO3b1/p/23atIG3tzc8PDywefNmWFtb6zEyMmUmecW+s7MzLCwsVJ5OnZaWBjc3N7XvcXNz06p8VVaW7VeUpaUlnn/+eVy+fLkiQqxSitv37O3tefDQgi72W11SrLOkeNzc3JCenq40/+nTp7h//75SGXXLeHYdZem/QkND8csvv2Dfvn2oW7euUtx5eXnIyMgoMe6yxqTYr8vyeVlZWaFx48bw8vJCTEwM2rZti2XLlhl0zFQ1adK+TUHDhg3h7OxcJY715ekTqXxMqW81pf0sKSkJ6enpeOGFF1CtWjVUq1YNBw4cwKeffopq1arB1dW1ytXZVJlSG9aGqY4VTKmfM2Wm0u4dHR3x3HPP4fLlyzo75zQGlZnLoNKZZGLfysoKXl5eSEhIkKYVFhYiISFB6aryZ/n4+CiVB4D4+Phiy1dlZdl+RRUUFODs2bOoXbt2RYVZZXDf0w1d7Le65OnpCTc3N6V4srKycOzYMSkeHx8fZGRkICkpSSqzd+9eFBYWwtvbWypz8OBB5OfnS2Xi4+PRtGlT1KhRQyqj6T4khEBoaCh++OEH7N27F56enkrzvby8YGlpqbS8lJQU3LhxQynus2fPKh3I4+PjYW9vjxYtWmgUky4+r8LCQuTm5hpVzFQ1aNK+TcHNmzdx7949oz7W66JPpPIxhb7VFPez3r174+zZszh9+rT01759e4waNUr6f1Wrs6kyhTZcFqY2VjDFfs6UmUq7f/ToEa5cuYLatWvr7JzTGFRmLoM0oN9n9+rPxo0bhUwmE3FxceL8+fNi0qRJwtHRUXo69ejRo8Xs2bOl8ocPHxbVqlUTixYtEhcuXBBz584VlpaW4uzZs/qqgl5pu/2io6PFrl27xJUrV0RSUpIYMWKEkMvlIjk5WV9V0JuHDx+KU6dOiVOnTgkAYvHixeLUqVPi+vXrQgghZs+eLUaPHi2V/+uvv4SNjY2YMWOGuHDhglixYoWwsLAQO3fu1FcVjFZp+62ulfZZf/TRR8LR0VH8+OOP4syZM6J///7C09NT5OTkSMvo06ePeP7558WxY8fEoUOHRJMmTcTIkSOl+RkZGcLV1VWMHj1anDt3TmzcuFHY2NiINWvWSGW06b+mTJkiHBwcxP79+8WdO3ekv8ePH0tlJk+eLOrXry/27t0rTpw4IXx8fISPj480/+nTp6JVq1bC399fnD59WuzcuVPUqlVLRERESGU02a+1+bxmz54tDhw4IK5evSrOnDkjZs+eLczMzMTu3bsNNmYybrpo38ampDo/fPhQvP322yIxMVFcvXpV7NmzR7zwwguiSZMm4smTJ/oOvcx00SdS+VX1vpX72b98fX3Fm2++Kb02hTqbiqrehotjimOF4rCfMz1Vsd2/9dZbYv/+/eLq1avi8OHDws/PTzg7O4v09HQhhG7OOQ2FoeQyqHQmm9gXQojly5eL+vXrCysrK9GxY0dx9OhRaZ6vr68ICgpSKr9582bx3HPPCSsrK9GyZUuxffv2So7YsGiz/cLCwqSyrq6u4qWXXhInT57UQ9T6t2/fPgFA5U+xvYKCgoSvr6/Ke9q1ayesrKxEw4YNRWxsbKXHXVWUtN/qWmmfdWFhoXjvvfeEq6urkMlkonfv3iIlJUVpGffu3RMjR44UdnZ2wt7eXgQHB4uHDx8qlfnjjz9E165dhUwmE3Xq1BEfffSRSiya9l/q4gWgtM/l5OSIqVOniho1aggbGxsxcOBAcefOHaXlXLt2TfTt21dYW1sLZ2dn8dZbb4n8/HyV7VPafq3p5zVu3Djh4eEhrKysRK1atUTv3r2lpL6hxkzGTRft29iUVOfHjx8Lf39/UatWLWFpaSk8PDzExIkTjfrkTQjd9YlUflW5b+V+9q+iiX1TqLMpqcptuDimOFYoDvs501TV2v3w4cNF7dq1hZWVlahTp44YPny4uHz5sjRfV+echsCQchlUMjMhhNDNtf9ERERERERERERERFTRTPIe+0RERERERERERERExoqJfSIiIiIiIiIiIiIiI8LEPhERERERERERERGREWFin4iIiIiIiIiIiIjIiDCxT0RERERERERERERkRJjYJyIiIiIiIiIiIiIyIkzsExEREREREREREREZESb2iYiIiIiIiIiIiIiMCBP7RERERERERERERERGhIl9IiIiIiIiIiIiIiIjwsQ+EREREREREREREZERYWKfiIiIiIiIiIiIiMiIMLFPRERERERERERERGREmNgnIiIiIiIiIiIiIjIiTOwTERERERERERERERkRJvaJiIiIiIiIiIiIiIwIE/tEREREREREREREREaEiX0iIiIiIiIiIiIiIiPCxD4RERERERERERERkRFhYp+IiIiIiIiIiIiIyIgwsU9EREREREREREREZESY2CciIiIiIiIiIiIiMiJM7BMRERERERERERERGREm9omIiIiIiIiIiIiIjAgT+0RERERERERERERERoSJfSIiIiIiIiIiIiIiI8LEPhERERERERERERGREWFin4iIiIiIiIiIiIjIiDCxT0RERERERERERERkRJjYJyIiIiIiIiIiIiIyIkzsExEREREREREREREZESb2iYiIiIiIiIiIiIiMCBP7RERERERERERERERGhIl9IiIiIiIiIiIiIiIjwsQ+EREREREREREREZERYWLfAPXo0QM9evSQXl+7dg1mZmaIi4ur1DjGjh2LBg0aVPh7iKqKuLg4mJmZ4dq1a3qLoWj/QWSoDKG9GJL9+/fDzMwM33//vb5DMUhVeX9RjPMWLVqk71BMir7G18akQYMGGDt2rL7D0Juq3O+YGnXnqGZmZoiKitLZ8u3s7DQqq8v1EhEBQFRUFMzMzJSm6fIYrlj+P//8U2pZUx876AMT+0RV3JEjRxAVFYWMjAx9h0Jk8G7fvo2oqCicPn1a36EQkRHZsGEDli5dqu8wqJI8fvwYUVFR2L9/v75DKdXKlSv18uWFvtZbFh9++CG2bdum7zBIzwz5nMlYjjFsS6Stymh358+fR1RUlMl/SWvI22HHjh38wrMcmNg3Ah4eHsjJycHo0aP1HQoZoSNHjiA6OtogB6lEhub27duIjo5mYr8SjB49Gjk5OfDw8NB3KGQEDH1/MZakC/2nPOPrx48fIzo6uson9lNSUvDFF19U+norW3HJSEPvd6h8cnJyMGfOHOl1ZZ0zFV2vJozlGMPEPmmrMtrd+fPnER0dbZAJ7YpU9BheWduhLGOHHTt2IDo6uoIiqvqY2C+FEAI5OTl6jcHMzAxyuRwWFhZ6jYOIiEhXLCwsIJfLVX42SqQO9xfSNUMcX2dnZ+s7BCUymQyWlpb6DkPy9OlT5OXlVdr62O/oX0W2CblcjmrVqlXY8g1tvUVVdnsi02FoxzJD9uTJExQWFlbIsvV1DDeUsUNhYSGePHmi7zAqhdEn9hX3erp8+TLGjh0LR0dHODg4IDg4GI8fP5bKPX36FPPnz0ejRo0gk8nQoEEDvPPOO8jNzVVaXoMGDdCvXz/s2rUL7du3h7W1NdasWSPd+3bz5s2Ijo5GnTp1UL16dQwZMgSZmZnIzc1FWFgYXFxcYGdnh+DgYJVlx8bGolevXnBxcYFMJkOLFi2watWqUutY9B6giljU/RW9d+Cvv/6Kbt26wdbWFtWrV0dgYCCSk5NV1rFt2za0atUKcrkcrVq1wg8//KDhJ1C67OxsvPXWW6hXrx5kMhmaNm2KRYsWQQihVE7T7aP4jA4dOoSOHTtCLpejYcOG+Oqrr7SOTdt17t+/X9ovWrduLV2ptXXrVrRu3RpyuRxeXl44deqUyjL27t0rfRaOjo7o378/Lly4oFSmuGcUqLtnmpmZGUJDQ6XPTiaToWXLlti5c6fS+2bMmAEA8PT0lPYTU/u2Wp9WrlyJli1bQiaTwd3dHSEhIWqvSFixYgUaNmwIa2trdOzYEb/99pvO7pefnp6O8ePHw9XVFXK5HG3btsX69etVyi1atAidO3dGzZo1YW1tDS8vL7X3+9Zk39OUtuvcsmULWrRoAWtra/j4+ODs2bMAgDVr1qBx48aQy+Xo0aOHyj7eo0cPtGrVCufPn0fPnj1hY2ODOnXqYOHChVKZ/fv3o0OHDgCA4OBgqb0YyxWHxqbovYu16dszMjIwffp0NGjQADKZDHXr1sWYMWOU7vuoyX7/7L3NFW3QxsYG/v7++PvvvyGEwPz581G3bl1YW1ujf//+uH//vko8mh5rNVFYWIgPPvgAdevWhVwuR+/evXH58mWVclu2bIGXlxesra3h7OyM1157Dbdu3VIqo7jn740bN9CvXz/Y2dmhTp06WLFiBQDg7Nmz6NWrF2xtbeHh4YENGzao3dZhYWHSMbxx48ZYsGCB1ichijZ45swZ+Pr6wsbGBo0bN5ba+4EDB+Dt7Q1ra2s0bdoUe/bsUXq/untdnzhxAgEBAXB2doa1tTU8PT0xbtw4ab4uPt8ff/wRgYGBcHd3h0wmQ6NGjTB//nwUFBQo1W379u24fv262vHYkydPEBUVheeeew5yuRy1a9fGoEGDcOXKFZXt9Pnnn0tj1Q4dOuD333/XajsbmuvXr2Pq1Klo2rQprK2tUbNmTQwdOlTtOESxb1hbW6Nu3bp4//33ERsbq3bcoos2p+4e+4o2c+vWLQwYMAB2dnaoVasW3n77bekzv3btGmrVqgUAiI6Olj7zZ39CfvHiRQwZMgROTk6Qy+Vo3749fvrpJ6X1K/bpAwcOYOrUqXBxcUHdunW1qmNqaiqCg4NRt25dyGQy1K5dG/3791fqV5OTk3HgwAEpTm3GFUXvk6uI+fDhwwgPD0etWrVga2uLgQMH4u7du0rvK2m9mvQrz7bfpUuXSu3i/PnzyMvLQ2RkJLy8vODg4ABbW1t069YN+/btU6lDYWEhli1bJo3Ta9WqhT59+uDEiRMA/h1fZGdnY/369VKsijoXd499TcZ2mow7TNGtW7cwfvx4qU/19PTElClTkJeXp5M2AWh+Xvtsu9XVOVNJfYe69QLAw4cPERYWJo1pXFxc8OKLL+LkyZMASj/GaDveebY9HT9+HLa2tnjzzTdV6nLz5k1YWFggJiZGo7qX1JYA4NSpU+jbty/s7e1hZ2eH3r174+jRoxot+1manr8XFhYiKioK7u7usLGxQc+ePXH+/Hm19//W1VjHFCnyFOfPn8err76KGjVqoGvXrjhz5gzGjh2Lhg0bQi6Xw83NDePGjcO9e/eU3ltau/vmm2+k8a6TkxNGjBiBv//+W+P44uLiMHToUABAz549pXU8+4s7Tc/XS1Pa+Ykij7dx40bMmTMHderUgY2NDbKysgAAx44dQ58+feDg4AAbGxv4+vri8OHDKus5dOgQOnToALlcjkaNGmHNmjVq43l2X9dkO2hax5LyrkXXCwD5+fmIjo5GkyZNIJfLUbNmTXTt2hXx8fEA/h17Kc5Nns1tKmiaT1TkC7799lvp8/z111/RoEED9O/fX6UuT548gYODA15//XWttoEh0v9XxToybNgweHp6IiYmBidPnsTatWvh4uKCBQsWAAAmTJiA9evXY8iQIXjrrbdw7NgxxMTE4MKFCyoH+5SUFIwcORKvv/46Jk6ciKZNm0rzYmJiYG1tjdmzZ+Py5ctYvnw5LC0tYW5ujgcPHiAqKgpHjx5FXFwcPD09ERkZKb131apVaNmyJV555RVUq1YNP//8M6ZOnYrCwkKEhIRoXNfmzZvj66+/VpqWkZGB8PBwuLi4SNO+/vprBAUFISAgAAsWLMDjx4+xatUqdO3aFadOnZIGBLt378bgwYPRokULxMTE4N69e9JJQnkJIfDKK69g3759GD9+PNq1a4ddu3ZhxowZuHXrFpYsWSKV1Wb7XL58GUOGDMH48eMRFBSEdevWYezYsfDy8kLLli01jk/bdb766qt4/fXX8dprr2HRokV4+eWXsXr1arzzzjuYOnUqgH/3kWHDhiElJQXm5v9+d7Znzx707dsXDRs2RFRUFHJycrB8+XJ06dIFJ0+eLPMDhw8dOoStW7di6tSpqF69Oj799FMMHjwYN27cQM2aNTFo0CD8+eef+O6777BkyRI4OzsDgHRCShUrKioK0dHR8PPzw5QpU5CSkoJVq1bh999/x+HDh6VvsletWoXQ0FB069YN06dPx7Vr1zBgwADUqFGj3O0wJycHPXr0wOXLlxEaGgpPT09s2bIFY8eORUZGhtJAftmyZXjllVcwatQo5OXlYePGjRg6dCh++eUXBAYGKi23tH1PU9qs87fffsNPP/0ktc2YmBj069cPM2fOxMqVKzF16lQ8ePAACxcuxLhx47B3716l9z948AB9+vTBoEGDMGzYMHz//feYNWsWWrdujb59+6J58+aYN28eIiMjMWnSJHTr1g0A0LlzZ622OZWdJn37o0eP0K1bN1y4cAHjxo3DCy+8gH/++Qc//fQTbt68CWdnZ632ewD49ttvkZeXh2nTpuH+/ftYuHAhhg0bhl69emH//v2YNWuWdMx/++23sW7dOum9mh5rNfXRRx/B3Nwcb7/9NjIzM7Fw4UKMGjUKx44dk8rExcUhODgYHTp0QExMDNLS0rBs2TIcPnwYp06dgqOjo1S2oKAAffv2Rffu3bFw4UJ8++23CA0Nha2tLd59912MGjUKgwYNwurVqzFmzBj4+PjA09MTwL+3G/H19cWtW7fw+uuvo379+jhy5AgiIiJw584drW8L8ODBA/Tr1w8jRozA0KFDsWrVKowYMQLffvstwsLCMHnyZLz66qv4+OOPMWTIEPz999+oXr262mWlp6fD398ftWrVwuzZs+Ho6Ihr165h69atKmXL8/nGxcXBzs4O4eHhsLOzw969exEZGYmsrCx8/PHHAIB3330XmZmZuHnzpjSuUTxEsaCgAP369UNCQgJGjBiBN998Ew8fPkR8fDzOnTuHRo0aSevasGEDHj58iNdffx1mZmZYuHAhBg0ahL/++ssgrnwqi99//x1HjhzBiBEjULduXVy7dg2rVq1Cjx49cP78edjY2AD4NxmmONGMiIiAra0t1q5dC5lMprJMXbe5ogoKChAQEABvb28sWrQIe/bswSeffIJGjRphypQpqFWrFlatWoUpU6Zg4MCBGDRoEACgTZs2AIDk5GR06dIFderUwezZs2Fra4vNmzdjwIAB+N///oeBAwcqrW/q1KmoVasWIiMjpascNa3j4MGDkZycjGnTpqFBgwZIT09HfHw8bty4gQYNGmDp0qWYNm0a7Ozs8O677wIAXF1dy7V9AGDatGmoUaMG5s6di2vXrmHp0qUIDQ3Fpk2bAKDE9Wrbr8TGxuLJkyeYNGkSZDIZnJyckJWVhbVr12LkyJGYOHEiHj58iC+//BIBAQE4fvw42rVrJ71//PjxiIuLQ9++fTFhwgQ8ffoUv/32G44ePYr27dvj66+/xoQJE9CxY0dMmjQJAJTaZVGaju2A0scdpub27dvo2LEjMjIyMGnSJDRr1gy3bt3C999/r5QYKk+bKOt5rS7OmUrrO4ozefJkfP/99wgNDUWLFi1w7949HDp0CBcuXMALL7xQ4jFG2/FO0fZUv359DBw4EJs2bcLixYuVfsH03XffQQiBUaNGaVT/ktpScnIyunXrBnt7e8ycOROWlpZYs2YNevToIX2xrylNz98jIiKwcOFCvPzyywgICMAff/yBgIAAlSt4dT3WMVVDhw5FkyZN8OGHH0IIgfj4ePz1118IDg6Gm5sbkpOT8fnnnyM5ORlHjx6FmZlZqe3ugw8+wHvvvYdhw4ZhwoQJuHv3LpYvX47u3burjHeL0717d7zxxhv49NNP8c4776B58+YAIP2rTZ9eEk3OTxTmz58PKyur/2PvzuOiqP8/gL8AWU45VA7xQDwB71CRUvFA0dDyKNP8Kt5pmnmkaZmCVqbmfWFlaql5lZVHKt6paGXepqmhVgre4sn5/v3hbyeGXWAXFpbF1/Px4KH7mc/OfOYz8znmszOfwTvvvIPk5GRoNBrs2rUL7dq1Q1BQECZOnAhra2vlR6yff/4ZjRo1AvD0phxt/zcqKgppaWmYOHFirm17bvlgqNzGXfWJiorClClTlPohKSkJv/32G37//Xe0bt0ab7zxBq5evYrY2FidcU5jxhOBpzfTrl27FkOHDkWZMmXg5+eH//3vf5g2bRpu376NUqVKKXE3btyIpKQk/O9//zMqD4oksXATJ04UANK3b19VeKdOnaR06dIiInLs2DEBIP3791fFeeeddwSA7Nq1Swnz9fUVALJ161ZV3N27dwsAqVWrlqSkpCjh3bt3FysrK2nXrp0qfkhIiPj6+qrCHj16pJP+8PBwqVy5siosNDRUQkNDlc/x8fECQJYuXao3DzIyMqR9+/bi7Owsp0+fFhGR+/fvi5ubmwwYMEAVNyEhQVxdXVXh9erVk7Jly8rdu3eVsO3btwsAnX3ITWRkpOo733//vQCQDz/8UBXvlVdeESsrK7lw4YISZmj+aI/Rvn37lLDr16+LnZ2djBo1yqj0GrvNgwcPKmHbtm0TAOLg4CCXL19WwhcvXiwAZPfu3UpYvXr1xNPTU27duqWEHT9+XKytraVXr15KWNb809Ke55kBEI1Go8rD48ePCwCZN2+eEjZ9+nQBIPHx8dlnBJnE0qVLlby+fv26aDQaadOmjaSnpytx5s+fLwDkyy+/FBGR5ORkKV26tDRs2FBSU1OVeMuWLRMAqrrAEFnrj9mzZwsAWbFihRKWkpIiISEh4uzsLElJSUp41vKQkpIitWrVkpYtW6rCDT33DGHMNu3s7FTnsbaseXt7q/Zj3LhxOud8aGioAJCvvvpKCUtOThZvb2/p0qWLEvbrr7/mWN+S6WQuLyKG1+0TJkwQAPLdd9/prDMjI0NEDD/vte2rh4eHqg3UnkN169ZVlcvu3buLRqORJ0+eiIhxbW1utP2MgIAASU5OVsLnzJkjAOTkyZPKfnh6ekqtWrXk8ePHSrxNmzYJAJkwYYISFhkZKQDk448/VsLu3LkjDg4OYmVlJatXr1bCz549KwBk4sSJStjkyZPFyclJ/vzzT1Vax44dKzY2NnLlyhWD909bBletWqWzTWtrazl06JASrm1fM5fDrOfLhg0bBID8+uuv2W4zv8dXRH8/4Y033hBHR0dVvIiICL3t95dffikAZObMmTrLtOerNp2lS5eW27dvK8t/+OEHASAbN27Mdh+LOn35FxcXp1Mfv/XWW2JlZSVHjx5Vwm7duiWlSpVSHXdTljl9/WttmZk0aZIqbv369SUoKEj5fOPGDZ3yotWqVSupXbu26vzIyMiQ559/XqpVq6aEac/pJk2aSFpamhJu6D7euXNHAMj06dNz3M+aNWsa3ZfQ8vX1lcjISJ00h4WFKeeviMiIESPExsZGVc6y266h9Yr2+Li4uMj169dVcdPS0lT1pMjT/PDy8lJdE+7atUsAyLBhw3TSkTn9Tk5Oqv3Mur/a88/Qvp2I4f2OZ0mvXr3E2tpab72dkZGR7zIhYtx1bdYynJ9rJkPrDn3bdXV1lSFDhuS4/uzaGGP7O/rKk7bN/emnn1ThderUMbruyK4sdezYUTQajVy8eFEJu3r1qpQsWVKaNWtm1DYMuX5PSEiQEiVKSMeOHVXxoqKiBIAqjabs6zyLtOMU3bt3V4XrO07ffPONTl8/u3J36dIlsbGxkY8++kgVfvLkSSlRooROeE7WrVunMz4jYlydnhtDrk+0ff3KlSur8icjI0OqVasm4eHhqrbp0aNH4ufnJ61bt1bCOnbsKPb29qrxpzNnzoiNjY3OeFHWNjy7fDCEIeOu2W23bt26EhERkeP6hwwZopN+EePGE7XXFNoxUa1z584JAFm0aJEq/KWXXpJKlSqp8txSWfxUPFqDBg1SfW7atClu3bqFpKQkbNmyBQAwcuRIVZxRo0YBADZv3qwK9/PzQ3h4uN7t9OrVS/WrXXBwMERE9ei3Nvzvv/9GWlqaEubg4KD8/969e7h58yZCQ0Px119/4d69e4buqo7Jkydj06ZNWLZsGQIDAwEAsbGxuHv3Lrp3746bN28qfzY2NggODlYeVb127RqOHTuGyMhIuLq6Kuts3bq1sq782LJlC2xsbDBs2DBV+KhRoyAi+Omnn5QwY/InMDBQuZsWePqrbo0aNfDXX38ZlT5jtxkSEqJ81t5Z0LJlS1SsWFEnXJsWbR737t1b9QthnTp10Lp1a+X8zIuwsDDVXUV16tSBi4uL0flAprdjxw6kpKRg+PDhypMbADBgwAC4uLgo9c5vv/2GW7duYcCAAar5Nnv06AF3d/d8p2PLli3w9vZG9+7dlTBbW1sMGzYMDx48wN69e5XwzOXhzp07uHfvHpo2bao8CpyZqc49Y7bZqlUr1Z2Y2rLWpUsX1V29WcuglrOzs+oXeY1Gg0aNGrG8FCGG1O3ffvst6tatq3PXKwDlsU1jznvg6V1GmdtA7Tn0v//9T1Uug4ODkZKSokx5Y2hba4w+ffpAo9Eon7X5oc2D3377DdevX8ebb74Je3t7JV5ERAT8/f11+jTA06cWtdzc3FCjRg04OTmha9euSniNGjXg5uamyut169ahadOmcHd3V+1fWFgY0tPTsW/fPqP2zdnZGd26ddPZZkBAgOpuvezKcGbau7Q2bdqE1NTUHLeb1+MLqOuo+/fv4+bNm2jatCkePXqEs2fP5rhd4On5WqZMGbz11ls6y7JOsffaa6+p6v2sx94SZc6/1NRU3Lp1C1WrVoWbm5uqnt+6dStCQkJUd1qXKlVK507Rgihz+ui7rjDkONy+fRu7du1C165dlfPl5s2buHXrFsLDw3H+/HmdKbMGDBigukvW0H10cHCARqPBnj17cOfOHRPsteEGDhyoOn+bNm2K9PR0XL58OdfvGluvdOnSReeuaRsbG6WezMjIwO3bt5GWloYGDRqozqtvv/0WVlZWmDhxok468jJvvqF9Oy32O/6TkZGB77//Hh06dECDBg10lmc+HnktEwV9XWuIvNQdbm5uOHz4MK5evWr09ozt7+grT2FhYfDx8cHKlSuVsFOnTuHEiRMmuZM1PT0d27dvR8eOHVG5cmUlvGzZsnj99dexf/9+ZSoSQxhy/b5z506kpaUpT9Rr6WuLTd3XeVZlPfczH6cnT57g5s2baNy4MQDovc7L6rvvvkNGRga6du2qOi7e3t6oVq2aSdp7Y+v0nBhyfaIVGRmpyp9jx47h/PnzeP3113Hr1i1lXx8+fIhWrVph3759yMjIQHp6OrZt24aOHTuqxp8CAgKyHb80tZzGXbPj5uaG06dP4/z580Zvz5jxRAAIDQ3Vqe+rV6+O4OBgVR13+/Zt/PTTT+jRo0exeI9OsZmKJ/OJDUC5MLpz5w4uX74Ma2trVK1aVRXH29sbbm5uOp1Q7SPohmxH22moUKGCTnhGRgbu3bunTEtx4MABTJw4EXFxcTrzUN27d0/VATHU1q1bER0djXHjxqFLly5KuLbQtGzZUu/3XFxcAEDZ92rVqunEqVGjhkGVbk4uX74MHx8fnUfptY/8ZM57Y/In63EAnh5zYy9s8rPNnI49ACUt2n3MPKWTVkBAALZt24aHDx/CycnJqLTrSxOQt3wg08vuuGs0GlSuXFlZrv03a/1UokSJfE8noF1/tWrVVJ0VQH8Z3LRpEz788EMcO3ZM9Y4QfY2dqc69/GzT0DKoVb58eZ31uru748SJE0almQqOIefVxYsXVe2dPsac9/q2a+i5ZWhba4yc+jOZ066vTfH398f+/ftVYdo5pTNzdXXVWx5cXV1VeX3+/HmcOHEi26kIrl+/bsguKbLbpqFlOLPQ0FB06dIF0dHRmDVrFpo3b46OHTvi9ddf15m+JT91x+nTpzF+/Hjs2rVL56LFkJsyLl68iBo1ahj0osTcjr0levz4MaZMmYKlS5fi33//Vc2Hmjn/Ll++rLp5Qitr21gQZS4rfWXG0PbtwoULEBF88MEH+OCDD/TGuX79OsqVK6d8znrdYeg+2tnZYerUqRg1ahS8vLzQuHFjtG/fHr169YK3t3euac2P/JyrxtYr2V2XLV++HDNmzMDZs2dVP+5ljn/x4kX4+PiobqzJD0P7dlrsd/znxo0bSEpKQq1atXKNm9cyUdDXtbnJa90xbdo0REZGokKFCggKCsKLL76IXr16qQbBs2Nsf0dfebK2tkaPHj2waNEiPHr0CI6Ojli5ciXs7e2VObnz48aNG3j06FG218IZGRn4+++/DZ5O15Dr9+yur0qVKqVz45Sp+zrPqqzn1u3btxEdHY3Vq1fr5KEh/afz589DRPSWZwAmmaLQ2Do9J4Zcn2hlV8dFRkZm+x3tez0fP36cbR2XnxtGDZVT+59dH2zSpEl4+eWXUb16ddSqVQtt27ZFz549lSkMc2LMeCKQfZ+hV69eGDp0KC5fvgxfX1+sW7cOqamp6NmzZ65psATFZmA/86/6mWW+gDD0l5jMv54Zup3ctn/x4kW0atUK/v7+mDlzJipUqACNRoMtW7Zg1qxZeXoxS3x8PHr06IHWrVvjww8/VC3Tru/rr7/W27k35AKzMBmbP4Yc78LapinSopXdOZr1pUsFsW16tv3888946aWX0KxZMyxcuBBly5aFra0tli5dqveFmqY490y1TUPTwvJS9JnrGOX13CqIttbUeZCfcpORkYHWrVtjzJgxeuNWr1690NKSlZWVFdavX49Dhw5h48aN2LZtG/r27YsZM2bg0KFDyvzD+dnu3bt3ERoaChcXF0yaNAlVqlSBvb09fv/9d7z77rsmf6lecayj3nrrLSxduhTDhw9HSEgIXF1dYWVlhW7duuUp/wqjf5vdcTCENn3vvPNOtnfPZR1oynrdYcw+Dh8+HB06dMD333+Pbdu24YMPPsCUKVOwa9cu1K9fP8/7kZv8nKvG1iv6rstWrFiB3r17o2PHjhg9ejQ8PT2Vl3zqeym1uRTHMl0Y8lMmzCmvdUfXrl3RtGlTbNiwAdu3b8f06dMxdepUfPfddyZ/F0N24xy9evXC9OnT8f3336N79+5YtWoV2rdvn6cbDwtSQYypmLqv86zKem517doVBw8exOjRo1GvXj04OzsjIyMDbdu2Neg4ZWRkwMrKCj/99JPespW5n2dpsqvjpk+frnpyMTNnZ2fVTXDmkpd2rVmzZrh48SJ++OEHbN++HV988QVmzZqFmJgY1VPFppBdHdetWzeMGDECK1euxHvvvYcVK1agQYMGen9wtERFoxUsYL6+vsjIyMD58+dVL4dITEzE3bt34evrW+Bp2LhxI5KTk/Hjjz+qfuXK6yNEjx8/RufOneHm5oZvvvlG51d67RQZnp6eCAsLy3Y92n3X91jMuXPn8pS2rOvfsWMH7t+/r/qVTfv4unb7ps4fQxTWNrX7qC8/z549izJlyih367u7u+t9A7sxvxZnVRweLbJEmY975jtuUlJSEB8fr5RLbbwLFy6gRYsWSry0tDRcunTJoF+yc0vHiRMnkJGRoaonspbBb7/9Fvb29ti2bZvqbtelS5fma/s5Mcc2c8PyUvRVqVIFp06dyjGOoee9KdIC5N7WmlLmuiXr3Yvnzp0zaZ+mSpUqePDgQaHtW140btwYjRs3xkcffYRVq1ahR48eWL16tUkuFPbs2YNbt27hu+++Q7NmzZTw+Ph4nbjZ1R1VqlTB4cOHkZqaarEvwM2P9evXIzIyEjNmzFDCnjx5otPX8fX1xYULF3S+nzXMHGVOn+yOt7a9t7W1zXP6jN3HKlWqYNSoURg1ahTOnz+PevXqYcaMGVixYkWOaS1oOZWJ/NYr69evR+XKlfHdd9+ptpN1yp0qVapg27ZtOi/MMzStWRnatyNdHh4ecHFxybX91qewrmvN2QcsW7Ys3nzzTbz55pu4fv06nnvuOXz00UfKwH52aTNVf6dWrVqoX78+Vq5cifLly+PKlSuYN2+e0fuhL50eHh5wdHTM9lrY2tpa5wm67Bh6/Z75+irzHby3bt3SeYLCEvo6lubOnTvYuXMnoqOjMWHCBCVcX9nMqa0QEfj5+eX7x5Wcyg9gmjrdkOuTnL4LPH36KKdtenh4wMHBwSLruFKlSqFPnz7o06cPHjx4gGbNmiEqKkrpr+d0jAwZTzRk+xEREVi5ciV69OiBAwcOFKsXYxebOfZz8uKLLwKAzoGbOXMmgKfz0hY07S9bWR9BzusA1qBBg/Dnn39iw4YNeufhDg8Ph4uLCz7++GO9c8/euHEDwNNORL169bB8+XLVI1GxsbE4c+ZMntKW2Ysvvoj09HTMnz9fFT5r1ixYWVkpnRVT548hCmubmfM484XsqVOnsH37duX8BJ5W6vfu3VM9onvt2jVs2LAhz9vX/mig7wcDKjhhYWHQaDSYO3eu6hxbsmQJ7t27p9Q7DRo0QOnSpfH555+r3smxcuVKk0y/8OKLLyIhIQFr1qxRwtLS0jBv3jw4OzsjNDQUwNPyYGVlpXo65NKlS/j+++/znYbsmGObuWF5Kfq6dOmC48eP660XtWXN0PM+vwxta02pQYMG8PT0RExMjOrOnZ9++gl//PGHSfs0Xbt2RVxcHLZt26az7O7du6o6q7DduXNH5+4g7V1OprqjSV8/ISUlBQsXLtSJ6+TkpPfR8i5duuDmzZs6/aCs6y2ubGxsdPZz3rx5Ok8ihoeHIy4uDseOHVPCbt++rZoPVRuvsMucPo6OjgB02wpPT080b94cixcvxrVr13S+Z0j6DN3HR48e4cmTJ6plVapUQcmSJVVlwMnJySxtWnbbNUW9oq9sHj58GHFxcap4Xbp0gYggOjpaZx2Zv2toHhnatyNd1tbW6NixIzZu3IjffvtNZ3lO9WFhXdeaow+Ynp6u03Z4enrCx8dHpxzra2NM2d/p2bMntm/fjtmzZ6N06dJ5elpAX1mysbFBmzZt8MMPP+DSpUtKeGJiIlatWoUmTZoYPI2aodfvrVq1QokSJbBo0SJVuL62uCj3dSyVvuME6I7HAdmXu86dO8PGxgbR0dE66xER3Lp1y+D0ZLcNU9bphlyfZCcoKAhVqlTBp59+igcPHugs19ZxNjY2CA8Px/fff48rV64oy//44w+9529W5rrOzXqsnJ2dUbVqVZ06DtBNm6HjiYbo2bMnzpw5g9GjR8PGxkb13i9L90zcsV+3bl1ERkbis88+Ux6r/uWXX7B8+XJ07NhRdZdsQWnTpg00Gg06dOiAN954Aw8ePMDnn38OT09PvR3/nGzevBlfffUVunTpghMnTqgGgZ2dndGxY0e4uLhg0aJF6NmzJ5577jl069YNHh4euHLlCjZv3owXXnhBKRxTpkxBREQEmjRpgr59++L27duYN28eatasqbdiMUaHDh3QokULvP/++7h06RLq1q2L7du344cffsDw4cOVXydNmT+GKsxtTp8+He3atUNISAj69euHx48fY968eXB1dUVUVJQSr1u3bnj33XfRqVMnDBs2DI8ePcKiRYtQvXr1PM8LGRQUBAB4//330a1bN9ja2qJDhw55mtOfDOfh4YFx48YhOjoabdu2xUsvvYRz585h4cKFaNiwofIyKo1Gg6ioKLz11lto2bIlunbtikuXLmHZsmWoUqVKvn9ZHzhwIBYvXozevXvjyJEjqFSpEtavX6/8Sq395TsiIgIzZ85E27Zt8frrr+P69etYsGABqlatWmBzwZpjm7mpUqUK3NzcEBMTg5IlS8LJyQnBwcE5vnuFCtfo0aOxfv16vPrqq+jbty+CgoJw+/Zt/Pjjj4iJiUHdunUNPu/zy5i21lRsbW0xdepU9OnTB6GhoejevTsSExMxZ84cVKpUCSNGjDDZtkaPHo0ff/wR7du3R+/evREUFISHDx/i5MmTWL9+PS5duoQyZcqYbHvGWL58ORYuXIhOnTqhSpUquH//Pj7//HO4uLiofjDPj+effx7u7u6IjIzEsGHDYGVlha+//lrvBVpQUBDWrFmDkSNHomHDhnB2dkaHDh3Qq1cvfPXVVxg5ciR++eUXNG3aFA8fPsSOHTvw5ptv4uWXXzZJWouq9u3b4+uvv4arqysCAwMRFxeHHTt2KO+f0hozZgxWrFiB1q1b46233oKTkxO++OILVKxYEbdv31baQnOUOX0cHBwQGBiINWvWoHr16ihVqhRq1aqFWrVqYcGCBWjSpAlq166NAQMGoHLlykhMTERcXBz++ecfHD9+PMd1G7qPf/75J1q1aoWuXbsiMDAQJUqUwIYNG5CYmKi6WA0KCsKiRYvw4YcfomrVqvD09Mx2rnJTym67pqhX2rdvj++++w6dOnVCREQE4uPjERMTg8DAQNW1S4sWLdCzZ0/MnTsX58+fV6aA+Pnnn9GiRQsMHTpUSeuOHTswc+ZM+Pj4wM/PT/VCby1D+3ak38cff4zt27cjNDQUAwcOREBAAK5du4Z169bpvB8ms8K6rjXHNdP9+/dRvnx5vPLKK6hbty6cnZ2xY8cO/Prrr6onnbJrY0zZ33n99dcxZswYbNiwAYMHD87TU2bZlaUPP/wQsbGxaNKkCd58802UKFECixcvRnJyMqZNm2bw+g29fvfy8sLbb7+NGTNm4KWXXkLbtm1x/Phx/PTTTyhTpozq+qoo93UslYuLC5o1a4Zp06YhNTUV5cqVw/bt2/U+8ZhduatSpQo+/PBDjBs3DpcuXULHjh1RsmRJxMfHY8OGDRg4cCDeeecdg9JTr1492NjYYOrUqbh37x7s7OzQsmVLeHp6mqxON+T6JDvW1tb44osv0K5dO9SsWRN9+vRBuXLl8O+//2L37t1wcXHBxo0bAQDR0dHYunUrmjZtijfffFP5Ia9mzZq5Xj/nlA8FKTAwEM2bN0dQUBBKlSqF3377DevXr1faYOC/82DYsGEIDw9XBt4NHU80REREBEqXLo1169ahXbt2Bb7fhUos3MSJEwWA3LhxQxW+dOlSASDx8fEiIpKamirR0dHi5+cntra2UqFCBRk3bpw8efJE9T1fX1+JiIjQ2c7u3bsFgKxbt07vdn799ddc0/Xjjz9KnTp1xN7eXipVqiRTp06VL7/8UpVOEZHQ0FAJDQ1VPsfHxwsAWbp0qWqb+v58fX110h0eHi6urq5ib28vVapUkd69e8tvv/2mivftt99KQECA2NnZSWBgoHz33XcSGRmps77c6PvO/fv3ZcSIEeLj4yO2trZSrVo1mT59umRkZKjiGZo/2R2jrPlmiPxuE4AMGTJEFaY9XtOnT1eF79ixQ1544QVxcHAQFxcX6dChg5w5c0Znndu3b5datWqJRqORGjVqyIoVK5TzKbdta9MaGRmpCps8ebKUK1dOrK2tdfaNTCdrvSMiMn/+fPH39xdbW1vx8vKSwYMHy507d3S+O3fuXPH19RU7Oztp1KiRHDhwQIKCgqRt27ZGpUFfOUhMTJQ+ffpImTJlRKPRSO3atZX6JLMlS5ZItWrVxM7OTvz9/WXp0qX5Pvdyk59tZlfW9NXXoaGhUrNmTZ3t66uzfvjhBwkMDJQSJUqo6l4yrazlxZi6/datWzJ06FApV66caDQaKV++vERGRsrNmzeVOIac98acQ5nTnLXNN7StzUl228zaB9Bas2aN1K9fX+zs7KRUqVLSo0cP+eeff1RxIiMjxcnJSWdb2ZUHfcfg/v37Mm7cOKlatapoNBopU6aMPP/88/Lpp59KSkqKwftnzDZFdMt81vPl999/l+7du0vFihXFzs5OPD09pX379qo8N8XxPXDggDRu3FgcHBzEx8dHxowZI9u2bRMAsnv3biXegwcP5PXXXxc3Nzed/tijR4/k/fffV/qg3t7e8sorr8jFixdzTKc2HyZOnKiboRbizp07Sjl0dnaW8PBwOXv2rN724ujRo9K0aVOxs7OT8uXLy5QpU2Tu3LkCQBISElRxTVHm9JWt7MqMvnbp4MGDEhQUJBqNRuc4Xbx4UXr16iXe3t5ia2sr5cqVk/bt28v69euVONnVJ4bu482bN2XIkCHi7+8vTk5O4urqKsHBwbJ27VrVehISEiQiIkJKliwpAIzqK2c9TjnVgVnLRE7bNaReyalcZGRkyMcff6z0m+rXry+bNm3S26anpaXJ9OnTxd/fXzQajXh4eEi7du3kyJEjSpyzZ89Ks2bNxMHBQQAo+6yvXydiWN/OmH7Hs+Ty5cvSq1cv8fDwEDs7O6lcubIMGTJEkpOT810mtAy9rtVXv+b1msmYuiPzdpOTk2X06NFSt25dKVmypDg5OUndunVl4cKFqu/k1Mbkp7+T1YsvvigA5ODBgwbtd1bZlSWRp+12eHi4ODs7i6Ojo7Ro0SJP2zH0+j0tLU0++OAD8fb2FgcHB2nZsqX88ccfUrp0aRk0aJBqnabq6zyLshuP++eff6RTp07i5uYmrq6u8uqrr8rVq1eNLnfffvutNGnSRJycnMTJyUn8/f1lyJAhcu7cOaPS+fnnn0vlypXFxsZGp70y9Ho9N7ldn2TX/9Q6evSodO7cWUqXLi12dnbi6+srXbt2lZ07d6ri7d27V+l/VK5cWWJiYvTWNfr6WjnlQ04MHXfVt90PP/xQGjVqJG5ubuLg4CD+/v7y0UcfqcpWWlqavPXWW+Lh4SFWVlaqfTF0PDG7MYrM3nzzTQEgq1atMmi/LYWVyDPwHDARkYXJyMiAh4cHOnfujM8//9zcySEiIip0w4cPx+LFi/HgwYN8vdSWiIhy16lTJ5w8eVLvO0+Kg7t378Ld3R0ffvgh3n//fXMnh4gK2YgRI7BkyRIkJCQo0yoWB8/EHPtEREXZkydPdKZ2+Oqrr3D79m00b97cPIkiIiIqRI8fP1Z9vnXrFr7++ms0adKEg/pERAXs2rVr2Lx5M3r27GnupJhE1jYF+G+Od15fET17njx5ghUrVqBLly7FalAfeEbm2Kf8u337NlJSUrJdbmNjAw8Pj0JMUc4SEhJyXO7g4ABXV9dCSg1Rzg4dOoQRI0bg1VdfRenSpfH7779jyZIlqFWrFl599VUAT1+ak/Vlg5lpNBqUKlWqsJKco/T09FxfEOjs7AxnZ+dCShGR+aSkpOD27ds5xnF1dYWDg0Mhpci0LK1/QEVXSEgImjdvjoCAACQmJmLJkiVISkrCBx98YNR6inuZMwX2k4kMc+/ePb0DxJl5e3sXUmoKRnx8PA4cOIAvvvgCtra2eOONN3TiFEadYeptrFmzBsuWLcOLL74IZ2dn7N+/H9988w3atGmDF154IV9ppaLh8ePHel8qnVmpUqWg0WiK9DbM6cGDB7m+f8TDw8Oib7C4fv06duzYgfXr1+PWrVt4++23zZ0k0zPzVEBkIUJDQ7Od1x965vY3t5zSiizz/RGZW3x8vHTo0EG8vLyUuf369OkjiYmJShxfX98cz2lj3y9RkLTzeOb0Z8lzRhMZQzufZk5/lvweB0vrH1DRNW7cOKlWrZo4ODiIo6OjNGnSRGJjY41eT3Evc6bAfjKRYSIjI3MtL5ZOO0d2xYoVs537uzDqDFNv48iRI9KqVSspXbq02NraSvny5eXtt9+W+/fv5zutVDTk9O5J7Z+hc8ibcxvmpJ07P6c/S38/o7Zf6OnpKfPmzTN3cgoE59gngxw5cgR37tzJdrmDg0OR+uV7x44dOS738fFBYGBgIaWGKP8OHDiQ4x1D7u7uytvkze3JkyfYv39/jnEqV66MypUrF1KKiMznzp07OHLkSI5xatasibJlyxZSikzL0voHVPwV9zJnCuwnExnmzJkzuHr1ao5xwsLCCik15lMYdQbrJTLWtWvXcPr06RzjBAUFwd3dvUhvw5z++usv/PXXXznGadKkCezt7QspRZQXHNgnIiIiIiIiIiIiIrIgz/Qc+xkZGbh69SpKliwJKysrcyeHyGAigvv378PHxwfW1nwHdlYs22SpWLZzx/JNlorlO2cs22SpWLZzx/JNlorlO2cs22SpilPZfqYH9q9evYoKFSqYOxlEefb333+jfPny5k5GkcOyTZaOZTt7LN9k6Vi+9WPZJkvHsp09lm+ydCzf+rFsk6UrDmX7mR7YL1myJICnB9LFxcXMqTFcamoqtm/fjjZt2sDW1tbcycmz4rAf5tqHpKQkVKhQQTmHSc1Sy7Y5FIdyWFgKI69YtnOXW/nmOZ13zLv8yS3/WL5z9iy13SxrTxWXfGDZzp02b+Lj4xEXF2fxx9xcikuZMYe85h3Ld86ytt2Weo4y3YWnqKS5OJXtZ3pgX/uokIuLi0VdQKSmpsLR0REuLi4WU3j1KQ77Ye594ONu+llq2TYHc5/DlqQw84plO3u5lW+e03nHvMsfQ/OP5Vu/Z6ntZll7qrjlA8t29rR5U7JkyWJ1zAtbcSszhSm/ecfyrV/WtttSz1Gmu/AUtTQXh7Jt2RMJERERERERERERERE9Y57pO/YLWqWxmw2Oe+mTiAJMCRFR8ZFd3cp6lDKrFbUNyen/3YHB84OI9GGbQlR86SvfLNtEloXlmChnHNgnIiIiIqJiz5ibboiIiKho4k20RP/hVDxERERERERERERERBaEd+wTERERERERUZHCKTiIiIhyxjv2iYiIiIiIiIiIiIgsCAf2iYiIiIiIiIqQffv2oUOHDvDx8YGVlRW+//571XIRwYQJE1C2bFk4ODggLCwM58+fV8W5ffs2evToARcXF7i5uaFfv3548OCBKs6JEyfQtGlT2Nvbo0KFCpg2bZpOWtatWwd/f3/Y29ujdu3a2LJli8n3l4iIiIzHgX0iIiIiIiKiIuThw4eoW7cuFixYoHf5tGnTMHfuXMTExODw4cNwcnJCeHg4njx5osTp0aMHTp8+jdjYWGzatAn79u3DwIEDleVJSUlo06YNfH19ceTIEUyfPh1RUVH47LPPlDgHDx5E9+7d0a9fPxw9ehQdO3ZEx44dcerUqYLbeSJ6JlUau1nnj4hyxjn2iYiIiIiIiIqQdu3aoV27dnqXiQhmz56N8ePH4+WXXwYAfPXVV/Dy8sL333+Pbt264Y8//sDWrVvx66+/okGDBgCAefPm4cUXX8Snn34KHx8frFy5EikpKfjyyy+h0WhQs2ZNHDt2DDNnzlR+AJgzZw7atm2L0aNHAwAmT56M2NhYzJ8/HzExMXrTl5ycjOTkZOVzUlISACA1NVX1b27sbEQnzNDvmuL7RY2x+Uf/yWveMa+JqKjjwD4RERERERGRhYiPj0dCQgLCwsKUMFdXVwQHByMuLg7dunVDXFwc3NzclEF9AAgLC4O1tTUOHz6MTp06IS4uDs2aNYNGo1HihIeHY+rUqbhz5w7c3d0RFxeHkSNHqrYfHh6uMzVQZlOmTEF0dLRO+O7du+Ho6IjY2FiD9nNaI90wY6YByu/3iypD8490GZt3jx49KqCUEBGZBgf2iYiIiIiIiCxEQkICAMDLy0sV7uXlpSxLSEiAp6enanmJEiVQqlQpVRw/Pz+ddWiXubu7IyEhIcft6DNu3DjVjwFJSUmoUKECWrRogcOHD6N169awtbXNdT9rRW3TCTsVFZ7r90z1/aImNTUVsbGxBucf/Sevead92oSIqKjiwD4RERERERERmYSdnR3s7Ox0wrUDqra2tgYNrianW2W7DkPk9/tFlaH5R7qMzTvmMxEVdRzYJyIiIiIii5Tdi/UufRJRyCkhKjze3t4AgMTERJQtW1YJT0xMRL169ZQ4169fV30vLS0Nt2/fVr7v7e2NxMREVRzt59ziaJcTERGR+VibOwFEREREREREZBg/Pz94e3tj586dSlhSUhIOHz6MkJAQAEBISAju3r2LI0eOKHF27dqFjIwMBAcHK3H27dunekFobGwsatSoAXd3dyVO5u1o42i3Q0RERObDgX0iIiIiIiKiIuTBgwc4duwYjh07BuDpC3OPHTuGK1euwMrKCsOHD8eHH36IH3/8ESdPnkSvXr3g4+ODjh07AgACAgLQtm1bDBgwAL/88gsOHDiAoUOHolu3bvDx8QEAvP7669BoNOjXrx9Onz6NNWvWYM6cOar58d9++21s3boVM2bMwNmzZxEVFYXffvsNQ4cOLewsISIioiw4FQ8RERERERFREfLbb7+hRYsWymftYHtkZCSWLVuGMWPG4OHDhxg4cCDu3r2LJk2aYOvWrbC3t1e+s3LlSgwdOhStWrWCtbU1unTpgrlz5yrLXV1dsX37dgwZMgRBQUEoU6YMJkyYgIEDBypxnn/+eaxatQrjx4/He++9h2rVquH7779HrVq1CiEXiIhML+s0fnY2gmmNzJQYonziwD4RERERERUr2c29T2QpmjdvDhHJdrmVlRUmTZqESZMmZRunVKlSWLVqVY7bqVOnDn7++ecc47z66qt49dVXc04wERERFTpOxUNEREREREREREREZEF4xz4RERERERERERFRLvQ9FXjpkwgzpISIA/tEREREREQqvGgnIiIioqKOU/EQEREREREREREVMZ988gmsrKwwfPhwJezJkycYMmQISpcuDWdnZ3Tp0gWJiYmq7125cgURERFwdHSEp6cnRo8ejbS0NFWcPXv24LnnnoOdnR2qVq2KZcuWFcIeEZEpcWCfiIjoGWLui4MFCxagUqVKsLe3R3BwMH755ZeC2E0iIiIiIov266+/YvHixahTp44qfMSIEdi4cSPWrVuHvXv34urVq+jcubOyPD09HREREUhJScHBgwexfPlyLFu2DBMmTFDixMfHIyIiAi1atMCxY8cwfPhw9O/fH9u2bSu0/SsMlcZu1vkjKk44FQ8REdEzIqeLg82bN2PdunVwdXXF0KFD0blzZxw4cADAfxcH3t7eOHjwIK5du4ZevXrB1tYWH3/8MYD/Lg4GDRqElStXYufOnejfvz/Kli2L8PBwAMCaNWswcuRIxMTEIDg4GLNnz0Z4eDjOnTsHT0/Pws0MIiIiIqIi6sGDB+jRowc+//xzfPjhh0r4vXv3sGTJEqxatQotW7YEACxduhQBAQE4dOgQGjdujO3bt+PMmTPYsWMHvLy8UK9ePUyePBnvvvsuoqKioNFoEBMTAz8/P8yYMQMAEBAQgP3792PWrFlK3z2r5ORkJCcnK5+TkpIAAKmpqcqf9nNe2NlInr6XX3bWT7draLr1pTOv+5wf+c1vcygqaTb39k3J5AP7UVFRiI6OVoXVqFEDZ8+eBfD0rsBRo0Zh9erVSE5ORnh4OBYuXAgvLy8l/pUrVzB48GDs3r0bzs7OiIyMxJQpU1CixH/J3bNnD0aOHInTp0+jQoUKGD9+PHr37m3q3SEiIioWisLFwcyZMzFgwAD06dMHABATE4PNmzfjyy+/xNixYws5R4iIiIiIiqYhQ4YgIiICYWFhqr77kSNHkJqairCwMCXM398fFStWRFxcHBo3boy4uDjUrl1bNc4WHh6OwYMH4/Tp06hfvz7i4uJU69DGyfxUb1ZTpkzRGe8DgO3bt8PR0VH5HBsbm5ddxrRGefqayRiabn3p3LJli4lTY7i85rc5mTvNjx49Muv2TalA7tivWbMmduzY8d9GMg3IF9ZdgcVZrahtmNbo6b/J6VYA+DIvIiLKmbkvDlJSUnDkyBGMGzdOWW5tbY2wsDDExcVlm+7c7gzKShumvfMmazhlr6jcQWOpcss/5isREREZYvXq1fj999/x66+/6ixLSEiARqOBm5ubKtzLywsJCQlKnMz9du1y7bKc4iQlJeHx48dwcHDQ2fa4ceMwcuRI5XNSUhIqVKiANm3awMXFBampqYiNjUXr1q1ha2tr9H7XijLPNEB21oLJDTIMTre+dJ6KKvyxyPzmtzkUlTRrrymLgwIZ2C9RogS8vb11ws35yFBxp2+eMA72ExERUDQuDu7cuYP09HS9cbRP9elj6J1BWU1ukKH6bM67aCyNue+gsXTZ5V9xujOIiMhceN1Lxd3ff/+Nt99+G7GxsbC3tzd3clTs7OxgZ2enE25ra6sapM362VDaG1fNxdB060unOQep85rf5mTuNFtafuWkQAb2z58/Dx8fH9jb2yMkJARTpkxBxYoVzfrIEGD8XX/5Zcz8YMZsX3sXYta7EfOzTnMoDncGmmsfLDnPqPjihVbRVJQvDgyR251BWWnvAvngN2skZ/zX6TbHXTSWpqjcQWOpcsu/4nRnEBERERWMI0eO4Pr163juueeUsPT0dOzbtw/z58/Htm3bkJKSgrt376puzElMTFRusPX29sYvv/yiWm9iYqKyTPuvNixzHBcXF7136xNR0WTygf3g4GAsW7YMNWrUwLVr1xAdHY2mTZvi1KlTZn1kCMj7XX95Zcz8YMbcSTi5gfbfjBzjWcrdicXhzsDC3gfe9UdEhioqFwc2NjawsbHRG0ffU35aht4ZlFVyhpXqbhoOVBvO3HfQWLrs8o95SkRERLlp1aoVTp48qQrr06cP/P398e6776JChQqwtbXFzp070aVLFwDAuXPncOXKFYSEhAAAQkJC8NFHH+H69evw9PQE8HTMwsXFBYGBgUqcrGNGsbGxyjqIyDKYfGC/Xbt2yv/r1KmD4OBg+Pr6Yu3atWb/1c/Yu/7yy5j5wYy5kzBo0lZMbpChczdiftZpDsXhzkBz7QPv+iMiQxWViwONRoOgoCDs3LkTHTt2BABkZGRg586dGDp0aIHtPxERERGRpShZsiRq1aqlCnNyckLp0qWV8H79+mHkyJEoVaoUXFxc8NZbbyEkJASNGzcGALRp0waBgYHo2bMnpk2bhoSEBIwfPx5DhgxRbpgZNGgQ5s+fjzFjxqBv377YtWsX1q5di82bdZ/CJqKiq0Cm4snMzc0N1atXx4ULF9C6dWuzPjKU17v+8sqY+cGM2b52MD/r3Yj5Wac5FYc7Awt7Hyw9v+jZwel5zK8oXRyMHDkSkZGRaNCgARo1aoTZs2fj4cOH6NOnTyHlBhERERGRZZs1axasra3RpUsXJCcnIzw8HAsXLlSW29jYYNOmTRg8eDBCQkLg5OSEyMhITJo0SYnj5+eHzZs3Y8SIEZgzZw7Kly+PL7744pl9byWRpSrwgf0HDx7g4sWL6NmzJ4KCgvjIEBERURFTWBcHr732Gm7cuIEJEyYgISEB9erVw9atW3Wm1yMiIiIioqf27Nmj+mxvb48FCxZgwYIF2X7H19c31+mZmzdvjqNHj5oiiURkJiYf2H/nnXfQoUMH+Pr64urVq5g4cSJsbGzQvXt3uLq6FttHhvTdlUpUnERFRem8o6JGjRo4e/YsAODJkycYNWoUVq9erRoYzDxgd+XKFQwePBi7d++Gs7MzIiMjMWXKFJQo8V9VtGfPHowcORKnT59GhQoVMH78ePTu3btQ9pHoWWHOi4OhQ4dy6h0iIiIiIiKifDL5wP4///yD7t2749atW/Dw8ECTJk1w6NAheHh4AOAjQ0SWrGbNmtixY4fyOfOA/IgRI7B582asW7cOrq6uGDp0KDp37owDBw4AePqyzoiICHh7e+PgwYO4du0aevXqBVtbW3z88ccAgPj4eERERGDQoEFYuXIldu7cif79+6Ns2bIs30RERERERERERP/P5AP7q1evznE5HxkislwlSpRQ3nWR2b1797BkyRKsWrUKLVu2BAAsXboUAQEBOHToEBo3bozt27fjzJkz2LFjB7y8vFCvXj1MnjwZ7777LqKioqDRaBATEwM/Pz/MmDEDABAQEID9+/dj1qxZOQ7sJycnIzk5WfmsfblwamoqUlNTTZkFxY42f0yRT3Y2YtQ2Tb2dgj7Wpsyr3LZBRERERIbh0/NEZAq1orbpvMeS74ejoq7A59invMuug2JnU8gJIfp/58+fh4+PD+zt7RESEoIpU6agYsWKOHLkCFJTUxEWFqbE9ff3R8WKFREXF4fGjRsjLi4OtWvXVk3NEx4ejsGDB+P06dOoX78+4uLiVOvQxhk+fHiO6ZoyZYrONEEAsH37djg6OuZvp58RsbGx+V7HtEaGxcvth9u8bie/6zWUKfIqO48ePSqwdRMRERERERFR8cGBfSIySHBwMJYtW4YaNWrg2rVriI6ORtOmTXHq1CkkJCRAo9HAzc1N9R0vLy8kJCQAABISEnRekKn9nFucpKQkPH78GA4ODnrTNm7cOIwcOVL5nJSUhAoVKqBNmzZwcXHJ134Xd6mpqYiNjUXr1q1ha2ubr3XVitpmULxTUfmbVsnQ7ZhiW5mZMq+yo33ahIiIiIiIiIgoJxzYLyL4+CAVde3atVP+X6dOHQQHB8PX1xdr167NdsC9sNjZ2Skv187M1ta2wAZgixtT5FXWxxZz2pY++upBfY8+GrqdnLaVHwV5XvF8JSIiIiIiIiJDWJs7AURkmdzc3FC9enVcuHAB3t7eSElJwd27d1VxEhMTlTn5vb29kZiYqLNcuyynOC4uLmb/8YCKj0pjN+v9IyIqbqKiomBlZaX68/f3V5Y/efIEQ4YMQenSpeHs7IwuXbrotMNXrlxBREQEHB0d4enpidGjRyMtLU0VZ8+ePXjuuedgZ2eHqlWrYtmyZYWxe4WObQcRERERFSUc2CeiPHnw4AEuXryIsmXLIigoCLa2tti5c6ey/Ny5c7hy5QpCQkIAACEhITh58iSuX7+uxImNjYWLiwsCAwOVOJnXoY2jXQcREREZp2bNmrh27Zryt3//fmXZiBEjsHHjRqxbtw579+7F1atX0blzZ2V5eno6IiIikJKSgoMHD2L58uVYtmwZJkyYoMSJj49HREQEWrRogWPHjmH48OHo378/tm0zfNo0IiIiIiIyHqfiISKDvPPOO+jQoQN8fX1x9epVTJw4ETY2NujevTtcXV3Rr18/jBw5EqVKlYKLiwveeusthISEoHHjxgCANm3aIDAwED179sS0adOQkJCA8ePHY8iQIco0OoMGDcL8+fMxZswY9O3bF7t27cLatWuxeTPviCMiIsqLEiVKKE/GZXbv3j0sWbIEq1atQsuWLQEAS5cuRUBAAA4dOoTGjRtj+/btOHPmDHbs2AEvLy/Uq1cPkydPxrvvvouoqChoNBrExMTAz88PM2bMAAAEBARg//79mDVrFsLDs3/PSXJyMpKTk5XP2neMpKamIjU11eD9s7MRg+MWBGPSmvU7eflucVJc8sHS009ERNnj03lU1HFgn4gM8s8//6B79+64desWPDw80KRJExw6dAgeHh4AgFmzZsHa2hpdunRBcnIywsPDsXDhQuX7NjY22LRpEwYPHoyQkBA4OTkhMjISkyZNUuL4+flh8+bNGDFiBObMmYPy5cvjiy++yHFggIiIiLJ3/vx5+Pj4wN7eHiEhIZgyZQoqVqyII0eOIDU1FWFhYUpcf39/VKxYEXFxcWjcuDHi4uJQu3Zt1Yvtw8PDMXjwYJw+fRr169dHXFycah3aOMOHD88xXVOmTEF0dLRO+Pbt2+Ho6Gjw/k1rZHDUArFly5Y8fzc2NtaEKbFclp4Pjx49MncSiIgsCgfLiUyHA/tEZJDVq1fnuNze3h4LFizAggULso3j6+ub6wVw8+bNcfTo0TylkYiIiP4THByMZcuWoUaNGrh27Rqio6PRtGlTnDp1CgkJCdBoNHBzc1N9x8vLCwkJCQCAhIQE1aC+drl2WU5xkpKS8Pjx42zfkTNu3DiMHDlS+ZyUlIQKFSqgTZs2cHFxMXgfa0WZd8qfU1HG33yQmpqK2NhYtG7d+pl+aXpxyQft0yZEREREhY0D+8VYdr+CXvokopBTQkRERESFrV27dsr/69Spg+DgYPj6+mLt2rVmfym9nZ2dMhVfZra2tkYN8ianW5kyWUbLz4C0sftaXFl6Plhy2omIiMiy8eW5RERERETPADc3N1SvXh0XLlyAt7c3UlJScPfuXVWcxMREZU5+b29vJCYm6izXLsspjouLi9l/PCAiIiIiKs44sE9ERERE9Ax48OABLl68iLJlyyIoKAi2trbYuXOnsvzcuXO4cuUKQkJCAAAhISE4efIkrl+/rsSJjY2Fi4sLAgMDlTiZ16GNo10HERWMqKgoWFlZqf78/f2V5U+ePMGQIUNQunRpODs7o0uXLjo/wl25cgURERFwdHSEp6cnRo8ejbS0NFWcPXv24LnnnoOdnR2qVq2KZcuWFcbuERERkQE4sE9EREREVAy988472Lt3Ly5duoSDBw+iU6dOsLGxQffu3eHq6op+/fph5MiR2L17N44cOYI+ffogJCQEjRs3BgC0adMGgYGB6NmzJ44fP45t27Zh/PjxGDJkiDKNzqBBg/DXX39hzJgxOHv2LBYuXIi1a9dixIgR5tx1omdCzZo1ce3aNeVv//79yrIRI0Zg48aNWLduHfbu3YurV6+ic+fOyvL09HREREQgJSUFBw8exPLly7Fs2TJMmDBBiRMfH4+IiAi0aNECx44dw/Dhw9G/f39s22bed1sQERHRU5xjn4iIiIioGPrnn3/QvXt33Lp1Cx4eHmjSpAkOHToEDw8PAMCsWbNgbW2NLl26IDk5GeHh4Vi4cKHyfRsbG2zatAmDBw9GSEgInJycEBkZiUmTJilx/Pz8sHnzZowYMQJz5sxB+fLl8cUXXyA83PiXyhKRcUqUKKFMi5XZvXv3sGTJEqxatQotW7YEACxduhQBAQE4dOgQGjdujO3bt+PMmTPYsWMHvLy8UK9ePUyePBnvvvsuoqKioNFoEBMTAz8/P8yYMQMAEBAQgP3792PWrFk5lvHk5GQkJycrn7UvGE5NTVX9mxs7GzEsI4xg6LaLImPzj/6T17xjXhNRUceBfcqWvpfv8sW7RERERJZh9erVOS63t7fHggULsGDBgmzj+Pr6YsuWLTmup3nz5jh69Gie0khEeXf+/Hn4+PjA3t4eISEhmDJlCipWrIgjR44gNTUVYWFhSlx/f39UrFgRcXFxaNy4MeLi4lC7dm14eXkpccLDwzF48GCcPn0a9evXR1xcnGod2jjDhw/PMV1TpkxBdHS0Tvju3bvh6OiI2NhYg/ZvWiODohklt/rMEhiaf6TL2Lx79OhRAaWEiht942cAx9Co4HFgn4iIiIiIiMiCBAcHY9myZahRowauXbuG6OhoNG3aFKdOnUJCQgI0Gg3c3NxU3/Hy8kJCQgIAICEhQTWor12uXZZTnKSkJDx+/DjbF2SPGzcOI0eOVD4nJSWhQoUKaNGiBQ4fPozWrVvD1tY2132sFWX6KX9ORRn+NJG+7RvzfVNLTU1FbGyswflH/8lr3mmfNiEiKqo4sE9ERERERERkQdq1a6f8v06dOggODoavry/Wrl2b7YB7YbGzs1Pew5GZdkDV1tbWoMHV5HQrk6fNmEFdfdsvCgPqhuYf6TI275jPRFTU8eW5RERERERERBbMzc0N1atXx4ULF+Dt7Y2UlBTcvXtXFScxMVGZk9/b2xuJiYk6y7XLcorj4uJi9h8PiIiIiAP7RERUyCqN3az3jwrGlClT0LBhQ5QsWRKenp7o2LEjzp07p4rz5MkTDBkyBKVLl4azszO6dOmicyF/5coVREREwNHREZ6enhg9ejTS0tJUcfbs2YPnnnsOdnZ2qFq1KpYtW6aTngULFqBSpUqwt7dHcHAwfvnlF5PvMxER0bPmwYMHuHjxIsqWLYugoCDY2tpi586dyvJz587hypUrCAkJAQCEhITg5MmTuH79uhInNjYWLi4uCAwMVOJkXoc2jnYdRGR6Ra3vTkRFGwf2iYiIirG9e/diyJAhOHToEGJjY5Gamoo2bdrg4cOHSpwRI0Zg48aNWLduHfbu3YurV6+ic+fOyvL09HREREQgJSUFBw8exPLly7Fs2TJMmDBBiRMfH4+IiAi0aNECx44dw/Dhw9G/f39s2/bf/LRr1qzByJEjMXHiRPz++++oW7cuwsPDVYMKRERElLt33nkHe/fuxaVLl3Dw4EF06tQJNjY26N69O1xdXdGvXz+MHDkSu3fvxpEjR9CnTx+EhISgcePGAIA2bdogMDAQPXv2xPHjx7Ft2zaMHz8eQ4YMUabRGTRoEP766y+MGTMGZ8+excKFC7F27VqMGDHCnLtuVrw5hQpaUeq7E1HRxzn284CNNxERWYqtW7eqPi9btgyenp44cuQImjVrhnv37mHJkiVYtWoVWrZsCQBYunQpAgICcOjQITRu3Bjbt2/HmTNnsGPHDnh5eaFevXqYPHky3n33XURFRUGj0SAmJgZ+fn6YMWMGACAgIAD79+/HrFmzEB7+9EVzM2fOxIABA9CnTx8AQExMDDZv3owvv/wSY8eOLcRcISIismz//PMPunfvjlu3bsHDwwNNmjTBoUOH4OHhAQCYNWsWrK2t0aVLFyQnJyM8PBwLFy5Uvm9jY4NNmzZh8ODBCAkJgZOTEyIjIzFp0iQljp+fHzZv3owRI0Zgzpw5KF++PL744gulXSci0ytKffeskpOTkZycrHzWvlw4NTVV+dN+zomdjeQtcwqInbWo/jUlfXlhqhdzG5rfRUlRSbO5t29KHNgnIiJ6hty7dw8AUKpUKQDAkSNHkJqairCwMCWOv78/KlasiLi4ODRu3BhxcXGoXbs2vLy8lDjh4eEYPHgwTp8+jfr16yMuLk61Dm2c4cOHAwBSUlJw5MgRjBs3TllubW2NsLAwxMXFZZve3C4gstKGZe2YF6fOW0EpKh1tS5Vb/jFficiUVq9eneNye3t7LFiwAAsWLMg2jq+vL7Zs2ZLjepo3b46jR4/mKY1ElH/m6rvrM2XKFERHR+uEb9++HY6Ojsrn2NjYHPdpWqMcF5vN5AYZJl+nvjpW3/7nVhfnJLf8LorMneZHjx6ZdfumxIF9IiKiZ0RGRgaGDx+OF154AbVq1QIAJCQkQKPRwM3NTRXXy8sLCQkJSpzMFwba5dplOcVJSkrC48ePcefOHaSnp+uNc/bs2WzTbOgFRFZZO+b56Sw/a8zd0bZ02eVfcbqAoP/oe5L30icRZkgJEREVN+bsu+t7Qfa4ceMwcuRI5XNSUhIqVKiANm3awMXFBampqYiNjUXr1q1ha2ub7X7pu2PdnOysBZMbZOCD36yRnGFlljTk9Y59Q/K7KCkqadbeLFYccGCfiIjoGTFkyBCcOnUK+/fvN3dSDJbbBURW2s5i1o55XjrLz5qi0tG2VLnlX3G6gCAiKk441S4VVUWt725nZ6e8gyMzW1tbVd8n6+esktPNM3iem+QMK7OlLT9979zyuygyd5otLb9ywoF9IiKiZ8DQoUOxadMm7Nu3D+XLl1fCvb29kZKSgrt376ru/ElMTIS3t7cS55dfflGtLzExUVmm/VcbljmOi4sLHBwcYGNjAxsbG71xtOvQx9ALiKyydsyLU+etoJm7o23psss/5ikREREZytx9dyKyDNbmTgAREREVHBHB0KFDsWHDBuzatQt+fn6q5UFBQbC1tcXOnTuVsHPnzuHKlSsICQkBAISEhODkyZO4fv26Eic2NhYuLi4IDAxU4mRehzaOdh0ajQZBQUGqOBkZGdi5c6cSh4iIiIjoWVZU+u5EZBl4xz4REVExNmTIEKxatQo//PADSpYsqcyr6erqCgcHB7i6uqJfv34YOXIkSpUqBRcXF7z11lsICQlB48aNAQBt2rRBYGAgevbsiWnTpiEhIQHjx4/HkCFDlLvpBw0ahPnz52PMmDHo27cvdu3ahbVr12Lz5v8ebx85ciQiIyPRoEEDNGrUCLNnz8bDhw/Rp0+fws8YIiIieuZw2h0q6opS352Iij4O7BMRPYO0FzV2NoJpjZ6+wOjcR+2zjZcVXwxoORYtWgQAaN68uSp86dKl6N27NwBg1qxZsLa2RpcuXZCcnIzw8HAsXLhQiWtjY4NNmzZh8ODBCAkJgZOTEyIjIzFp0iQljp+fHzZv3owRI0Zgzpw5KF++PL744guEh/83t/1rr72GGzduYMKECUhISEC9evWwdetWnRd3ERHpwwE5IiIq7opS350KD6+7Ka84sE9EREUWB3HyT0RyjWNvb48FCxZgwYIF2cbx9fXFli1bclxP8+bNcfTo0RzjDB06FEOHDs01TUREREREz5qi1ncn89J3PczBfsqMc+wTEREREREREREREVkQDuwTEREREREREREREVkQTsXzDOLUFkT0rMhvfZf5+9r3ERARERERERERmRvv2CciIiIiIiIiIiIisiC8Y5+IiIiIiIiIiIioiNM+Va59orxW1Dac+6i9mVNF5sKBfSIiIiIiIhPJbhq4S59EFHJKiIiIiKg448A+ERGREWpFbUNyupVOOAdsiIiIiIiIiKiwcGCfiIiMxpdwExERERHxKR0iIjIfDuxTocrc6eF8YERERERERERERETG48A+EREB4F34RERERESmoq9vzbv4iaggGHMtz3qoeOHAfi440EVERERERERERERERQkH9skkeDcCUeFimSMiIiIiIiIienZxYJ+KBQ5yEunHp46IiIiKBm2bzPdMEREREZEpcGCfjMJBQiIqrli/EREREREREZGl4MA+ERERERERERERUTHHGS+KFw7sExERERERERERkUnxqWiigsWBfSIiIiIiIjPgXXNERERElFcc2CciIiIiIiIiKmD8MY+IiiLWTZaLA/tUJLASIWI5ICKyFPrqazsbwbRGZkgMFTvZTVvAPgEREREVFvZHLAMH9qnI4iAnWRo2fEREREREZAxeQxCRJeFYXdFibe4E5NeCBQtQqVIl2NvbIzg4GL/88ou5k0T/r9LYzTp/BbFOvoyl+GL5JiqeWLaJii+W74LDPjCZE8s2UfHF8k1kuSz6jv01a9Zg5MiRiImJQXBwMGbPno3w8HCcO3cOnp6e5k4emRl/RbRsxb1882K8+DH0mD7r9VBxL9tEzzKW78LH/i4VBpZtouKL5ZvIsln0wP7MmTMxYMAA9OnTBwAQExODzZs348svv8TYsWN14icnJyM5OVn5fO/ePQDA7du3kZqaqncbJdIeFkDK86dEhuDRowyUSLVGeoaVuZOTZ+bYj1u3bumEBU/ZafD3D49rpfqcmpqKR48e4datW7C1tc31+/nZVmb3798HAIiIweuzNMaU77yU7YKQXX2h77wztG6p+s5a/dsyMG5ulXxxqU8Kg6nySt/5oMWynf+2W1svZz1OOeU7PWVsm/Ys01eHa+uI7PKP5Tv/bXdR7JfnRUG3vdn1HfTJqb9Z0IpLncOybVzbbcwxLy5lPq+ylmU7a8H4+tm3M5S9vNY3LN/Gtd368tkSyrGlXhMXpXQb2vcoKvVYsSrbYqGSk5PFxsZGNmzYoArv1auXvPTSS3q/M3HiRAHAP/4Vm7+///67EEpb4TO2fLNs86+4/bFs/4flm3/F7Y/l+ymWbf4Vtz+W7f+wfPOvuP2xfD/Fss2/4vZXHMq2xd6xf/PmTaSnp8PLy0sV7uXlhbNnz+r9zrhx4zBy5Ejlc0ZGBm7fvo3SpUvDyspyfpVLSkpChQoV8Pfff8PFxcXcycmz4rAf5toHEcH9+/fh4+NTaNssTMaW7+JSts2hOJTDwlIYecWyrcvY8s1zOu+Yd/mTW/6xfKs9y203y9pTxSUfWLZ1ZVe+bW1tUbFiRYs/5uZSXMqMOeQ171i+1XJruy31HGW6C09RSXNxKtsWO7CfF3Z2drCzs1OFubm5mScxJuDi4mIxhTcnxWE/zLEPrq6uhbq9oqy4lW1zKA7lsLAUdF6xbKvltXzznM475l3+5JR/LN//YdvNsqZVHPKBZVstu/KdlJQEoHgcc3Ni/uVdXvKO5fs/hrbdlnqOMt2FpyikubiUbWtzJyCvypQpAxsbGyQmJqrCExMT4e3tbaZUEZEpsHwTFU8s20TFF8s3UfHEsk1UfLF8E1k+ix3Y12g0CAoKws6d/72MNCMjAzt37kRISIgZU0ZE+cXyTVQ8sWwTFV8s30TFE8s2UfHF8k1k+Sx6Kp6RI0ciMjISDRo0QKNGjTB79mw8fPhQeZt3cWVnZ4eJEyfqPAJlaYrDfhSHfSiqntXyXdh4DhuOeWUaBV22eZzyjnmXP8w/tt2G4rnyFPPBcpiqbPOY5w/zL++Yd9kzZdttqfnMdBceS0xzUWclImLuROTH/PnzMX36dCQkJKBevXqYO3cugoODzZ0sIjIBlm+i4ollm6j4YvkmKp5YtomKL5ZvIstl8QP7RERERERERERERETPEoudY5+IiIiIiIiIiIiI6FnEgX0iIiIiIiIiIiIiIgvCgX0iIiIiIiIiIiIiIgvCgX0iIiIiIiIiIiIiIgvCgX0LtGDBAlSqVAn29vYIDg7GL7/8Yu4kGWzKlClo2LAhSpYsCU9PT3Ts2BHnzp0zd7Ly5ZNPPoGVlRWGDx9u7qQQGSQ9PR0ffPAB/Pz84ODggCpVqmDy5Mngu9Sf2rdvHzp06AAfHx9YWVnh+++/Vy0XEUyYMAFly5aFg4MDwsLCcP78efMk9hllbDu4bt06+Pv7w97eHrVr18aWLVsKKaVFjzF5t2zZMlhZWan+7O3tCzG1RUdu9YI+e/bswXPPPQc7OztUrVoVy5YtK/B0kvlERUXplBd/f39l+ZMnTzBkyBCULl0azs7O6NKlCxITE1XruHLlCiIiIuDo6AhPT0+MHj0aaWlphb0rRjFFm3n79m306NEDLi4ucHNzQ79+/fDgwQNVnBMnTqBp06awt7dHhQoVMG3atILeNcojttH5w3Y6b9hOm5+ljVMVl7EpSxqP+vfff/G///0PpUuXhoODA2rXro3ffvvN3MmyeBzYtzBr1qzByJEjMXHiRPz++++oW7cuwsPDcf36dXMnzSB79+7FkCFDcOjQIcTGxiI1NRVt2rTBw4cPzZ20PPn111+xePFi1KlTx9xJITLY1KlTsWjRIsyfPx9//PEHpk6dimnTpmHevHnmTlqR8PDhQ9StWxcLFizQu3zatGmYO3cuYmJicPjwYTg5OSE8PBxPnjwp5JQ+m4xtBw8ePIju3bujX79+OHr0KDp27IiOHTvi1KlThZxy88tLH8LFxQXXrl1T/i5fvlyIKS46cqsXsoqPj0dERARatGiBY8eOYfjw4ejfvz+2bdtWwCklc6pZs6aqvOzfv19ZNmLECGzcuBHr1q3D3r17cfXqVXTu3FlZnp6ejoiICKSkpODgwYNYvnw5li1bhgkTJphjVwxmijazR48eOH36NGJjY7Fp0ybs27cPAwcOVJYnJSWhTZs28PX1xZEjRzB9+nRERUXhs88+K/D9I+Owjc4fttN5x3bavCxxnKo4jE1Z0njUnTt38MILL8DW1hY//fQTzpw5gxkzZsDd3d3cSbN8QhalUaNGMmTIEOVzenq6+Pj4yJQpU8yYqry7fv26AJC9e/eaOylGu3//vlSrVk1iY2MlNDRU3n77bXMnicggERER0rdvX1VY586dpUePHmZKUdEFQDZs2KB8zsjIEG9vb5k+fboSdvfuXbGzs5NvvvnGDCl89hjbDnbt2lUiIiJUYcHBwfLGG28UaDqLImPzbunSpeLq6lpIqbMcWesFfcaMGSM1a9ZUhb322msSHh5egCkjc5o4caLUrVtX77K7d++Kra2trFu3Tgn7448/BIDExcWJiMiWLVvE2tpaEhISlDiLFi0SFxcXSU5OLtC0m0pe2swzZ84IAPn111+VOD/99JNYWVnJv//+KyIiCxcuFHd3d1U+vPvuu1KjRo0C3iMyFtvo/GE7bRpspwtfcRinsrSxKUsbj3r33XelSZMm5k5GscQ79i1ISkoKjhw5grCwMCXM2toaYWFhiIuLM2PK8u7evXsAgFKlSpk5JcYbMmQIIiIiVMeDyBI8//zz2LlzJ/78808AwPHjx7F//360a9fOzCkr+uLj45GQkKAq966urggODrbYetiS5KUdjIuL06mnw8PDn7njldc+xIMHD+Dr64sKFSrg5ZdfxunTpwsjuRaP592z6fz58/Dx8UHlypXRo0cPXLlyBQBw5MgRpKamqs4Jf39/VKxYUTkn4uLiULt2bXh5eSlxwsPDkZSUZLHlzpA2My4uDm5ubmjQoIESJywsDNbW1jh8+LASp1mzZtBoNEqc8PBwnDt3Dnfu3CmkvaHcsI3OH7bThYvnnukUl3EqSxubsrTxqB9//BENGjTAq6++Ck9PT9SvXx+ff/65uZNVLHBg34LcvHkT6enpqg4/AHh5eSEhIcFMqcq7jIwMDB8+HC+88AJq1apl7uQYZfXq1fj9998xZcoUcyeFyGhjx45Ft27d4O/vD1tbW9SvXx/Dhw9Hjx49zJ20Ik9b1xaXetjS5KUdTEhI4PFC3vKuRo0a+PLLL/HDDz9gxYoVyMjIwPPPP49//vmnMJJs0bI775KSkvD48WMzpYoKUnBwMJYtW4atW7di0aJFiI+PR9OmTXH//n0kJCRAo9HAzc1N9Z3M5S+7c0a7zBIZ0mYmJCTA09NTtbxEiRIoVapUsc6b4ohtdP6wnS5cbKdNpziMU1na2JQljkf99ddfWLRoEapVq4Zt27Zh8ODBGDZsGJYvX27upFm8EuZOAD27hgwZglOnTqnmH7UEf//9N95++23ExsY+sy8nIsu2du1arFy5EqtWrULNmjWVeSV9fHwQGRlp7uQRUREREhKCkJAQ5fPzzz+PgIAALF68GJMnTzZjyoiKnsxPvdWpUwfBwcHw9fXF2rVr4eDgYMaUEVFxxXaayDQsaWzKUsejMjIy0KBBA3z88ccAgPr16+PUqVOIiYnhGEQ+8Y59C1KmTBnY2NggMTFRFZ6YmAhvb28zpSpvhg4dik2bNmH37t0oX768uZNjlCNHjuD69et47rnnUKJECZQoUQJ79+7F3LlzUaJECaSnp5s7iUQ5Gj16tHLXfu3atdGzZ0+MGDHCon7xNxdtXVsc6mFLlJd20Nvbm8cLpulDaJ/wuXDhQkEksVjJ7rxzcXHhIO8zws3NDdWrV8eFCxfg7e2NlJQU3L17VxUnc/nL7pzRLrNEhrSZ3t7eOi9XTEtLw+3bt4t13hRHbKPzh+104WI7bTqWPk5laWNTljoeVbZsWQQGBqrCAgIClGkLKe84sG9BNBoNgoKCsHPnTiUsIyMDO3fuVP1SX5SJCIYOHYoNGzZg165d8PPzM3eSjNaqVSucPHkSx44dU/4aNGiAHj164NixY7CxsTF3Eoly9OjRI1hbq6t/GxsbZGRkmClFlsPPzw/e3t6qejgpKQmHDx+2mHrYkuWlHQwJCVHFB4DY2Nhn7niZog+Rnp6OkydPomzZsgWVzGKD5x09ePAAFy9eRNmyZREUFARbW1vVOXHu3DlcuXJFOSdCQkJw8uRJ1SB3bGwsXFxcdC6ELYUhbWZISAju3r2LI0eOKHF27dqFjIwMBAcHK3H27duH1NRUJU5sbCxq1KgBd3f3Qtobyg3b6PxhO124eO6ZjqWOU1nq2JSljke98MILOHfunCrszz//hK+vr5lSVIyY++29ZJzVq1eLnZ2dLFu2TM6cOSMDBw4UNzc3SUhIMHfSDDJ48GBxdXWVPXv2yLVr15S/R48emTtp+WIJbyEn0oqMjJRy5crJpk2bJD4+Xr777jspU6aMjBkzxtxJKxLu378vR48elaNHjwoAmTlzphw9elQuX74sIiKffPKJuLm5yQ8//CAnTpyQl19+Wfz8/OTx48dmTvmzIbd2sGfPnjJ27Fgl/oEDB6REiRLy6aefyh9//CETJ04UW1tbOXnypLl2wWyMzbvo6GjZtm2bXLx4UY4cOSLdunUTe3t7OX36tLl2wWxyqxfGjh0rPXv2VOL/9ddf4ujoKKNHj5Y//vhDFixYIDY2NrJ161Zz7QIVsFGjRsmePXskPj5eDhw4IGFhYVKmTBm5fv26iIgMGjRIKlasKLt27ZLffvtNQkJCJCQkRPl+Wlqa1KpVS9q0aSPHjh2TrVu3ioeHh4wbN85cu2QQU7SZbdu2lfr168vhw4dl//79Uq1aNenevbuy/O7du+Ll5SU9e/aUU6dOyerVq8XR0VEWL15c6PtLOWMbnT9sp/OO7bR5WeI4VXEam7KE8ahffvlFSpQoIR999JGcP39eVq5cKY6OjrJixQpzJ83icWDfAs2bN08qVqwoGo1GGjVqJIcOHTJ3kgwGQO/f0qVLzZ20fLGEipRIKykpSd5++22pWLGi2NvbS+XKleX999+X5ORkcyetSNi9e7feeioyMlJERDIyMuSDDz4QLy8vsbOzk1atWsm5c+fMm+hnTE7tYGhoqHKstNauXSvVq1cXjUYjNWvWlM2bNxdyiosOY/Ju+PDhSlwvLy958cUX5ffffzdDqs0vt3ohMjJSQkNDdb5Tr1490Wg0UrlyZYvv61DOXnvtNSlbtqxoNBopV66cvPbaa3LhwgVl+ePHj+XNN98Ud3d3cXR0lE6dOsm1a9dU67h06ZK0a9dOHBwcpEyZMjJq1ChJTU0t7F0xiinazFu3bkn37t3F2dlZXFxcpE+fPnL//n1VnOPHj0uTJk3Ezs5OypUrJ5988klh7SIZiW10/rCdzhu20+ZnaeNUxWlsylLGozZu3Ci1atUSOzs78ff3l88++8zcSSoWrERECvaZACIiIiIiIiIiIiIiMhXOsU9EREREREREREREZEE4sE9EREREREREREREZEE4sE9EREREREREREREZEE4sE9EREREREREREREZEE4sE9EREREREREREREZEE4sE9EREREREREREREZEE4sE9EREREREREREREZEE4sE9EREREREREREREZEE4sE9EREREREREREREZEE4sE9EREREREREREREZEE4sE9EREREREREREREZEE4sE9EREREREREREREZEE4sE9EREREREREREREZEE4sE9EREREREREREREZEE4sE9EREREREREREREZEE4sE9EREREREREREREZEE4sE9EREREREREREREZEE4sE9EREREREREREREZEE4sE9EREREREREREREZEE4sE9EREREREREREREZEE4sE9EREREREREREREZEE4sE9EREREREREREREZEE4sE9EREREREREREREZEE4sE9EREREREREREREZEE4sE9EREREREREREREZEE4sE9EREREREREREREZEE4sE9EREREREREREREZEE4sE9EREREREREREREZEE4sE9EREREREREREREZEE4sE9EREREREREREREZEE4sE9EREREREREREREZEE4sE9EREREREREREREZEE4sE9EREREREREREREZEE4sE9EREREREREREREZEE4sE9EREREREREREREZEE4sF/AevfujUqVKqnCrKysEBUVZZb0mEKlSpXQvn37XOPt2bMHVlZW2LNnT8EniogszqVLl2BlZYVly5aZOylUTCxbtgxWVla4dOmSuZNSILTt6vr1682dlGda8+bNUatWLXMng4qJ5s2bo3nz5spnc7WN+q5ZCuI7RERk2aKiomBlZZWn73799dfw9/eHra0t3NzcTJuw//esXmPm57gUF5Y+1ppXHNgvAg4ePIioqCjcvXvX3ElRnDlzBlFRUcV2cISoKLl69SqioqJw7NgxcyeFCsGWLVueyQ5HUVaYbd6jR48QFRXFH73NiH0cIiIytcK4pmf7RZbs7Nmz6N27N6pUqYLPP/8cn332WaFt29zXX6tWrcLs2bPNtv3cFMUxyeyY+1gWRRzYN4PHjx9j/PjxyueDBw8iOjq6SBWiM2fOIDo6Ol+dhmbNmuHx48do1qyZ6RJGVAxdvXoV0dHRHNh/RmzZsgXR0dHmTkax1LNnTzx+/Bi+vr5Gfc8UbZ6hHj16hOjoaA7sm1FhHm8iY/n6+uLx48fo2bOnuZOSq88//xznzp0zdzKIioTCuKZn+0WWbM+ePcjIyMCcOXPQu3dvdO3atdC2be7rr8IY2B8/fjweP36cp+8WxTHJ7OR0LLOOtT4rOLCfjYcPHxbYuu3t7VGiRIkCW39+PHnyBBkZGSZZl7W1Nezt7WFtzdPMFNLS0pCSkmLuZBARFVk2Njawt7d/5h9DJaK8EZE8XxSbipWVFezt7WFjY2PWdBjC1tYWdnZ25k4GUYEpyB43S9kAAGkUSURBVDEBomfN9evXAaDApuApTI8ePTJ3EnSUKFEC9vb25k6GSmHnU1Eeay1Iz8yI67///ot+/frBx8cHdnZ28PPzw+DBg5GSkqLMybt37168+eab8PT0RPny5ZXv/vTTT2jatCmcnJxQsmRJRERE4PTp0zrb+P7771GrVi3Y29ujVq1a2LBhg960ZJ73KSoqCqNHjwYA+Pn5wcrKSpkfuHPnznjuuedU3+3QoQOsrKzw448/KmGHDx+GlZUVfvrpJyXsr7/+wquvvopSpUrB0dERjRs3xubNm1Xr0s7Vu3r1aowfPx7lypWDo6Mj5s6di1dffRUA0KJFCyVNWe8u3L9/Pxo1agR7e3tUrlwZX331ld71Z/6edl7aM2fOoEWLFnB0dES5cuUwbdo0nXxKTk7GxIkTUbVqVdjZ2aFChQoYM2YMkpOTVfFiY2PRpEkTuLm5wdnZGTVq1MB7772nijNv3jzUrFkTjo6OcHd3R4MGDbBq1SqdbeZk9erVCAoKQsmSJeHi4oLatWtjzpw5qjh3797FiBEjUKlSJdjZ2aF8+fLo1asXbt68qcS5fv06+vXrBy8vL9jb26Nu3bpYvny5aj3aeeE+/fRTzJ49G1WqVIGdnR3OnDkD4OljbK+88gpKlSoFe3t7NGjQQHVOkK7Lly/jzTffRI0aNeDg4IDSpUvj1Vdf1XvHy4kTJxAaGgoHBweUL18eH374IZYuXap37m5D64fs7NmzBw0bNgQA9OnTRylvmecEXLduHYKCguDg4IAyZcrgf//7H/7991+j88DQMmVlZYWhQ4di3bp1CAwMhIODA0JCQnDy5EkAwOLFi1G1alXY29ujefPmOnmiLedHjhzB888/DwcHB/j5+SEmJsagdO7atUvJUzc3N7z88sv4448/lOW7d++GlZWV3jp21apVsLKyQlxcHICn8/86OzvjypUraN++PZydnVGuXDksWLAAAHDy5Em0bNkSTk5O8PX11Vsv3L17F8OHD0eFChVgZ2eHqlWrYurUqaofQTOX2c8++0wpsw0bNsSvv/6qxOvdu7eybe2x5iC06WSdY1/7Tpic2qtly5bl2uYZUs6159q///6Ljh07wtnZGR4eHnjnnXeQnp4O4Ol54uHhAQCIjo5WtmXs46QZGRn46KOPUL58edjb26NVq1a4cOGCTjxD6o7CKiOG0NYd2jrY0dERVatWVd4psHfvXgQHB8PBwQE1atTAjh07VN83pJ439HiHhoYq7X3Dhg317rchfRkyLe38sRcuXEDv3r3h5uYGV1dX9OnTR3XxmJaWhsmTJyt1caVKlfDee+/ptHfaOmLbtm1o0KABHBwcsHjxYqUPu3btWkRHR6NcuXIoWbIkXnnlFdy7dw/JyckYPnw4PD094ezsjD59+uise+nSpWjZsiU8PT1hZ2eHwMBALFq0KNd9zDo3sDYt+v6yzm9v6muW3GSdY9/QtlDr7Nmz6Nq1Kzw8PJRy/f7776viHD16FO3atYOLiwucnZ3RqlUrHDp0SBVHW/fv378fw4YNg4eHB9zc3PDGG28gJSUFd+/eRa9eveDu7g53d3eMGTMGIqJaR0ZGBmbPno2aNWvC3t4eXl5eeOONN3Dnzp085Q1ZHm39cubMGbz++utwd3dHkyZNcOLECfTu3RuVK1eGvb09vL290bdvX9y6dUv13eyu6bVWrFihtMmlSpVCt27d8PfffxucPkPar4ULF6JmzZqws7ODj48PhgwZYvQduLdv38Y777yD2rVrw9nZGS4uLmjXrh2OHz+uE/fy5ct46aWX4OTkBE9PT4wYMQLbtm3TO3Zw+PBhtG3bFq6urnB0dERoaCgOHDhgVNqo8O3fvx8NGzaEvb09qlSpgsWLF+uNl9v5XalSJUycOBEA4OHhoer//vDDD4iIiFDG6qpUqYLJkycr/efM6+jdu7fOtrO+qyar/F5/Zb62bdasGRwdHZXxJkPS3rx5c2zevBmXL1/W234beo2eG31z7Guv67Xtvp2dHWrWrImtW7eqvmeK+iu/+aR1+PBhvPjii3B3d4eTkxPq1KmjjLvldiz1XVcZ0484cOAARo4cCQ8PDzg5OaFTp064ceOGIdlvXvIM+Pfff8XHx0ccHR1l+PDhEhMTIx988IEEBATInTt3ZOnSpQJAAgMDJTQ0VObNmyeffPKJiIh89dVXYmVlJW3btpV58+bJ1KlTpVKlSuLm5ibx8fHKNrZt2ybW1tZSq1YtmTlzprz//vvi6uoqNWvWFF9fX1V6AMjEiRNFROT48ePSvXt3ASCzZs2Sr7/+Wr7++mt58OCBzJw5U6ytreXevXsiIpKRkSHu7u5ibW0t77zzjrK+6dOnq+IlJCSIl5eXlCxZUt5//32ZOXOm1K1bV6ytreW7775Tvrd7925lv+vVqyczZ86UKVOmyOnTp2XYsGECQN577z0lTQkJCSIi4uvrKzVq1BAvLy957733ZP78+fLcc8+JlZWVnDp1Smf9u3fvVsJCQ0PFx8dHKlSoIG+//bYsXLhQWrZsKQBky5YtSrz09HRp06aNcswWL14sQ4cOlRIlSsjLL7+sxDt16pRoNBpp0KCBzJkzR2JiYuSdd96RZs2aKXE+++wzASCvvPKKLF68WObMmSP9+vWTYcOGGXwObd++XQBIq1atZMGCBbJgwQIZOnSovPrqq0qc+/fvS61atcTGxkYGDBggixYtksmTJ0vDhg3l6NGjIiLy6NEjCQgIEFtbWxkxYoTMnTtXmjZtKgBk9uzZyrri4+OVY1O5cmX55JNPZNasWXL58mU5deqUuLq6SmBgoEydOlXmz58vzZo1EysrK9XxJbV169ZJ3bp1ZcKECfLZZ5/Je++9J+7u7uLr6ysPHz5U4v3zzz9SqlQpKV26tERHR8unn34q/v7+UrduXQGgKveG1g85SUhIkEmTJgkAGThwoFLeLl68KCKi1E8NGzaUWbNmydixY8XBwUEqVaokd+7cMXj/DS1TIk/rqDp16kiFChXkk08+kU8++URcXV2lYsWKMn/+fAkMDJQZM2bI+PHjRaPRSIsWLVTf15ZzT09PGTp0qMydO1eaNGkiAGTJkiVKPO15vnTpUiUsNjZWSpQoIdWrV5dp06ZJdHS0lClTRtzd3ZU8zcjIkAoVKkiXLl109vPFF1+UKlWqKJ8jIyPF3t5eAgMDZdCgQbJgwQJ5/vnnle36+PjI6NGjZd68eVKzZk2xsbGRv/76S/n+w4cPpU6dOlK6dGl57733JCYmRnr16iVWVlby9ttv6+xL/fr1pWrVqjJ16lSZNm2alClTRsqXLy8pKSkiInLw4EFp3bq1AFCO9ddff23wcaScacuL9lwxpL26ePFijm2eoeVce67VrFlT+vbtK4sWLZIuXboIAFm4cKGIiDx48EAWLVokAKRTp07Kto4fP27Q/mnb1fr160tQUJDMmjVLoqKixNHRURo1aqQ3L3KrOwqrjBgicx9Bu83AwECxsbGR1atXi7e3t0RFRcns2bOlXLly4urqKklJScr3DannczveS5cuFSsrK6lVq5Z89NFHsmDBAunfv7/07NlTbzpz6suQ6U2cOFEpA507d5aFCxdK//79BYCMGTNGiRcZGan0/RYsWCC9evUSANKxY0fV+nx9faVq1ari7u4uY8eOlZiYGNm9e7dS1urVqychISEyd+5cGTZsmFhZWUm3bt3k9ddfl3bt2smCBQukZ8+eAkCio6NV627YsKH07t1bZs2aJfPmzZM2bdoIAJk/f74qXmhoqISGhiqfs7aNCQkJqvbi66+/lnnz5omtra00bNhQ+V5BXLPkJjIyUvUdQ9tCkafXQC4uLlK6dGkZN26cLF68WMaMGSO1a9dW4pw6dUqcnJykbNmyMnnyZPnkk0/Ez89P7Ozs5NChQ0o8bX1Xr149adu2req4jBkzRpo0aSKvv/66LFy4UNq3by8AZPny5ap96d+/v5QoUUIGDBggMTEx8u6774qTk5M0bNhQlW4qvrT1S2BgoLz88suycOFCWbBggXz66afStGlTmTRpknz22Wfy9ttvi4ODgzRq1EgyMjJEJOdrehGRDz/8UKysrOS1116ThQsXKv1bY/rzubVf2vSHhYXJvHnzZOjQoWJjY2P0Ofzrr79KlSpVZOzYsbJ48WKZNGmS0ub++++/SrwHDx5I5cqVxcHBQcaOHSuzZ8+WRo0aKddMmccAdu7cKRqNRkJCQmTGjBkya9YsqVOnjmg0Gjl8+LDBaaPCdeLECXFwcJCKFSvKlClTZPLkyeLl5SV16tSRzEOJhpzfGzZskE6dOgkAWbRokar/27FjR+natatMnz5dFi1aJK+++qoAUI15iTxtsyMjI3XSmVs7mt/rr9DQUPH29hYPDw956623ZPHixfL9998bnPbt27dLvXr1pEyZMsq2N2zYICLGXaPnRlsHZAZA6tatq7Sjs2fPlsqVK4ujo6PcvHlTRExXf+U3n7R5pdFoxNfXVyZOnCiLFi2SYcOGSVhYmIjkfiwzj7WKGN+PqF+/vrRs2VLmzZsno0aNEhsbG+natatRx8EcnomB/V69eom1tbX8+uuvOssyMjKUg9ikSRNJS0tTlt2/f1/c3NxkwIABqu8kJCSIq6urKrxevXpStmxZuXv3rhKmHQzOaWBf5OnAfNYBQ5GnjWrmi8QTJ04IAHn11VclODhYiffSSy9J/fr1lc/Dhw8XAPLzzz+r9sXPz08qVaok6enpIvLfAEHlypXl0aNHqm2vW7dOp0HW8vX1FQCyb98+Jez69etiZ2cno0aNUsKyG9gHIF999ZUSlpycLN7e3qpBuq+//lqsra1V+yAiEhMTIwDkwIEDIiIya9YsASA3btzQSafWyy+/LDVr1sx2uSHefvttcXFxUZ0fWU2YMEEA6B1c13b6Zs+eLQBkxYoVyrKUlBQJCQkRZ2dnZYBC2xi5uLjI9evXVetq1aqV1K5dW548eaJa//PPPy/VqlXL134WZ1nPcRGRuLg4nfPxrbfeEisrK+XHGBGRW7duSalSpVTl1Jj6ITfasp55gFvk6bnh6ekptWrVksePHyvhmzZtEgAyYcIEg7dhaJkSeVpH2dnZqeqkxYsXCwDx9vZWDaSNGzdOp/7SlvMZM2YoYcnJyVKvXj3x9PRULi70Dexr49y6dUsJO378uFhbW0uvXr1U27Wzs1PVudevX5cSJUqo6lft4M7HH3+shN25c0ccHBzEyspKVq9erYSfPXtWp36ePHmyODk5yZ9//qnKt7Fjx4qNjY1cuXJFtS+lS5eW27dvK/F++OEHASAbN25UwoYMGaLT6SLT0Dewb0h7lV2bZ0w5155rkyZNUsXVDsJr3bhxQ+c8M5S2XQ0ICJDk5GQlfM6cOQJATp48KSLG1R2FVUYMoa07Vq1apbNNa2trVQd827ZtOvWHofV8dsf77t27UrJkSQkODlblm8h/7XjmdObWlyHT01609u3bVxXeqVMnKV26tIiIHDt2TABI//79VXHeeecdASC7du1SwrR1xNatW1VxtWWtVq1aqgGx7t27i5WVlbRr104VPyQkRKe/r+98DA8Pl8qVK6vCchuQyCojI0Pat28vzs7Ocvr0aREpuGuW3GQ3sG9IW9isWTMpWbKkXL58WWf/tDp27CgajUa52UFE5OrVq1KyZEnVTTzauj88PFz1/ZCQELGyspJBgwYpYWlpaVK+fHlVnv/8888CQFauXKlKy9atW/WGU/GkrV+6d++uCtdXlr/55hud/kV21/SXLl0SGxsb+eijj1ThJ0+elBIlSuiE5yS79uv69eui0WikTZs2yrW+iMj8+fMFgHz55ZcGb+PJkyeqdYg8Ldt2dnaqPs6MGTMEgDJwJyLy+PFj8ff3V6UxIyNDqlWrplM+Hz16JH5+ftK6dWuD00aFq2PHjmJvb6+qp8+cOSM2NjbKtYwx57e2jGUdu9FXxt544w1xdHRUjXnkdWBfJH/XX9p+X0xMjM4yQ9MeERGht4015ho9N9kN7Gs0Grlw4YISdvz4cQEg8+bNU8JMUX/lN5/S0tLEz89PfH19dX7wzFx35HQss16nGNuPCAsLU21rxIgRYmNjo+ozFUXFfiqejIwMfP/99+jQoQMaNGigszzzYxsDBgxQzWcZGxuLu3fvonv37rh586byZ2Njg+DgYOzevRsAcO3aNRw7dgyRkZFwdXVVvt+6dWsEBgbmOe3169eHs7Mz9u3bBwD4+eeflaldfv/9dzx69Agigv3796Np06bK97Zs2YJGjRqhSZMmSpizszMGDhyIS5cuKdO5aEVGRsLBwcGotAUGBqq26eHhgRo1auCvv/7K9bvOzs743//+p3zWaDRo1KiR6rvr1q1DQEAA/P39VXnfsmVLAFDyXjs/2w8//JDtI/9ubm74559/9D4CbCg3Nzc8fPgQsbGx2cb59ttvUbduXXTq1ElnmfY827JlC7y9vdG9e3dlma2tLYYNG4YHDx5g7969qu916dJFmbYBePpo5K5du9C1a1fcv39fyZdbt24hPDwc58+fz9MULc+CzOd4amoqbt26hapVq8LNzQ2///67smzr1q0ICQlBvXr1lLBSpUqhR48eqvUZWj/kx2+//Ybr16/jzTffVM2XFxERAX9/f53ptXJiaJnSatWqleoRweDgYABPz8mSJUvqhGct+yVKlMAbb7yhfNZoNHjjjTdw/fp1HDlyRG8atXVp7969UapUKSW8Tp06aN26NbZs2aKE9erVC8nJycoUHQCwZs0apKWlqeoXrf79+yv/d3NzQ40aNeDk5KR6aVONGjXg5uamUxc1bdoU7u7uqnwLCwtDenq6Uj9rvfbaa3B3d1c+a+tJQ+pGKhj5aa/yUs4HDRqk+ty0aVOTH/8+ffpAo9GotgH8d57lpe4orDKSG2dnZ3Tr1k1nmwEBAUp9A+ivewyt57MTGxuL+/fvY+zYsTpzlGZ9tNmQvgwVHH3l7NatW0hKSlLaipEjR6rijBo1CgB0zn8/Pz+Eh4fr3U6vXr1ga2urfA4ODoaIoG/fvqp4wcHB+Pvvv5GWlqaEZT4f7927h5s3byI0NBR//fUX7t27Z+iu6pg8eTI2bdqEZcuWKdcZ5r5mySq3tvDGjRvYt28f+vbti4oVK6q+qy1r6enp2L59Ozp27IjKlSsry8uWLYvXX38d+/fvR1JSkuq7/fr1U5VV7fHq16+fEmZjY4MGDRro1GOurq5o3bq1Kv+CgoLg7Oxskj4dWY6s9UvmsvzkyRPcvHkTjRs3BgCD2pbvvvsOGRkZ6Nq1q+r88vb2RrVq1Uxyfu3YsQMpKSkYPny46v12AwYMgIuLi1HXDHZ2dso60tPTcevWLWW626zXTOXKlcNLL72khNnb22PAgAGq9R07dgznz5/H66+/jlu3bin7//DhQ7Rq1Qr79u0z2Tv+yHTS09Oxbds2dOzYUVVPBwQEqNpMU5zfmcuYdoyjadOmePToEc6ePWvaHcsjOzs79OnTRyc8v2k39ho9L8LCwlClShXlc506deDi4mJQn9XY45uffDp69Cji4+MxfPhwnfcw5GXq2rz0IwYOHKjaVtOmTZGeno7Lly8bvf3CVOzfKnDjxg0kJSWhVq1aucb18/NTfT5//jwAKIUqKxcXFwBQDnK1atV04mRtAI1hY2ODkJAQ/PzzzwCeDuw3bdoUTZo0QXp6Og4dOgQvLy/cvn1bNWhx+fJl1cWvVkBAgLI8c35k3W9DZO2EA4C7u7tB81CWL19ep2C6u7vjxIkTyufz58/jjz/+UA1qZ6Z98cprr72GL774Av3798fYsWPRqlUrdO7cGa+88orSIXn33XexY8cONGrUCFWrVkWbNm3w+uuv44UXXjB4f998802sXbsW7dq1Q7ly5dCmTRt07doVbdu2VeJcvHgRXbp0yXE9ly9fRrVq1XReKJz52GSW9dhcuHABIoIPPvgAH3zwgd5tXL9+HeXKlTN4354Vjx8/xpQpU7B06VL8+++/qrlVM19gX758GSEhITrfr1q1quqzofVDfmjPhxo1augs8/f3x/79+w1el6FlSitrGdcOAFSoUEFveNay7+PjAycnJ1VY9erVATydg1d7QZRZTvsbEBCAbdu24eHDh3BycoK/vz8aNmyIlStXKhfsK1euROPGjXWOlb29vc5+u7q66q2LXF1dVfty/vx5nDhxIs/5ph3Y4By95pOf9srYcq7vXDN0W8bI7Twztu4ozDKSm+y2aUjdY2g9n52LFy8CgEF9RkP6MlRwcioDly9fhrW1tU5b4O3tDTc3t1z7WjltJ6e2MCMjA/fu3UPp0qUBAAcOHMDEiRMRFxen8/K4e/fuqQbWDbV161ZER0dj3Lhxqj6nua9ZssqtjtIOJuRU1m7cuIFHjx5l2yfIyMjA33//jZo1a2a73ZyOV9Z67N69e/D09NSbFmPrMbJsWeuE27dvIzo6GqtXr9Y5FwxpW86fPw8R0VvuAKh+PMyr7Np9jUaDypUrGzUolZGRgTlz5mDhwoWIj49XzYGtrd+026xSpYpOW5jdNVNkZGS227x3757qx0Ayvxs3buDx48fZthfaH9FNcX6fPn0a48ePx65du3QGWvPzQ7gplStXTnVTjVZ+027sNXpe5PdayJjjm598MqYfbghT9CMs5Vq+2A/sGyPrXevaX46//vpreHt768QvjLctN2nSBB999BGePHmCn3/+Ge+//z7c3NxQq1Yt/Pzzz/Dy8gIA1cC+sYy9Wx+A6smGzDJfROfnuxkZGahduzZmzpypN662g+7g4IB9+/Zh9+7d2Lx5M7Zu3Yo1a9agZcuW2L59O2xsbBAQEIBz585h06ZN2Lp1K7799lssXLgQEyZMQHR0dK7pBQBPT08cO3YM27Ztw08//YSffvoJS5cuRa9evXRefGtK2Z2T77zzTrZ3l2XtTNFTb731FpYuXYrhw4cjJCQErq6usLKyQrdu3fJ0l0hRqB+MYWiZ0squnOan7Jtar1698Pbbb+Off/5BcnIyDh06hPnz5+vEy8++ZGRkoHXr1hgzZozeuNofK4xZJxWu/BwTY8t5dtsyNVOfZ4VZRgoyLaau5/OSTpb1wmFI/ht6d1dO/eC8no8XL15Eq1at4O/vj5kzZ6JChQrQaDTYsmULZs2alafzMT4+Hj169EDr1q3x4YcfqpYVtT6JucqHMccraz3m6emJlStX6v1+dgMuVDxlrRO6du2KgwcPYvTo0ahXrx6cnZ2RkZGBtm3bGlSWMzIyYGVlhZ9++knvuejs7GyytJvCxx9/jA8++AB9+/bF5MmTUapUKVhbW2P48OH5umaaPn266onozIpaHpDh8nt+3717F6GhoXBxccGkSZNQpUoV2Nvb4/fff8e7776rOueya9fT09MLvA+ur69gTNqzY+w1el7k91rImONbUPlUWCy1f1+0Rp4KgIeHB1xcXHDq1Cmjv6t9XMXT0xNhYWHZxvP19QXw36/RmZ07dy7X7eR04dG0aVOkpKTgm2++wb///qsM4Ddr1kwZ2K9evboywK9Nj77tah9x0aY3r2kqDFWqVMHx48fRqlWrXNNibW2NVq1aoVWrVpg5cyY+/vhjvP/++9i9e7dy3JycnPDaa6/htddeQ0pKCjp37oyPPvoI48aN03ncPjsajQYdOnRAhw4dkJGRgTfffBOLFy/GBx98gKpVq6JKlSq5nme+vr44ceIEMjIyVHftG3pstI8Q2dra5nhOkq7169cjMjISM2bMUMKePHmCu3fvquL5+vriwoULOt/PGmZo/WCI7M5x7flw7tw5nbvwzp07Z1BZ1jKmTJnC1atXlbvrtf78808AUE3xk1nm/c3q7NmzKFOmjGp93bp1w8iRI/HNN9/g8ePHsLW1xWuvvWbCvXiabw8ePDBpeTN3/Uq6sjsmpiznuW3LlExZd+SmIMpIXhlaz+d2vE+dOsUfyS2Yr68vMjIycP78eeWJSABITEzE3bt3TXr+Z2fjxo1ITk7Gjz/+qLr7K6+P1D9+/BidO3eGm5sbvvnmG50nPwvrmsVUtP3ZnPrNHh4ecHR0zLZPYG1tbZIBD+Bp/u3YsQMvvPBCnm54ouLrzp072LlzJ6KjozFhwgQlXF8ZyqltERH4+fkZ/WO3odvI3O5nnnIiJSUF8fHxRrXR69evR4sWLbBkyRJV+N27d1GmTBnVNs+cOQMRUaUru2smFxeXItFXIMN4eHjAwcEh1/Yiv+f3nj17cOvWLXz33Xdo1qyZEh4fH68T193dXadPBzx9eiTzea9PQfS/jUl7TvVDYV6jZ6cg6y9D8ylzPzynusLQfCrMfoS5Ffs59q2trdGxY0ds3LgRv/32m87ynH55CQ8Ph4uLCz7++GOkpqbqLL9x4waAp3M01atXD8uXL1c9bhMbG6szn70+2oEqfZVUcHAwbG1tMXXqVJQqVUp5TKRp06Y4dOgQ9u7dq3O3/osvvohffvkFcXFxStjDhw/x2WefoVKlSgbNoZlTmgpD165d8e+//+Lzzz/XWfb48WM8fPgQwNNHI7PS3gmQnJwMALh165ZquUajQWBgIERE73HVJ+s6rK2tUadOHdV2unTpguPHj2PDhg0639eeZy+++CISEhKwZs0aZVlaWhrmzZsHZ2dnhIaG5pgOT09PNG/eHIsXL8a1a9d0lmvPSdJlY2OjU97nzZunerwUeFru4+LicOzYMSXs9u3bOndxGVo/GCK78tagQQN4enoiJiZGOc8A4KeffsIff/yBiIgIg7dhaJkylbS0NCxevFj5nJKSgsWLF8PDwwNBQUF6v5O5Ls2cF6dOncL27dvx4osvquKXKVMG7dq1w4oVK7By5Uq0bdtWdcFhCl27dkVcXBy2bdums+zu3buq+ZQNZe76lXRld0xMWc61HB0d9W7LlExZd+SmIMpIXhlaz2d3vNu0aYOSJUtiypQpePLkiWpZUb9Th/6jbStmz56tCtfeDWfK8z872ju+sk4HtXTp0jytb9CgQfjzzz+xYcMGvdNVFNY1i6l4eHigWbNm+PLLL3HlyhXVMm2e2djYoE2bNvjhhx9w6dIlZXliYiJWrVqFJk2amGTaQ+BpPZaeno7JkyfrLEtLS2N7/QzTV5YB3foFyL5t6dy5M2xsbBAdHa2zHhHRuc7MSXbbCAsLg0ajwdy5c1XbWLJkCe7du2dUvaevLV23bp3Oe9zCw8Px77//4scff1TCnjx5onOtERQUhCpVquDTTz/FgwcPdLbH69eiycbGBuHh4fj+++9V9fQff/yh6vPl9/zWV8ZSUlKwcOFCnbhVqlTBoUOHkJKSooRt2rQJf//9d677UxDXX8ak3cnJSe/UPIV9jZ6dgqy/DM2n5557Dn5+fpg9e7ZOOjJ/19BjWZj9CHMr9nfsA08fJ9u+fTtCQ0MxcOBABAQE4Nq1a1i3bl2Oc1S7uLhg0aJF6NmzJ5577jl069YNHh4euHLlCjZv3owXXnhBmfZhypQpiIiIQJMmTdC3b1/cvn0b8+bNQ82aNfU2YJlpB7nef/99dOvWDba2tujQoQOcnJzg6OiIoKAgHDp0CB06dFB+nWrWrBkePnyIhw8f6gzsjx07Ft988w3atWuHYcOGoVSpUli+fDni4+Px7bff6tzlo0+9evVgY2ODqVOn4t69e7Czs0PLli2znXvS1Hr27Im1a9di0KBB2L17N1544QWkp6fj7NmzWLt2LbZt24YGDRpg0qRJ2LdvHyIiIuDr64vr169j4cKFKF++vPLy4DZt2sDb2xsvvPACvLy88Mcff2D+/PmIiIhQvQQ0J/3798ft27fRsmVLlC9fHpcvX8a8efNQr1495W6w0aNHY/369Xj11VfRt29fBAUF4fbt2/jxxx8RExODunXrYuDAgVi8eDF69+6NI0eOoFKlSli/fj0OHDiA2bNnG5SeBQsWoEmTJqhduzYGDBiAypUrIzExEXFxcfjnn39w/PjxvGd8Mda+fXt8/fXXcHV1RWBgIOLi4rBjxw7VXJEAMGbMGKxYsQKtW7fGW2+9BScnJ3zxxReoWLEibt++rZRBY+qH3FSpUgVubm6IiYlByZIl4eTkhODgYPj5+WHq1Kno06cPQkND0b17dyQmJmLOnDmoVKkSRowYYfD+G1qmTMXHxwdTp07FpUuXUL16daxZswbHjh3DZ599luNci9OnT0e7du0QEhKCfv364fHjx5g3bx5cXV0RFRWlE79Xr1545ZVXAEDvBXl+jR49Gj/++CPat2+P3r17IygoCA8fPsTJkyexfv16XLp0yegfE7R1/rBhwxAeHg4bGxvVy0Kp8OXU5pmqnGs5ODggMDAQa9asQfXq1VGqVCnUqlXLZPNJAlBuCDBF3ZGbgigjeWVoPZ/T8Z41axb69++Phg0b4vXXX4e7uzuOHz+OR48eFejUe2Q6devWRWRkJD777DPl8e9ffvkFy5cvR8eOHdGiRYsCT0ObNm2UJz3feOMNPHjwAJ9//jk8PT313piRk82bN+Orr75Cly5dcOLECdV7HJydndGxY8dCu2Yxpblz56JJkyZ47rnnMHDgQPj5+eHSpUvYvHmzcnPFhx9+iNjYWDRp0gRvvvkmSpQogcWLFyM5ORnTpk0zWVpCQ0PxxhtvYMqUKTh27BjatGkDW1tbnD9/HuvWrcOcOXOUvgY9W1xcXNCsWTNMmzYNqampKFeuHLZv3673jtzsrumrVKmCDz/8EOPGjcOlS5fQsWNHlCxZEvHx8diwYQMGDhyId955x6D05NR+jRs3DtHR0Wjbti1eeuklnDt3DgsXLkTDhg1VL3vPTfv27TFp0iT06dMHzz//PE6ePImVK1fq3BH9xhtvYP78+ejevTvefvttlC1bFitXrlSehtdeM1lbW+OLL75Au3btULNmTfTp0wflypXDv//+i927d8PFxQUbN240OH1UeKKjo7F161Y0bdoUb775pnJDYs2aNZW2KL/n9/PPPw93d3dERkZi2LBhsLKywtdff633hor+/ftj/fr1aNu2Lbp27YqLFy9ixYoVqhfDZqcgrr+MSXtQUBDWrFmDkSNHomHDhnB2dkaHDh0K/Ro9OwVZfxmaT9bW1li0aBE6dOiAevXqoU+fPihbtizOnj2L06dPKz8oGXMsC6sfYXbyjLh8+bL06tVLPDw8xM7OTipXrixDhgyR5ORkWbp0qQCQX3/9Ve93d+/eLeHh4eLq6ir29vZSpUoV6d27t/z222+qeN9++60EBASInZ2dBAYGynfffSeRkZHi6+urigdAJk6cqAqbPHmylCtXTqytrQWAxMfHK8tGjx4tAGTq1Kmq71StWlUAyMWLF3XSfPHiRXnllVfEzc1N7O3tpVGjRrJp0yad/QIg69at07vfn3/+uVSuXFlsbGwEgOzevVtERHx9fSUiIkInfmhoqISGhuqsX/s9bZyaNWvqfFdfPqWkpMjUqVOlZs2aYmdnJ+7u7hIUFCTR0dFy7949ERHZuXOnvPzyy+Lj4yMajUZ8fHyke/fu8ueffyrrWbx4sTRr1kxKly4tdnZ2UqVKFRk9erSyDkOsX79e2rRpI56enqLRaKRixYryxhtvyLVr11Txbt26JUOHDpVy5cqJRqOR8uXLS2RkpNy8eVOJk5iYKH369JEyZcqIRqOR2rVry9KlS1XriY+PFwAyffp0vem5ePGi9OrVS7y9vcXW1lbKlSsn7du3l/Xr1xu8T8+aO3fuKPnu7Ows4eHhcvbsWfH19ZXIyEhV3KNHj0rTpk3Fzs5OypcvL1OmTJG5c+cKAElISFDFNbR+yM0PP/wggYGBUqJECQGgOifWrFkj9evXFzs7OylVqpT06NFD/vnnH6PzwJAyJfK0jhoyZIjqu9mdk/rqEW05/+233yQkJETs7e3F19dX5s+fr3edWc//HTt2yAsvvCAODg7i4uIiHTp0kDNnzujdp+TkZHF3dxdXV1d5/PixzvLIyEhxcnLSCc+uLtJXv92/f1/GjRsnVatWFY1GI2XKlJHnn39ePv30U0lJSckxf0R06/y0tDR56623xMPDQ6ysrOQZaooLnLY917ahhrZXItm3eSKGlfPszrWJEyfqHOODBw9KUFCQaDQavX2C7GTXbmdXlgypOwqrjBjCmG2K6NZVxtTzOR3vH3/8UZ5//nmlDmrUqJF88803uaZTX1+GTEtbnm7cuKEKz1r2U1NTJTo6Wvz8/MTW1lYqVKgg48aNkydPnqi+l925lV1Zy+6aQV+6fvzxR6lTp47Y29tLpUqVZOrUqfLll1/q9POz1kdZy7N2m/r+sp5vpr5myU3W7xjTFoqInDp1Sjp16qRcr9SoUUM++OADVZzff/9dwsPDxdnZWRwdHaVFixZy8OBBVRxjjos23frqvc8++0yCgoLEwcFBSpYsKbVr15YxY8bI1atXDckOsnDZnS///POPcp66urrKq6++KlevXjX6mv7bb7+VJk2aiJOTkzg5OYm/v78MGTJEzp07Z1Q6c2q/5s+fL/7+/mJrayteXl4yePBguXPnjlHrf/LkiYwaNUrKli0rDg4O8sILL0hcXJzevtNff/0lERER4uDgIB4eHjJq1Cj59ttvBYAcOnRIFffo0aPSuXNn5Zrc19dXunbtKjt37jQqfVS49u7dq/RZK1euLDExMXr7toac39mVsQMHDkjjxo3FwcFBfHx8ZMyYMbJt2zad81tEZMaMGVKuXDmxs7OTF154QX777bdc21GR/F1/ZdfvMybtDx48kNdff13c3Nx02m9Dr9Fzo++46LuuFxG9feP81l+myCcRkf3790vr1q2lZMmS4uTkJHXq1JF58+Ypy3M6lvrq5fz0I/SNaRZFViJ8tpiIKDfDhw/H4sWL8eDBg0J7Qaalat68OW7evJmnd5sYKy0tDT4+PujQoYPOXKBERERERFR4Zs+ejREjRuCff/5BuXLlzJ0cIqJir9jPsU9EZKzHjx+rPt+6dQtff/01mjRpwkH9Iub777/HjRs30KtXL3MnhYiIiIjomZH1munJkydYvHgxqlWrxkF9IqJC8kzMsU+UnfT09Fxf2OPs7AxnZ+dCShEVBSEhIWjevDkCAgKQmJiIJUuWICkpCR988IFR60lJSdH7gufMXF1d4eDgkOe0FsY2iqLDhw/jxIkTmDx5MurXr5/ri6eJirLiXo5v376tetFZVjY2NvDw8CjEFBFRTlhmiQrX48eP9b5YM7NSpUpBo9EUqW107twZFStWRL169XDv3j2sWLECZ8+excqVK/OcTqLCYilt3b1793R+RMvK29u7kFJDRREH9umZ9vfff8PPzy/HOBMnTtT70k4qvl588UWsX78en332GaysrPDcc89hyZIlaNasmVHrOXjwYK4v6Vu6dCl69+6d57QWxjaKokWLFmHFihWoV68eli1bZu7kEOVLcS/HnTt3xt69e7Nd7uvri0uXLhVegogoRyyzRIVrzZo16NOnT45xdu/ejebNmxepbYSHh+OLL77AypUrkZ6ejsDAQKxevRqvvfZantNJVFgspa17++23sXz58hzjcIb1Zxvn2Kdn2pMnT7B///4c41SuXBmVK1cupBRRcXLnzh0cOXIkxzg1a9ZE2bJli/Q2iKhgFfdyfOTIEdy5cyfb5Q4ODnjhhRcKMUVElBOWWaLCde3aNZw+fTrHOEFBQXB3dy/S2yCyJJbS1p05cwZXr17NMU5YWFghpYaKIg7sExERERERERERERFZkGd6Kp6MjAxcvXoVJUuWhJWVlbmTQ2QwEcH9+/fh4+MDa2u+Azsrlm2yVCzbuWP5JkvF8p0zlm2yVCzbuWP5JkvF8p0zlm2yVMWpbD/TA/tXr15FhQoVzJ0Mojz7+++/Ub58eXMno8hh2SZLx7KdPZZvsnQs3/qxbJOlY9nOHss3WTqWb/1YtsnSFYey/UwP7JcsWRLA0wPp4uKiszw1NRXbt29HmzZtYGtrW9jJMwnuQ9Fg6n1ISkpChQoVlHPYFKZMmYLvvvsOZ8+ehYODA55//nlMnToVNWrUUOI8efIEo0aNwurVq5GcnIzw8HAsXLgQXl5eSpwrV65g8ODB2L17N5ydnREZGYkpU6agRIn/qps9e/Zg5MiROH36NCpUqIDx48frvBRywYIFmD59OhISElC3bl3MmzcPjRo1MmhfnoWyrU9x3S+g+O5b1v0qiLJd3Dyr5bswMO/yJ7f8Y/nOWW5lW5/ies4W1/0Ciue+sWznLi/l+1lWHMuJueQ3L1m+c8Z+OffRUhWnsv1MD+xrHxVycXHJthJydHSEi4uLxZ683IeioaD2wZSPu+3duxdDhgxBw4YNkZaWhvfeew9t2rTBmTNn4OTkBAAYMWIENm/ejHXr1sHV1RVDhw5F586dceDAAQBAeno6IiIi4O3tjYMHD+LatWvo1asXbG1t8fHHHwMA4uPjERERgUGDBmHlypXYuXMn+vfvj7JlyyI8PBwAsGbNGowcORIxMTEIDg7G7NmzER4ejnPnzsHT09PgfCnOZVuf4rpfQPHdt+z2i4+yZu9ZLd+FgXmXP4bmH8u3frmVbX2K6zlbXPcLKN77xrKdvbyU72dZcS4nhc1UecnyrR/75dxHS1ccyvYzPbBPRP/ZunWr6vOyZcvg6emJI0eOoFmzZrh37x6WLFmCVatWoWXLlgCApUuXIiAgAIcOHULjxo2xfft2nDlzBjt27ICXlxfq1auHyZMn491330VUVBQ0Gg1iYmLg5+eHGTNmAAACAgKwf/9+zJo1SxnYnzlzJgYMGIA+ffoAAGJiYrB582Z8+eWXGDt2rE7ak5OTkZycrHxOSkoC8LQBSk1N1YmvDdO3zJIV1/0Ciu++Zd2v4rZ/RERERERERFQwOLBvgFpR25Cc/t+vOJc+iTBjaogKx7179wAApUqVAgAcOXIEqampCAsLU+L4+/ujYsWKiIuLQ+PGjREXF4fatWurpuYJ/7/27j0qiivPA/iXV/NQG0SFhhWRRONbiBix8zAmIsSQbEjYrBqjRI2OLnhUMj7IGkVNBuNbI5FsEmXmRNbHHjUzkkFbDDoqvlBWxMiJjgmZjQ2ZGCS+AOHuH56uUHQ3b7q7iu/nnDraVZfq+6vuX1f3rVv3Rkdj9uzZKCoqwuOPP468vDzZPkxl5s2bBwCoqqpCfn4+kpOTpe3Ozs6IjIxEXl6exbqmpqZi+fLlZusPHToELy8vqzEaDIZGjoIyqTUuQL2xmeK6e/eunWuiHjx3U0ezatUqJCcnY+7cudi4cSMA5Qyh11S9F2fJHru7CKxu26cgIpLU/8wB+H2CqCX4vZyo/bBhn4jM1NbWYt68eXjqqacwePBgAIDRaIRGo4GPj4+srL+/P4xGo1SmbmOBabtpW0NlKioqcO/ePfzyyy+oqamxWObKlSsW65ucnIykpCTpsWm8tKioKKu3BBoMBowdO1Z2K9nglIMW938pJdriekdjLS41UGts9eMy3W1CRNQcZ8+exSeffIKhQ4fK1itlCD0iIiIiImo+NuwTkZmEhARcunQJx48ft3dVmsTd3R3u7u5m693c3BpsBK6/vW4vgvrllKSxuJVMrbGZ4lJjbETUvm7fvo1Jkybh008/xfvvvy+td+Qh9IiIlIq9+ImIyJGwYZ+IZBITE3HgwAEcO3YMPXv2lNbrdDpUVVWhvLxc1mu/tLQUOp1OKnPmzBnZ/kpLS6Vtpn9N6+qW0Wq18PT0hIuLC1xcXCyWMe2DiIiIHkpISEBMTAwiIyNlDfuOPIQe0Pz5cYCHQ+/IHjsL6W/URM3zrqgxNjXFQkRERMrChn0iAgAIITBnzhzs27cPubm5CAkJkW0PDw+Hm5sbcnJyEBcXBwAoLi5GSUkJ9Ho9AECv1+ODDz5AWVmZdOu9wWCAVqvFwIEDpTJfffWVbN8Gg0Hah0ajQXh4OHJychAbGwvg4dBAOTk5SExMbLf4iYiIlGbnzp04f/48zp49a7bNkYfQA1o2P4618fTVPv+KGqkpNs6Po3yWeuETEREpARv2iQjAwx5/mZmZ+PLLL9GlSxfpB723tzc8PT3h7e2N6dOnIykpCb6+vtBqtZgzZw70ej1GjhwJAIiKisLAgQMxefJkrF69GkajEUuWLEFCQoI0VM6sWbOwZcsWLFy4ENOmTcORI0ewe/duZGX99oU6KSkJ8fHxGD58OEaMGIGNGzfizp070i3+REREHd0PP/yAuXPnwmAwwMPDw97Vabbmzo8DmM+F4+4ssHJ4rernX1ETNcbG+XGIiIjIXtiwT0QAgK1btwIARo8eLVu/fft2vPXWWwCADRs2wNnZGXFxcaisrER0dDQ+/vhjqayLiwsOHDiA2bNnQ6/Xo1OnToiPj8eKFSukMiEhIcjKysL8+fOxadMm9OzZE5999pk0Ti8AjB8/Hj/99BOWLl0Ko9GIsLAwZGdnm/UGJCIi6qjy8/NRVlaGYcOGSetqampw7NgxbNmyBQcPHnToIfRaMj9OQ3PhqKWRuC61xgWoKza1xEFERETKw4Z9IgLwcCiexnh4eCAtLQ1paWlWywQHB5sNtVPf6NGjceHChQbLJCYmcugdIiIiK8aMGYPCwkLZuqlTp6J///5YtGgRgoKCOIQeEREREZGKsWGfiIiIiEhhunTpgsGDB8vWderUCd26dZPWcwg9IiIiIiL1crZ3BYiIiKj9pKSkwMnJSbb0799f2n7//n0kJCSgW7du6Ny5M+Li4syG1CgpKUFMTAy8vLzg5+eHBQsW4MGDB7Iyubm5GDZsGNzd3dGnTx9kZGSY1SUtLQ29e/eGh4cHIiIizIYAIaK2tWHDBrz00kuIi4vDqFGjoNPpsHfvXmm7aQg9FxcX6PV6vPnmm5gyZYrFIfQMBgNCQ0Oxbt06i0PorV27FkuXLkVYWBgKCgo4hB4RERERUTtjj30iIiKVGzRoEA4fPiw9dnX97fQ/f/58ZGVlYc+ePfD29kZiYiJee+01nDhxAsDDMbtjYmKg0+lw8uRJ3LhxA1OmTIGbmxv+8Ic/AACuX7+OmJgYzJo1Czt27EBOTg7efvttBAQESI1/u3btQlJSEtLT0xEREYGNGzciOjoaxcXF0hAgRNQ6ubm5ssccQo+ISK734qzGC9n4+b9bFWOHmhApl7U8Zi5RR8SGfSIiIpVzdXW1OInlrVu38PnnnyMzMxPPP/88gIcTZg8YMACnTp3CyJEjcejQIVy+fBmHDx+Gv78/wsLCsHLlSixatAgpKSnQaDRIT09HSEgI1q1bBwAYMGAAjh8/jg0bNkgN++vXr8eMGTOkoTnS09ORlZWFbdu2YfHixVbrXllZicrKSulxRUUFAKC6uhrV1dVm5U3r3J2FxfVknekY8Vi1TGPHj8eViIiIiIjaEhv2iYiIVO7bb79FYGAgPDw8oNfrkZqail69eiE/Px/V1dWIjIyUyvbv3x+9evVCXl4eRo4ciby8PAwZMkQ2pEZ0dDRmz56NoqIiPP7448jLy5Ptw1Rm3rx5AICqqirk5+cjOTlZ2u7s7IzIyEjk5eU1WPfU1FQsX77cbP2hQ4fg5eVl9e9WDq+VPW6sRzL9xmAw2LsKimbt+N29e9fGNSEiIiWo3/vY3UVg9Qg7VYaIiBSlVQ37q1atQnJyMubOnYuNGzcCeDhW7zvvvIOdO3eisrIS0dHR+Pjjj2UNAiUlJZg9eza+/vprdO7cGfHx8UhNTZUNDZCbm4ukpCQUFRUhKCgIS5YswVtvvSV7/rS0NKxZswZGoxGhoaH46KOPMGIEz4BEREQmERERyMjIQL9+/XDjxg0sX74czzzzDC5dugSj0QiNRgMfHx/Z3/j7+8NoNAIAjEaj2TjZpseNlamoqMC9e/fwyy+/oKamxmKZK1euNFj/5ORkJCUlSY8rKioQFBSEqKgoaLVas/LV1dUwGAx475wzKmudpPWXUqLNypKc6diNHTsWbm5u9q6O4jR2/Ex3mxAREREREbWFFjfsnz17Fp988gmGDh0qW8+xeomIiBzHuHHjpP8PHToUERERCA4Oxu7du+Hp6WnHmjWNu7s73N3dzda7ubk12PhcWeuEyhonWXlqmsaOLTXM2vHjMSUiIiIiorbUoob927dvY9KkSfj000/x/vvvS+sdfazejjhOrxrGy2UM1vdHRNRcPj4+eOyxx3D16lWMHTsWVVVVKC8vl/XaLy0tlcbk1+l0OHPmjGwfpaWl0jbTv6Z1dctotVp4enrCxcUFLi4uFstYGvufiIiISOnsPVEvERGpX4sa9hMSEhATE4PIyEhZw76jj9XbkcfpVcN4uYzhNxynl4ha6vbt27h27RomT56M8PBwuLm5IScnB3FxcQCA4uJilJSUQK/XAwD0ej0++OADlJWVSXfEGQwGaLVaDBw4UCpT/9xoMBikfWg0GoSHhyMnJwexsbEAgNraWuTk5CAxMdEWYRMRERERkQOzdDHsu1UxdqgJkXI0u2F/586dOH/+PM6ePWu2zdHH6u2I4/SqYbxcxmCO4/QSUVP9/ve/x8svv4zg4GD8+OOPWLZsGVxcXDBx4kR4e3tj+vTpSEpKgq+vL7RaLebMmQO9Xo+RI0cCAKKiojBw4EBMnjwZq1evhtFoxJIlS5CQkCANkTNr1ixs2bIFCxcuxLRp03DkyBHs3r0bWVm/fTlPSkpCfHw8hg8fjhEjRmDjxo24c+eOdOcdERERtZy9578jIiIi22tWw/4PP/yAuXPnwmAwwMPDo73q1G468ji9ahgvlzHI90NE1BT/+Mc/MHHiRPz888/o0aMHnn76aZw6dQo9evQAAGzYsAHOzs6Ii4uT/eg3cXFxwYEDBzB79mzo9Xp06tQJ8fHxWLFihVQmJCQEWVlZmD9/PjZt2oSePXvis88+k4bPA4Dx48fjp59+wtKlS2E0GhEWFobs7Gyzi/RERETUPPae/66j45A71BzHjh3DmjVrkJ+fjxs3bmDfvn3SHa0AIITAsmXL8Omnn6K8vBxPPfUUtm7dir59+0plbt68iTlz5uAvf/mL9D1+06ZN6Ny5s1Tm4sWLSEhIwNmzZ9GjRw/MmTMHCxculNVlz549eO+99/Ddd9+hb9+++PDDD/Hiiy+2+zEgorbTrIb9/Px8lJWVYdiwYdK6mpoaHDt2DFu2bMHBgwc5Vi8REZED2blzZ4PbPTw8kJaWhrS0NKtlgoODGx2GbvTo0bhw4UKDZRITEzn0DhERURtyhPnviKjp7ty5g9DQUEybNg2vvfaa2fbVq1dj8+bN+OMf/4iQkBC89957iI6OxuXLl6UOtpMmTcKNGzdgMBhQXV2NqVOnYubMmcjMzATw8A7/qKgoREZGIj09HYWFhZg2bRp8fHwwc+ZMAMDJkycxceJEpKam4qWXXkJmZiZiY2Nx/vx5DB482HYHhIhapVkN+2PGjEFhYaFs3dSpU9G/f38sWrQIQUFBHKuXiIiIiIiIyAbsPf+dJZWVlaisrJQem4YRra6uRnV1dWtDbhV3F2HX528Kd+eHdbT3sVID0zFs6bFsj9dg3LhxGDdunMVtQghs3LgRS5YswSuvvAIA+NOf/gR/f3/s378fEyZMwDfffIPs7GycPXsWw4cPBwB89NFHePHFF7F27VoEBgZix44dqKqqwrZt26DRaDBo0CAUFBRg/fr1UsP+pk2b8MILL2DBggUAgJUrV8JgMGDLli1IT0+3WL/m5rZpnek9XX99fZby01JZa3lsj5xp7XtMCdQYo5piaVbDfpcuXcyu3HXq1AndunWT1nOsXiIiIiIiIqL25Qjz33l6epo9d2pqKpYvX262/tChQ/Dy8mp6gO1g9Qi7Pn2zGAwGe1dBNVp6LO/evdvGNWnY9evXYTQaZRfTvL29ERERgby8PEyYMAF5eXnw8fGRGvUBIDIyEs7Ozjh9+jReffVV5OXlYdSoUdBoNFKZ6OhofPjhh/jll1/QtWtX5OXlyeagNJXZv3+/1fq1NLdXDq+VPbZ2J7Cl/LRU1loeN3aHcXvqCPmqphhtndvtqdmT5zaGY/USERERERERtR9Hnv8uOTlZ1mBYUVGBoKAgREVFQavV2rFmwOCUg3Z9/qZwdxZYObwWY8eO5dxqrVRdXQ2DwdDiY2nqkW4rpgtqli6m1b3YZhr9wsTV1RW+vr6yMiEhIWb7MG3r2rWr1Yt2pn1Y0tzcNh3/9845o7L2t3krL6VYHsbLUn5aKmstj63ttz219j2mBGqM0da53Z5a3bCfm5sre8yxeomIiIiIiIjaj6PMf2eJu7u7dDd+XW5ubnZvFKqscWq8kINwhOOlFi09ljz+ci3N7cpaJ1nuWStrKT8tlbWWx/Z8vTpCvqopRrXEAQDO9q4AERERERERETWdaf67goICaRk+fDgmTZok/d80/52JpfnvCgsLUVZWJpWxNP9d3X2Yypj2QURtx3RBzdLFtLoX2+rmLAA8ePAAN2/ebPSCXN3nsFbGtJ2IlIEN+0REREREREQKYpr/ru5Sd/47b29vaf67r7/+Gvn5+Zg6darV+e/+93//FwcPHrQ4/93f//53LFy4EFeuXMHHH3+M3bt3Y/78+fYMn0iVQkJCoNPpZBfTKioqcPr0adkFufLycuTn50tljhw5gtraWkREREhljh07Jpsg1GAwoF+/fujatatUhhftiJSPDftEREREREREKrNhwwa89NJLiIuLw6hRo6DT6bB3715pu2n+OxcXF+j1erz55puYMmWKxfnvDAYDQkNDsW7dOrP574io6W7fvi3dZQM8nDC3oKAAJSUlcHJywrx58/D+++/jz3/+MwoLCzFlyhQEBgYiNjYWADBgwAC88MILmDFjBs6cOYMTJ04gMTEREyZMQGBgIADgjTfegEajwfTp01FUVIRdu3Zh06ZNsvHx586di+zsbKxbtw5XrlxBSkoKzp07x+GuiRSmzSfPJSIiIiIiIiLbsuf8d0TUNOfOncNzzz0nPTY1tsfHxyMjIwMLFy7EnTt3MHPmTJSXl+Ppp59Gdna2bJLsHTt2IDExEWPGjIGzszPi4uKwefNmabu3tzcOHTqEhIQEhIeHo3v37li6dClmzpwplXnyySeRmZmJJUuW4N1330Xfvn2xf/9+DB482AZHgYjaChv2iYiIiIiIiIgcyOCUg2aThH63KsZOtaG2Mnr0aAghrG53cnLCihUrZHfO1Ofr64vMzMwGn2fo0KH429/+1mCZ119/Ha+//nrDFVa43ouzzNYxj0hN2LBPRERERERERKpiqUGPiIhITTjGPhERERERERERERGRgrBhn4iIiIiIiIiIiIhIQdiwT0RERERERERERESkIGzYJyIiIiIiIiIiIiJSEDbsExEREREREREREREpCBv2iYiIiIiIiIiIiIgUhA37REREREREREREREQKwoZ9IiIiIiIiIiIiIiIFYcM+EREREREREREREZGCsGGfiAAAx44dw8svv4zAwEA4OTlh//79su1CCCxduhQBAQHw9PREZGQkvv32W1mZmzdvYtKkSdBqtfDx8cH06dNx+/ZtWZmLFy/imWeegYeHB4KCgrB69WqzuuzZswf9+/eHh4cHhgwZgq+++qrN4yUiIiIiIlKS3ouzzBYiIuq42LBPRACAO3fuIDQ0FGlpaRa3r169Gps3b0Z6ejpOnz6NTp06ITo6Gvfv35fKTJo0CUVFRTAYDDhw4ACOHTuGmTNnStsrKioQFRWF4OBg5OfnY82aNUhJScF//dd/SWVOnjyJiRMnYvr06bhw4QJiY2MRGxuLS5cutV/wRERECpSamoonnngCXbp0gZ+fH2JjY1FcXCwrc//+fSQkJKBbt27o3Lkz4uLiUFpaKitTUlKCmJgYeHl5wc/PDwsWLMCDBw9kZXJzczFs2DC4u7ujT58+yMjIMKtPWloaevfuDQ8PD0RERODMmTNtHjMRERERET3kau8KEJFjGDduHMaNG2dxmxACGzduxJIlS/DKK68AAP70pz/B398f+/fvx4QJE/DNN98gOzsbZ8+exfDhwwEAH330EV588UWsXbsWgYGB2LFjB6qqqrBt2zZoNBoMGjQIBQUFWL9+vXQBYNOmTXjhhRewYMECAMDKlSthMBiwZcsWpKenW6xfZWUlKisrpccVFRUAgOrqalRXV5uVN62rv83dRVjcv6V9OCJrcamBWmOrH5fa4iOi9nX06FEkJCTgiSeewIMHD/Duu+8iKioKly9fRqdOnQAA8+fPR1ZWFvbs2QNvb28kJibitddew4kTJwAANTU1iImJgU6nw8mTJ3Hjxg1MmTIFbm5u+MMf/gAAuH79OmJiYjBr1izs2LEDOTk5ePvttxEQEIDo6GgAwK5du5CUlIT09HRERERg48aNiI6ORnFxMfz8/OxzgIiIiIiIVIwN+0TUqOvXr8NoNCIyMlJa5+3tjYiICOTl5WHChAnIy8uDj4+P1KgPAJGRkXB2dsbp06fx6quvIi8vD6NGjYJGo5HKREdH48MPP8Qvv/yCrl27Ii8vD0lJSbLnj46ONhsaqK7U1FQsX77cbP2hQ4fg5eVl9e8MBoPs8eoRlsspbSig+nGpiVpjM8V19+5dO9eEiJQkOztb9jgjIwN+fn7Iz8/HqFGjcOvWLXz++efIzMzE888/DwDYvn07BgwYgFOnTmHkyJE4dOgQLl++jMOHD8Pf3x9hYWFYuXIlFi1ahJSUFGg0GqSnpyMkJATr1q0DAAwYMADHjx/Hhg0bpIb99evXY8aMGZg6dSoAID09HVlZWdi2bRsWL15sw6NCRERERNQxsGGfiBplNBoBAP7+/rL1/v7+0jaj0WjWI8/V1RW+vr6yMiEhIWb7MG3r2rUrjEZjg89jSXJysuxiQEVFBYKCghAVFQWtVmtWvrq6GgaDAWPHjoWbm5u0fnDKQavPUd+llOgml7UVa3GpgVpjqx+X6W4TIqKWuHXrFgDA19cXAJCfn4/q6mrZhfn+/fujV69eyMvLw8iRI5GXl4chQ4bIzr3R0dGYPXs2ioqK8PjjjyMvL0+2D1OZefPmAQCqqqqQn5+P5ORkabuzszMiIyORl5dnsa7NvdsOML+zzt1ZSH+jJmq+i0uNsakpFiIiIlIWNuwTkeK5u7vD3d3dbL2bm1uDjcD1t1fWODX5OR25cbmxuJVMrbGZ4lJjbERkG7W1tZg3bx6eeuopDB48GMDDi+YajQY+Pj6ysvUvzFu6oG7a1lCZiooK3Lt3D7/88gtqamoslrly5YrF+rbkbjtrd9ap/W4uNVJTbLzbjoiIiOyFDftE1CidTgcAKC0tRUBAgLS+tLQUYWFhUpmysjLZ3z148AA3b96U/l6n05lN2Gd63FgZ03Yiap7U1FTs3bsXV65cgaenJ5588kl8+OGH6Nevn1Rm9OjROHr0qOzvfve738nmtSgpKcHs2bPx9ddfo3PnzoiPj0dqaipcXX/7KpGbm4ukpCQUFRUhKCgIS5YswVtvvSXbb1paGtasWQOj0YjQ0FB89NFHGDHCSmsdETVZQkICLl26hOPHj9u7Kk3S3LvtAPM769ydBVYOr1X93VxqosbYeLcdERER2Qsb9omoUSEhIdDpdMjJyZEa8isqKnD69GnMnj0bAKDX61FeXo78/HyEh4cDAI4cOYLa2lpERERIZf7zP/8T1dXV0o85g8GAfv36oWvXrlKZnJwc6fZ+Uxm9Xm+jaInUpSmTawLAjBkzsGLFCulx3R6znFyTyLElJibiwIEDOHbsGHr27Cmt1+l0qKqqQnl5uazXft0L5jqdDmfOnJHtr6kX3bVaLTw9PeHi4gIXF5dmXZhvyd121u6sU+sdT2qNC1BXbGqJg4iIiJTHuTmFU1NT8cQTT6BLly7w8/NDbGwsiouLZWXu37+PhIQEdOvWDZ07d0ZcXJzZl/ySkhLExMTAy8sLfn5+WLBgAR48eCArk5ubi2HDhsHd3R19+vRBRkaGWX3S0tLQu3dveHh4ICIiwuxHCRE13e3bt1FQUICCggIADxvpCgoKUFJSAicnJ8ybNw/vv/8+/vznP6OwsBBTpkxBYGAgYmNjATycSO+FF17AjBkzcObMGZw4cQKJiYmYMGECAgMDAQBvvPEGNBoNpk+fjqKiIuzatQubNm2S9dibO3cusrOzsW7dOly5cgUpKSk4d+4cEhMTbX1IiFQhOzsbb731FgYNGoTQ0FBkZGSgpKQE+fn5snJeXl7Q6XTSUrfHrGlyzS+++AJhYWEYN24cVq5cibS0NFRVVQGAbHLNAQMGIDExEf/2b/+GDRs2SPupO7nmwIEDkZ6eDi8vL2zbts1q/SsrK1FRUSFbgN/G4ba0AA978rq7/LY0VJ6L/NjZuw5KXpry3mxLQggkJiZi3759OHLkiNk8NuHh4XBzc0NOTo60rri4GCUlJdIFc71ej8LCQtlddwaDAVqtFgMHDpTK1N2HqYxpHxqNBuHh4bIytbW1yMnJ4YV5IqJ21ntxltlCREQdQ7N67Del19/8+fORlZWFPXv2wNvbG4mJiXjttddw4sQJAOz1R+Sozp07h+eee056bGpsj4+PR0ZGBhYuXIg7d+5g5syZKC8vx9NPP43s7Gx4eHhIf7Njxw4kJiZizJgxcHZ2RlxcHDZv3ixt9/b2xqFDh5CQkIDw8HB0794dS5cuxcyZM6UyTz75JDIzM7FkyRK8++676Nu3L/bv3y+NF0xErVN/ck2THTt24IsvvoBOp8PLL7+M9957T+q1b6/JNYGWjcMNACuH18oef/XVV1bLkpyaxr62B2vHrz3G4U5ISEBmZia+/PJLdOnSRRoT39vbG56envD29sb06dORlJQEX19faLVazJkzB3q9HiNHjgQAREVFYeDAgZg8eTJWr14No9GIJUuWICEhQepRP2vWLGzZsgULFy7EtGnTcOTIEezevRtZWb81HiUlJSE+Ph7Dhw/HiBEjsHHjRty5cwdTp05t87iJiIiIiKiZDfvZ2dmyxxkZGfDz80N+fj5GjRqFW7du4fPPP0dmZiaef/55AMD27dsxYMAAnDp1CiNHjpR6/R0+fBj+/v4ICwvDypUrsWjRIqSkpECj0ch6/QEPewIfP34cGzZskBr26/b6Ax72FMzKysK2bduwePFii/WvrKxEZWWl9Lh+r7/6TOvcnYXF9UpQt/eYUjEG6/trS6NHj4YQwup2JycnrFixQjZUR32+vr7IzMxs8HmGDh2Kv/3tbw2Wef311/H66683XGEiajZLk2sCD++mCQ4ORmBgIC5evIhFixahuLgYe/fuBWC/yTWB5o/DXV39cPzm9845o7L2t2E7LqVEN3hsSJ1jX9tSY8evPcbh3rp1K4CH5/C6tm/fLs1vsWHDBulie2VlJaKjo/Hxxx9LZV1cXHDgwAHMnj0ber0enTp1Qnx8vOx8HxISgqysLMyfPx+bNm1Cz5498dlnn0nfywFg/Pjx+Omnn7B06VIYjUaEhYUhOzvbLOeJqG00ZQ6d+/fv45133sHOnTtl+V83L9tqDh0iahspKSlmnVr69esnfV9mXhNRXa0aY79+r7/8/HxUV1fLeuz1798fvXr1Ql5eHkaOHMlef3aiht53jOE37dHrj4jUz9rkmnXvmhkyZAgCAgIwZswYXLt2DY8++qitqynTknG4AaCy1kk2HjcbqptOTWNf24O149cex7ShC/ImHh4eSEtLQ1pamtUywcHBjX6/HT16NC5cuNBgmcTERA6dR2QjjnQ3vb1x6BlSm0GDBuHw4cPS47oN8h0lr4maw9J54LtVMXaoie21uGHfUq8/o9EIjUYjm5wLeNgbr7EefaZtDZVhr7/mU0PvO8Zgrj16/RGRulmbXNMS04TXV69exaOPPmq3yTWJiIjIMke6m76+5t4p31ruLo1f5FQS04gB9UcOaA4l3+3ellp757y9jqOrq6vF78f2zOuOoCM3DpNytbhh31qvP0fWkXv9qaH3HWOQ74eIqCmEEJgzZw727duH3Nxcs8k1LTFNoh0QEADg4cSZH3zwAcrKyqR5bCxNrlm/x6+1yTVNk26bJtdkD18iao3BKQdl39UB/hCnjsded9Nb0tI75Vtq9Yg236VDqD9yQHMocZSB9tTSO+ftdaf8t99+i8DAQHh4eECv1yM1NRW9evWya14D7T+8taWLdJbKWruY19SyrX1+S9vVfDFNCTE297Vz5Fiaq0UN+9Z6/el0OlRVVaG8vFzWa79ubzz2+iMiIrKdxibXvHbtGjIzM/Hiiy+iW7duuHjxIubPn49Ro0Zh6NChADi5JhERkSOz5930np6eZvVp7p3yrTU45WCb79Oe3J0FVg6vNRs5oDmUNMpAe2rtnfP2uFM+IiICGRkZ6NevH27cuIHly5fjmWeewaVLl+ya10D7D29t6SKdpbLWLuY1tWxrn98SNQwd3RhHjrG5r52ahrduVsN+Y73+wsPD4ebmhpycHMTFxQEAiouLUVJSIvXYY68/InIUlnr4EalNY5NrajQaHD58WGpkDwoKQlxcHJYsWSKV5eSaREREjsvR7qZv6Z3yLaXW7/P1Rw5oDt7hLdfS9549juO4ceOk/w8dOhQREREIDg7G7t27rTa420p7D29t6SKdpbLWLuY1tWxrn78uNQwd3RglxNjc105Nw1s3q2G/sV5/3t7emD59OpKSkuDr6wutVos5c+ZAr9dj5MiRANjrj4iIyJYam1wzKCgIR48ebXQ/nFyTiIjI8dj7bnpyTNYmFOYwZcrj4+ODxx57DFevXsXYsWPtmtftPby1pQtZlspau+DV1LKtfX5rz+2ojd5txZFjbO5r56hxtIRzcwpv3boVt27dwujRoxEQECAtu3btksps2LABL730EuLi4jBq1CjodDrs3btX2m7q9efi4gK9Xo8333wTU6ZMsdjrz2AwIDQ0FOvWrbPY62/t2rVYunQpwsLCUFBQwF5/REREREREpHpCCCQmJmLfvn04cuRIg3fTm1i6m76wsBBlZWVSGUt309fdh6mMaR9E1L5u376Na9euISAggHlNRGaaPRRPYzw8PJCWloa0tDSrZdjrj4iIiIiIiKhlHOlueiJqO7///e/x8ssvIzg4GD/++COWLVsGFxcXTJw4kXlNRGZaNHkuEREREREREdlHY3PoAA/vpnd2dkZcXBwqKysRHR2Njz/+WCrbVnPoEFHb+cc//oGJEyfi559/Ro8ePfD000/j1KlT6NGjBwDmNRHJsWGfiIiIiIiISEEc7W56ImobO3fubHA785qI6mLDPhFRC1iakIqTURERERERERERkS00a/JcIiIiIiIiIiIiIiKyLzbsExEREREREREREREpCBv2iYiIiIiIiIiIiIgUhGPsExEREREREREREZFDsDSvIcC5Detjwz4RERERERERkcpZaihjIxkRkXJxKB4iIiIiIiIiIiIiIgVhwz4RERERERERERERkYJwKB4iojbCMeCIiIiIiIiIiMgW2GOfiIiIiIiIiIiIiEhB2GOfiIiIiIiIiByetTtkqeU4oS4RkXKxxz4RERERERERERERkYKwYZ+IiIiIiIiIiIiISEE4FE8L8FY1IiIiIiIiIiIiIrIXNuwTEbUzXgwkIiIiIiIiIqK2xIZ9IiIiIiIiIiICYH2SYnZOIiJyLGzYJyJSIEtftr9dGWWHmhARERERERERka1x8lwiIiIiIiIiIiIiIgVhj30iIhXjbbREREREREREROrDhn0iIgdmrWHeksEpB7F6xMN/K2uc2rFWRERERETtqznfg8k2LL0m7DBERGQ/HIqHiIiIiIiIiIiIiEhBFN+wn5aWht69e8PDwwMRERE4c+aMXerRe3GW2UJEreMo+d0e+JlBHZmac5uoo2N+E6kTc5tIvZjfRMql6KF4du3ahaSkJKSnpyMiIgIbN25EdHQ0iouL4efnZ+/qEVErML/bV1MvJPDWWmprzG0i9XKk/OZwEURtx5FymxwPP2+VjflNpGyKbthfv349ZsyYgalTpwIA0tPTkZWVhW3btmHx4sVm5SsrK1FZWSk9vnXrFgDg5s2bqK6uNitfXV2Nu3fvwrXaGTW1zR+vus/vd1tcfzp5TLP31VKmGH7++We4ubnZ7HnbEmMw9+uvvwIAhBCt3pejak5+2zq324ulz4zmfEi71grcvVvbpnFZ+xyzpD0/29TwOWBJ/biY2+137v7555/bOhTVUWue2Upjx4/53bpzNwC4Prgjf9zM855SPgfUnItqjI253fpztzX1c76jaI/v9LbmCG0hQOs/c5jf7fO729r52FLOWypr7bOhqWVb+/x1qfG8Vp+9Ymyv1xlQWW4LhaqsrBQuLi5i3759svVTpkwR//qv/2rxb5YtWyYAcOGimuWHH36wQbbZXnPzm7nNRW0Lc/s3zG8ualuY3w8xt7mobWFu/4b5zUVtC/P7IeY2F7UtashtxfbY/+c//4mamhr4+/vL1vv7++PKlSsW/yY5ORlJSUnS49raWty8eRPdunWDk5P5lfCKigoEBQXhhx9+gFarbdsAbIQxOIa2jkEIgV9//RWBgYFtUDvH09z87oi5bYla4wLUG1v9uJjb5pjftsNj1zqNHT/mt1xzc9sStb5n1RoXoM7YmNvm2iK/OzI15om9tPZYMr/l+L3cHGNUJjXltmIb9lvC3d0d7u7usnU+Pj6N/p1Wq1X8m5cxOIa2jMHb27tN9qMGHTm3LVFrXIB6Y6sbF3Nbjvltezx2rdPQ8WN+/6aluW2JWt+zao0LUF9szG25tszvjkxteWJPrTmWzO/f8Hu5dYxRedSS2872rkBLde/eHS4uLigtLZWtLy0thU6ns1OtiKgtML+J1Im5TaRezG8idWJuE6kX85tI+RTbsK/RaBAeHo6cnBxpXW1tLXJycqDX6+1YMyJqLeY3kToxt4nUi/lNpE7MbSL1Yn4TKZ+ih+JJSkpCfHw8hg8fjhEjRmDjxo24c+eONJt3a7m7u2PZsmVmtxopCWNwDGqIwdbaM7/V+nqoNS5AvbGpNa6G8NztuHjsWofHr/3zuz61HnO1xgWoOzY1s3Vud3TMk7bDY9k4/u5uHcZI9uYkhBD2rkRrbNmyBWvWrIHRaERYWBg2b96MiIgIe1eLiNoA85tInZjbROrF/CZSJ+Y2kXoxv4mUS/EN+0REREREREREREREHYlix9gnIiIiIiIiIiIiIuqI2LBPRERERERERERERKQgbNgnIiIiIiIiIiIiIlIQNuwTERERERERERERESkIG/atSEtLQ+/eveHh4YGIiAicOXPG3lWSHDt2DC+//DICAwPh5OSE/fv3y7YLIbB06VIEBATA09MTkZGR+Pbbb2Vlbt68iUmTJkGr1cLHxwfTp0/H7du3bVL/1NRUPPHEE+jSpQv8/PwQGxuL4uJiWZn79+8jISEB3bp1Q+fOnREXF4fS0lJZmZKSEsTExMDLywt+fn5YsGABHjx4YJMYAGDr1q0YOnQotFottFot9Ho9/vrXvyoqho7IkXO7qZqSQ6NHj4aTk5NsmTVrlp1q3DQpKSlmde7fv7+0vSk55ah69+5tFpuTkxMSEhIAKPP1sqfm5vGePXvQv39/eHh4YMiQIfjqq69sVFPH05xjl5GRYfa+9PDwsGFtHUdj370syc3NxbBhw+Du7o4+ffogIyOj3evZkXSU87mSz30mq1atgpOTE+bNmyetU0NcRK3B83Hr8dzs+NRwrramsd+uStMW7YxkH2zYt2DXrl1ISkrCsmXLcP78eYSGhiI6OhplZWX2rhoA4M6dOwgNDUVaWprF7atXr8bmzZuRnp6O06dPo1OnToiOjsb9+/elMpMmTUJRUREMBgMOHDiAY8eOYebMmTap/9GjR5GQkIBTp07BYDCguroaUVFRuHPnjlRm/vz5+Mtf/oI9e/bg6NGj+PHHH/Haa69J22tqahATE4OqqiqcPHkSf/zjH5GRkYGlS5faJAYA6NmzJ1atWoX8/HycO3cOzz//PF555RUUFRUpJoaOxtFzu6makkMAMGPGDNy4cUNaVq9ebacaN92gQYNkdT5+/Li0rbGccmRnz56VxWUwGAAAr7/+ulRGia+XPTQ3j0+ePImJEydi+vTpuHDhAmJjYxEbG4tLly7ZuOb215LPQK1WK3tffv/99zasseNo7LtXfdevX0dMTAyee+45FBQUYN68eXj77bdx8ODBdq5px9CRzudKPvcBD89/n3zyCYYOHSpbr/S4iFqD5+O2wXOzY1PLubohDf12VZq2aGckOxFkZsSIESIhIUF6XFNTIwIDA0Vqaqoda2UZALFv3z7pcW1trdDpdGLNmjXSuvLycuHu7i7++7//WwghxOXLlwUAcfbsWanMX//6V+Hk5CT+7//+z2Z1NykrKxMAxNGjR6X6urm5iT179khlvvnmGwFA5OXlCSGE+Oqrr4Szs7MwGo1Sma1btwqtVisqKyttG0AdXbt2FZ999pmiY1AzJeV2c9TPISGEePbZZ8XcuXPtV6kWWLZsmQgNDbW4rSk5pSRz584Vjz76qKitrRVCKPP1spfm5vG///u/i5iYGNm6iIgI8bvf/a5d6+mImnvstm/fLry9vW1UO+Wo/93LkoULF4pBgwbJ1o0fP15ER0e3Y806jo5yPlf6ue/XX38Vffv2FQaDQXaeU3pcRK3F83Hb47nZ8aj1XG3S0G9XpWtJOyPZD3vs11NVVYX8/HxERkZK65ydnREZGYm8vDw71qxprl+/DqPRKKu/t7c3IiIipPrn5eXBx8cHw4cPl8pERkbC2dkZp0+ftnmdb926BQDw9fUFAOTn56O6uloWQ//+/dGrVy9ZDEOGDIG/v79UJjo6GhUVFVKPeVuqqanBzp07cefOHej1ekXGoHZKz+2G1M8hkx07dqB79+4YPHgwkpOTcffuXXtUr1m+/fZbBAYG4pFHHsGkSZNQUlICoGmfC0pRVVWFL774AtOmTYOTk5O0Xomvl621JI/z8vJk5YGHn7VKe9+0Vks/A2/fvo3g4GAEBQXJ7kqjhvF913460vlc6ee+hIQExMTEmOWC0uMiag2ej+2H52bbUfO5ui5rv13VpintjGQ/rvaugKP55z//iZqaGlljKwD4+/vjypUrdqpV0xmNRgCwWH/TNqPRCD8/P9l2V1dX+Pr6SmVspba2FvPmzcNTTz2FwYMHS/XTaDTw8fGRla0fg6UYTdtspbCwEHq9Hvfv30fnzp2xb98+DBw4EAUFBYqJoaNQem5bYymHAOCNN95AcHAwAgMDcfHiRSxatAjFxcXYu3evHWvbsIiICGRkZKBfv364ceMGli9fjmeeeQaXLl1q0ueCUuzfvx/l5eV46623pHVKfL3soSV5bO2zVmnvm9ZqybHr168ftm3bhqFDh+LWrVtYu3YtnnzySRQVFaFnz562qLZiWXvfVVRU4N69e/D09LRTzZSvI53PlXzu27lzJ86fP4+zZ8+abVNyXEStxfOx/fDcbDtqPVfX1dBv1y5duti7em2qKe2MZD9s2Ce7SkhIwKVLlxQ7Flm/fv1QUFCAW7du4X/+538QHx+Po0eP2rta1IFYy6G6c2YMGTIEAQEBGDNmDK5du4ZHH33U1tVsknHjxkn/Hzp0KCIiIhAcHIzdu3er6ov2559/jnHjxiEwMFBap8TXi9RPr9dDr9dLj5988kkMGDAAn3zyCVauXGnHmhGpj9K/E9f1ww8/YO7cuTAYDJzgk6gN8HxM5Hga+u06ffp0O9aMOhoOxVNP9+7d4eLigtLSUtn60tJS6HQ6O9Wq6Ux1bKj+Op3ObMKSBw8e4ObNmzaNMTExEQcOHMDXX38t62mg0+lQVVWF8vJyWfn6MViK0bTNVjQaDfr06YPw8HCkpqYiNDQUmzZtUlQMHYXSc9sSazlkSUREBADg6tWrtqham/Dx8cFjjz2Gq1evNimnlOD777/H4cOH8fbbbzdYTomvly20JI+tfdYq6X3TFtriM9DNzQ2PP/4435dNYO19p9VqVXWh0h460vlcqee+/Px8lJWVYdiwYXB1dYWrqyuOHj2KzZs3w9XVFf7+/oqMi6gt8HxsPzw3244az9WNqfvbVW2a0s5I9sOG/Xo0Gg3Cw8ORk5MjrautrUVOTo7sKrmjCgkJgU6nk9W/oqICp0+fluqv1+tRXl6O/Px8qcyRI0dQW1srNSa1JyEEEhMTsW/fPhw5cgQhISGy7eHh4XBzc5PFUFxcjJKSElkMhYWFsgsUBoMBWq0WAwcObPcYrKmtrUVlZaWiY1Arped2XY3lkCUFBQUAgICAgHauXdu5ffs2rl27hoCAgCbllBJs374dfn5+iImJabCcEl8vW2hJHuv1ell54OFnrZLeN22hLT4Da2pqUFhYyPdlE/B913460vlcqee+MWPGoLCwEAUFBdIyfPhwTJo0Sfq/EuMiags8H9sPz822o6ZzdVPV/e2qNk1pZyQ7svPkvQ5p586dwt3dXWRkZIjLly+LmTNnCh8fH2E0Gu1dNSGEEL/++qu4cOGCuHDhggAg1q9fLy5cuCC+//57IYQQq1atEj4+PuLLL78UFy9eFK+88ooICQkR9+7dk/bxwgsviMcff1ycPn1aHD9+XPTt21dMnDjRJvWfPXu28Pb2Frm5ueLGjRvScvfuXanMrFmzRK9evcSRI0fEuXPnhF6vF3q9Xtr+4MEDMXjwYBEVFSUKCgpEdna26NGjh0hOTrZJDEIIsXjxYnH06FFx/fp1cfHiRbF48WLh5OQkDh06pJgYOhpHz+2maiyHrl69KlasWCHOnTsnrl+/Lr788kvxyCOPiFGjRtm55g175513RG5urrh+/bo4ceKEiIyMFN27dxdlZWVCiMZzytHV1NSIXr16iUWLFsnWK/X1spfG8njy5Mli8eLFUvkTJ04IV1dXsXbtWvHNN9+IZcuWCTc3N1FYWGivEOymucdu+fLl4uDBg+LatWsiPz9fTJgwQXh4eIiioiJ7hWA3jX33Wrx4sZg8ebJU/u9//7vw8vISCxYsEN98841IS0sTLi4uIjs7214hqEpHOZ8Lofxzn8mzzz4r5s6dKz1WS1xELcHzcdvgudmxqeVcbU1jv12Vpi3aGck+2LBvxUcffSR69eolNBqNGDFihDh16pS9qyT5+uuvBQCzJT4+XgghRG1trXjvvfeEv7+/cHd3F2PGjBHFxcWyffz8889i4sSJonPnzkKr1YqpU6eKX3/91Sb1t1R3AGL79u1SmXv37on/+I//EF27dhVeXl7i1VdfFTdu3JDt57vvvhPjxo0Tnp6eonv37uKdd94R1dXVNolBCCGmTZsmgoODhUajET169BBjxoyRGvWVEkNH5Mi53VSN5VBJSYkYNWqU8PX1Fe7u7qJPnz5iwYIF4tatW/ateCPGjx8vAgIChEajEf/yL/8ixo8fL65evSptb0pOObKDBw8KAGafx0p9veypoTx+9tlnpfOhye7du8Vjjz0mNBqNGDRokMjKyrJxjR1Hc47dvHnzpLL+/v7ixRdfFOfPn7dDre2vse9e8fHx4tlnnzX7m7CwMKHRaMQjjzwi+55DrdcRzudCKP/cZ1K/YV8tcRG1FM/Hrcdzs+NTw7namsZ+uypNW7Qzkn04CSFEO90MQEREREREREREREREbYxj7BMRERERERERERERKQgb9omIiIiIiIiIiIiIFIQN+0RERERERERERERECsKGfSIiIiIiIiIiIiIiBWHDPhERERERERERERGRgrBhn4iIiIiIiIiIiIhIQdiwT0RERERERERERESkIGzYJyIiIiIiIiIiIiJSEDbsExEREREREREREREpCBv2iYiIiIiIiIiIiIgUhA37REREREREREREREQK8v8rMP8TAQRK1QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1500x1000 with 36 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loan_status\n",
      "0    50295\n",
      "1     8350\n",
      "Name: count, dtype: int64\n",
      "loan_status\n",
      "0    0.857618\n",
      "1    0.142382\n",
      "Name: proportion, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train['creditworthiness_score'] = (train['person_income'].astype('float64') / (train['loan_amnt'].astype('float64') * train['loan_int_rate'].astype('float64'))) * (train['cb_person_cred_hist_length'].astype('float64') + 1).astype('float64')\n",
    "# train['age_to_employment'] = (train['person_age'].astype('float64') / (train['person_emp_length'].astype('float64') + 1)).astype('float64')\n",
    "# train['intent_home_match'] = ((train['loan_intent'].astype('float64') == 5) & (train['person_home_ownership'].astype('float64') == 2)).astype('float64')\n",
    "# train['normalized_income'] = train.groupby('age_category')['person_income'].transform(lambda x: ((x.astype('float64') - x.mean().astype('float64')) / x.std().astype('float64'))).astype('float64')\n",
    "# train['rate_to_age'] = (train['loan_int_rate'].astype('float64') / train['person_age'].astype('float64')).astype('float64')\n",
    "# train['risk_score'] = train['loan_percent_income'] * train['loan_int_rate'] * (6 - train['loan_grade'].astype('float64'))\n",
    "# train['loan_intent_grade'] = ((train['loan_intent'].astype('float64') * 10 + train['loan_grade'].astype('float64'))/100).astype('category')\n",
    "# train['income_category'] = train['person_income'].apply(categorize_income, args=(income_quantiles,)).astype('category')\n",
    "# train['age_interest_interaction'] = (train['person_age'].astype('float64') * train['loan_int_rate'].astype('float64')).astype('float64')   \n",
    "# train['credit_history_to_age'] = (train['cb_person_cred_hist_length'].astype('float64') / train['person_age'].astype('float64')).astype('float64')\n",
    "# train['rate_to_credit_history'] = (train['loan_int_rate'].astype('float64') / (train['cb_person_cred_hist_length'].astype('float64') + 1)).astype('float64')\n",
    "# train[\"loantoincome\"] = ((train[\"loan_amnt\"] / train[\"person_income\"])).astype('Float64')\n",
    "# train[\"loan_percent_incometoincome\"] = ((train[\"loan_percent_income\"] / train[\"person_income\"])).astype('Float64')\n",
    "# train['person_age_to_person_income'] = (train['person_age'] / train['person_income']).astype(str).astype('Float64')\n",
    "# train['person_emp_length_to_person_age'] = (train['person_emp_length'] / train['person_age']).astype('Float64')\n",
    "# train['loan_int_rate_to_loan_amnt'] = (train['loan_int_rate'] / train['loan_amnt']).astype('Float64')\n",
    "# train['income_to_age'] = train['person_income'] / train['person_age']\n",
    "# train['rate_to_loan'] = train['loan_int_rate'] / train['loan_amnt']\n",
    "# train['person_home_ownership'] = train['person_home_ownership'].replace({'RENT': 0, 'MORTGAGE': 1, 'OWN': 2, 'OTHER': 3}).astype('category')\n",
    "# train['loan_intent'] = train['loan_intent'].replace({'EDUCATION': 0, 'MEDICAL': 1, 'PERSONAL': 2, 'VENTURE': 3, 'DEBTCONSOLIDATION': 4, 'HOMEIMPROVEMENT': 5}).astype('category')\n",
    "# train['loan_grade'] = train['loan_grade'].replace({'A':6, 'B':5, 'C':4, 'D':3, 'E':2, 'F':1, 'G':0}).astype('category')\n",
    "# train['cb_person_default_on_file'] = train['cb_person_default_on_file'].replace({'N': 0, 'Y': 1}).astype('category')\n",
    "# train[\"person_home_ownership_income\"] = pd.Series(pd.factorize((train[\"person_home_ownership\"].astype(str) + train[\"person_income\"].astype(str)).to_numpy())[0]).astype('category')\n",
    "# train['log_income'] = np.log1p(train['person_income']).astype('float64')\n",
    "# train['age_credit_history_interaction'] = (train['person_age'] * train['cb_person_cred_hist_length']).astype('float64')\n",
    "# train['high_loan_to_income'] = (train['loan_percent_income'] > 0.5).astype('float64')\n",
    "# train['is_new_credit_user'] = (train['cb_person_cred_hist_length'] < 2).astype('float64')\n",
    "# train['high_interest_rate'] = (train['loan_int_rate'] > train['loan_int_rate'].mean()).astype('float64')\n",
    "# train['loan_to_employment'] = (train['loan_amnt'] / (train['person_emp_length'] + 1)).astype('float64')\n",
    "# train['rate_to_grade'] = train.groupby('loan_grade')['loan_int_rate'].transform('mean').astype('float64')\n",
    "# train['age_category'] = train['person_age'].apply(categorize_age).astype('category')\n",
    "# train['age_to_credit_history'] = (train['person_age'] / (train['cb_person_cred_hist_length'] + 1)).astype('float64')\n",
    "# train['income_to_loan'] = (train['person_income'] / train['loan_amnt']).astype('float64')\n",
    "# train['normalized_loan_amount'] = train.groupby('loan_intent')['loan_amnt'].transform(lambda x: (x - x.mean()) / x.std()).astype('float64')\n",
    "# train['log_loan_amnt'] = np.log1p(train['loan_amnt']).astype('float64')\n",
    "# train['income_home_mismatch'] = ((train['person_income'] > train['person_income'].quantile(0.8)) & (train['person_home_ownership'] == 0)).astype('float64')\n",
    "# train['default_grade_interaction'] = ((train['cb_person_default_on_file'].astype('float64')*10 +  train['loan_grade'].astype('float64'))/16).astype('category')\n",
    "\n",
    "\n",
    "\n",
    "# Plot histograms for numerical columns\n",
    "numerical_columns = ['person_age','loantoincome','person_emp_length_to_person_age',\n",
    "                     'loan_int_rate_to_loan_amnt','loan_percent_incometoincome',\n",
    "                     'person_age_to_person_income','person_income', 'loan_amnt',\"person_emp_length\" ,\n",
    "                     'loan_int_rate', 'loan_percent_income', 'cb_person_cred_hist_length','income_to_age','rate_to_loan','log_income',\n",
    "                     'age_credit_history_interaction','high_loan_to_income','is_new_credit_user','high_interest_rate','loan_to_employment','rate_to_grade',\n",
    "                     'risk_score','age_to_credit_history','income_to_loan','normalized_loan_amount','log_loan_amnt','income_home_mismatch',\n",
    "                     'age_interest_interaction','credit_history_to_age','rate_to_credit_history',\n",
    "                     'creditworthiness_score','age_to_employment','intent_home_match','normalized_income','rate_to_age',\n",
    "                     'default_rate_interaction'\n",
    "                     ]\n",
    "train[numerical_columns].hist(bins=30, figsize=(15, 10))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot count plots for categorical columns\n",
    "categorical_columns = ['person_home_ownership', 'loan_intent', 'loan_grade', 'cb_person_default_on_file', 'loan_status',\n",
    "    \"person_home_ownership_income\",\n",
    "    'age_category',\n",
    "    'loan_intent_grade',\n",
    "    'income_category',\n",
    "    'default_grade_interaction',\n",
    "    'loan_amount_category',\n",
    "    'age_income_mismatch',\n",
    "    'high_loan_amount',\n",
    "    'home_ownership_loan_interaction',\n",
    "    'loan_int_rate_category',\n",
    "    'intent_grade_interaction',\n",
    "    'home_ownership_intent',\n",
    "]\n",
    "numerical_features = numerical_columns\n",
    "categorical_features = categorical_columns\n",
    "if  not  DEV:\n",
    "    fig, axes = plt.subplots(math.ceil(len(categorical_columns)/2)+1, 2, figsize=(15, 15))  # Adjusted to 3x2 grid\n",
    "    for ax, col in zip(axes.flatten(), categorical_columns):\n",
    "        sns.countplot(data=train, x=col, ax=ax)\n",
    "        ax.set_title(f'Distribution of {col}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "features = numerical_columns + categorical_columns \n",
    "categorical_columns.remove('loan_status')\n",
    "features.remove('loan_status')\n",
    "# Define the preprocessing for numerical and categorical features\n",
    "#print how many 'load_status' 0 and 1 and find the ratio\n",
    "print(train['loan_status'].value_counts())\n",
    "print(train['loan_status'].value_counts(normalize=True))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58645, 54)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_intent</th>\n",
       "      <th>loan_grade</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_default_on_file</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>loantoincome</th>\n",
       "      <th>loan_percent_incometoincome</th>\n",
       "      <th>person_age_to_person_income</th>\n",
       "      <th>person_emp_length_to_person_age</th>\n",
       "      <th>loan_int_rate_to_loan_amnt</th>\n",
       "      <th>income_to_age</th>\n",
       "      <th>rate_to_loan</th>\n",
       "      <th>person_home_ownership_income</th>\n",
       "      <th>log_income</th>\n",
       "      <th>age_credit_history_interaction</th>\n",
       "      <th>high_loan_to_income</th>\n",
       "      <th>is_new_credit_user</th>\n",
       "      <th>high_interest_rate</th>\n",
       "      <th>loan_to_employment</th>\n",
       "      <th>rate_to_grade</th>\n",
       "      <th>age_category</th>\n",
       "      <th>age_to_credit_history</th>\n",
       "      <th>income_to_loan</th>\n",
       "      <th>normalized_loan_amount</th>\n",
       "      <th>log_loan_amnt</th>\n",
       "      <th>income_home_mismatch</th>\n",
       "      <th>default_grade_interaction</th>\n",
       "      <th>age_interest_interaction</th>\n",
       "      <th>credit_history_to_age</th>\n",
       "      <th>rate_to_credit_history</th>\n",
       "      <th>high_loan_amount</th>\n",
       "      <th>age_income_mismatch</th>\n",
       "      <th>loan_int_rate_category</th>\n",
       "      <th>default_rate_interaction</th>\n",
       "      <th>intent_grade_interaction</th>\n",
       "      <th>home_ownership_intent</th>\n",
       "      <th>loan_amount_category</th>\n",
       "      <th>risk_score</th>\n",
       "      <th>loan_intent_grade</th>\n",
       "      <th>income_category</th>\n",
       "      <th>creditworthiness_score</th>\n",
       "      <th>age_to_employment</th>\n",
       "      <th>intent_home_match</th>\n",
       "      <th>normalized_income</th>\n",
       "      <th>rate_to_age</th>\n",
       "      <th>home_ownership_loan_interaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>35000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6000</td>\n",
       "      <td>11.49</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>945.945946</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>0</td>\n",
       "      <td>10.463132</td>\n",
       "      <td>518.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>11.034733</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.466667</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>-0.558667</td>\n",
       "      <td>8.699681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>425.13</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.766000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9533</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.615318</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.838998</td>\n",
       "      <td>0.310541</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>56000</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4000</td>\n",
       "      <td>13.35</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.003337</td>\n",
       "      <td>2545.454545</td>\n",
       "      <td>0.003337</td>\n",
       "      <td>1</td>\n",
       "      <td>10.933125</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>571.428571</td>\n",
       "      <td>13.510343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>-0.896247</td>\n",
       "      <td>8.294300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>293.70</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>4.450000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.8690</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.146067</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.107897</td>\n",
       "      <td>0.606818</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>28800</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6000</td>\n",
       "      <td>8.90</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.001483</td>\n",
       "      <td>993.103448</td>\n",
       "      <td>0.001483</td>\n",
       "      <td>2</td>\n",
       "      <td>10.268165</td>\n",
       "      <td>290.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>666.666667</td>\n",
       "      <td>7.335176</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.636364</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>-0.584460</td>\n",
       "      <td>8.699681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>258.10</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.809091</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.932584</td>\n",
       "      <td>3.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.928901</td>\n",
       "      <td>0.306897</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>70000</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>12000</td>\n",
       "      <td>11.11</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>2333.333333</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>3</td>\n",
       "      <td>11.156265</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>11.034733</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>0.492919</td>\n",
       "      <td>9.392745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>333.30</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.851667</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.8887</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.150315</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046948</td>\n",
       "      <td>0.370333</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  person_age  person_income person_home_ownership  person_emp_length  \\\n",
       "0   0          37          35000                     0                0.0   \n",
       "1   1          22          56000                     2                6.0   \n",
       "2   2          29          28800                     2                8.0   \n",
       "3   3          30          70000                     0               14.0   \n",
       "\n",
       "  loan_intent loan_grade  loan_amnt  loan_int_rate  loan_percent_income  \\\n",
       "0           0          5       6000          11.49                 0.17   \n",
       "1           1          4       4000          13.35                 0.07   \n",
       "2           2          6       6000           8.90                 0.21   \n",
       "3           3          5      12000          11.11                 0.17   \n",
       "\n",
       "  cb_person_default_on_file  cb_person_cred_hist_length  loan_status  \\\n",
       "0                         0                          14            0   \n",
       "1                         0                           2            0   \n",
       "2                         0                          10            0   \n",
       "3                         0                           5            0   \n",
       "\n",
       "   loantoincome  loan_percent_incometoincome  person_age_to_person_income  \\\n",
       "0      0.171429                     0.000005                     0.001057   \n",
       "1      0.071429                     0.000001                     0.000393   \n",
       "2      0.208333                     0.000007                     0.001007   \n",
       "3      0.171429                     0.000002                     0.000429   \n",
       "\n",
       "   person_emp_length_to_person_age  loan_int_rate_to_loan_amnt  income_to_age  \\\n",
       "0                              0.0                    0.001915     945.945946   \n",
       "1                         0.272727                    0.003337    2545.454545   \n",
       "2                         0.275862                    0.001483     993.103448   \n",
       "3                         0.466667                    0.000926    2333.333333   \n",
       "\n",
       "   rate_to_loan person_home_ownership_income  log_income  \\\n",
       "0      0.001915                            0   10.463132   \n",
       "1      0.003337                            1   10.933125   \n",
       "2      0.001483                            2   10.268165   \n",
       "3      0.000926                            3   11.156265   \n",
       "\n",
       "   age_credit_history_interaction  high_loan_to_income  is_new_credit_user  \\\n",
       "0                           518.0                  0.0                 0.0   \n",
       "1                            44.0                  0.0                 0.0   \n",
       "2                           290.0                  0.0                 0.0   \n",
       "3                           150.0                  0.0                 0.0   \n",
       "\n",
       "   high_interest_rate  loan_to_employment  rate_to_grade age_category  \\\n",
       "0                 1.0         6000.000000      11.034733          0.2   \n",
       "1                 1.0          571.428571      13.510343          0.0   \n",
       "2                 0.0          666.666667       7.335176          0.1   \n",
       "3                 1.0          800.000000      11.034733          0.1   \n",
       "\n",
       "   age_to_credit_history  income_to_loan  normalized_loan_amount  \\\n",
       "0               2.466667        5.833333               -0.558667   \n",
       "1               7.333333       14.000000               -0.896247   \n",
       "2               2.636364        4.800000               -0.584460   \n",
       "3               5.000000        5.833333                0.492919   \n",
       "\n",
       "   log_loan_amnt  income_home_mismatch default_grade_interaction  \\\n",
       "0       8.699681                   0.0                    0.3125   \n",
       "1       8.294300                   0.0                    0.2500   \n",
       "2       8.699681                   0.0                    0.3750   \n",
       "3       9.392745                   0.0                    0.3125   \n",
       "\n",
       "   age_interest_interaction  credit_history_to_age  rate_to_credit_history  \\\n",
       "0                    425.13               0.378378                0.766000   \n",
       "1                    293.70               0.090909                4.450000   \n",
       "2                    258.10               0.344828                0.809091   \n",
       "3                    333.30               0.166667                1.851667   \n",
       "\n",
       "  high_loan_amount age_income_mismatch loan_int_rate_category  \\\n",
       "0            False               False                      2   \n",
       "1            False               False                      3   \n",
       "2            False               False                      1   \n",
       "3            False               False                      2   \n",
       "\n",
       "   default_rate_interaction intent_grade_interaction home_ownership_intent  \\\n",
       "0                       2.0                      5.0                   0.0   \n",
       "1                       3.0                     14.0                  21.0   \n",
       "2                       1.0                     26.0                  22.0   \n",
       "3                       2.0                     35.0                   3.0   \n",
       "\n",
       "  loan_amount_category  risk_score loan_intent_grade income_category  \\\n",
       "0                    1      1.9533              0.05             0.0   \n",
       "1                    0      1.8690              0.14             0.2   \n",
       "2                    1      0.0000              0.26             0.0   \n",
       "3                    3      1.8887              0.35             0.3   \n",
       "\n",
       "   creditworthiness_score  age_to_employment  intent_home_match  \\\n",
       "0                7.615318          37.000000                0.0   \n",
       "1                3.146067           3.142857                0.0   \n",
       "2                5.932584           3.222222                0.0   \n",
       "3                3.150315           2.000000                0.0   \n",
       "\n",
       "   normalized_income  rate_to_age home_ownership_loan_interaction  \n",
       "0          -0.838998     0.310541                             1.0  \n",
       "1          -0.107897     0.606818                            20.0  \n",
       "2          -0.928901     0.306897                            21.0  \n",
       "3           0.046948     0.370333                             3.0  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(train.head(4))\n",
    "#print all the columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(train.shape)\n",
    "train.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['person_age',\n",
       " 'loantoincome',\n",
       " 'person_emp_length_to_person_age',\n",
       " 'loan_int_rate_to_loan_amnt',\n",
       " 'loan_percent_incometoincome',\n",
       " 'person_age_to_person_income',\n",
       " 'person_income',\n",
       " 'loan_amnt',\n",
       " 'person_emp_length',\n",
       " 'loan_int_rate',\n",
       " 'loan_percent_income',\n",
       " 'cb_person_cred_hist_length',\n",
       " 'income_to_age',\n",
       " 'rate_to_loan',\n",
       " 'log_income',\n",
       " 'age_credit_history_interaction',\n",
       " 'high_loan_to_income',\n",
       " 'is_new_credit_user',\n",
       " 'high_interest_rate',\n",
       " 'loan_to_employment',\n",
       " 'rate_to_grade',\n",
       " 'risk_score',\n",
       " 'age_to_credit_history',\n",
       " 'income_to_loan',\n",
       " 'normalized_loan_amount',\n",
       " 'log_loan_amnt',\n",
       " 'income_home_mismatch',\n",
       " 'age_interest_interaction',\n",
       " 'credit_history_to_age',\n",
       " 'rate_to_credit_history',\n",
       " 'creditworthiness_score',\n",
       " 'age_to_employment',\n",
       " 'intent_home_match',\n",
       " 'normalized_income',\n",
       " 'rate_to_age',\n",
       " 'default_rate_interaction',\n",
       " 'person_home_ownership',\n",
       " 'loan_intent',\n",
       " 'loan_grade',\n",
       " 'cb_person_default_on_file',\n",
       " 'person_home_ownership_income',\n",
       " 'age_category',\n",
       " 'loan_intent_grade',\n",
       " 'income_category',\n",
       " 'default_grade_interaction',\n",
       " 'loan_amount_category',\n",
       " 'age_income_mismatch',\n",
       " 'high_loan_amount',\n",
       " 'home_ownership_loan_interaction',\n",
       " 'loan_int_rate_category',\n",
       " 'intent_grade_interaction',\n",
       " 'home_ownership_intent']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((58645, 52), (58645, 1), (39098, 52), (39098,))"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "target = ['loan_status']  # Replace with the actual target column name\n",
    "\n",
    "# Preprocess the data\n",
    "X = train[features]\n",
    "y = train[target]\n",
    "ids = train['id']\n",
    "testx = test[features]\n",
    "test_ids = test['id']\n",
    "\n",
    "X.shape , y.shape , testx.shape,  test_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140748, 52)\n",
      "(35187, 52)\n",
      "(140748, 1)\n",
      "(35187, 1)\n",
      "(140748,)\n",
      "(35187,)\n",
      "(39098, 52)\n",
      "(39098,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test, ids_train, ids_test = train_test_split(X, y, ids, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the preprocessing for numerical and categorical features\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    # ('onehot', OneHotEncoder(handle_unknown='error'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "testx = preprocessor.transform(testx)\n",
    "\n",
    "# Function to add noise\n",
    "def add_noise(data, noise_level=0.01):\n",
    "    noise = np.random.normal(0, noise_level, data.shape)\n",
    "    return data + noise\n",
    "\n",
    "# Add noise to the numerical features\n",
    "X_train_noisy = X_train.copy()\n",
    "X_test_noisy = X_test.copy()\n",
    "X_train_noisy[:, :len(numerical_features)] = add_noise(X_train[:, :len(numerical_features)])\n",
    "X_test_noisy[:, :len(numerical_features)] = add_noise(X_test[:, :len(numerical_features)])\n",
    "\n",
    "\n",
    "X_train_less_noise = X_train.copy()\n",
    "X_test_less_noise = X_test.copy()\n",
    "X_train_less_noise[:, :len(numerical_features)] = add_noise(X_train[:, :len(numerical_features)],noise_level=0.001)\n",
    "X_test_less_noise[:, :len(numerical_features)] = add_noise(X_test[:, :len(numerical_features)],noise_level=0.001)\n",
    "\n",
    "# Concatenate the original data with the noisy data vertically\n",
    "X_train_combined = np.vstack((X_train, X_train_noisy, X_train_less_noise))\n",
    "X_test_combined = np.vstack((X_test, X_test_noisy, X_test_less_noise))\n",
    "\n",
    "# Concatenate the target variable as well\n",
    "y_train_combined = np.vstack((y_train, y_train, y_train))\n",
    "y_test_combined = np.vstack((y_test, y_test,y_test))\n",
    "\n",
    "# Concatenate the ids as well\n",
    "ids_train_combined = np.hstack((ids_train, ids_train, ids_train))\n",
    "ids_test_combined = np.hstack((ids_test, ids_test, ids_test))\n",
    "\n",
    "# Update the original variables\n",
    "X_train = X_train_combined\n",
    "X_test = X_test_combined\n",
    "y_train = y_train_combined\n",
    "y_test = y_test_combined\n",
    "ids_train = ids_train_combined\n",
    "ids_test = ids_test_combined\n",
    "xult , yult  , idsult= np.vstack((X_train, X_test)), np.vstack((y_train, y_test)) , np.hstack((ids_train, ids_test))\n",
    "print(X_train.shape)  # Should output (46916 + 46916, 26)\n",
    "print(X_test.shape)   # Should output (11729 + 11729, 26)\n",
    "print(y_train.shape)  # Should output (46916 + 46916, 1)\n",
    "print(y_test.shape)   # Should output (11729 + 11729, 1)\n",
    "print(ids_train.shape)  # Should output (46916 + 46916,)\n",
    "print(ids_test.shape)   # Should output (11729 + 11729,)\n",
    "print(testx.shape)   # Should output (11729 + 11729,)\n",
    "print(test_ids.shape)   # Should output (11729 + 11729,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmax(value=False):\n",
    "    if(value):\n",
    "        try:\n",
    "            with open(\"fmax.txt\", \"w\") as f:\n",
    "                f.write(str(value))\n",
    "            return 0    \n",
    "        except:\n",
    "            return 0\n",
    "    try:\n",
    "        with open(\"fmax.txt\", \"r\") as f:\n",
    "            return float(f.read())\n",
    "    except:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ensemble:\n",
    "    def __init__(self):\n",
    "        self.models = []\n",
    "        \n",
    "    def add_model(self, model):\n",
    "        self.models.append(model)\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        predictions = []\n",
    "        for model in self.models:\n",
    "            pred = model.predict(X_test)\n",
    "            predictions.append(pred)\n",
    "            count_greater_than_0_5 = (pred > model.THRESHOLD).sum()\n",
    "            count_less_than_or_equal_0_5 = (pred <= model.THRESHOLD).sum()\n",
    "            print(f'Percentage of predictions greater than {model.THRESHOLD}: {count_greater_than_0_5 / len(pred) * 100:.2f}%')\n",
    "            passc = count_greater_than_0_5 / len(pred) * 100\n",
    "            if passc < 5:\n",
    "                predictions.pop()\n",
    "                continue\n",
    "            print(f'Percentage of predictions less than or equal to {model.THRESHOLD}: {count_less_than_or_equal_0_5 / len(pred) * 100:.2f}%')\n",
    "        \n",
    "        # Stack predictions to form a 2D array\n",
    "        stacked_predictions = np.hstack(predictions)\n",
    "        \n",
    "        # Average the predictions across models\n",
    "        y_pred = np.mean(stacked_predictions, axis=1)\n",
    "        \n",
    "        # Apply threshold\n",
    "        # y_pred = (y_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Flatten the predictions to form a 1D array\n",
    "        y_pred = y_pred.flatten()\n",
    "        \n",
    "        # Assuming test_ids is defined elsewhere in your code\n",
    "        ids = test_ids\n",
    "        predictions_df = pd.DataFrame({'id': ids, 'loan_status': y_pred})\n",
    "        return predictions_df\n",
    "    \n",
    "    def save(self, testx, path=\"ftt.csv\"):\n",
    "        df = self.predict(testx)\n",
    "        df.to_csv(path, index=False)\n",
    "        csvfile =  pd.read_csv(path)\n",
    "        csvfile\n",
    "        \n",
    "    def rmamodel(self):\n",
    "        self.models = []\n",
    "\n",
    "ens = ensemble()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ktrain( model , xult , yult,splits=5,epochs=15,batch_size=32,random_state=42):\n",
    "    \n",
    "    if splits==1:\n",
    "        class temp:\n",
    "            def split(self, X):\n",
    "                n_samples = len(X)\n",
    "                indices = list(range(n_samples))\n",
    "                yield indices, indices  # Use the same indices for train and test\n",
    "\n",
    "        kf = temp()\n",
    "    else:\n",
    "        kf = KFold(n_splits=splits, shuffle=True, random_state=random_state)\n",
    "        obj = kf \n",
    "    losses, aucs, precisions, recalls, f1s, roc_aucs = [], [], [], [], [], []\n",
    "    iter = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        xt, xv = xult[train_index], xult[test_index]\n",
    "        yt, yv = yult[train_index], yult[test_index]\n",
    "        \n",
    "        # Initialize and compile the model\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(xt, yt, epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        results = model.evaluate(xv, yv)\n",
    "        loss, auc, precision, recall = results[0], results[1], results[2], results[3]\n",
    "        \n",
    "        # Predict probabilities for the test set\n",
    "        y_pred_prob = model.predict(xult)\n",
    "        y_pred = (y_pred_prob > model.THRESHOLD).astype(int)\n",
    "        \n",
    "        # Calculate F1 score and ROC AUC score\n",
    "        f1 = f1_score(yult, y_pred)\n",
    "        #count which iteration is this\n",
    "        count = train_index[0]\n",
    "        roc_auc = roc_auc_score(yult, y_pred_prob)\n",
    "        if f1 > fmax():\n",
    "            model.f1max(iter,epochs,splits)\n",
    "            fmax(f1)\n",
    "            model.save('best.keras')\n",
    "            print(colored(f'F1 Score improved to {f1}. Saving model...', 'green','on_red'))\n",
    "        # Store metrics\n",
    "        losses.append(loss)\n",
    "        aucs.append(auc)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1s.append(f1)\n",
    "        roc_aucs.append(roc_auc)\n",
    "        iter += 1\n",
    "    print('losses: ', losses)\n",
    "    print('aucs: ', aucs)\n",
    "    print('precisions: ', precisions)\n",
    "    print('recalls: ', recalls)\n",
    "    print('f1s: ', f1s)\n",
    "    print('roc_aucs: ', roc_aucs)\n",
    "    print(f'Average Loss: {sum(losses) / len(losses)}')\n",
    "    print(f'Average AUC: {sum(aucs) / len(aucs)}')\n",
    "    print(f'Average Precision: {sum(precisions) / len(precisions)}')\n",
    "    print(f'Average Recall: {sum(recalls) / len(recalls)}')\n",
    "    print(f'Average F1 Score: {sum(f1s) / len(f1s)}')\n",
    "    print(f'Average ROC AUC Score: {sum(roc_aucs) / len(roc_aucs)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[9919  107]\n",
      " [ 431 1272]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10035    59]\n",
      " [  222  1413]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10048    32]\n",
      " [  175  1474]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10094     9]\n",
      " [   71  1555]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[9979    0]\n",
      " [  46 1704]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [0.9655883545998255, 0.9933514868493045, 0.9972594622041255, 0.999719616121233, 0.9999592859290224]\n",
      "precisions:  [0.9224075416968818, 0.9599184782608695, 0.9787516600265604, 0.9942455242966752, 1.0]\n",
      "recalls:  [0.7469172049324722, 0.8642201834862385, 0.8938750758035173, 0.9563345633456335, 0.9737142857142858]\n",
      "f1s:  [0.8634167573449402, 0.8971114519427403, 0.9186146640623359, 0.9314269039976656, 0.9395447194924742]\n",
      "roc_aucs:  [0.892425553505773, 0.9175257656473513, 0.9342072213064675, 0.9440527752527553, 0.9505357135416015]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 0.9911756411407021\n",
      "Average Precision: 0.9710646408561974\n",
      "Average Recall: 0.8870122626564296\n",
      "Average F1 Score: 0.9100228993680313\n",
      "Average ROC AUC Score: 0.9277494058507898\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10054     1]\n",
      " [   33  1641]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10055     0]\n",
      " [   11  1663]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10065     0]\n",
      " [    3  1661]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[9989    0]\n",
      " [   0 1740]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10118     0]\n",
      " [    1  1610]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [0.999939104340702, 0.9999997623584027, 0.9999998208758455, 1.0, 1.0]\n",
      "precisions:  [0.9993909866017052, 1.0, 1.0, 1.0, 1.0]\n",
      "recalls:  [0.9802867383512545, 0.9934289127837514, 0.9981971153846154, 1.0, 0.9993792675356921]\n",
      "f1s:  [0.942705427798095, 0.9477518263195802, 0.9500595018260906, 0.9513535684987695, 0.9518047579983593]\n",
      "roc_aucs:  [0.9535731142347972, 0.9579274932588348, 0.9603395813006654, 0.9612441802943471, 0.9615001927748044]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 0.99998773751499\n",
      "Average Precision: 0.999878197320341\n",
      "Average Recall: 0.9942584068110627\n",
      "Average F1 Score: 0.9487350164881789\n",
      "Average ROC AUC Score: 0.9589169123726897\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10025     0]\n",
      " [    0  1704]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10065     0]\n",
      " [    0  1664]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10030     0]\n",
      " [    0  1699]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10067     0]\n",
      " [    0  1662]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10095     0]\n",
      " [    0  1634]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "precisions:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "recalls:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "f1s:  [0.9524453736727749, 0.9532679671668065, 0.9541408312358033, 0.9544106518315505, 0.9545928485269765]\n",
      "roc_aucs:  [0.9620657025743722, 0.9630539199957775, 0.9636591951795782, 0.9640152402224084, 0.9642747986480563]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 1.0\n",
      "Average Precision: 1.0\n",
      "Average Recall: 1.0\n",
      "Average F1 Score: 0.9537715344867823\n",
      "Average ROC AUC Score: 0.9634137713240385\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10055     0]\n",
      " [    0  1674]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10063     0]\n",
      " [    0  1666]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10030     0]\n",
      " [    0  1699]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10054     0]\n",
      " [    0  1675]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10080     0]\n",
      " [    0  1649]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "precisions:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "recalls:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "f1s:  [0.95509269668663, 0.9556354426242902, 0.9551927752691907, 0.9554561607744624, 0.9556213621974881]\n",
      "roc_aucs:  [0.9646373164794777, 0.9652195499645903, 0.9648503271814063, 0.9651564333307736, 0.9652661750760334]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 1.0\n",
      "Average Precision: 1.0\n",
      "Average Recall: 1.0\n",
      "Average F1 Score: 0.9553996875104124\n",
      "Average ROC AUC Score: 0.9650259604064562\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10054     0]\n",
      " [    0  1675]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10078     0]\n",
      " [    0  1651]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10070     0]\n",
      " [    0  1659]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10013     0]\n",
      " [    0  1716]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10067     0]\n",
      " [    0  1662]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "precisions:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "recalls:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "f1s:  [0.9559000755765263, 0.9560796324655436, 0.9558223093254941, 0.9562057208191266, 0.9565820615359504]\n",
      "roc_aucs:  [0.9653625069177679, 0.9656054190455949, 0.9655290472837008, 0.9657085332268162, 0.9661810249666688]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 1.0\n",
      "Average Precision: 1.0\n",
      "Average Recall: 1.0\n",
      "Average F1 Score: 0.9561179599445282\n",
      "Average ROC AUC Score: 0.9656773062881097\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10089     0]\n",
      " [    0  1640]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10098     0]\n",
      " [    0  1631]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "[[10034     0]\n",
      " [    0  1695]]\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[195], line 70\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m     xgb_model \u001b[38;5;241m=\u001b[39m XGBoostClassifierModel(eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauc\u001b[39m\u001b[38;5;124m'\u001b[39m, model_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxgb_model.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 70\u001b[0m \u001b[43mktrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m ens\u001b[38;5;241m.\u001b[39madd_model(xgb_model)\n",
      "Cell \u001b[0;32mIn[194], line 23\u001b[0m, in \u001b[0;36mktrain\u001b[0;34m(model, xult, yult, splits, epochs, batch_size, random_state)\u001b[0m\n\u001b[1;32m     18\u001b[0m yt, yv \u001b[38;5;241m=\u001b[39m yult[train_index], yult[test_index]\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Initialize and compile the model\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m     26\u001b[0m results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(xv, yv)\n",
      "Cell \u001b[0;32mIn[195], line 14\u001b[0m, in \u001b[0;36mXGBoostClassifierModel.fit\u001b[0;34m(self, X_train, y_train, verbose, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X_train, y_train, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_exists\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_model()\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/xgboost/sklearn.py:1531\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1511\u001b[0m model, metric, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[1;32m   1512\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1513\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1514\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1528\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[1;32m   1529\u001b[0m )\n\u001b[0;32m-> 1531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1534\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1546\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/xgboost/core.py:2101\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2100\u001b[0m     _check_call(\n\u001b[0;32m-> 2101\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[1;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2104\u001b[0m     )\n\u001b[1;32m   2105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2106\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, precision_score, recall_score\n",
    "\n",
    "class XGBoostClassifierModel:\n",
    "    def __init__(self, eval_metric='logloss', model_path='xgb_model.json', **kwargs):\n",
    "        self.model = xgb.XGBClassifier(objective='binary:logistic', eval_metric=eval_metric, **kwargs)\n",
    "        self.model_path = model_path\n",
    "        self.THRESHOLD = 0.5\n",
    "        self.load_model()\n",
    "        self.f1 = 0 # Placeholder for F1 score\n",
    "\n",
    "    def fit(self, X_train, y_train, verbose=0, **kwargs):\n",
    "        self.model.fit(X_train, y_train, verbose=verbose, xgb_model=self.model_path if self.model_exists() else None)\n",
    "        self.save_model()\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        print(colored('predicting using xgboost model', 'green'))\n",
    "        return self.model.predict(X_test).reshape(-1, 1)\n",
    "\n",
    "    def predict_proba(self, X_test):\n",
    "        return self.model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        y_pred = self.predict(X_test)\n",
    "        y_pred_proba = self.predict_proba(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        print(cm)\n",
    "        # Assuming loss is not directly available, using log loss as a proxy\n",
    "        loss = -1  # Placeholder, as XGBoost does not directly provide loss in this context\n",
    "        return [loss, auc, precision, recall]\n",
    "\n",
    "    def summary(self):\n",
    "        print(self.model)\n",
    "    def f1max(self, *args, **kwargs):\n",
    "        print(self.summary())\n",
    "        if args:\n",
    "            print(f\"iter: {args[0]}, epochs: {args[1]}, splits: {args[2]}\")\n",
    "        print(kwargs)\n",
    "    def save_model(self):\n",
    "        self.model.save_model(self.model_path)\n",
    "\n",
    "    def load_model(self):\n",
    "        if self.model_exists():\n",
    "            self.model.load_model(self.model_path)\n",
    "\n",
    "    def model_exists(self):\n",
    "        try:\n",
    "            with open(self.model_path, 'r'):\n",
    "                return True\n",
    "        except FileNotFoundError:\n",
    "            return False\n",
    "    def save(self, path):\n",
    "        self.model.save_model(path)\n",
    "\n",
    "# Example usage\n",
    "# Assuming xult and yult are your feature matrix and target vector\n",
    "# Split the data into training and test sets\n",
    "\n",
    "for i in range(10):\n",
    "    if i%2==0:\n",
    "        xgb_model = XGBoostClassifierModel(eval_metric='logloss' , model_path=f'xgb_model.json')\n",
    "    else:\n",
    "        xgb_model = XGBoostClassifierModel(eval_metric='auc', model_path=f'xgb_model.json')\n",
    "    ktrain(xgb_model, xult, yult, epochs=10, batch_size=32, splits=5, random_state=i)\n",
    "    ens.add_model(xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - auc_16: 0.7752 - loss: 0.3728 - precision_16: 0.5512 - recall_16: 0.1862 - val_auc_16: 0.9006 - val_loss: 0.2426 - val_precision_16: 0.8015 - val_recall_16: 0.5048\n",
      "Epoch 2/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - auc_16: 0.8883 - loss: 0.2569 - precision_16: 0.7591 - recall_16: 0.4535 - val_auc_16: 0.8951 - val_loss: 0.2736 - val_precision_16: 0.6190 - val_recall_16: 0.6680\n",
      "Epoch 3/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - auc_16: 0.9022 - loss: 0.2348 - precision_16: 0.7881 - recall_16: 0.5293 - val_auc_16: 0.9167 - val_loss: 0.2317 - val_precision_16: 0.7903 - val_recall_16: 0.5987\n",
      "Epoch 4/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - auc_16: 0.9123 - loss: 0.2223 - precision_16: 0.8092 - recall_16: 0.5482 - val_auc_16: 0.9192 - val_loss: 0.2193 - val_precision_16: 0.7494 - val_recall_16: 0.6334\n",
      "Epoch 5/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - auc_16: 0.9081 - loss: 0.2229 - precision_16: 0.8254 - recall_16: 0.5390 - val_auc_16: 0.9177 - val_loss: 0.2209 - val_precision_16: 0.8514 - val_recall_16: 0.5271\n",
      "Epoch 6/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - auc_16: 0.9087 - loss: 0.2264 - precision_16: 0.8194 - recall_16: 0.5349 - val_auc_16: 0.9195 - val_loss: 0.2204 - val_precision_16: 0.7895 - val_recall_16: 0.5971\n",
      "Epoch 7/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - auc_16: 0.9106 - loss: 0.2256 - precision_16: 0.7974 - recall_16: 0.5566 - val_auc_16: 0.9189 - val_loss: 0.2258 - val_precision_16: 0.8593 - val_recall_16: 0.5374\n",
      "Epoch 8/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - auc_16: 0.9158 - loss: 0.2176 - precision_16: 0.8170 - recall_16: 0.5646 - val_auc_16: 0.9251 - val_loss: 0.2062 - val_precision_16: 0.8267 - val_recall_16: 0.5983\n",
      "Epoch 9/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - auc_16: 0.9158 - loss: 0.2175 - precision_16: 0.8127 - recall_16: 0.5865 - val_auc_16: 0.9215 - val_loss: 0.2116 - val_precision_16: 0.8314 - val_recall_16: 0.5653\n",
      "Epoch 10/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - auc_16: 0.9198 - loss: 0.2115 - precision_16: 0.8298 - recall_16: 0.5818 - val_auc_16: 0.9206 - val_loss: 0.2273 - val_precision_16: 0.7302 - val_recall_16: 0.6851\n",
      "Epoch 11/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - auc_16: 0.9220 - loss: 0.2071 - precision_16: 0.8269 - recall_16: 0.5830 - val_auc_16: 0.9222 - val_loss: 0.2117 - val_precision_16: 0.7898 - val_recall_16: 0.6417\n",
      "Epoch 12/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - auc_16: 0.9248 - loss: 0.2066 - precision_16: 0.8208 - recall_16: 0.6023 - val_auc_16: 0.9206 - val_loss: 0.2228 - val_precision_16: 0.7389 - val_recall_16: 0.6409\n",
      "Epoch 13/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - auc_16: 0.9216 - loss: 0.2103 - precision_16: 0.8221 - recall_16: 0.6104 - val_auc_16: 0.9250 - val_loss: 0.2047 - val_precision_16: 0.8645 - val_recall_16: 0.5561\n",
      "Epoch 14/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - auc_16: 0.9234 - loss: 0.2042 - precision_16: 0.8343 - recall_16: 0.5932 - val_auc_16: 0.9235 - val_loss: 0.2062 - val_precision_16: 0.8637 - val_recall_16: 0.5649\n",
      "Epoch 15/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - auc_16: 0.9234 - loss: 0.2009 - precision_16: 0.8405 - recall_16: 0.6002 - val_auc_16: 0.9248 - val_loss: 0.2054 - val_precision_16: 0.8515 - val_recall_16: 0.5752\n",
      "\u001b[1m1833/1833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_16: 0.9268 - loss: 0.1999 - precision_16: 0.8623 - recall_16: 0.5868\n",
      "\u001b[32mPredicting with encoding_dim 512...\u001b[0m\n",
      "\u001b[1m5498/5498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 887us/step\n",
      "losses:  [0.2012104094028473]\n",
      "aucs:  [0.9269636869430542]\n",
      "precisions:  [0.8600348830223083]\n",
      "recalls:  [0.5892622470855713]\n",
      "f1s:  [0.7019282966319715]\n",
      "roc_aucs:  [0.9282054456219946]\n",
      "Average Loss: 0.2012104094028473\n",
      "Average AUC: 0.9269636869430542\n",
      "Average Precision: 0.8600348830223083\n",
      "Average Recall: 0.5892622470855713\n",
      "Average F1 Score: 0.7019282966319715\n",
      "Average ROC AUC Score: 0.9282054456219946\n",
      "Epoch 1/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - auc_17: 0.7263 - loss: 0.3869 - precision_17: 0.4492 - recall_17: 0.0349 - val_auc_17: 0.7872 - val_loss: 0.3219 - val_precision_17: 0.8673 - val_recall_17: 0.1405\n",
      "Epoch 2/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_17: 0.8378 - loss: 0.3033 - precision_17: 0.8306 - recall_17: 0.2183 - val_auc_17: 0.9058 - val_loss: 0.2515 - val_precision_17: 0.7415 - val_recall_17: 0.4841\n",
      "Epoch 3/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - auc_17: 0.8885 - loss: 0.2513 - precision_17: 0.7949 - recall_17: 0.4482 - val_auc_17: 0.9103 - val_loss: 0.2303 - val_precision_17: 0.7445 - val_recall_17: 0.6242\n",
      "Epoch 4/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_17: 0.9018 - loss: 0.2390 - precision_17: 0.8002 - recall_17: 0.4993 - val_auc_17: 0.9140 - val_loss: 0.2245 - val_precision_17: 0.7789 - val_recall_17: 0.5764\n",
      "Epoch 5/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_17: 0.9028 - loss: 0.2436 - precision_17: 0.7598 - recall_17: 0.5097 - val_auc_17: 0.9051 - val_loss: 0.2355 - val_precision_17: 0.8154 - val_recall_17: 0.4837\n",
      "Epoch 6/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_17: 0.9094 - loss: 0.2289 - precision_17: 0.8240 - recall_17: 0.5260 - val_auc_17: 0.9153 - val_loss: 0.2389 - val_precision_17: 0.9088 - val_recall_17: 0.3650\n",
      "Epoch 7/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_17: 0.9181 - loss: 0.2174 - precision_17: 0.8232 - recall_17: 0.5525 - val_auc_17: 0.9174 - val_loss: 0.2335 - val_precision_17: 0.9020 - val_recall_17: 0.3993\n",
      "Epoch 8/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_17: 0.9144 - loss: 0.2234 - precision_17: 0.8329 - recall_17: 0.5398 - val_auc_17: 0.9220 - val_loss: 0.2141 - val_precision_17: 0.8118 - val_recall_17: 0.5788\n",
      "Epoch 9/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_17: 0.9184 - loss: 0.2112 - precision_17: 0.8315 - recall_17: 0.5683 - val_auc_17: 0.9105 - val_loss: 0.2668 - val_precision_17: 0.6100 - val_recall_17: 0.6756\n",
      "Epoch 10/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_17: 0.9142 - loss: 0.2196 - precision_17: 0.8350 - recall_17: 0.5459 - val_auc_17: 0.9222 - val_loss: 0.2157 - val_precision_17: 0.8745 - val_recall_17: 0.4936\n",
      "Epoch 11/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_17: 0.9217 - loss: 0.2076 - precision_17: 0.8307 - recall_17: 0.5762 - val_auc_17: 0.9237 - val_loss: 0.2148 - val_precision_17: 0.8806 - val_recall_17: 0.5283\n",
      "Epoch 12/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_17: 0.9240 - loss: 0.2078 - precision_17: 0.8321 - recall_17: 0.5831 - val_auc_17: 0.9247 - val_loss: 0.2062 - val_precision_17: 0.8722 - val_recall_17: 0.5518\n",
      "Epoch 13/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_17: 0.9226 - loss: 0.2077 - precision_17: 0.8290 - recall_17: 0.5830 - val_auc_17: 0.9260 - val_loss: 0.2049 - val_precision_17: 0.7968 - val_recall_17: 0.6322\n",
      "Epoch 14/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_17: 0.9241 - loss: 0.2071 - precision_17: 0.8137 - recall_17: 0.6112 - val_auc_17: 0.9259 - val_loss: 0.2081 - val_precision_17: 0.8084 - val_recall_17: 0.6397\n",
      "Epoch 15/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_17: 0.9268 - loss: 0.2016 - precision_17: 0.8252 - recall_17: 0.6164 - val_auc_17: 0.9263 - val_loss: 0.2124 - val_precision_17: 0.9001 - val_recall_17: 0.4952\n",
      "\u001b[1m1833/1833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 930us/step - auc_17: 0.9277 - loss: 0.2070 - precision_17: 0.9040 - recall_17: 0.5009\n",
      "\u001b[32mPredicting with encoding_dim 256...\u001b[0m\n",
      "\u001b[1m5498/5498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 745us/step\n",
      "losses:  [0.20848621428012848]\n",
      "aucs:  [0.9277516007423401]\n",
      "precisions:  [0.9076625108718872]\n",
      "recalls:  [0.504244863986969]\n",
      "f1s:  [0.6529380164232176]\n",
      "roc_aucs:  [0.9280062901006483]\n",
      "Average Loss: 0.20848621428012848\n",
      "Average AUC: 0.9277516007423401\n",
      "Average Precision: 0.9076625108718872\n",
      "Average Recall: 0.504244863986969\n",
      "Average F1 Score: 0.6529380164232176\n",
      "Average ROC AUC Score: 0.9280062901006483\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Reshape, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from colorama import init\n",
    "from termcolor import colored\n",
    "# Define the L2 regularizers\n",
    "\n",
    "\n",
    "k = .0001\n",
    "kernel_regularizer = l2(0.0001*k)\n",
    "bias_regularizer = l2(0.00001*k)\n",
    "\n",
    "# Define the CNN model with different regularization strengths for kernel and bias\n",
    "class AutoencoderModel:\n",
    "    def __init__(self, input_dim, encoding_dim=512):\n",
    "        self.input_dim = input_dim\n",
    "        self.encoding_dim = encoding_dim\n",
    "        self.autoencoder = self.build_model()\n",
    "        self.THRESHOLD = 0.5\n",
    "    def build_model(self):\n",
    "        # Encoder\n",
    "        input_layer = Input(shape=(self.input_dim,))\n",
    "        encoded = Dense(self.encoding_dim, activation='relu')(input_layer)\n",
    "        encoded = Dense(self.encoding_dim // 2, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(encoded)\n",
    "        encoded = Dense(self.encoding_dim // 4, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(encoded)\n",
    "        encoded = Dense(self.encoding_dim // 8, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(encoded)\n",
    "        encoded = Dense(self.encoding_dim // 16, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(encoded)\n",
    "        encoded = Dense(self.encoding_dim // 32, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(encoded)\n",
    "    \n",
    "        # Decoder\n",
    "        decoded = Dense(self.encoding_dim // 32, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(encoded)\n",
    "        decoded = Dense(self.encoding_dim // 16, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(encoded)\n",
    "        decoded = Dense(self.encoding_dim // 8, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(encoded)\n",
    "        decoded = Dense(self.encoding_dim // 4, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(decoded)\n",
    "        decoded = Dense(self.encoding_dim // 2, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(decoded)\n",
    "        decoded = Dense(1, activation='sigmoid')(decoded)\n",
    "    \n",
    "        # Autoencoder\n",
    "        autoencoder = Model(input_layer, decoded)\n",
    "    \n",
    "        # Compile the model with Binary Crossentropy loss\n",
    "        autoencoder.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(), metrics=[AUC(), Precision(), Recall()])    \n",
    "        return autoencoder\n",
    "\n",
    "    def fit(self, X_train, y_train, epochs=10, verbose=0, batch_size=32, validation_split=0.3, validation_data=None):\n",
    "        if validation_data is not None:\n",
    "            self.autoencoder.fit(X_train, y_train, epochs=epochs, verbose=verbose, batch_size=batch_size, validation_data=validation_data, validation_split=validation_split)\n",
    "            return \n",
    "        self.autoencoder.fit(X_train, y_train, epochs=epochs, verbose=verbose, batch_size=batch_size, validation_split=validation_split)\n",
    "    def f1max(self, *args, **kwargs):\n",
    "        print(self.summary())\n",
    "        if args:\n",
    "            print(f\"iter: {args[0]}, epochs: {args[1]}, splits: {args[2]}\")\n",
    "        print(kwargs)\n",
    "    def predict(self, X_test):\n",
    "        print(colored(f'Predicting with encoding_dim {self.encoding_dim}...', 'green'))\n",
    "        return self.autoencoder.predict(X_test)\n",
    "    \n",
    "    def summary(self):\n",
    "        self.autoencoder.summary()\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        return self.autoencoder.evaluate(X_test, y_test)\n",
    "    def save(self, path):\n",
    "        self.autoencoder.save(path)\n",
    "\n",
    "dim = [512, 256, 128, 64, 256]\n",
    "for i in range(2):\n",
    "    automodel = AutoencoderModel(X_train.shape[1], encoding_dim=dim[i])\n",
    "    ktrain(automodel, xult, yult, splits=1, epochs=15, batch_size=32, random_state=i)\n",
    "    ens.add_model(automodel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - auc_18: 0.4987 - loss: 0.6615 - precision_18: 0.1194 - recall_18: 0.0282 - val_auc_18: 0.5000 - val_loss: 0.4812 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 2/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.5008 - loss: 0.4587 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4241 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 3/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_18: 0.4955 - loss: 0.4125 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4131 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 4/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4981 - loss: 0.4062 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4118 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 5/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4894 - loss: 0.4034 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4118 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 6/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.5000 - loss: 0.4057 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4118 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 7/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4989 - loss: 0.4083 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4119 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 8/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4959 - loss: 0.4114 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4119 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 9/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4932 - loss: 0.4063 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4118 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 10/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4969 - loss: 0.4082 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4118 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 11/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4986 - loss: 0.4092 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4119 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 12/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4951 - loss: 0.4099 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4118 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 13/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4981 - loss: 0.4051 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4118 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 14/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.5001 - loss: 0.4131 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5001 - val_loss: 0.4118 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 15/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.5012 - loss: 0.4049 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4118 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - auc_18: 0.5000 - loss: 0.4144 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00\n",
      "\u001b[32mpredicting using dense model of hidden 64\u001b[0m\n",
      "\u001b[1m5498/5498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 656us/step\n",
      "Epoch 1/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4993 - loss: 0.4044 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4104 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 2/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4976 - loss: 0.4131 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4104 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 3/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.5000 - loss: 0.4141 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4104 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 4/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.5000 - loss: 0.4125 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4104 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 5/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.5000 - loss: 0.4102 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4104 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 6/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4956 - loss: 0.4141 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4104 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 7/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.5000 - loss: 0.4146 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4104 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 8/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4995 - loss: 0.4110 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4104 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 9/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4995 - loss: 0.4066 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4104 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 10/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4963 - loss: 0.4115 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4104 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 11/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.5000 - loss: 0.4101 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4104 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 12/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.5000 - loss: 0.4063 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4104 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 13/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4991 - loss: 0.4112 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4104 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 14/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.5000 - loss: 0.4135 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4104 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 15/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4982 - loss: 0.4124 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4104 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - auc_18: 0.5000 - loss: 0.4031 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00\n",
      "\u001b[32mpredicting using dense model of hidden 64\u001b[0m\n",
      "\u001b[1m5498/5498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 645us/step\n",
      "Epoch 1/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4997 - loss: 0.4125 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4080 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 2/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4973 - loss: 0.4089 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4080 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 3/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.5000 - loss: 0.4117 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4080 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 4/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.5000 - loss: 0.4122 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4080 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 5/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4924 - loss: 0.4218 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4080 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 6/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4945 - loss: 0.4110 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4080 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 7/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4993 - loss: 0.4143 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4080 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 8/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.5000 - loss: 0.4092 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4080 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 9/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4994 - loss: 0.4104 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4080 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 10/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.5000 - loss: 0.4103 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4080 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 11/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4967 - loss: 0.4069 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4081 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 12/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4910 - loss: 0.4059 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4081 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 13/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4945 - loss: 0.4151 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4080 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 14/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4999 - loss: 0.4152 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4080 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 15/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.5000 - loss: 0.4154 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4080 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - auc_18: 0.5000 - loss: 0.4054 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00\n",
      "\u001b[32mpredicting using dense model of hidden 64\u001b[0m\n",
      "\u001b[1m5498/5498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 639us/step\n",
      "Epoch 1/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4996 - loss: 0.4114 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4135 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 2/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4915 - loss: 0.4057 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4135 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 3/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.5000 - loss: 0.4124 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4135 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 4/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4995 - loss: 0.4165 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4135 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 5/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4920 - loss: 0.4038 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4134 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 6/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4938 - loss: 0.4097 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4134 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 7/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4987 - loss: 0.4156 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4135 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 8/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4982 - loss: 0.4109 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4135 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 9/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.5000 - loss: 0.4086 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4135 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 10/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - auc_18: 0.5000 - loss: 0.4130 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4135 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 11/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.5000 - loss: 0.4123 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4135 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 12/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4946 - loss: 0.4060 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4135 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 13/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.5000 - loss: 0.4101 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4135 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 14/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.5000 - loss: 0.4102 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4135 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 15/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4985 - loss: 0.4150 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4135 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - auc_18: 0.5000 - loss: 0.4106 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00\n",
      "\u001b[32mpredicting using dense model of hidden 64\u001b[0m\n",
      "\u001b[1m5498/5498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 661us/step\n",
      "Epoch 1/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.5001 - loss: 0.4073 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4058 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 2/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.5000 - loss: 0.4063 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4058 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 3/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4980 - loss: 0.4095 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4058 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 4/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.5003 - loss: 0.4071 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4058 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 5/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.5000 - loss: 0.4107 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4058 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 6/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4931 - loss: 0.4110 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4058 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 7/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4871 - loss: 0.4055 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4058 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 8/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4988 - loss: 0.4130 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4058 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 9/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_18: 0.4916 - loss: 0.4063 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4058 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 10/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4998 - loss: 0.4096 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4058 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 11/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4966 - loss: 0.4101 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4058 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 12/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - auc_18: 0.4877 - loss: 0.4079 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4058 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 13/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_18: 0.5003 - loss: 0.4098 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4058 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 14/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.4979 - loss: 0.4055 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4058 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 15/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_18: 0.5007 - loss: 0.4068 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00 - val_auc_18: 0.5000 - val_loss: 0.4058 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - auc_18: 0.5000 - loss: 0.4047 - precision_18: 0.0000e+00 - recall_18: 0.0000e+00\n",
      "\u001b[32mpredicting using dense model of hidden 64\u001b[0m\n",
      "\u001b[1m5498/5498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 655us/step\n",
      "losses:  [0.41434603929519653, 0.40392085909843445, 0.406063050031662, 0.40253233909606934, 0.4216136336326599]\n",
      "aucs:  [0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "precisions:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "recalls:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "f1s:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "roc_aucs:  [0.49997680352586404, 0.49997680352586404, 0.49997680352586404, 0.49997680352586404, 0.49997680352586404]\n",
      "Average Loss: 0.4096951842308044\n",
      "Average AUC: 0.5\n",
      "Average Precision: 0.0\n",
      "Average Recall: 0.0\n",
      "Average F1 Score: 0.0\n",
      "Average ROC AUC Score: 0.499976803525864\n",
      "Epoch 1/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - auc_19: 0.7152 - loss: 0.4355 - precision_19: 0.3181 - recall_19: 0.0455 - val_auc_19: 0.8234 - val_loss: 0.3364 - val_precision_19: 0.7608 - val_recall_19: 0.2568\n",
      "Epoch 2/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.8375 - loss: 0.3041 - precision_19: 0.7971 - recall_19: 0.2811 - val_auc_19: 0.8851 - val_loss: 0.2625 - val_precision_19: 0.7917 - val_recall_19: 0.4709\n",
      "Epoch 3/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.8759 - loss: 0.2703 - precision_19: 0.7898 - recall_19: 0.3807 - val_auc_19: 0.8808 - val_loss: 0.2679 - val_precision_19: 0.8098 - val_recall_19: 0.4975\n",
      "Epoch 4/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.8888 - loss: 0.2578 - precision_19: 0.8236 - recall_19: 0.4362 - val_auc_19: 0.9083 - val_loss: 0.2337 - val_precision_19: 0.8263 - val_recall_19: 0.4343\n",
      "Epoch 5/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9014 - loss: 0.2405 - precision_19: 0.8151 - recall_19: 0.4659 - val_auc_19: 0.8938 - val_loss: 0.2523 - val_precision_19: 0.8155 - val_recall_19: 0.4122\n",
      "Epoch 6/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9023 - loss: 0.2369 - precision_19: 0.8352 - recall_19: 0.4920 - val_auc_19: 0.9119 - val_loss: 0.2254 - val_precision_19: 0.8712 - val_recall_19: 0.4784\n",
      "Epoch 7/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9107 - loss: 0.2273 - precision_19: 0.8329 - recall_19: 0.5239 - val_auc_19: 0.9190 - val_loss: 0.2148 - val_precision_19: 0.8359 - val_recall_19: 0.5491\n",
      "Epoch 8/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_19: 0.9161 - loss: 0.2221 - precision_19: 0.8232 - recall_19: 0.5430 - val_auc_19: 0.9199 - val_loss: 0.2169 - val_precision_19: 0.8465 - val_recall_19: 0.5171\n",
      "Epoch 9/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_19: 0.9096 - loss: 0.2241 - precision_19: 0.8317 - recall_19: 0.5124 - val_auc_19: 0.9157 - val_loss: 0.2222 - val_precision_19: 0.8010 - val_recall_19: 0.5552\n",
      "Epoch 10/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9183 - loss: 0.2180 - precision_19: 0.8374 - recall_19: 0.5381 - val_auc_19: 0.9202 - val_loss: 0.2150 - val_precision_19: 0.7756 - val_recall_19: 0.5998\n",
      "Epoch 11/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_19: 0.9204 - loss: 0.2143 - precision_19: 0.8287 - recall_19: 0.5723 - val_auc_19: 0.9163 - val_loss: 0.2182 - val_precision_19: 0.8571 - val_recall_19: 0.5206\n",
      "Epoch 12/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9182 - loss: 0.2151 - precision_19: 0.8316 - recall_19: 0.5479 - val_auc_19: 0.9228 - val_loss: 0.2104 - val_precision_19: 0.8602 - val_recall_19: 0.5276\n",
      "Epoch 13/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9170 - loss: 0.2172 - precision_19: 0.8334 - recall_19: 0.5180 - val_auc_19: 0.9184 - val_loss: 0.2167 - val_precision_19: 0.8830 - val_recall_19: 0.4995\n",
      "Epoch 14/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9188 - loss: 0.2144 - precision_19: 0.8392 - recall_19: 0.5760 - val_auc_19: 0.9234 - val_loss: 0.2078 - val_precision_19: 0.8544 - val_recall_19: 0.5502\n",
      "Epoch 15/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9201 - loss: 0.2137 - precision_19: 0.8467 - recall_19: 0.5694 - val_auc_19: 0.9229 - val_loss: 0.2066 - val_precision_19: 0.8439 - val_recall_19: 0.5883\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - auc_19: 0.9204 - loss: 0.2016 - precision_19: 0.8619 - recall_19: 0.5956\n",
      "\u001b[32mpredicting using dense model of hidden 64\u001b[0m\n",
      "\u001b[1m5498/5498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 656us/step\n",
      "Epoch 1/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9204 - loss: 0.2086 - precision_19: 0.8444 - recall_19: 0.5846 - val_auc_19: 0.9157 - val_loss: 0.2260 - val_precision_19: 0.8715 - val_recall_19: 0.4559\n",
      "Epoch 2/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9202 - loss: 0.2063 - precision_19: 0.8278 - recall_19: 0.5860 - val_auc_19: 0.9220 - val_loss: 0.2118 - val_precision_19: 0.7839 - val_recall_19: 0.6459\n",
      "Epoch 3/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9213 - loss: 0.2064 - precision_19: 0.8309 - recall_19: 0.5819 - val_auc_19: 0.9257 - val_loss: 0.2006 - val_precision_19: 0.8796 - val_recall_19: 0.5607\n",
      "Epoch 4/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9203 - loss: 0.2109 - precision_19: 0.8381 - recall_19: 0.5805 - val_auc_19: 0.9231 - val_loss: 0.2099 - val_precision_19: 0.8789 - val_recall_19: 0.5276\n",
      "Epoch 5/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_19: 0.9222 - loss: 0.2050 - precision_19: 0.8340 - recall_19: 0.5916 - val_auc_19: 0.9248 - val_loss: 0.2095 - val_precision_19: 0.8436 - val_recall_19: 0.5707\n",
      "Epoch 6/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_19: 0.9267 - loss: 0.2032 - precision_19: 0.8412 - recall_19: 0.6035 - val_auc_19: 0.9248 - val_loss: 0.2060 - val_precision_19: 0.8741 - val_recall_19: 0.5221\n",
      "Epoch 7/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9248 - loss: 0.2040 - precision_19: 0.8459 - recall_19: 0.5886 - val_auc_19: 0.9247 - val_loss: 0.2079 - val_precision_19: 0.8985 - val_recall_19: 0.4970\n",
      "Epoch 8/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_19: 0.9222 - loss: 0.2032 - precision_19: 0.8467 - recall_19: 0.6018 - val_auc_19: 0.9245 - val_loss: 0.2031 - val_precision_19: 0.8512 - val_recall_19: 0.5853\n",
      "Epoch 9/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_19: 0.9256 - loss: 0.2018 - precision_19: 0.8402 - recall_19: 0.6076 - val_auc_19: 0.9215 - val_loss: 0.2078 - val_precision_19: 0.7931 - val_recall_19: 0.6384\n",
      "Epoch 10/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_19: 0.9249 - loss: 0.1998 - precision_19: 0.8364 - recall_19: 0.6255 - val_auc_19: 0.9242 - val_loss: 0.2052 - val_precision_19: 0.8544 - val_recall_19: 0.5888\n",
      "Epoch 11/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9258 - loss: 0.2019 - precision_19: 0.8464 - recall_19: 0.6037 - val_auc_19: 0.9252 - val_loss: 0.2050 - val_precision_19: 0.8717 - val_recall_19: 0.5451\n",
      "Epoch 12/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9281 - loss: 0.2025 - precision_19: 0.8466 - recall_19: 0.6065 - val_auc_19: 0.9271 - val_loss: 0.2009 - val_precision_19: 0.8796 - val_recall_19: 0.5532\n",
      "Epoch 13/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9270 - loss: 0.1986 - precision_19: 0.8472 - recall_19: 0.6136 - val_auc_19: 0.9258 - val_loss: 0.2095 - val_precision_19: 0.9307 - val_recall_19: 0.4514\n",
      "Epoch 14/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9287 - loss: 0.1975 - precision_19: 0.8579 - recall_19: 0.6046 - val_auc_19: 0.9232 - val_loss: 0.2133 - val_precision_19: 0.8950 - val_recall_19: 0.4875\n",
      "Epoch 15/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9269 - loss: 0.1976 - precision_19: 0.8421 - recall_19: 0.6093 - val_auc_19: 0.9281 - val_loss: 0.1999 - val_precision_19: 0.8058 - val_recall_19: 0.6555\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - auc_19: 0.9238 - loss: 0.2105 - precision_19: 0.7948 - recall_19: 0.6528\n",
      "\u001b[32mpredicting using dense model of hidden 64\u001b[0m\n",
      "\u001b[1m5498/5498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 652us/step\n",
      "Epoch 1/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_19: 0.9247 - loss: 0.2013 - precision_19: 0.8237 - recall_19: 0.6017 - val_auc_19: 0.9276 - val_loss: 0.2028 - val_precision_19: 0.8779 - val_recall_19: 0.5679\n",
      "Epoch 2/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_19: 0.9230 - loss: 0.2034 - precision_19: 0.8321 - recall_19: 0.5999 - val_auc_19: 0.9280 - val_loss: 0.2003 - val_precision_19: 0.8629 - val_recall_19: 0.5959\n",
      "Epoch 3/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_19: 0.9275 - loss: 0.1937 - precision_19: 0.8514 - recall_19: 0.6084 - val_auc_19: 0.9283 - val_loss: 0.2039 - val_precision_19: 0.8698 - val_recall_19: 0.5669\n",
      "Epoch 4/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9260 - loss: 0.1969 - precision_19: 0.8340 - recall_19: 0.6228 - val_auc_19: 0.9273 - val_loss: 0.2057 - val_precision_19: 0.8574 - val_recall_19: 0.5959\n",
      "Epoch 5/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9309 - loss: 0.1979 - precision_19: 0.8367 - recall_19: 0.6245 - val_auc_19: 0.9297 - val_loss: 0.2016 - val_precision_19: 0.8255 - val_recall_19: 0.6219\n",
      "Epoch 6/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9266 - loss: 0.1984 - precision_19: 0.8307 - recall_19: 0.6261 - val_auc_19: 0.9300 - val_loss: 0.1987 - val_precision_19: 0.8326 - val_recall_19: 0.6268\n",
      "Epoch 7/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9284 - loss: 0.1937 - precision_19: 0.8431 - recall_19: 0.6366 - val_auc_19: 0.9310 - val_loss: 0.2001 - val_precision_19: 0.8564 - val_recall_19: 0.5969\n",
      "Epoch 8/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9278 - loss: 0.1945 - precision_19: 0.8425 - recall_19: 0.6230 - val_auc_19: 0.9300 - val_loss: 0.1993 - val_precision_19: 0.8347 - val_recall_19: 0.6317\n",
      "Epoch 9/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9282 - loss: 0.1935 - precision_19: 0.8289 - recall_19: 0.6405 - val_auc_19: 0.9292 - val_loss: 0.2035 - val_precision_19: 0.8684 - val_recall_19: 0.5665\n",
      "Epoch 10/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9358 - loss: 0.1865 - precision_19: 0.8401 - recall_19: 0.6374 - val_auc_19: 0.9314 - val_loss: 0.2007 - val_precision_19: 0.8545 - val_recall_19: 0.5964\n",
      "Epoch 11/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9311 - loss: 0.1933 - precision_19: 0.8354 - recall_19: 0.6406 - val_auc_19: 0.9329 - val_loss: 0.1950 - val_precision_19: 0.8593 - val_recall_19: 0.6322\n",
      "Epoch 12/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_19: 0.9286 - loss: 0.1942 - precision_19: 0.8302 - recall_19: 0.6304 - val_auc_19: 0.9276 - val_loss: 0.2047 - val_precision_19: 0.8681 - val_recall_19: 0.5841\n",
      "Epoch 13/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9324 - loss: 0.1906 - precision_19: 0.8502 - recall_19: 0.6308 - val_auc_19: 0.9308 - val_loss: 0.2069 - val_precision_19: 0.8908 - val_recall_19: 0.5562\n",
      "Epoch 14/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9314 - loss: 0.1904 - precision_19: 0.8557 - recall_19: 0.6113 - val_auc_19: 0.9308 - val_loss: 0.2014 - val_precision_19: 0.8560 - val_recall_19: 0.6008\n",
      "Epoch 15/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9314 - loss: 0.1919 - precision_19: 0.8477 - recall_19: 0.6388 - val_auc_19: 0.9276 - val_loss: 0.2065 - val_precision_19: 0.8633 - val_recall_19: 0.5978\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - auc_19: 0.9288 - loss: 0.1996 - precision_19: 0.8509 - recall_19: 0.6281\n",
      "\u001b[32mpredicting using dense model of hidden 64\u001b[0m\n",
      "\u001b[1m5498/5498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 649us/step\n",
      "Epoch 1/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_19: 0.9317 - loss: 0.1902 - precision_19: 0.8406 - recall_19: 0.6238 - val_auc_19: 0.9322 - val_loss: 0.1939 - val_precision_19: 0.8648 - val_recall_19: 0.6180\n",
      "Epoch 2/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_19: 0.9348 - loss: 0.1885 - precision_19: 0.8351 - recall_19: 0.6476 - val_auc_19: 0.9291 - val_loss: 0.2018 - val_precision_19: 0.8760 - val_recall_19: 0.5732\n",
      "Epoch 3/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_19: 0.9353 - loss: 0.1830 - precision_19: 0.8412 - recall_19: 0.6518 - val_auc_19: 0.9331 - val_loss: 0.1972 - val_precision_19: 0.8904 - val_recall_19: 0.5623\n",
      "Epoch 4/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9357 - loss: 0.1852 - precision_19: 0.8556 - recall_19: 0.6520 - val_auc_19: 0.9331 - val_loss: 0.1968 - val_precision_19: 0.8869 - val_recall_19: 0.5742\n",
      "Epoch 5/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_19: 0.9351 - loss: 0.1857 - precision_19: 0.8614 - recall_19: 0.6419 - val_auc_19: 0.9311 - val_loss: 0.1991 - val_precision_19: 0.8447 - val_recall_19: 0.6310\n",
      "Epoch 6/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9341 - loss: 0.1843 - precision_19: 0.8498 - recall_19: 0.6573 - val_auc_19: 0.9329 - val_loss: 0.1938 - val_precision_19: 0.8541 - val_recall_19: 0.6295\n",
      "Epoch 7/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9358 - loss: 0.1863 - precision_19: 0.8503 - recall_19: 0.6476 - val_auc_19: 0.9323 - val_loss: 0.1937 - val_precision_19: 0.8206 - val_recall_19: 0.6653\n",
      "Epoch 8/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9390 - loss: 0.1802 - precision_19: 0.8529 - recall_19: 0.6671 - val_auc_19: 0.9334 - val_loss: 0.1937 - val_precision_19: 0.8437 - val_recall_19: 0.6504\n",
      "Epoch 9/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9389 - loss: 0.1789 - precision_19: 0.8487 - recall_19: 0.6573 - val_auc_19: 0.9345 - val_loss: 0.1948 - val_precision_19: 0.8071 - val_recall_19: 0.6813\n",
      "Epoch 10/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9360 - loss: 0.1837 - precision_19: 0.8447 - recall_19: 0.6552 - val_auc_19: 0.9344 - val_loss: 0.1921 - val_precision_19: 0.8469 - val_recall_19: 0.6474\n",
      "Epoch 11/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9381 - loss: 0.1806 - precision_19: 0.8231 - recall_19: 0.6589 - val_auc_19: 0.9247 - val_loss: 0.2091 - val_precision_19: 0.8168 - val_recall_19: 0.6041\n",
      "Epoch 12/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9416 - loss: 0.1794 - precision_19: 0.8469 - recall_19: 0.6608 - val_auc_19: 0.9346 - val_loss: 0.1959 - val_precision_19: 0.8907 - val_recall_19: 0.5842\n",
      "Epoch 13/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9388 - loss: 0.1796 - precision_19: 0.8548 - recall_19: 0.6643 - val_auc_19: 0.9336 - val_loss: 0.1935 - val_precision_19: 0.8542 - val_recall_19: 0.6330\n",
      "Epoch 14/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9403 - loss: 0.1763 - precision_19: 0.8639 - recall_19: 0.6614 - val_auc_19: 0.9333 - val_loss: 0.1934 - val_precision_19: 0.8453 - val_recall_19: 0.6559\n",
      "Epoch 15/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9375 - loss: 0.1848 - precision_19: 0.8574 - recall_19: 0.6405 - val_auc_19: 0.9359 - val_loss: 0.1941 - val_precision_19: 0.8651 - val_recall_19: 0.6130\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - auc_19: 0.9264 - loss: 0.2168 - precision_19: 0.8461 - recall_19: 0.5847\n",
      "\u001b[32mpredicting using dense model of hidden 64\u001b[0m\n",
      "\u001b[1m5498/5498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 756us/step\n",
      "Epoch 1/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_19: 0.9380 - loss: 0.1898 - precision_19: 0.8500 - recall_19: 0.6563 - val_auc_19: 0.9325 - val_loss: 0.1982 - val_precision_19: 0.8023 - val_recall_19: 0.6836\n",
      "Epoch 2/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9337 - loss: 0.1904 - precision_19: 0.8460 - recall_19: 0.6487 - val_auc_19: 0.9320 - val_loss: 0.1988 - val_precision_19: 0.8612 - val_recall_19: 0.5999\n",
      "Epoch 3/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_19: 0.9387 - loss: 0.1814 - precision_19: 0.8599 - recall_19: 0.6536 - val_auc_19: 0.9327 - val_loss: 0.1923 - val_precision_19: 0.8588 - val_recall_19: 0.6273\n",
      "Epoch 4/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_19: 0.9408 - loss: 0.1820 - precision_19: 0.8636 - recall_19: 0.6620 - val_auc_19: 0.9293 - val_loss: 0.2115 - val_precision_19: 0.7653 - val_recall_19: 0.6971\n",
      "Epoch 5/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_19: 0.9333 - loss: 0.1899 - precision_19: 0.8485 - recall_19: 0.6438 - val_auc_19: 0.9324 - val_loss: 0.2028 - val_precision_19: 0.8344 - val_recall_19: 0.6303\n",
      "Epoch 6/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9353 - loss: 0.1957 - precision_19: 0.8352 - recall_19: 0.6428 - val_auc_19: 0.9356 - val_loss: 0.1907 - val_precision_19: 0.8258 - val_recall_19: 0.6592\n",
      "Epoch 7/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9384 - loss: 0.1845 - precision_19: 0.8561 - recall_19: 0.6470 - val_auc_19: 0.9332 - val_loss: 0.1951 - val_precision_19: 0.8591 - val_recall_19: 0.6109\n",
      "Epoch 8/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_19: 0.9393 - loss: 0.1830 - precision_19: 0.8617 - recall_19: 0.6395 - val_auc_19: 0.9358 - val_loss: 0.1904 - val_precision_19: 0.8343 - val_recall_19: 0.6522\n",
      "Epoch 9/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_19: 0.9411 - loss: 0.1813 - precision_19: 0.8657 - recall_19: 0.6561 - val_auc_19: 0.9361 - val_loss: 0.1952 - val_precision_19: 0.8662 - val_recall_19: 0.6034\n",
      "Epoch 10/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_19: 0.9397 - loss: 0.1786 - precision_19: 0.8622 - recall_19: 0.6519 - val_auc_19: 0.9338 - val_loss: 0.1937 - val_precision_19: 0.8364 - val_recall_19: 0.6572\n",
      "Epoch 11/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9406 - loss: 0.1822 - precision_19: 0.8620 - recall_19: 0.6581 - val_auc_19: 0.9343 - val_loss: 0.1967 - val_precision_19: 0.8770 - val_recall_19: 0.6143\n",
      "Epoch 12/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc_19: 0.9425 - loss: 0.1769 - precision_19: 0.8575 - recall_19: 0.6637 - val_auc_19: 0.9362 - val_loss: 0.1923 - val_precision_19: 0.8226 - val_recall_19: 0.6677\n",
      "Epoch 13/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_19: 0.9395 - loss: 0.1790 - precision_19: 0.8680 - recall_19: 0.6526 - val_auc_19: 0.9289 - val_loss: 0.2282 - val_precision_19: 0.7315 - val_recall_19: 0.6951\n",
      "Epoch 14/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_19: 0.9410 - loss: 0.1799 - precision_19: 0.8443 - recall_19: 0.6639 - val_auc_19: 0.9365 - val_loss: 0.1916 - val_precision_19: 0.8854 - val_recall_19: 0.5969\n",
      "Epoch 15/15\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_19: 0.9433 - loss: 0.1787 - precision_19: 0.8645 - recall_19: 0.6684 - val_auc_19: 0.9372 - val_loss: 0.1881 - val_precision_19: 0.8683 - val_recall_19: 0.6502\n",
      "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - auc_19: 0.9341 - loss: 0.1805 - precision_19: 0.8332 - recall_19: 0.6513\n",
      "\u001b[32mpredicting using dense model of hidden 64\u001b[0m\n",
      "\u001b[1m5498/5498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 717us/step\n",
      "losses:  [0.2085159718990326, 0.20616906881332397, 0.20232722163200378, 0.20895688235759735, 0.1808524876832962]\n",
      "aucs:  [0.9207091331481934, 0.9262762665748596, 0.9248902201652527, 0.9290586709976196, 0.9382126927375793]\n",
      "precisions:  [0.848537027835846, 0.8067597150802612, 0.8527919054031372, 0.85028475522995, 0.848753035068512]\n",
      "recalls:  [0.5890083909034729, 0.6559139490127563, 0.6057692170143127, 0.6005747318267822, 0.6548727750778198]\n",
      "f1s:  [0.698668172619888, 0.7273006202195972, 0.70921284857042, 0.7219292335571406, 0.7485174412049878]\n",
      "roc_aucs:  [0.9253929193672172, 0.9301861856034097, 0.9280283126625433, 0.9363924480958222, 0.9404712901796897]\n",
      "Average Loss: 0.20136432647705077\n",
      "Average AUC: 0.9278293967247009\n",
      "Average Precision: 0.8414252877235413\n",
      "Average Recall: 0.6212278127670288\n",
      "Average F1 Score: 0.7211256632344067\n",
      "Average ROC AUC Score: 0.9320942311817365\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from colorama import init\n",
    "from termcolor import colored\n",
    "\n",
    "# Define the L2 regularizers\n",
    "k = .0001\n",
    "kernel_regularizer = l2(0.0001*k)\n",
    "bias_regularizer = l2(0.00001*k)\n",
    "\n",
    "# Define the Dense model with different regularization strengths for kernel and bias\n",
    "class DenseModel:\n",
    "    def __init__(self, input_dim, hidden_dim=64):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.model = self.build_model()\n",
    "        self.THRESHOLD = 0.5\n",
    "\n",
    "    def build_model(self):\n",
    "        input_layer = Input(shape=(self.input_dim,))\n",
    "        x = Dense(self.hidden_dim, activation='relu')(input_layer)\n",
    "        x = Dense(self.hidden_dim // 2, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(x)\n",
    "        x = Dense(self.hidden_dim // 4, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(x)\n",
    "        x = Dense(self.hidden_dim // 8, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(x)\n",
    "        x = Dense(self.hidden_dim // 16, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(x)\n",
    "        x = Dense(self.hidden_dim // 32, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(x)\n",
    "        output_layer = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "        model = Model(input_layer, output_layer)\n",
    "\n",
    "        # Compile the model with Binary Crossentropy loss\n",
    "        model.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(), metrics=[AUC(), Precision(), Recall()])\n",
    "        return model\n",
    "\n",
    "    def fit(self, X_train, y_train, epochs=10, verbose=0, batch_size=32, validation_split=0.3, validation_data=None):\n",
    "        if validation_data is not None:\n",
    "            self.model.fit(X_train, y_train, epochs=epochs, verbose=verbose, batch_size=batch_size, validation_data=validation_data, validation_split=validation_split)\n",
    "            return \n",
    "        self.model.fit(X_train, y_train, epochs=epochs, verbose=verbose, batch_size=batch_size, validation_split=validation_split)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        print(colored(f'predicting using dense model of hidden {self.hidden_dim}', 'green'))\n",
    "        return self.model.predict(X_test)\n",
    "    \n",
    "    def f1max(self, *args, **kwargs):\n",
    "        print(self.summary())\n",
    "        if args:\n",
    "            print(f\"iter: {args[0]}, epochs: {args[1]}, splits: {args[2]}\")\n",
    "        print(kwargs)\n",
    "        \n",
    "    def summary(self):\n",
    "        self.model.summary()\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        return self.model.evaluate(X_test, y_test)\n",
    "\n",
    "    def save(self, path):\n",
    "        self.model.save(path)\n",
    "\n",
    "# Example usage\n",
    "# Assuming xult and yult are your feature matrix and target vector\n",
    "for i in range(2):\n",
    "    dense_model = DenseModel(input_dim=xult.shape[1])\n",
    "    ktrain(dense_model, xult, yult,epochs=15,batch_size=32,splits=5,random_state=i)\n",
    "    ens.add_model(dense_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "[[9935  154]\n",
      " [ 471 1169]]\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "[[9978  120]\n",
      " [ 484 1147]]\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "[[9939   95]\n",
      " [ 543 1152]]\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "[[9922   91]\n",
      " [ 524 1192]]\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "[[9970   78]\n",
      " [ 492 1189]]\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [0.9227603898474308, 0.9423572350863438, 0.9462664110167025, 0.9523555275577646, 0.9577955024685791]\n",
      "precisions:  [0.8835978835978836, 0.9052880820836622, 0.9238171611868484, 0.9290724863600935, 0.9384372533543804]\n",
      "recalls:  [0.7128048780487805, 0.7032495401594114, 0.679646017699115, 0.6946386946386947, 0.7073170731707317]\n",
      "f1s:  [0.7766776677667767, 0.790106039229964, 0.7915803845716236, 0.7974223997095662, 0.8025174888501505]\n",
      "roc_aucs:  [0.8431825086282352, 0.8414402907079767, 0.8421883680695078, 0.8459335390259346, 0.8491431016086923]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 0.9443070131953644\n",
      "Average Precision: 0.9160425733165736\n",
      "Average Recall: 0.6995312407433467\n",
      "Average F1 Score: 0.7916607960256161\n",
      "Average ROC AUC Score: 0.8443775616080693\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "[[9935  154]\n",
      " [ 471 1169]]\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "[[9978  120]\n",
      " [ 484 1147]]\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "[[9939   95]\n",
      " [ 543 1152]]\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "[[9922   91]\n",
      " [ 524 1192]]\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "[[9970   78]\n",
      " [ 492 1189]]\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [0.9227603898474308, 0.9423572350863438, 0.9462664110167025, 0.9523555275577646, 0.9577955024685791]\n",
      "precisions:  [0.8835978835978836, 0.9052880820836622, 0.9238171611868484, 0.9290724863600935, 0.9384372533543804]\n",
      "recalls:  [0.7128048780487805, 0.7032495401594114, 0.679646017699115, 0.6946386946386947, 0.7073170731707317]\n",
      "f1s:  [0.7766776677667767, 0.790106039229964, 0.7915803845716236, 0.7974223997095662, 0.8025174888501505]\n",
      "roc_aucs:  [0.8431825086282352, 0.8414402907079767, 0.8421883680695078, 0.8459335390259346, 0.8491431016086923]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 0.9443070131953644\n",
      "Average Precision: 0.9160425733165736\n",
      "Average Recall: 0.6995312407433467\n",
      "Average F1 Score: 0.7916607960256161\n",
      "Average ROC AUC Score: 0.8443775616080693\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, precision_score, recall_score\n",
    "\n",
    "class XGBRFClassifierModel:\n",
    "    def __init__(self, objective='binary:logistic', eval_metric='auc', n_estimators=600, max_depth=5, subsample=0.9,\n",
    "                 colsample_bynode=0.9, reg_alpha=0.1, reg_lambda=1.0, min_child_weight=1, random_state=42, model_path='xgbrf_model.json', **kwargs):\n",
    "        self.model = xgb.XGBRFClassifier(objective=objective, eval_metric=eval_metric, n_estimators=n_estimators,\n",
    "                                         max_depth=max_depth, subsample=subsample, colsample_bynode=colsample_bynode, reg_alpha=reg_alpha,\n",
    "                                         reg_lambda=reg_lambda, min_child_weight=min_child_weight, random_state=random_state, **kwargs)\n",
    "        self.model_path = model_path\n",
    "        self.THRESHOLD = 0.5\n",
    "        self.load_model()\n",
    "\n",
    "    def fit(self, X_train, y_train, verbose=0, **kwargs):\n",
    "        self.model.fit(X_train, y_train, verbose=verbose, xgb_model=self.model_path if self.model_exists() else None)\n",
    "        self.save_model()\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        print(colored('predicting using xgbrf model', 'green'))\n",
    "        return self.model.predict(X_test).reshape(-1, 1)\n",
    "\n",
    "    def predict_proba(self, X_test):\n",
    "        return self.model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        y_pred = self.predict(X_test)\n",
    "        y_pred_proba = self.predict_proba(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        print(cm)\n",
    "        # Assuming loss is not directly available, using log loss as a proxy\n",
    "        loss = -1  # Placeholder, as XGBoost does not directly provide loss in this context\n",
    "        return [loss, auc, precision, recall]\n",
    "\n",
    "    def summary(self):\n",
    "        print(self.model)\n",
    "\n",
    "    def save_model(self):\n",
    "        self.model.save_model(self.model_path)\n",
    "\n",
    "    def load_model(self):\n",
    "        if self.model_exists():\n",
    "            self.model.load_model(self.model_path)\n",
    "            \n",
    "    def f1max(self, *args, **kwargs):\n",
    "        print(self.summary())\n",
    "        if args:\n",
    "            print(f\"iter: {args[0]}, epochs: {args[1]}, splits: {args[2]}\")\n",
    "        print(kwargs)\n",
    "\n",
    "    def model_exists(self):\n",
    "        try:\n",
    "            with open(self.model_path, 'r'):\n",
    "                return True\n",
    "        except FileNotFoundError:\n",
    "            return False\n",
    "    def save(self, path):\n",
    "        self.model.save_model(path)\n",
    "\n",
    "for i in range(2):\n",
    "    if i%2==0:\n",
    "        xgbrf_model = XGBRFClassifierModel(model_path=f'xgbrf_model{i}.json')\n",
    "    else:\n",
    "        xgbrf_model = XGBRFClassifierModel(eval_metric='logloss', model_path=f'xgbrf_model{i}.json')\n",
    "    ktrain(xgbrf_model, xult, yult, epochs=10, batch_size=32, splits=5, random_state=5)\n",
    "    ens.add_model(xgbrf_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6660, number of negative: 40256\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004022 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9291\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.141956 -> initscore=-1.799140\n",
      "[LightGBM] [Info] Start training from score -1.799140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "[[9931   95]\n",
      " [ 468 1235]]\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6728, number of negative: 40188\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003739 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9290\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.143405 -> initscore=-1.787291\n",
      "[LightGBM] [Info] Start training from score -1.787291\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "[[10008    86]\n",
      " [  433  1202]]\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6714, number of negative: 40202\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004143 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9291\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.143107 -> initscore=-1.789722\n",
      "[LightGBM] [Info] Start training from score -1.789722\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "[[9991   89]\n",
      " [ 474 1175]]\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6737, number of negative: 40179\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015267 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9290\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.143597 -> initscore=-1.785730\n",
      "[LightGBM] [Info] Start training from score -1.785730\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "[[10000   103]\n",
      " [  446  1180]]\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6613, number of negative: 40303\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003939 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9289\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.140954 -> initscore=-1.807388\n",
      "[LightGBM] [Info] Start training from score -1.807388\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "[[9899   80]\n",
      " [ 527 1223]]\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [0.9619504555331709, 0.964829319988439, 0.9564279577810506, 0.9622020799540866, 0.9560945700256253]\n",
      "precisions:  [0.9285714285714286, 0.9332298136645962, 0.9295886075949367, 0.9197194076383476, 0.9386032233307752]\n",
      "recalls:  [0.7251908396946565, 0.7351681957186544, 0.7125530624620983, 0.7257072570725708, 0.6988571428571428]\n",
      "f1s:  [0.8256634795818069, 0.8245810055865922, 0.8252310164724789, 0.8266322143764061, 0.8260820987240508]\n",
      "roc_aucs:  [0.864773068437139, 0.8641212455296189, 0.8647867878915595, 0.8660911301961144, 0.8649092430508305]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 0.9603008766564745\n",
      "Average Precision: 0.9299424961600169\n",
      "Average Recall: 0.7194952995610245\n",
      "Average F1 Score: 0.825637962948267\n",
      "Average ROC AUC Score: 0.8649362950210524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6689, number of negative: 40227\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003798 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9291\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142574 -> initscore=-1.794074\n",
      "[LightGBM] [Info] Start training from score -1.794074\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "[[9970   85]\n",
      " [ 471 1203]]\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6689, number of negative: 40227\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003760 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9289\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142574 -> initscore=-1.794074\n",
      "[LightGBM] [Info] Start training from score -1.794074\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "[[9962   93]\n",
      " [ 472 1202]]\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6699, number of negative: 40217\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003829 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9290\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142787 -> initscore=-1.792332\n",
      "[LightGBM] [Info] Start training from score -1.792332\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "[[9959  106]\n",
      " [ 465 1199]]\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6623, number of negative: 40293\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003833 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9289\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.141167 -> initscore=-1.805629\n",
      "[LightGBM] [Info] Start training from score -1.805629\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "[[9894   95]\n",
      " [ 503 1237]]\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6752, number of negative: 40164\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003845 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9291\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.143917 -> initscore=-1.783132\n",
      "[LightGBM] [Info] Start training from score -1.783132\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "[[10043    75]\n",
      " [  443  1168]]\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [0.9634063427730516, 0.9603094271827529, 0.9606597381443693, 0.9573625240638265, 0.9579087193218102]\n",
      "precisions:  [0.9340062111801242, 0.9281853281853282, 0.9187739463601533, 0.9286786786786787, 0.9396621078037007]\n",
      "recalls:  [0.7186379928315412, 0.7180406212664278, 0.7205528846153846, 0.710919540229885, 0.7250155183116077]\n",
      "f1s:  [0.8225498776902533, 0.8256487048253358, 0.8256827555456471, 0.8245053102291783, 0.8265809504676443]\n",
      "roc_aucs:  [0.8618682190247202, 0.8646331931028092, 0.8653559210240421, 0.8639248037377875, 0.8654716712315502]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 0.9599293502971621\n",
      "Average Precision: 0.9298612544415971\n",
      "Average Recall: 0.7186333114509693\n",
      "Average F1 Score: 0.8249935197516118\n",
      "Average ROC AUC Score: 0.8642507616241819\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, precision_score, recall_score\n",
    "\n",
    "class LGBMClassifierModel:\n",
    "    def __init__(self, eval_metric='logloss', model_path='lgbm_model.txt', **kwargs):\n",
    "        self.model = lgb.LGBMClassifier(objective='binary', metric=eval_metric, )\n",
    "        self.model_path = model_path\n",
    "        self.THRESHOLD = 0.5\n",
    "        self.init_model = None\n",
    "        self.load_model()\n",
    "\n",
    "    def fit(self, X_train, y_train, verbose=0, **kwargs):\n",
    "        self.model.fit(X_train, y_train,   init_model=self.init_model)\n",
    "        self.save_model()\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        ret = self.model.predict(X_test).astype(float)\n",
    "        # All ret values multiplied by 1.1\n",
    "        # ret *= 1.1\n",
    "        print(colored('predicting using lgbm model', 'green'))\n",
    "        return ret.reshape(-1, 1)\n",
    "\n",
    "    def predict_proba(self, X_test):\n",
    "        return self.model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        y_pred = self.predict(X_test)\n",
    "        y_pred_proba = self.predict_proba(X_test)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        print(cm)\n",
    "        # Assuming loss is not directly available, using log loss as a proxy\n",
    "        loss = -1  # Placeholder, as LightGBM does not directly provide loss in this context\n",
    "        return [loss, auc, precision, recall]\n",
    "\n",
    "    def summary(self):\n",
    "        print(self.model)\n",
    "\n",
    "    def save_model(self):\n",
    "        self.model.booster_.save_model(self.model_path)\n",
    "\n",
    "    def load_model(self):\n",
    "        if self.model_exists():\n",
    "            self.init_model = self.model_path\n",
    "\n",
    "    def f1max(self, *args, **kwargs):\n",
    "        print(self.summary())\n",
    "        if args:\n",
    "            print(f\"iter: {args[0]}, epochs: {args[1]}, splits: {args[2]}\")\n",
    "        print(kwargs)\n",
    "\n",
    "    def model_exists(self):\n",
    "        try:\n",
    "            with open(self.model_path, 'r'):\n",
    "                return True\n",
    "        except FileNotFoundError:\n",
    "            return False\n",
    "\n",
    "    def save(self, path):\n",
    "        self.model.booster_.save_model(path)\n",
    "\n",
    "# Example usage\n",
    "# Assuming xult and yult are your feature matrix and target vector\n",
    "# Split the data into training and test sets\n",
    "\n",
    "for i in range(2):\n",
    "    # Initialize the LightGBM classifier model\n",
    "    if i % 2 == 0:\n",
    "        lgbm_model = LGBMClassifierModel(model_path=f'lgbm_model{i}.txt')\n",
    "    else:\n",
    "        lgbm_model = LGBMClassifierModel(eval_metric='auc', model_path=f'lgbm_model{i}.txt')\n",
    "    # Fit the model on training data\n",
    "    ktrain(lgbm_model, xult, yult, epochs=10, batch_size=32, splits=5, random_state=i)\n",
    "    ens.add_model(lgbm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6660, number of negative: 40256\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9291\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.141956 -> initscore=-1.799140\n",
      "[LightGBM] [Info] Start training from score -1.799140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9887  139]\n",
      " [ 487 1216]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6728, number of negative: 40188\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013779 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9290\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.143405 -> initscore=-1.787291\n",
      "[LightGBM] [Info] Start training from score -1.787291\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9989  105]\n",
      " [ 469 1166]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6714, number of negative: 40202\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9291\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.143107 -> initscore=-1.789722\n",
      "[LightGBM] [Info] Start training from score -1.789722\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9985   95]\n",
      " [ 497 1152]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6737, number of negative: 40179\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010091 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9290\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.143597 -> initscore=-1.785730\n",
      "[LightGBM] [Info] Start training from score -1.785730\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9969  134]\n",
      " [ 459 1167]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6613, number of negative: 40303\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9289\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.140954 -> initscore=-1.807388\n",
      "[LightGBM] [Info] Start training from score -1.807388\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9851  128]\n",
      " [ 550 1200]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [0.9232435187010543, 0.927043739915134, 0.9189037427685851, 0.9260536523013453, 0.9191525059768371]\n",
      "precisions:  [0.8974169741697416, 0.9173878835562549, 0.9238171611868484, 0.8970023059185243, 0.9036144578313253]\n",
      "recalls:  [0.714034057545508, 0.7131498470948012, 0.698605215281989, 0.7177121771217713, 0.6857142857142857]\n",
      "f1s:  [0.7981577535324629, 0.794743935309973, 0.7978142076502732, 0.7956245367354732, 0.7952194077773814]\n",
      "roc_aucs:  [0.8502298316182031, 0.8472185542425439, 0.8485047024948017, 0.8476807176977191, 0.8494132482623976]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 0.9228794319325913\n",
      "Average Precision: 0.9078477565325389\n",
      "Average Recall: 0.705843116551671\n",
      "Average F1 Score: 0.7963119682011127\n",
      "Average ROC AUC Score: 0.8486094108631331\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6689, number of negative: 40227\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010214 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9291\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142574 -> initscore=-1.794074\n",
      "[LightGBM] [Info] Start training from score -1.794074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9939  116]\n",
      " [ 484 1190]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6689, number of negative: 40227\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010112 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9289\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142574 -> initscore=-1.794074\n",
      "[LightGBM] [Info] Start training from score -1.794074\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9947  108]\n",
      " [ 510 1164]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6699, number of negative: 40217\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9290\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142787 -> initscore=-1.792332\n",
      "[LightGBM] [Info] Start training from score -1.792332\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9941  124]\n",
      " [ 488 1176]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6623, number of negative: 40293\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9289\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.141167 -> initscore=-1.805629\n",
      "[LightGBM] [Info] Start training from score -1.805629\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9878  111]\n",
      " [ 530 1210]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6752, number of negative: 40164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9291\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.143917 -> initscore=-1.783132\n",
      "[LightGBM] [Info] Start training from score -1.783132\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[10016   102]\n",
      " [  478  1133]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [0.9249099189820384, 0.9283442559352474, 0.9258258817685048, 0.9185932399202341, 0.9192218660280448]\n",
      "precisions:  [0.9111791730474732, 0.9150943396226415, 0.9046153846153846, 0.9159727479182438, 0.9174089068825911]\n",
      "recalls:  [0.7108721624850657, 0.6953405017921147, 0.7067307692307693, 0.6954022988505747, 0.7032898820608318]\n",
      "f1s:  [0.7966185529924906, 0.7972593507806357, 0.794232461583591, 0.7964144500359454, 0.7961763382816014]\n",
      "roc_aucs:  [0.8479395796338528, 0.8484919116930667, 0.8457500567013899, 0.8480363758019304, 0.8476035720585869]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 0.9233790325268141\n",
      "Average Precision: 0.9128541104172669\n",
      "Average Recall: 0.7023271228838712\n",
      "Average F1 Score: 0.7961402307348528\n",
      "Average ROC AUC Score: 0.8475642991777654\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6659, number of negative: 40257\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9291\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.141935 -> initscore=-1.799315\n",
      "[LightGBM] [Info] Start training from score -1.799315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9897  128]\n",
      " [ 508 1196]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6699, number of negative: 40217\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004947 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9291\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142787 -> initscore=-1.792332\n",
      "[LightGBM] [Info] Start training from score -1.792332\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9944  121]\n",
      " [ 491 1173]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6664, number of negative: 40252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9291\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142041 -> initscore=-1.798440\n",
      "[LightGBM] [Info] Start training from score -1.798440\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9903  127]\n",
      " [ 506 1193]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6701, number of negative: 40215\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009934 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9291\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142830 -> initscore=-1.791983\n",
      "[LightGBM] [Info] Start training from score -1.791983\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9939  128]\n",
      " [ 480 1182]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6729, number of negative: 40187\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9290\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.143427 -> initscore=-1.787117\n",
      "[LightGBM] [Info] Start training from score -1.787117\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[10015    80]\n",
      " [  483  1151]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [0.9214574771990212, 0.9224621391245367, 0.9242898438293126, 0.9247953273835458, 0.9236559902468774]\n",
      "precisions:  [0.9033232628398792, 0.9064914992272025, 0.9037878787878788, 0.9022900763358779, 0.9350121852152722]\n",
      "recalls:  [0.7018779342723005, 0.7049278846153846, 0.7021777516185992, 0.7111913357400722, 0.704406364749082]\n",
      "f1s:  [0.795596921424736, 0.7974156367483848, 0.7951839584638797, 0.796883770009654, 0.7966722878021361]\n",
      "roc_aucs:  [0.8487067023126429, 0.8480120958996611, 0.8484206336308396, 0.8484523010842814, 0.847949520979911]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 0.9233321555566587\n",
      "Average Precision: 0.9101809804812222\n",
      "Average Recall: 0.7049162541990877\n",
      "Average F1 Score: 0.796350514889758\n",
      "Average ROC AUC Score: 0.8483082507814672\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6689, number of negative: 40227\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9290\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142574 -> initscore=-1.794074\n",
      "[LightGBM] [Info] Start training from score -1.794074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9956   99]\n",
      " [ 511 1163]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6697, number of negative: 40219\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010657 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9290\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142744 -> initscore=-1.792680\n",
      "[LightGBM] [Info] Start training from score -1.792680\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9932  131]\n",
      " [ 462 1204]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6664, number of negative: 40252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9290\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142041 -> initscore=-1.798440\n",
      "[LightGBM] [Info] Start training from score -1.798440\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9908  122]\n",
      " [ 496 1203]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6688, number of negative: 40228\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010140 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9290\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142553 -> initscore=-1.794248\n",
      "[LightGBM] [Info] Start training from score -1.794248\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9921  133]\n",
      " [ 493 1182]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6714, number of negative: 40202\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010153 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9291\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.143107 -> initscore=-1.789722\n",
      "[LightGBM] [Info] Start training from score -1.789722\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9960  120]\n",
      " [ 508 1141]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [0.9179703981744373, 0.9314560167702179, 0.9288923107076652, 0.9188980104450891, 0.9186388515887455]\n",
      "precisions:  [0.9215530903328051, 0.90187265917603, 0.9079245283018867, 0.8988593155893536, 0.9048374306106265]\n",
      "recalls:  [0.6947431302270012, 0.7226890756302521, 0.7080635668040024, 0.7056716417910448, 0.6919345057610673]\n",
      "f1s:  [0.7977227210333265, 0.7954662314725806, 0.7943608938297062, 0.7974457443958203, 0.7967958958666157]\n",
      "roc_aucs:  [0.848278281889348, 0.8488467324224203, 0.8475953332424523, 0.8502171955919159, 0.8478228233859351]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 0.9231711175372311\n",
      "Average Precision: 0.9070094048021404\n",
      "Average Recall: 0.7046203840426737\n",
      "Average F1 Score: 0.7963582973196098\n",
      "Average ROC AUC Score: 0.8485520733064142\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6688, number of negative: 40228\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9290\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142553 -> initscore=-1.794248\n",
      "[LightGBM] [Info] Start training from score -1.794248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9946  108]\n",
      " [ 506 1169]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6712, number of negative: 40204\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012107 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9290\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.143064 -> initscore=-1.790070\n",
      "[LightGBM] [Info] Start training from score -1.790070\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9983   95]\n",
      " [ 484 1167]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6704, number of negative: 40212\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9290\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142894 -> initscore=-1.791461\n",
      "[LightGBM] [Info] Start training from score -1.791461\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9938  132]\n",
      " [ 485 1174]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6647, number of negative: 40269\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010060 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9291\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.141679 -> initscore=-1.801416\n",
      "[LightGBM] [Info] Start training from score -1.801416\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9886  127]\n",
      " [ 517 1199]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6701, number of negative: 40215\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010213 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9291\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142830 -> initscore=-1.791983\n",
      "[LightGBM] [Info] Start training from score -1.791983\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[[9947  120]\n",
      " [ 486 1176]]\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [0.9264179401381791, 0.9247082628303592, 0.9205781949499974, 0.9208793137685577, 0.9214732411973353]\n",
      "precisions:  [0.9154267815191856, 0.9247226624405706, 0.8989280245022971, 0.9042232277526395, 0.9074074074074074]\n",
      "recalls:  [0.697910447761194, 0.7068443367655967, 0.707655213984328, 0.6987179487179487, 0.7075812274368231]\n",
      "f1s:  [0.796889398332322, 0.7959027465105808, 0.796545706743031, 0.7967374011248796, 0.7945771233614652]\n",
      "roc_aucs:  [0.8481691592458784, 0.8472240983784494, 0.8492120997095183, 0.8488888055482632, 0.84732197797466]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 0.9228113905768858\n",
      "Average Precision: 0.91014162072442\n",
      "Average Recall: 0.7037418349331781\n",
      "Average F1 Score: 0.7961304752144557\n",
      "Average ROC AUC Score: 0.8481632281713539\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, precision_score, recall_score\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, precision_score, recall_score\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, precision_score, recall_score\n",
    "\n",
    "class LGBMRandomForestClassifierModel:\n",
    "    def __init__(self, eval_metric='logloss', model_path='lgbm_rf_model.txt', bagging_freq=1, bagging_fraction=0.8, feature_fraction=0.8, **kwargs):\n",
    "        self.model_path = model_path\n",
    "        self.model = lgb.LGBMClassifier(boosting_type='rf', objective='binary', metric=eval_metric,\n",
    "                                        bagging_freq=bagging_freq, bagging_fraction=bagging_fraction,\n",
    "                                        feature_fraction=feature_fraction, **kwargs)\n",
    "        self.THRESHOLD = 0.5\n",
    "        self.load_model()  # Load the saved model if available\n",
    "\n",
    "    def fit(self, X_train, y_train, verbose=0, **kwargs):\n",
    "        # Train model from scratch\n",
    "        self.model.fit(X_train, y_train)\n",
    "        self.save_model()  # Save model state after training\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        print(colored('predicting using lgbm_rf model', 'green'))\n",
    "        ret = self.model.predict(X_test).astype(float)\n",
    "        return ret.reshape(-1, 1)\n",
    "\n",
    "    def predict_proba(self, X_test):\n",
    "        return self.model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        y_pred = self.predict(X_test)\n",
    "        y_pred_proba = self.predict_proba(X_test)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        print(cm)\n",
    "        loss = -1  # Placeholder for loss\n",
    "        return [loss, auc, precision, recall]\n",
    "\n",
    "    def summary(self):\n",
    "        print(self.model)\n",
    "\n",
    "    def save_model(self):\n",
    "        self.model.booster_.save_model(self.model_path)\n",
    "\n",
    "    def f1max(self, *args, **kwargs):\n",
    "        print(self.summary())\n",
    "        if args:\n",
    "            print(f\"iter: {args[0]}, epochs: {args[1]}, splits: {args[2]}\")\n",
    "        print(kwargs)\n",
    "\n",
    "    def load_model(self):\n",
    "        if self.model_exists():\n",
    "            # Load the booster and convert to LGBMClassifier\n",
    "            booster = lgb.Booster(model_file=self.model_path)\n",
    "            self.model._Booster = booster  # Inject the booster into the LGBMClassifier\n",
    "\n",
    "    def model_exists(self):\n",
    "        try:\n",
    "            with open(self.model_path, 'r'):\n",
    "                return True\n",
    "        except FileNotFoundError:\n",
    "            return False\n",
    "\n",
    "# Assuming xult and yult are your feature matrix and target vector\n",
    "# Split the data into training and test sets\n",
    "\n",
    "# yyyyyyy.shape \n",
    "for i in range(5):\n",
    "    # Initialize the LightGBM classifier model\n",
    "    if i % 2 == 0:\n",
    "        lgbm_rf_model = LGBMRandomForestClassifierModel(model_path=f'lgbm_rf_model{i}.txt')\n",
    "    else:\n",
    "        lgbm_rf_model = LGBMRandomForestClassifierModel(eval_metric='auc', model_path=f'lgbm_rf_model{i}.txt')\n",
    "    # Fit the model on training data\n",
    "    ktrain(lgbm_rf_model, xult, yult, epochs=1, batch_size=32, splits=5, random_state=i)\n",
    "    ens.add_model(lgbm_rf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "Percentage of predictions greater than 0.5: 11.49%\n",
      "Percentage of predictions less than or equal to 0.5: 88.51%\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of predictions greater than 0.5: 11.62%\n",
      "Percentage of predictions less than or equal to 0.5: 88.38%\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "Percentage of predictions greater than 0.5: 11.62%\n",
      "Percentage of predictions less than or equal to 0.5: 88.38%\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "Percentage of predictions greater than 0.5: 11.67%\n",
      "Percentage of predictions less than or equal to 0.5: 88.33%\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "Percentage of predictions greater than 0.5: 11.65%\n",
      "Percentage of predictions less than or equal to 0.5: 88.35%\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "Percentage of predictions greater than 0.5: 11.66%\n",
      "Percentage of predictions less than or equal to 0.5: 88.34%\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "Percentage of predictions greater than 0.5: 11.67%\n",
      "Percentage of predictions less than or equal to 0.5: 88.33%\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "Percentage of predictions greater than 0.5: 11.69%\n",
      "Percentage of predictions less than or equal to 0.5: 88.31%\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "Percentage of predictions greater than 0.5: 11.68%\n",
      "Percentage of predictions less than or equal to 0.5: 88.32%\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "Percentage of predictions greater than 0.5: 11.78%\n",
      "Percentage of predictions less than or equal to 0.5: 88.22%\n",
      "\u001b[32mPredicting with encoding_dim 512...\u001b[0m\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 885us/step\n",
      "Percentage of predictions greater than 0.5: 9.64%\n",
      "Percentage of predictions less than or equal to 0.5: 90.36%\n",
      "\u001b[32mPredicting with encoding_dim 256...\u001b[0m\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 733us/step\n",
      "Percentage of predictions greater than 0.5: 7.84%\n",
      "Percentage of predictions less than or equal to 0.5: 92.16%\n",
      "\u001b[32mpredicting using dense model of hidden 64\u001b[0m\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step\n",
      "Percentage of predictions greater than 0.5: 0.00%\n",
      "\u001b[32mpredicting using dense model of hidden 64\u001b[0m\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step\n",
      "Percentage of predictions greater than 0.5: 10.60%\n",
      "Percentage of predictions less than or equal to 0.5: 89.40%\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "Percentage of predictions greater than 0.5: 10.43%\n",
      "Percentage of predictions less than or equal to 0.5: 89.57%\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "Percentage of predictions greater than 0.5: 10.43%\n",
      "Percentage of predictions less than or equal to 0.5: 89.57%\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "Percentage of predictions greater than 0.5: 10.55%\n",
      "Percentage of predictions less than or equal to 0.5: 89.45%\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "Percentage of predictions greater than 0.5: 10.62%\n",
      "Percentage of predictions less than or equal to 0.5: 89.38%\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Percentage of predictions greater than 0.5: 10.92%\n",
      "Percentage of predictions less than or equal to 0.5: 89.08%\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Percentage of predictions greater than 0.5: 10.78%\n",
      "Percentage of predictions less than or equal to 0.5: 89.22%\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Percentage of predictions greater than 0.5: 10.69%\n",
      "Percentage of predictions less than or equal to 0.5: 89.31%\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Percentage of predictions greater than 0.5: 10.68%\n",
      "Percentage of predictions less than or equal to 0.5: 89.32%\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Percentage of predictions greater than 0.5: 10.79%\n",
      "Percentage of predictions less than or equal to 0.5: 89.21%\n"
     ]
    }
   ],
   "source": [
    "ens.save(testx, 'finals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
