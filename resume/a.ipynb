{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 08:30:22.200240: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-22 08:30:22.203469: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-22 08:30:22.212681: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-22 08:30:22.227396: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-22 08:30:22.231630: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-22 08:30:22.243376: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-22 08:30:23.238358: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "##load saved bm.keras and optimize it and then also train on test data and train data then upload final \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#default ml libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sklearn as sk\n",
    "#tf libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, ConfusionMatrixDisplay, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test.csv file\n",
    "loaddata = pd.read_csv('train.csv')\n",
    "testdata = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  person_age  person_income person_home_ownership  person_emp_length  \\\n",
      "0   0          37          35000                  RENT                0.0   \n",
      "1   1          22          56000                   OWN                6.0   \n",
      "2   2          29          28800                   OWN                8.0   \n",
      "3   3          30          70000                  RENT               14.0   \n",
      "4   4          22          60000                  RENT                2.0   \n",
      "\n",
      "  loan_intent loan_grade  loan_amnt  loan_int_rate  loan_percent_income  \\\n",
      "0   EDUCATION          B       6000          11.49                 0.17   \n",
      "1     MEDICAL          C       4000          13.35                 0.07   \n",
      "2    PERSONAL          A       6000           8.90                 0.21   \n",
      "3     VENTURE          B      12000          11.11                 0.17   \n",
      "4     MEDICAL          A       6000           6.92                 0.10   \n",
      "\n",
      "  cb_person_default_on_file  cb_person_cred_hist_length  loan_status  \n",
      "0                         N                          14            0  \n",
      "1                         N                           2            0  \n",
      "2                         N                          10            0  \n",
      "3                         N                           5            0  \n",
      "4                         N                           3            0  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      id  person_age  person_income person_home_ownership  person_emp_length  \\\n",
      "0  58645          23          69000                  RENT                3.0   \n",
      "1  58646          26          96000              MORTGAGE                6.0   \n",
      "2  58647          26          30000                  RENT                5.0   \n",
      "3  58648          33          50000                  RENT                4.0   \n",
      "4  58649          26         102000              MORTGAGE                8.0   \n",
      "\n",
      "         loan_intent loan_grade  loan_amnt  loan_int_rate  \\\n",
      "0    HOMEIMPROVEMENT          F      25000          15.76   \n",
      "1           PERSONAL          C      10000          12.68   \n",
      "2            VENTURE          E       4000          17.19   \n",
      "3  DEBTCONSOLIDATION          A       7000           8.90   \n",
      "4    HOMEIMPROVEMENT          D      15000          16.32   \n",
      "\n",
      "   loan_percent_income cb_person_default_on_file  cb_person_cred_hist_length  \n",
      "0                 0.36                         N                           2  \n",
      "1                 0.10                         Y                           4  \n",
      "2                 0.13                         Y                           2  \n",
      "3                 0.14                         N                           7  \n",
      "4                 0.15                         Y                           4  \n"
     ]
    }
   ],
   "source": [
    "train = loaddata.copy()\n",
    "print(train.head())\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "test = testdata.copy()\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_101669/2910247999.py:20: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test['person_home_ownership'] = test['person_home_ownership'].replace({'RENT': 0, 'MORTGAGE': 1, 'OWN': 2, 'OTHER': 3}).astype('category')\n",
      "/tmp/ipykernel_101669/2910247999.py:21: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test['loan_intent'] = test['loan_intent'].replace({'EDUCATION': 0, 'MEDICAL': 1, 'PERSONAL': 2, 'VENTURE': 3, 'DEBTCONSOLIDATION': 4, 'HOMEIMPROVEMENT': 5}).astype('category')\n",
      "/tmp/ipykernel_101669/2910247999.py:22: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test['loan_grade'] = test['loan_grade'].replace({'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6}).astype('category')\n",
      "/tmp/ipykernel_101669/2910247999.py:23: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test['cb_person_default_on_file'] = test['cb_person_default_on_file'].replace({'N': 0, 'Y': 1}).astype('category')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, ..., 3136, 3137, 3138, 3139, 3140]\n",
       "Length: 3141\n",
       "Categories (3141, int64): [0, 1, 2, 3, ..., 3137, 3138, 3139, 3140]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature engineering\n",
    "test[\"loantoincome\"] = ((test[\"loan_amnt\"] / test[\"person_income\"])).astype('Float64')\n",
    "test[\"loan_percent_incometoincome\"] = ((test[\"loan_percent_income\"] / test[\"person_income\"])).astype('Float64')\n",
    "test['person_age_to_person_income'] = (test['person_age'] / test['person_income']).astype(str).astype('Float64')\n",
    "test['person_emp_length_to_person_age'] = (test['person_emp_length'] / test['person_age']).astype('Float64')\n",
    "test['loan_int_rate_to_loan_amnt'] = (test['loan_int_rate'] / test['loan_amnt']).astype('Float64')\n",
    "\n",
    "\n",
    "\n",
    "test['income_to_age'] = test['person_income'] / test['person_age']\n",
    "test['loan_to_income'] = test['loan_amnt'] / test['person_income']\n",
    "test['rate_to_loan'] = test['loan_int_rate'] / test['loan_amnt']\n",
    "\n",
    "\n",
    "\n",
    "# Remove the original columns\n",
    "# train.drop(columns=['person_home_ownership', 'loan_intent', 'loan_grade', 'cb_person_default_on_file'], inplace=True)\n",
    "\n",
    "# Add the transformed columns\n",
    "test['person_home_ownership'] = test['person_home_ownership'].replace({'RENT': 0, 'MORTGAGE': 1, 'OWN': 2, 'OTHER': 3}).astype('category')\n",
    "test['loan_intent'] = test['loan_intent'].replace({'EDUCATION': 0, 'MEDICAL': 1, 'PERSONAL': 2, 'VENTURE': 3, 'DEBTCONSOLIDATION': 4, 'HOMEIMPROVEMENT': 5}).astype('category')\n",
    "test['loan_grade'] = test['loan_grade'].replace({'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6}).astype('category')\n",
    "test['cb_person_default_on_file'] = test['cb_person_default_on_file'].replace({'N': 0, 'Y': 1}).astype('category')\n",
    "test[\"person_home_ownership_income\"] = pd.Series(pd.factorize((test[\"person_home_ownership\"].astype(str) + test[\"person_income\"].astype(str)).to_numpy())[0]).astype('category')\n",
    "# test['person_emp_length'] = test['person_emp_length'].astype(str).astype('category')\n",
    "# test['loan_int_rate'] = (test['loan_int_rate'] * 100).astype(str).astype('category')\n",
    "# test['loan_percent_income'] = (test['loan_percent_income'] * 100).astype(str).astype('category')\n",
    "\n",
    "# more feature engineering\n",
    "\n",
    "test['person_home_ownership_income'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_101669/1369573505.py:18: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train['person_home_ownership'] = train['person_home_ownership'].replace({'RENT': 0, 'MORTGAGE': 1, 'OWN': 2, 'OTHER': 3}).astype('category')\n",
      "/tmp/ipykernel_101669/1369573505.py:19: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train['loan_intent'] = train['loan_intent'].replace({'EDUCATION': 0, 'MEDICAL': 1, 'PERSONAL': 2, 'VENTURE': 3, 'DEBTCONSOLIDATION': 4, 'HOMEIMPROVEMENT': 5}).astype('category')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_101669/1369573505.py:20: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train['loan_grade'] = train['loan_grade'].replace({'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6}).astype('category')\n",
      "/tmp/ipykernel_101669/1369573505.py:21: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train['cb_person_default_on_file'] = train['cb_person_default_on_file'].replace({'N': 0, 'Y': 1}).astype('category')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, ..., 3894, 3895, 3896, 3897, 3898]\n",
       "Length: 3899\n",
       "Categories (3899, int64): [0, 1, 2, 3, ..., 3895, 3896, 3897, 3898]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature engineering\n",
    "train[\"loantoincome\"] = ((train[\"loan_amnt\"] / train[\"person_income\"])).astype('Float64')\n",
    "train[\"loan_percent_incometoincome\"] = ((train[\"loan_percent_income\"] / train[\"person_income\"])).astype('Float64')\n",
    "train['person_age_to_person_income'] = (train['person_age'] / train['person_income']).astype(str).astype('Float64')\n",
    "train['person_emp_length_to_person_age'] = (train['person_emp_length'] / train['person_age']).astype('Float64')\n",
    "train['loan_int_rate_to_loan_amnt'] = (train['loan_int_rate'] / train['loan_amnt']).astype('Float64')\n",
    "\n",
    "\n",
    "train['income_to_age'] = train['person_income'] / train['person_age']\n",
    "train['loan_to_income'] = train['loan_amnt'] / train['person_income']\n",
    "train['rate_to_loan'] = train['loan_int_rate'] / train['loan_amnt']\n",
    "\n",
    "\n",
    "# Remove the original columns\n",
    "# train.drop(columns=['person_home_ownership', 'loan_intent', 'loan_grade', 'cb_person_default_on_file'], inplace=True)\n",
    "\n",
    "# Add the transformed columns\n",
    "train['person_home_ownership'] = train['person_home_ownership'].replace({'RENT': 0, 'MORTGAGE': 1, 'OWN': 2, 'OTHER': 3}).astype('category')\n",
    "train['loan_intent'] = train['loan_intent'].replace({'EDUCATION': 0, 'MEDICAL': 1, 'PERSONAL': 2, 'VENTURE': 3, 'DEBTCONSOLIDATION': 4, 'HOMEIMPROVEMENT': 5}).astype('category')\n",
    "train['loan_grade'] = train['loan_grade'].replace({'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6}).astype('category')\n",
    "train['cb_person_default_on_file'] = train['cb_person_default_on_file'].replace({'N': 0, 'Y': 1}).astype('category')\n",
    "train[\"person_home_ownership_income\"] = pd.Series(pd.factorize((train[\"person_home_ownership\"].astype(str) + train[\"person_income\"].astype(str)).to_numpy())[0]).astype('category')\n",
    "# train['person_emp_length'] = train['person_emp_length'].astype(str).astype('category')\n",
    "# train['loan_int_rate'] = (train['loan_int_rate'] * 100).astype(str).astype('category')\n",
    "# train['loan_percent_income'] = (train['loan_percent_income'] * 100).astype(str).astype('category')\n",
    "\n",
    "# more feature engineering\n",
    "\n",
    "train['person_home_ownership_income'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABc4AAAPdCAYAAACz4vsuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdeVxU1f8/8NeAzLA5gMoigYD7joaJuC8IKmkkaS4pKmoZWEi55gJquZU7ilYulXwrNa3UVNwzMRPFNf1ogZYJmIooKiBzfn/wm9tcQZ1BYIB5PR8PHjrnnnvvOe+Zuefe98ycqxBCCBAREREREREREREREQDAzNgNICIiIiIiIiIiIiIqT5g4JyIiIiIiIiIiIiLSwcQ5EREREREREREREZEOJs6JiIiIiIiIiIiIiHQwcU5EREREREREREREpIOJcyIiIiIiIiIiIiIiHUycExERERERERERERHpYOKciIiIiIiIiIiIiEgHE+dERERERERERERERDqYOCciIiIiesy6deugUCiQmppq7KY8t8rUFyIiotI0bNgweHp6GrsZz6Qd248fP27sphBVakycExERERGVU/fv30d0dDQOHDhg7KYQERFRGVuxYgXWrVtXqvs4cuQIoqOjkZmZWar7IaqImDgnIiIiIiqn7t+/j5iYmOdKnA8ZMgQPHjyAh4dHyTWMiIiISl1ZJc5jYmKYOCcqAhPnRCbo/v37xm4CERERlRFzc3NYWlpCoVAYuylERFSCeF1HJMf3BJU0Js6Jypno6GgoFApcuHAB/fv3h1qtRvXq1fHuu+/i4cOHsrpfffUVfHx8YGVlhWrVqmHAgAH466+/ZHU6d+6Mpk2bIikpCR07doS1tTWmTJkCADh+/DgCAwNRo0YNWFlZwcvLCyNGjJCtn52djffeew/u7u5QqVRo0KABPv74YwghZPUUCgUiIiKwdetWNG3aFCqVCk2aNMHOnTsNjsHHH3+Mtm3bonr16rCysoKPjw82bdpUqN6DBw/wzjvvoEaNGqhatSr69OmDa9euQaFQIDo6Wlb32rVrGDFiBJydnaW2rVmzxuC2ERGR6VqxYgWaNGkClUoFV1dXhIeHF/p21s8//4x+/fqhVq1aUKlUcHd3x7hx4/DgwQNZvWHDhsHW1hbXrl1DcHAwbG1t4ejoiPfffx/5+fkAgNTUVDg6OgIAYmJioFAoCo1x+/btQ4cOHWBjYwN7e3u88sor+P3332X7KmqOc09PT7z88ss4fPgwWrduDUtLS9SuXRtffPFFoX5nZmZi3Lhx8PT0hEqlgpubG4YOHYp///1XqpORkYGwsDA4OzvD0tIS3t7eWL9+vWw7qampUCgU+PjjjxEbG4vatWvD2toaAQEB+OuvvyCEwKxZs+Dm5gYrKyu88soruHXrVqH2/PTTT1Kfq1atiqCgIJw7d+7JTxwRkRHwug7QaDRYvHgxmjRpAktLSzg7O+PNN9/E7du3ZfW0Y9KBAwfQqlUrWFlZoVmzZtKvrb777js0a9YMlpaW8PHxwcmTJ2Xra8fUP//8E4GBgbCxsYGrqytmzpxZqH/FYWg/9BlbT58+jU6dOsHKygpubm6YPXs21q5dKxuvPT09ce7cORw8eFA6B+jcubNsOzk5OYiKioKjoyNsbGzw6quv4saNG3r3LTo6GuPHjwcAeHl5SfvRtuHRo0eYNWsW6tSpA5VKBU9PT0yZMgU5OTn6BxCGvR+AyvueYK6jAhJEVK7MmDFDABDNmjUTvXv3FsuXLxdvvPGGACCGDBki1Zs9e7ZQKBTi9ddfFytWrBAxMTGiRo0awtPTU9y+fVuq16lTJ+Hi4iIcHR3F2LFjxapVq8TWrVtFenq6cHBwEPXr1xcLFiwQn376qfjggw9Eo0aNpHU1Go3o2rWrUCgUYuTIkWL58uWid+/eAoCIjIyUtRuA8Pb2FjVr1hSzZs0SixcvFrVr1xbW1tbi33//NSgGbm5u4u233xbLly8XCxcuFK1btxYAxLZt22T1+vfvL8UlNjZW9O/fX3h7ewsAYsaMGVK9tLQ04ebmJtzd3cXMmTPFypUrRZ8+fQQAsWjRIoPaRkREpmHt2rUCgEhJSRFC/Dc++/v7i2XLlomIiAhhbm4uXnrpJZGbmyutN3bsWNGrVy/x0UcfiVWrVomwsDBhbm4uXnvtNdn2Q0NDhaWlpWjSpIkYMWKEWLlypQgJCREAxIoVK4QQQty7d0+sXLlSABCvvvqq+PLLL8WXX34pTp06JYQQIiEhQVSpUkXUr19fzJ8/XzoXcHBwkNpdVF+EEMLDw0M0aNBAODs7iylTpojly5eLF198USgUCnH27Fmp3t27d0XTpk2Fubm5GDVqlFi5cqWYNWuWeOmll8TJkyeFEELcv39fNGrUSFhYWIhx48aJpUuXig4dOggAYvHixdK2UlJSBADRokUL0bhxY7Fw4UIxdepUoVQqRZs2bcSUKVNE27ZtxdKlS8U777wjFAqFGD58uCxuX3zxhVAoFKJHjx5i2bJlYt68ecLT01PY29vL+kdEZGy8rhNi5MiRokqVKmLUqFEiLi5OTJw4UdjY2BQaO7VjUs2aNUV0dLRYtGiReOGFF4Stra346quvRK1atcTcuXPF3LlzhZ2dnahbt67Iz8+X1teOqfXq1RNDhgwRy5cvFy+//LIAIKZNm2ZQm0NDQ4WHh8dz9eNZY+vff/8tqlWrJqpXry5iYmLExx9/LBo2bChdy2rHsy1btgg3NzfRsGFD6Rxg9+7dQoj/xvaWLVuKrl27imXLlon33ntPmJubi/79++vd31OnTomBAwdK18ba/dy7d0+KBwDx2muvidjYWDF06FABQAQHBxsUV33fD0JU7vcEcx0VDxPnROWMdkDp06ePrPztt98WAMSpU6dEamqqMDc3Fx9++KGszpkzZ0SVKlVk5Z06dRIARFxcnKzuli1bBADx22+/PbEtW7duFQDE7NmzZeWvvfaaUCgU4vLly1IZAKFUKmVlp06dEgDEsmXL9A+AKLgA15WbmyuaNm0qunbtKpUlJSUVOagNGzas0GASFhYmatasWWhQGzBggLCzsyu0PyIiIt1kc0ZGhlAqlSIgIEB2ob58+XIBQKxZs0YqK2pMmTNnjlAoFOLKlStSmfZCdObMmbK6LVu2FD4+PtLjGzduFBrXtFq0aCGcnJzEzZs3pbJTp04JMzMzMXTo0CL7ouXh4SEAiEOHDkllGRkZQqVSiffee08qmz59ugAgvvvuu0L712g0QgghFi9eLACIr776SlqWm5sr/Pz8hK2trcjKyhJC/Jc4d3R0FJmZmVLdyZMnSxeleXl5UvnAgQOFUqkUDx8+FEIUJPHt7e3FqFGjZO1IS0sTdnZ2hcqJiIzJ1K/rfv75ZwFAbNiwQVa+c+fOQuXaMenIkSNS2a5duwQAYWVlJRs/V61aJQCI/fv3S2XaMXXs2LFSmUajEUFBQUKpVIobN27o3e7HE+fF6cezxtaxY8cKhUIhfQAthBA3b94U1apVKzReN2nSRHTq1KlQO7Vju7+/vzQeCyHEuHHjhLm5uWycfZYFCxYU2q8QQiQnJwsAYuTIkbLy999/XwAQ+/bt03sf+rwfhBCV+j0hBHMdFRGnaiEqp8LDw2WPx44dCwDYsWMHvvvuO2g0GvTv3x///vuv9Ofi4oJ69eph//79snVVKhWGDx8uK7O3twcAbNu2DXl5eUW2YceOHTA3N8c777wjK3/vvfcghMBPP/0kK/f390edOnWkx82bN4darcaff/6pf8cBWFlZSf+/ffs27ty5gw4dOuDEiRNSufZnUW+//bZsXW2ctIQQ2Lx5M3r37g0hhCxegYGBuHPnjmy7REREj9uzZw9yc3MRGRkJM7P/Tp9HjRoFtVqN7du3S2W6Y1h2djb+/fdftG3bFkKIQj8tB4C33npL9rhDhw56jZvXr19HcnIyhg0bhmrVqknlzZs3R/fu3bFjx45nbqNx48bo0KGD9NjR0RENGjSQ7X/z5s3w9vbGq6++Wmh97ZzpO3bsgIuLCwYOHCgts7CwwDvvvIN79+7h4MGDsvX69esHOzs76bGvry8A4I033kCVKlVk5bm5ubh27RoAICEhAZmZmRg4cKBsPDc3N4evr2+h8x8iovLAVK/rNm7cCDs7O3Tv3l3WNx8fH9ja2hbqW+PGjeHn5yc91o4NXbt2Ra1atQqVF9WWiIgI6f/a6TVyc3OxZ88evdtdEv141ti6c+dO+Pn5oUWLFlJZtWrVMHjwYIPbN3r0aNk9TDp06ID8/HxcuXLF4G09TnsuERUVJSt/7733AEB2/qOvp70fAFTq9wTAXEdFVOXZVYjIGOrVqyd7XKdOHZiZmSE1NRVmZmYQQhSqo2VhYSF7/MILL0CpVMrKOnXqhJCQEMTExGDRokXo3LkzgoODMWjQIKhUKgDAlStX4OrqiqpVq8rWbdSokbRcl+4JjZaDg0Ohud+eZdu2bZg9ezaSk5Nlc6fpnhBcuXIFZmZm8PLykq1bt25d2eMbN24gMzMTq1evxurVq4vcX0ZGhkHtIyIi06Id7xo0aCArVyqVqF27tmw8vHr1KqZPn44ffvih0Ph3584d2WNLS0tpDnMtfcfNJ7UJKBind+3ahezsbNjY2DxxG/qM23/88QdCQkKe2ZZ69erJPlTQtkO3rU/arzaJ7u7uXmS5tj2XLl0CUJBEKYparX5qO4mIjMFUr+suXbqEO3fuwMnJqcjlj1+DFXds0DIzM0Pt2rVlZfXr1wcA2T0+DPW8/QAKx+7KlSuyDwm0Hr+W1cfj+3NwcABQOD7Fob3mfrxdLi4usLe3L1Zy/mnvB6Ag3pX1PQEw11ERMXFOVEHoHkg1Gg0UCgV++uknmJubF6pra2sre6z7qabu9jZt2oSjR4/ixx9/xK5duzBixAh88sknOHr0aKFt6KOotgAw6IYsP//8M/r06YOOHTtixYoVqFmzJiwsLLB27VrEx8cb3CaNRgOg4FtsoaGhRdZp3ry5wdslIiJ6XH5+Prp3745bt25h4sSJaNiwIWxsbHDt2jUMGzZMGpO0njRulpWSGLdLcr/Pao82fl9++SVcXFwK1dP9tjoRUXllKtd1Go0GTk5O2LBhQ5HLH//guLhjQ2krqX6UVnvLYn+6r9mS9vi2K/N7grmOiolnl0Tl1KVLl2SfMF6+fBkajQaenp4wNzeHEAJeXl7Sp+jF1aZNG7Rp0wYffvgh4uPjMXjwYHz99dcYOXIkPDw8sGfPHty9e1f2SeyFCxcAAB4eHs+176Js3rwZlpaW2LVrl/RpMACsXbtWVs/DwwMajQYpKSmyT6MvX74sq+fo6IiqVasiPz8f/v7+Jd5eIiKq/LTj3cWLF2XfZsvNzUVKSoo0vpw5cwb/+9//sH79egwdOlSql5CQUOx9P+liVbdNj7tw4QJq1Kjx1G+b66tOnTo4e/bsU+t4eHjg9OnT0Gg0sm+dl/T5gvYn0k5OThzTiajCMNXrujp16mDPnj1o165dkcnNkqbRaPDnn3/K4vi///0PAODp6Vns7ZZGPzw8PApdtwKFr2WB0k1aP2sf2mvuS5cuSd/EBoD09HRkZmYW63XztPcDUBDvyvqeYK6jYuIc50TlVGxsrOzxsmXLAAA9e/ZE3759YW5ujpiYmEKfcAohcPPmzWdu//bt24XW1c6xpv3JUK9evZCfn4/ly5fL6i1atAgKhQI9e/Y0qE/6MDc3h0KhQH5+vlSWmpqKrVu3yuoFBgYCAFasWCEr18ZJd3shISHYvHlzkRf+N27cKKGWExFRZeXv7w+lUomlS5fKxs7PP/8cd+7cQVBQEID/vo2kW0cIgSVLlhR739bW1gCAzMxMWXnNmjXRokULrF+/Xrbs7Nmz2L17N3r16lXsfeoKCQnBqVOnsGXLlkLLtP3s1asX0tLS8M0330jLHj16hGXLlsHW1hadOnUqkbYEBgZCrVbjo48+KnLOUo7pRFQemep1Xf/+/ZGfn49Zs2YVWvbo0aNC41pJ0O2fEALLly+HhYUFunXrVuxtlkY/AgMDkZiYiOTkZKns1q1bRX6r3cbGplRi9fg+gMLnGtpzicWLF8vKFy5cCADS+Y8hnvZ+AFCp3xPMdVRM/MY5UTmVkpKCPn36oEePHkhMTMRXX32FQYMGwdvbGwAwe/ZsTJ48GampqQgODkbVqlWRkpKCLVu2YPTo0Xj//fefuv3169djxYoVePXVV1GnTh3cvXsXn376KdRqtTRA9u7dG126dMEHH3yA1NRUeHt7Y/fu3fj+++8RGRkpuzlGSQkKCsLChQvRo0cPDBo0CBkZGYiNjUXdunVx+vRpqZ6Pjw9CQkKwePFi3Lx5E23atMHBgwelbxXofmo+d+5c7N+/H76+vhg1ahQaN26MW7du4cSJE9izZw9u3bpV4v0gIqLKw9HREZMnT0ZMTAx69OiBPn364OLFi1ixYgVeeuklvPHGGwCAhg0bok6dOnj//fdx7do1qNVqbN68+bnmGbWyskLjxo3xzTffoH79+qhWrRqaNm2Kpk2bYsGCBejZsyf8/PwQFhaGBw8eYNmyZbCzs0N0dHSJ9H38+PHYtGkT+vXrhxEjRsDHxwe3bt3CDz/8gLi4OHh7e2P06NFYtWoVhg0bhqSkJHh6emLTpk345ZdfsHjx4kLzhxaXWq3GypUrMWTIELz44osYMGAAHB0dcfXqVWzfvh3t2rUrdAFMRGRspnpd16lTJ7z55puYM2cOkpOTERAQAAsLC1y6dAkbN27EkiVL8Nprr5XY/iwtLbFz506EhobC19cXP/30E7Zv344pU6YUmk7F2P2YMGECvvrqK3Tv3h1jx46FjY0NPvvsM9SqVQu3bt2SXcv6+Phg5cqVmD17NurWrQsnJ6cn3uujuHx8fAAAH3zwAQYMGAALCwv07t0b3t7eCA0NxerVq5GZmYlOnTrh2LFjWL9+PYKDg9GlSxeD9/Ws90OdOnUq7XuCuY4KShBRuTJjxgwBQJw/f1689tpromrVqsLBwUFERESIBw8eyOpu3rxZtG/fXtjY2AgbGxvRsGFDER4eLi5evCjV6dSpk2jSpEmh/Zw4cUIMHDhQ1KpVS6hUKuHk5CRefvllcfz4cVm9u3fvinHjxglXV1dhYWEh6tWrJxYsWCA0Go2sHgARHh5eaD8eHh4iNDTUoBh8/vnnol69ekKlUomGDRuKtWvXSnHRlZ2dLcLDw0W1atWEra2tCA4OFhcvXhQAxNy5c2V109PTRXh4uHB3dxcWFhbCxcVFdOvWTaxevdqgthERkWlYu3atACBSUlKksuXLl4uGDRsKCwsL4ezsLMaMGSNu374tW+/8+fPC399f2Nraiho1aohRo0aJU6dOCQBi7dq1Ur3Q0FBhY2NTaL9FjXdHjhwRPj4+QqlUCgBixowZ0rI9e/aIdu3aCSsrK6FWq0Xv3r3F+fPnn9kXDw8PERQUVGj/nTp1Ep06dZKV3bx5U0RERIgXXnhBKJVK4ebmJkJDQ8W///4r1UlPTxfDhw8XNWrUEEqlUjRr1kzWXyGESElJEQDEggULZOX79+8XAMTGjRuLbPdvv/1WqH5gYKCws7MTlpaWok6dOmLYsGGFzmGIiIyJ13UFVq9eLXx8fISVlZWoWrWqaNasmZgwYYL4559/ZNsuakwqqi1FjSXaMfWPP/4QAQEBwtraWjg7O4sZM2aI/Px8g9obGhoqPDw8SrQfRY2tJ0+eFB06dBAqlUq4ubmJOXPmiKVLlwoAIi0tTaqXlpYmgoKCRNWqVQUAaTtPGyMBiP379xvU71mzZokXXnhBmJmZyc4Z8vLyRExMjPDy8hIWFhbC3d1dTJ48WTx8+NCg7RvyfhCi8r4nmOuoeBRClNEdFYhIL9HR0YiJicGNGzdQo0YNYzenwklOTkbLli3x1VdfYfDgwcZuDhERERERmSBe15WdYcOGYdOmTbh3756xm/JcIiMjsWrVKty7d8/oNxAvaXw/PD/mOoyDc5wTUYX14MGDQmWLFy+GmZkZOnbsaIQWERERERERET3d49eyN2/exJdffon27dtXuqQ5GY65jvKDc5wTUZnIz89/5s0pbG1tYWtrq/c258+fj6SkJHTp0gVVqlTBTz/9hJ9++gmjR4+Gu7v78zaZiIiIiIiIdJTGdV1ZuHXrFnJzc5+43Nzc/LnmQjeUn58fOnfujEaNGiE9PR2ff/45srKyMG3atBLbx7179575LXxHR8fnStTru4/KjLmOyo2JcyIqE3/99Re8vLyeWmfGjBkG3cysbdu2SEhIwKxZs3Dv3j3UqlUL0dHR+OCDD56ztURERERERPS40riuKwt9+/bFwYMHn7jcw8MDqampZdaeXr16YdOmTVi9ejUUCgVefPFFfP755yX6beKPP/4YMTExT62TkpICT0/PUt9HZcZcR+XGOc6JqEw8fPgQhw8ffmqd2rVro3bt2mXUIiIiIiIiIjJERb2uS0pKwu3bt5+43MrKCu3atSvDFpW+P//8E3/++edT67Rv3x6Wlpbleh/lXUV9T5B+mDgnIiIiIiIiIiIiItJh0lO1aDQa/PPPP6hatSoUCoWxm0NERAQAEELg7t27cHV1hZkZ7+PN8ZqIiMojjteFccwmIqLyqLhjtkknzv/55x9Oqk9EROXWX3/9BTc3N2M3w+g4XhMRUXnG8fo/HLOJiKg8M3TMNunEedWqVQEUBE2tVj/XtvLy8rB7924EBATAwsKiJJpXaTFW+mOs9MM46Y+x0p8xY5WVlQV3d3dpnDJ1HK+fH/ttOv02xT4D7Lcp9bs89ZnjdWEcs0se41CAcWAMtBiHAoxDAX3jUNwx26QT59qfjqnV6hIZ1K2traFWq036BasPxkp/jJV+GCf9MVb6Kw+xep6fOM+ZMwffffcdLly4ACsrK7Rt2xbz5s1DgwYNpDqdO3fGwYMHZeu9+eabiIuLkx5fvXoVY8aMwf79+2Fra4vQ0FDMmTMHVar8dwpx4MABREVF4dy5c3B3d8fUqVMxbNgw2XZjY2OxYMECpKWlwdvbG8uWLUPr1q316gvH6+fHfptOv02xzwD7bUr9Lo995pQk/+GYXfIYhwKMA2OgxTgUYBwKGBoHQ8dsTsRGRERUCR08eBDh4eE4evQoEhISkJeXh4CAAGRnZ8vqjRo1CtevX5f+5s+fLy3Lz89HUFAQcnNzceTIEaxfvx7r1q3D9OnTpTopKSkICgpCly5dkJycjMjISIwcORK7du2S6nzzzTeIiorCjBkzcOLECXh7eyMwMBAZGRmlHwgiIiIiIiKiYjDpb5wTERFVVjt37pQ9XrduHZycnJCUlISOHTtK5dbW1nBxcSlyG7t378b58+exZ88eODs7o0WLFpg1axYmTpyI6OhoKJVKxMXFwcvLC5988gkAoFGjRjh8+DAWLVqEwMBAAMDChQsxatQoDB8+HAAQFxeH7du3Y82aNZg0aVJpdJ+IiIiIiIjouTBxTkREZALu3LkDAKhWrZqsfMOGDfjqq6/g4uKC3r17Y9q0abC2tgYAJCYmolmzZnB2dpbqBwYGYsyYMTh37hxatmyJxMRE+Pv7y7YZGBiIyMhIAEBubi6SkpIwefJkabmZmRn8/f2RmJhYZFtzcnKQk5MjPc7KygJQ8DO8vLy8YkYA0jZ0/zUV7Lfp9NsU+wyw36bU7/LU5/LQBiIiIio9TJwTERFVchqNBpGRkWjXrh2aNm0qlQ8aNAgeHh5wdXXF6dOnMXHiRFy8eBHfffcdACAtLU2WNAcgPU5LS3tqnaysLDx48AC3b99Gfn5+kXUuXLhQZHvnzJmDmJiYQuW7d++WkvrPKyEhoUS2U9Gw36bDFPsMsN+mpDz0+f79+8ZuAhEREZUiJs6JiIgqufDwcJw9exaHDx+WlY8ePVr6f7NmzVCzZk1069YNf/zxB+rUqVPWzZRMnjwZUVFR0mPtHdADAgJK5EZjCQkJ6N69u0ndRIf9Np1+m2KfAfbblPpdnvqs/UUUERERVU5MnBMREVViERER2LZtGw4dOgQ3N7en1vX19QUAXL58GXXq1IGLiwuOHTsmq5Oeng4A0rzoLi4uUpluHbVaDSsrK5ibm8Pc3LzIOk+aW12lUkGlUhUqt7CwKLEkSUluqyJhv02HKfYZYL9NSXnos7H3T0RERKWLifMS1jR6F3LyFXrXT50bVIqtISIiUyWEwNixY7FlyxYcOHAAXl5ez1wnOTkZAFCzZk0AgJ+fHz788ENkZGTAyckJQMFP49VqNRo3bizV2bFjh2w7CQkJ8PPzAwAolUr4+Phg7969CA4OBlAwdczevXsRERFREl0tE56Tthu8Dsd4IiKi58drbCIiMhYmzomIiCqh8PBwxMfH4/vvv0fVqlWlOcnt7OxgZWWFP/74A/Hx8ejVqxeqV6+O06dPY9y4cejYsSOaN28OAAgICEDjxo0xZMgQzJ8/H2lpaZg6dSrCw8Olb4S/9dZbWL58OSZMmIARI0Zg3759+Pbbb7F9+3+J5qioKISGhqJVq1Zo3bo1Fi9ejOzsbAwfPrzsA0NERERERESkBybOiYiIKqGVK1cCADp37iwrX7t2LYYNGwalUok9e/ZISWx3d3eEhIRg6tSpUl1zc3Ns27YNY8aMgZ+fH2xsbBAaGoqZM2dKdby8vLB9+3aMGzcOS5YsgZubGz777DMEBgZKdV5//XXcuHED06dPR1paGlq0aIGdO3cWumEoERERERERUXnBxDkREVElJIR46nJ3d3ccPHjwmdvx8PAoNBXL4zp37oyTJ08+tU5ERESFmpqFiIiIiIiITJuZsRtARERERERERERERFSeMHFORERERERERERERKSDiXMiIiIiIiIiIiIiIh1MnBMRERERERERERER6WDinIiIiIiIiIiIiIhIBxPnREREREREREREREQ6mDgnIiIiIiIiIiIiItLBxDkRERERERERERERkQ6DE+eHDh1C79694erqCoVCga1bt8qWDxs2DAqFQvbXo0cPWZ1bt25h8ODBUKvVsLe3R1hYGO7duyerc/r0aXTo0AGWlpZwd3fH/PnzC7Vl48aNaNiwISwtLdGsWTPs2LHD0O4Yneek7Qb/EREREREREREREVHpMThxnp2dDW9vb8TGxj6xTo8ePXD9+nXp7//+7/9kywcPHoxz584hISEB27Ztw6FDhzB69GhpeVZWFgICAuDh4YGkpCQsWLAA0dHRWL16tVTnyJEjGDhwIMLCwnDy5EkEBwcjODgYZ8+eNbRLRERERERERERERESSKoau0LNnT/Ts2fOpdVQqFVxcXIpc9vvvv2Pnzp347bff0KpVKwDAsmXL0KtXL3z88cdwdXXFhg0bkJubizVr1kCpVKJJkyZITk7GwoULpQT7kiVL0KNHD4wfPx4AMGvWLCQkJGD58uWIi4srct85OTnIycmRHmdlZQEA8vLykJeXZ1ggHqNdX2Umnms7huyrotK2v6L3oywwVvphnPTHWOnPmLHi80NERERERERkXAYnzvVx4MABODk5wcHBAV27dsXs2bNRvXp1AEBiYiLs7e2lpDkA+Pv7w8zMDL/++iteffVVJCYmomPHjlAqlVKdwMBAzJs3D7dv34aDgwMSExMRFRUl229gYGChqWN0zZkzBzExMYXKd+/eDWtr6+fsdYFZrTQlsp2nqYhT0hQlISHB2E2oMBgr/TBO+mOs9GeMWN2/f7/M90lERERERERE/ynxxHmPHj3Qt29feHl54Y8//sCUKVPQs2dPJCYmwtzcHGlpaXBycpI3okoVVKtWDWlpaQCAtLQ0eHl5yeo4OztLyxwcHJCWliaV6dbRbqMokydPliXbs7Ky4O7ujoCAAKjV6ufqd15eHhISEjDtuBlyNIrn2taznI0OLNXtlzZtrLp37w4LCwtjN6dcY6z0wzjpj7HSnzFjpf1FFBEREREREREZR4knzgcMGCD9v1mzZmjevDnq1KmDAwcOoFu3biW9O4OoVCqoVKpC5RYWFiWWFMnRKJCTX7qJ88qS7CrJuFd2jJV+GCf9MVb6M0as+NwQERERERERGZfBNwc1VO3atVGjRg1cvnwZAODi4oKMjAxZnUePHuHWrVvSvOguLi5IT0+X1dE+fladJ82tTkRERERERERERESkj1JPnP/999+4efMmatasCQDw8/NDZmYmkpKSpDr79u2DRqOBr6+vVOfQoUOym6MlJCSgQYMGcHBwkOrs3btXtq+EhAT4+fmVdpeIiIiIiIiIiIiIqBIzOHF+7949JCcnIzk5GQCQkpKC5ORkXL16Fffu3cP48eNx9OhRpKamYu/evXjllVdQt25dBAYWzMvdqFEj9OjRA6NGjcKxY8fwyy+/ICIiAgMGDICrqysAYNCgQVAqlQgLC8O5c+fwzTffYMmSJbL5yd99913s3LkTn3zyCS5cuIDo6GgcP34cERERJRAWIiIiIiIiIiIiIjJVBifOjx8/jpYtW6Jly5YAgKioKLRs2RLTp0+Hubk5Tp8+jT59+qB+/foICwuDj48Pfv75Z9nc4hs2bEDDhg3RrVs39OrVC+3bt8fq1aul5XZ2dti9ezdSUlLg4+OD9957D9OnT8fo0aOlOm3btkV8fDxWr14Nb29vbNq0CVu3bkXTpk2fJx5EREREREREREREZOIMTpx37twZQohCf+vWrYOVlRV27dqFjIwM5ObmIjU1FatXr4azs7NsG9WqVUN8fDzu3r2LO3fuYM2aNbC1tZXVad68OX7++Wc8fPgQf//9NyZOnFioLf369cPFixeRk5ODs2fPolevXoZ2h4iIiIiIiMgoVq5ciebNm0OtVkOtVsPPzw8//fSTtPzhw4cIDw9H9erVYWtri5CQkEL3+rp69SqCgoJgbW0NJycnjB8/Ho8ePZLVOXDgAF588UWoVCrUrVsX69atK9SW2NhYeHp6wtLSEr6+vjh27Fip9JmIiKiiKPU5zomIiIiIiIioMDc3N8ydOxdJSUk4fvw4unbtildeeQXnzp0DAIwbNw4//vgjNm7ciIMHD+Kff/5B3759pfXz8/MRFBSE3NxcHDlyBOvXr8e6deswffp0qU5KSgqCgoLQpUsXJCcnIzIyEiNHjsSuXbukOt988w2ioqIwY8YMnDhxAt7e3ggMDERGRkbZBYOIiKicYeKciIiIiIiIyAh69+6NXr16oV69eqhfvz4+/PBD2Nra4ujRo7hz5w4+//xzLFy4EF27doWPjw/Wrl2LI0eO4OjRowCA3bt34/z58/jqq6/QokUL9OzZE7NmzUJsbCxyc3MBAHFxcfDy8sInn3yCRo0aISIiAq+99hoWLVoktWPhwoUYNWoUhg8fjsaNGyMuLg7W1tZYs2aNUeJCRERUHlQxdgOIiIiIiIiITF1+fj42btyI7Oxs+Pn5ISkpCXl5efD395fqNGzYELVq1UJiYiLatGmDxMRENGvWTDY9amBgIMaMGYNz586hZcuWSExMlG1DWycyMhIAkJubi6SkJEyePFlabmZmBn9/fyQmJj61zTk5OcjJyZEeZ2VlAQDy8vKQl5dX7FhotwEAKjNRrPUqC21/Klu/DMU4MAZajEMBxqGAvnEobpyYOCciIiIiIiIykjNnzsDPzw8PHz6Era0ttmzZgsaNGyM5ORlKpRL29vay+s7OzkhLSwMApKWlFbqnmPbxs+pkZWXhwYMHuH37NvLz84usc+HChae2fc6cOYiJiSlUvnv3blhbWz+783qY1UpjUP0dO3aUyH7Lm4SEBGM3oVxgHBgDLcahAONQ4FlxuH//frG2y8R5BeQ5abtB9VPnBpVSS4iIqLyaM2cOvvvuO1y4cAFWVlZo27Yt5s2bhwYNGkh1Hj58iPfeew9ff/01cnJyEBgYiBUrVsgunK9evYoxY8Zg//79sLW1RWhoKObMmYMqVf47hThw4ACioqJw7tw5uLu7Y+rUqRg2bJisPbGxsViwYAHS0tLg7e2NZcuWoXXr1qUeByIiovKuQYMGSE5Oxp07d7Bp0yaEhobi4MGDxm6WXiZPnoyoqCjpcVZWFtzd3REQEAC1Wv1c287Ly0NCQgKmHTdDjkah93pnowOfa7/ljTYO3bt3h4WFhbGbYzSMA2OgxTgUYBwK6BsH7S+iDMXEORERUSV08OBBhIeH46WXXsKjR48wZcoUBAQE4Pz587CxsQFQcMOx7du3Y+PGjbCzs0NERAT69u2LX375BcB/NxxzcXHBkSNHcP36dQwdOhQWFhb46KOPAPx3w7G33noLGzZswN69ezFy5EjUrFkTgYEFF67aG47FxcXB19cXixcvRmBgIC5evAgnJyfjBIiIiKicUCqVqFu3LgDAx8cHv/32G5YsWYLXX38dubm5yMzMlH3rPD09HS4uLgAAFxcXHDt2TLa99PR0aZn2X22Zbh21Wg0rKyuYm5vD3Ny8yDrabTyJSqWCSqUqVG5hYVFiiZwcjQI5+fonzitrAqkkY1qRMQ6MgRbjUIBxKPCsOBQ3RkycExERVUI7d+6UPV63bh2cnJyQlJSEjh07Sjcci4+PR9euXQEAa9euRaNGjXD06FG0adNGuuHYnj174OzsjBYtWmDWrFmYOHEioqOjoVQqZTccA4BGjRrh8OHDWLRokZQ4173hGFBwk7Lt27djzZo1mDRpUqG2l8V8qYZuR2Vu2PyqxdlHaTLVORBNsd+m2GeA/TalfpenPpdWGzQaDXJycuDj4wMLCwvs3bsXISEhAICLFy/i6tWr8PPzAwD4+fnhww8/REZGhvRhdEJCAtRqNRo3bizVeXz6koSEBGkbSqUSPj4+2Lt3L4KDg6U27N27FxEREaXSRyIiooqAiXMiIiITcOfOHQBAtWrVAKBc33CsLOZLNXQuwPnFmFWmPM6xaqpzIJpiv02xzwD7bUrKQ5+LO1+qrsmTJ6Nnz56oVasW7t69i/j4eBw4cAC7du2CnZ0dwsLCEBUVhWrVqkGtVmPs2LHw8/NDmzZtAAABAQFo3LgxhgwZgvnz5yMtLQ1Tp05FeHi49E3wt956C8uXL8eECRMwYsQI7Nu3D99++y22b/9vCtCoqCiEhoaiVatWaN26NRYvXozs7GzpQ28iIiJTxMQ5ERFRJafRaBAZGYl27dqhadOmAApuFFZebzhWFvOlGjoXYNPoXQbvqzzNsWqqcyCaYr9Nsc8A+21K/S5PfS7ufKm6MjIyMHToUFy/fh12dnZo3rw5du3ahe7duwMAFi1aBDMzM4SEhMjuR6Jlbm6Obdu2YcyYMfDz84ONjQ1CQ0Mxc+ZMqY6Xlxe2b9+OcePGYcmSJXBzc8Nnn30m/TIMAF5//XXcuHED06dPR1paGlq0aIGdO3cWGr+JiIhMCRPnRERElVx4eDjOnj2Lw4cPG7speimL+VIN3ZYhc6vq7qO8MdU5EE2x36bYZ4D9NiXloc8lsf/PP//8qcstLS0RGxuL2NjYJ9bx8PB45q+cOnfujJMnTz61TkREBKdmISIi0mFm7AYQERFR6YmIiMC2bduwf/9+uLm5SeUuLi7SDcd0PX7DsaJuFKZd9rQ62huO1ahRo9g3HCMiIiIiIiIyFn7jnIiIqBISQmDs2LHYsmULDhw4AC8vL9lyU7/hWNPoXcX6FjkRERERERGZBibOiYiIKqHw8HDEx8fj+++/R9WqVaU5ye3s7GBlZcUbjhERERERERE9BRPnREREldDKlSsBFMxpqmvt2rUYNmwYAN5wjIiIiIiIiOhJmDgnIiKqhIQQz6zDG44RERERERERFY03ByUiIiIiIiIiIiIi0sHEORERERERERERERGRDibOiYiIiIiIiIiIiIh0MHFORERERERERERERKSDiXMiIiIiIiIiIiIiIh1MnBMRERERERERERER6WDinIiIiIiIiIiIiIhIBxPnREREREREREREREQ6mDgnIiIiIiIiIiIiItLBxDkRERERERERERERkQ4mzomIiIiIiIiIiIiIdDBxTkRERERERERERESkg4lzIiIiIiIiIiIiIiIdTJwTEREREREREREREelg4pyIiIiIiIiIiIiISAcT50REREREREREREREOpg4JyIiIiIiIiIiIiLSwcQ5EREREREREREREZEOJs6JiIiIiIiIiIiIiHQwcU5EREREREREREREpIOJcyIiIiIiIiIiIiIiHUycExERERERERERERHpYOKciIioEjp06BB69+4NV1dXKBQKbN26VbZ82LBhUCgUsr8ePXrI6ty6dQuDBw+GWq2Gvb09wsLCcO/ePVmd06dPo0OHDrC0tIS7uzvmz59fqC0bN25Ew4YNYWlpiWbNmmHHjh0l3l8iIiIiIiKikmRw4vxZF+JCCEyfPh01a9aElZUV/P39cenSJVkdXogTERGVruzsbHh7eyM2NvaJdXr06IHr169Lf//3f/8nWz548GCcO3cOCQkJ2LZtGw4dOoTRo0dLy7OyshAQEAAPDw8kJSVhwYIFiI6OxurVq6U6R44cwcCBAxEWFoaTJ08iODgYwcHBOHv2bMl3moiIiIiIiKiEVDF0Be2F+IgRI9C3b99Cy+fPn4+lS5di/fr18PLywrRp0xAYGIjz58/D0tISQMGF+PXr15GQkIC8vDwMHz4co0ePRnx8PID/LsT9/f0RFxeHM2fOYMSIEbC3t5cu2LUX4nPmzMHLL7+M+Ph4BAcH48SJE2jatOnzxISIiKjC69mzJ3r27PnUOiqVCi4uLkUu+/3337Fz50789ttvaNWqFQBg2bJl6NWrFz7++GO4urpiw4YNyM3NxZo1a6BUKtGkSRMkJydj4cKF0ni9ZMkS9OjRA+PHjwcAzJo1CwkJCVi+fDni4uKK3HdOTg5ycnKkx1lZWQCAvLw85OXlGRaIx2jXV5mJ59qOIfsqD7RtKU9tKgum2G9T7DPAfptSv8tTn8tDG4iIiKj0GJw4f9qFuBACixcvxtSpU/HKK68AAL744gs4Oztj69atGDBgAC/EjaC8ndCVp5Pd8o6x0g/jpD/GSn/GjFVZ7fPAgQNwcnKCg4MDunbtitmzZ6N69eoAgMTERNjb20tjNQD4+/vDzMwMv/76K1599VUkJiaiY8eOUCqVUp3AwEDMmzcPt2/fhoODAxITExEVFSXbb2BgYKFfrOmaM2cOYmJiCpXv3r0b1tbWz9nrArNaaUpkO09THn8Jl5CQYOwmGIUp9tsU+wyw36akPPT5/v37xm4CERERlSKDE+dPk5KSgrS0NPj7+0tldnZ28PX1RWJiIgYMGMALcSMojxfuQPk42a0oGCv9ME76Y6z0Z4xYlcWFeI8ePdC3b194eXnhjz/+wJQpU9CzZ08kJibC3NwcaWlpcHJykq1TpUoVVKtWDWlpaQCAtLQ0eHl5yeo4OztLyxwcHJCWliaV6dbRbqMokydPlo3xWVlZcHd3R0BAANRq9XP1Oy8vDwkJCZh23Aw5GsVzbetZzkYHlur2DaHtd/fu3WFhYWHs5pQZU+y3KfYZYL9Nqd/lqc/aL2IRERFR5VSiiXPtRfDTLpB5IV72ytOFO1C+TnbLO8ZKP4yT/hgr/RkzVmVxIT5gwADp/82aNUPz5s1Rp04dHDhwAN26dSv1/T+NSqWCSqUqVG5hYVFiz0WORoGc/NIdr8vje6wkY1iRmGK/TbHPAPttSspDn429fyIiIipdJZo4L+8qy4W4ocrrCV15ONmtKBgr/TBO+mOs9GeMWBnjualduzZq1KiBy5cvo1u3bnBxcUFGRoaszqNHj3Dr1i1pXnQXFxekp6fL6mgfP6vOk+ZWJyIiIiIiIioPzEpyY9qL4KddIPNCnIiIqPz5+++/cfPmTdSsWRMA4Ofnh8zMTCQlJUl19u3bB41GA19fX6nOoUOHZHOyJyQkoEGDBnBwcJDq7N27V7avhIQE+Pn5lXaXiIiIiIiIiIqtRBPnXl5ecHFxkV0gZ2Vl4ddff5UukHkhTkREVPru3buH5ORkJCcnAyi4D0lycjKuXr2Ke/fuYfz48Th69ChSU1Oxd+9evPLKK6hbty4CAwum92rUqBF69OiBUaNG4dixY/jll18QERGBAQMGwNXVFQAwaNAgKJVKhIWF4dy5c/jmm2+wZMkS2bRo7777Lnbu3IlPPvkEFy5cQHR0NI4fP46IiIgyjwkREVF5M2fOHLz00kuoWrUqnJycEBwcjIsXL8rqPHz4EOHh4ahevTpsbW0REhJS6EtkV69eRVBQEKytreHk5ITx48fj0aNHsjoHDhzAiy++CJVKhbp162LdunWF2hMbGwtPT09YWlrC19cXx44dK/E+ExERVRQGJ86fdiGuUCgQGRmJ2bNn44cffsCZM2cwdOhQuLq6Ijg4GAAvxImIiMrC8ePH0bJlS7Rs2RIAEBUVhZYtW2L69OkwNzfH6dOn0adPH9SvXx9hYWHw8fHBzz//LJvSbMOGDWjYsCG6deuGXr16oX379li9erW03M7ODrt370ZKSgp8fHzw3nvvYfr06Rg9erRUp23btoiPj8fq1avh7e2NTZs2YevWrWjatGnZBYOIiKicOnjwIMLDw3H06FEkJCQgLy8PAQEByM7OluqMGzcOP/74IzZu3IiDBw/in3/+Qd++faXl+fn5CAoKQm5uLo4cOYL169dj3bp1mD59ulQnJSUFQUFB6NKlC5KTkxEZGYmRI0di165dUp1vvvkGUVFRmDFjBk6cOAFvb28EBgYW+sU4ERGRqTB4jvPjx4+jS5cu0mNtMjs0NBTr1q3DhAkTkJ2djdGjRyMzMxPt27fHzp07YWlpKa2zYcMGREREoFu3bjAzM0NISAiWLl0qLddeiIeHh8PHxwc1atR44oX41KlTMWXKFNSrV48X4kRERP9f586dIYR44nLdC+UnqVatGuLj459ap3nz5vj555+fWqdfv37o16/fM/dHRERkanbu3Cl7vG7dOjg5OSEpKQkdO3bEnTt38PnnnyM+Ph5du3YFAKxduxaNGjXC0aNH0aZNG+zevRvnz5/Hnj174OzsjBYtWmDWrFmYOHEioqOjoVQqERcXBy8vL3zyyScACr7QdvjwYSxatEj6tdnChQsxatQoDB8+HAAQFxeH7du3Y82aNZg0aVIZRoWIiKh8MDhx/qwLcYVCgZkzZ2LmzJlPrMMLcSIiIiIiIiK5O3fuACi4ZgaApKQk5OXlwd/fX6rTsGFD1KpVC4mJiWjTpg0SExPRrFkzODs7S3UCAwMxZswYnDt3Di1btkRiYqJsG9o6kZGRAIDc3FwkJSVh8uTJ0nIzMzP4+/sjMTHxie3NyclBTk6O9DgrKwsAkJeXJ5t6tTi066vMnpx/eNp6lYW2P5WtX4ZiHBgDLcahAONQQN84FDdOBifOiYiIiIiIiKhkaTQaREZGol27dtIvqdPS0qBUKmFvby+r6+zsjLS0NKmObtJcu1y77Gl1srKy8ODBA9y+fRv5+flF1rlw4cIT2zxnzhzExMQUKt+9ezesra316PWzzWqlMaj+jh07SmS/5U1CQoKxm1AuMA6MgRbjUIBxKPCsONy/f79Y22XinIiIiIiIiMjIwsPDcfbsWRw+fNjYTdHb5MmTZfciy8rKgru7OwICAqBWq59r23l5eUhISMC042bI0Sj0Xu9sdOBz7be80cahe/fusLCwMHZzjIZxYAy0GIcCjEMBfeOg/UWUoZg4JyIiIiIiIjKiiIgIbNu2DYcOHYKbm5tU7uLigtzcXGRmZsq+dZ6eng4XFxepzrFjx2TbS09Pl5Zp/9WW6dZRq9WwsrKCubk5zM3Ni6yj3UZRVCqV7MbiWhYWFiWWyMnRKJCTr3/ivLImkEoyphUZ48AYaDEOBRiHAs+KQ3FjZFbcBhERERERERFR8QkhEBERgS1btmDfvn3w8vKSLffx8YGFhQX27t0rlV28eBFXr16Fn58fAMDPzw9nzpxBRkaGVCchIQFqtRqNGzeW6uhuQ1tHuw2lUgkfHx9ZHY1Gg71790p1iIiITA2/cU5ERERERERkBOHh4YiPj8f333+PqlWrSnOS29nZwcrKCnZ2dggLC0NUVBSqVasGtVqNsWPHws/PD23atAEABAQEoHHjxhgyZAjmz5+PtLQ0TJ06FeHh4dK3wd966y0sX74cEyZMwIgRI7Bv3z58++232L59u9SWqKgohIaGolWrVmjdujUWL16M7OxsDB8+vOwDQ0REVA4wcU5ERERERERkBCtXrgQAdO7cWVa+du1aDBs2DACwaNEimJmZISQkBDk5OQgMDMSKFSukuubm5ti2bRvGjBkDPz8/2NjYIDQ0FDNnzpTqeHl5Yfv27Rg3bhyWLFkCNzc3fPbZZwgM/G8+8Ndffx03btzA9OnTkZaWhhYtWmDnzp2FbhhKRERkKpg4JyIiIiIiIjICIcQz61haWiI2NhaxsbFPrOPh4YEdO3Y8dTudO3fGyZMnn1onIiICERERz2xTeeY5afuzKz0mdW5QKbSEiIgqOs5xTkRERERERERERESkg4lzIiIiIiIiIiIiIiIdTJwTEREREREREREREelg4pyIiIiIiIiIiIiISAcT50REREREREREREREOpg4JyIiIiIiIiIiIiLSwcQ5EREREREREREREZEOJs6JiIiIiIiIiIiIiHQwcU5EREREREREREREpIOJcyIiIiIiIiIiIiIiHUycExERERERERERERHpYOKciIiIiIiIiIiIiEgHE+dERERERERERERERDqYOCciIiIiIiIiIiIi0sHEORERUSV06NAh9O7dG66urlAoFNi6datsuRAC06dPR82aNWFlZQV/f39cunRJVufWrVsYPHgw1Go17O3tERYWhnv37snqnD59Gh06dIClpSXc3d0xf/78Qm3ZuHEjGjZsCEtLSzRr1gw7duwo8f4SERERERERlaQqxm4AERERlbzs7Gx4e3tjxIgR6Nu3b6Hl8+fPx9KlS7F+/Xp4eXlh2rRpCAwMxPnz52FpaQkAGDx4MK5fv46EhATk5eVh+PDhGD16NOLj4wEAWVlZCAgIgL+/P+Li4nDmzBmMGDEC9vb2GD16NADgyJEjGDhwIObMmYOXX34Z8fHxCA4OxokTJ9C0adOyC4gReE7abvA6qXODSqElREREREREZCgmzomIiCqhnj17omfPnkUuE0Jg8eLFmDp1Kl555RUAwBdffAFnZ2ds3boVAwYMwO+//46dO3fit99+Q6tWrQAAy5YtQ69evfDxxx/D1dUVGzZsQG5uLtasWQOlUokmTZogOTkZCxculBLnS5YsQY8ePTB+/HgAwKxZs5CQkIDly5cjLi6uyPbl5OQgJydHepyVlQUAyMvLQ15e3nPFRbu+ykw813ZKy/P271nbLa3tl1em2G9T7DPAfptSv8tTn8tDG4iIiKj0MHFORERkYlJSUpCWlgZ/f3+pzM7ODr6+vkhMTMSAAQOQmJgIe3t7KWkOAP7+/jAzM8Ovv/6KV199FYmJiejYsSOUSqVUJzAwEPPmzcPt27fh4OCAxMREREVFyfYfGBhYaOoYXXPmzEFMTEyh8t27d8Pa2vo5ev6fWa00JbKdklba09gkJCSU6vbLK1Pstyn2GWC/TUl56PP9+/eN3QQiIiIqRUycExERmZi0tDQAgLOzs6zc2dlZWpaWlgYnJyfZ8ipVqqBatWqyOl5eXoW2oV3m4OCAtLS0p+6nKJMnT5Yl27OysuDu7o6AgACo1WpDulpIXl4eEhISMO24GXI0iufaVmk4Gx1YKtvV9rt79+6wsLAolX2UR6bYb1PsM8B+m1K/y1Oftb+IIiIiosqJiXMiIiIqV1QqFVQqVaFyCwuLEkuS5GgUyMkvf4nz0k4ClWQMKxJT7Lcp9hlgv01JeeizsfdPREREpcvM2A0gIiKisuXi4gIASE9Pl5Wnp6dLy1xcXJCRkSFb/ujRI9y6dUtWp6ht6O7jSXW0y4mIiIiIiIjKIybOiYiITIyXlxdcXFywd+9eqSwrKwu//vor/Pz8AAB+fn7IzMxEUlKSVGffvn3QaDTw9fWV6hw6dEh2c7SEhAQ0aNAADg4OUh3d/WjraPdDREREREREVB4xcU5ERFQJ3bt3D8nJyUhOTgZQcEPQ5ORkXL16FQqFApGRkZg9ezZ++OEHnDlzBkOHDoWrqyuCg4MBAI0aNUKPHj0watQoHDt2DL/88gsiIiIwYMAAuLq6AgAGDRoEpVKJsLAwnDt3Dt988w2WLFkim5/83Xffxc6dO/HJJ5/gwoULiI6OxvHjxxEREVHWISEiIiIiIiLSG+c4JyIiqoSOHz+OLl26SI+1yezQ0FCsW7cOEyZMQHZ2NkaPHo3MzEy0b98eO3fuhKWlpbTOhg0bEBERgW7dusHMzAwhISFYunSptNzOzg67d+9GeHg4fHx8UKNGDUyfPh2jR4+W6rRt2xbx8fGYOnUqpkyZgnr16mHr1q1o2rRpGUSBiIiIiIiIqHiYOCciIqqEOnfuDCHEE5crFArMnDkTM2fOfGKdatWqIT4+/qn7ad68OX7++een1unXrx/69ev39AYTERERERERlSOcqoWIiIiIiIiIiIiISAcT50REREREREREREREOpg4JyIiIiIiIiIiIiLSwcQ5EREREREREREREZEOJs6JiIiIiIiIiIiIiHQwcU5EREREREREREREpKPEE+fR0dFQKBSyv4YNG0rLHz58iPDwcFSvXh22trYICQlBenq6bBtXr15FUFAQrK2t4eTkhPHjx+PRo0eyOgcOHMCLL74IlUqFunXrYt26dSXdFSIiIiIiIiIiIiIyQaXyjfMmTZrg+vXr0t/hw4elZePGjcOPP/6IjRs34uDBg/jnn3/Qt29faXl+fj6CgoKQm5uLI0eOYP369Vi3bh2mT58u1UlJSUFQUBC6dOmC5ORkREZGYuTIkdi1a1dpdIeIiIiIiIiIiIiITEiVUtlolSpwcXEpVH7nzh18/vnniI+PR9euXQEAa9euRaNGjXD06FG0adMGu3fvxvnz57Fnzx44OzujRYsWmDVrFiZOnIjo6GgolUrExcXBy8sLn3zyCQCgUaNGOHz4MBYtWoTAwMDS6BIRERERERERERERmYhSSZxfunQJrq6usLS0hJ+fH+bMmYNatWohKSkJeXl58Pf3l+o2bNgQtWrVQmJiItq0aYPExEQ0a9YMzs7OUp3AwECMGTMG586dQ8uWLZGYmCjbhrZOZGTkU9uVk5ODnJwc6XFWVhYAIC8vD3l5ec/VZ+36KjPxXNspDc/bt5KmbU95a1d5xFjph3HSH2OlP2PGis8PERERERERkXGVeOLc19cX69atQ4MGDXD9+nXExMSgQ4cOOHv2LNLS0qBUKmFvby9bx9nZGWlpaQCAtLQ0WdJcu1y77Gl1srKy8ODBA1hZWRXZtjlz5iAmJqZQ+e7du2FtbV2s/j5uVitNiWynJO3YscPYTShSQkKCsZtQYTBW+mGc9MdY6c8Ysbp//36Z75OIiIiM49ChQ1iwYAGSkpJw/fp1bNmyBcHBwdJyIQRmzJiBTz/9FJmZmWjXrh1WrlyJevXqSXVu3bqFsWPH4scff4SZmRlCQkKwZMkS2NraSnVOnz6N8PBw/Pbbb3B0dMTYsWMxYcIEWVs2btyIadOmITU1FfXq1cO8efPQq1evUo8BERFReVTiifOePXtK/2/evDl8fX3h4eGBb7/99okJ7bIyefJkREVFSY+zsrLg7u6OgIAAqNXq59p2Xl4eEhISMO24GXI0iudtaok6G12+pq/Rxqp79+6wsLAwdnPKNcZKP4yT/hgr/RkzVtpfRBEREVHll52dDW9vb4wYMUJ2/y+t+fPnY+nSpVi/fj28vLwwbdo0BAYG4vz587C0tAQADB48GNevX0dCQgLy8vIwfPhwjB49GvHx8QAKzi0CAgLg7++PuLg4nDlzBiNGjIC9vT1Gjx4NADhy5AgGDhyIOXPm4OWXX0Z8fDyCg4Nx4sQJNG3atOwCQkREVE6UylQtuuzt7VG/fn1cvnwZ3bt3R25uLjIzM2XfOk9PT5fmRHdxccGxY8dk20hPT5eWaf/VlunWUavVT03Oq1QqqFSqQuUWFhYllhTJ0SiQk1++Euf1pu02eJ3UuUGl0BK5kox7ZcdY6Ydx0h9jpT9jxIrPDRERkeno2bOn7AtouoQQWLx4MaZOnYpXXnkFAPDFF1/A2dkZW7duxYABA/D7779j586d+O2339CqVSsAwLJly9CrVy98/PHHcHV1xYYNG5Cbm4s1a9ZAqVSiSZMmSE5OxsKFC6XE+ZIlS9CjRw+MHz8eADBr1iwkJCRg+fLliIuLK7J9lWU61PI8TR6nWizAODAGWoxDAcahgL5xKG6cSj1xfu/ePfzxxx8YMmQIfHx8YGFhgb179yIkJAQAcPHiRVy9ehV+fn4AAD8/P3z44YfIyMiAk5MTgIKfyavVajRu3Fiq8/j0IwkJCdI2iIiIiIiIiCq6lJQUpKWlye7xZWdnB19fXyQmJmLAgAFITEyEvb29lDQHAH9/f5iZmeHXX3/Fq6++isTERHTs2BFKpVKqExgYiHnz5uH27dtwcHBAYmKi7Bfa2jpbt259Yvsqy3So5XV6U12carEA48AYaDEOBRiHAs+KQ3GnQy3xxPn777+P3r17w8PDA//88w9mzJgBc3NzDBw4EHZ2dggLC0NUVBSqVasGtVqNsWPHws/PD23atAEABAQEoHHjxhgyZAjmz5+PtLQ0TJ06FeHh4dK3xd966y0sX74cEyZMwIgRI7Bv3z58++232L59e0l3h4iIiIiIiMgotPf5KuoeX7r3ANN+6UyrSpUqqFatmqyOl5dXoW1olzk4ODzxXmLabRSlskyHWt6mN9XFqRYLMA6MgRbjUIBxKKBvHIo7HWqJJ87//vtvDBw4EDdv3oSjoyPat2+Po0ePwtHREQCwaNEi6WYlOTk5CAwMxIoVK6T1zc3NsW3bNowZMwZ+fn6wsbFBaGgoZs6cKdXx8vLC9u3bMW7cOCxZsgRubm747LPPEBhYfgc7IiIiIiIiosqkskyHWhGSTpxqsQDjwBhoMQ4FGIcCz4pDcWNU4onzr7/++qnLLS0tERsbi9jY2CfW8fDweOZPpTp37oyTJ08Wq41ERERERERE5Z32Pl/p6emoWbOmVJ6eno4WLVpIdTIyMmTrPXr0CLdu3XrmfcJ09/GkOtrlREREpsbM2A0gIiIiIiIiosK8vLzg4uKCvXv3SmVZWVn49ddfZfcJy8zMRFJSklRn37590Gg08PX1leocOnRIdnO0hIQENGjQAA4ODlId3f1o6/BeYkREZKqYOCciIiIiIiIyknv37iE5ORnJyckACm4ImpycjKtXr0KhUCAyMhKzZ8/GDz/8gDNnzmDo0KFwdXVFcHAwAKBRo0bo0aMHRo0ahWPHjuGXX35BREQEBgwYAFdXVwDAoEGDoFQqERYWhnPnzuGbb77BkiVLZPOTv/vuu9i5cyc++eQTXLhwAdHR0Th+/DgiIiLKOiRERETlQolP1UKVg+ckw2+0mjo3qBRaQkREREREVHkdP34cXbp0kR5rk9mhoaFYt24dJkyYgOzsbIwePRqZmZlo3749du7cCUtLS2mdDRs2ICIiAt26dZPuKbZ06VJpuZ2dHXbv3o3w8HD4+PigRo0amD59OkaPHi3Vadu2LeLj4zF16lRMmTIF9erVw9atW9G0adMyiAIREVH5w8Q5ERERERERkZF07twZQognLlcoFJg5cyZmzpz5xDrVqlVDfHz8U/fTvHlz/Pzzz0+t069fP/Tr1+/pDSYiIjIRnKqFiIiIiIiIiIiIiEgHE+dEREQmKDo6GgqFQvbXsGFDafnDhw8RHh6O6tWrw9bWFiEhIUhPT5dt4+rVqwgKCoK1tTWcnJwwfvx4PHr0SFbnwIEDePHFF6FSqVC3bl2sW7euLLpHRERERERE9FyYOCciIjJRTZo0wfXr16W/w4cPS8vGjRuHH3/8ERs3bsTBgwfxzz//oG/fvtLy/Px8BAUFITc3F0eOHMH69euxbt06TJ8+XaqTkpKCoKAgdOnSBcnJyYiMjMTIkSOxa9euMu0nERERERERkaE4xzkREZGJqlKlClxcXAqV37lzB59//jni4+PRtWtXAMDatWvRqFEjHD16FG3atMHu3btx/vx57NmzB87OzmjRogVmzZqFiRMnIjo6GkqlEnFxcfDy8sInn3wCAGjUqBEOHz6MRYsWITAwsEz7SkRERERERGQIJs6JiIhM1KVLl+Dq6gpLS0v4+flhzpw5qFWrFpKSkpCXlwd/f3+pbsOGDVGrVi0kJiaiTZs2SExMRLNmzeDs7CzVCQwMxJgxY3Du3Dm0bNkSiYmJsm1o60RGRj61XTk5OcjJyZEeZ2VlAQDy8vKQl5f3XH3Wrq8ye/JN2Izpefv3rO2W1vbLK1Pstyn2GWC/Tanf5anP5aENREREVHqYOCciIjJBvr6+WLduHRo0aIDr168jJiYGHTp0wNmzZ5GWlgalUgl7e3vZOs7OzkhLSwMApKWlyZLm2uXaZU+rk5WVhQcPHsDKyqrIts2ZMwcxMTGFynfv3g1ra+ti9fdxs1ppSmQ7JW3Hjh2luv2EhIRS3X55ZYr9NsU+A+y3KSkPfb5//76xm0BERESliIlzIiIiE9SzZ0/p/82bN4evry88PDzw7bffPjGhXVYmT56MqKgo6XFWVhbc3d0REBAAtVr9XNvOy8tDQkICph03Q45G8bxNLXFno0tnChttv7t37w4LC4tS2Ud5ZIr9NsU+A+y3KfW7PPVZ+4soIiIiqpyYOCciIiLY29ujfv36uHz5Mrp3747c3FxkZmbKvnWenp4uzYnu4uKCY8eOybaRnp4uLdP+qy3TraNWq5+anFepVFCpVIXKLSwsSixJkqNRICe//CXOSzsJVJIxrEhMsd+m2GeA/TYl5aHPxt4/ERERlS4zYzeAiIiIjO/evXv4448/ULNmTfj4+MDCwgJ79+6Vll+8eBFXr16Fn58fAMDPzw9nzpxBRkaGVCchIQFqtRqNGzeW6uhuQ1tHuw0iIiIiIiKi8oqJcyIiIhP0/vvv4+DBg0hNTcWRI0fw6quvwtzcHAMHDoSdnR3CwsIQFRWF/fv3IykpCcOHD4efnx/atGkDAAgICEDjxo0xZMgQnDp1Crt27cLUqVMRHh4ufVv8rbfewp9//okJEybgwoULWLFiBb799luMGzfOmF0nIiIiIiIieiZO1UJERGSC/v77bwwcOBA3b96Eo6Mj2rdvj6NHj8LR0REAsGjRIpiZmSEkJAQ5OTkIDAzEihUrpPXNzc2xbds2jBkzBn5+frCxsUFoaChmzpwp1fHy8sL27dsxbtw4LFmyBG5ubvjss88QGFg683gTERERERERlRQmzomIiEzQ119//dTllpaWiI2NRWxs7BPreHh4YMeOHU/dTufOnXHy5MlitZGIiIiIiIjIWDhVCxERERERERERERGRDibOiYiIiIiIiIiIiIh0cKoWIiIionLCc9J2g9dJnRtUCi0hIiIiIiIybfzGORERERERERERERGRDibOiYiIiIiIiIiIiIh0MHFORERERERERERERKSDc5wTERERERERkcky9B4jvL8IEZFp4DfOiYiIiIiIiIiIiIh0MHFORERERERERERERKSDU7VQidH3520qc4H5rYGm0btw8cOXS7lVRERERERERERERIbhN86JiIiIiIiIiIiIiHQwcU5EREREREREREREpIOJcyIiIiIiIiIiIiIiHZzjnIxK33nRdaXODSqFlhAREREREREREREV4DfOiYiIiIiIiIiIiIh0MHFORERERERERERERKSDiXMiIiIiIiIiIiIiIh1MnBMRERERERERERER6WDinIiIiIiIiIiIiIhIBxPnREREREREREREREQ6mDgnIiIiIiIiIiIiItJRxdgNIDKU56TtBq+TOjeoFFpCRERERERERERElVGFT5zHxsZiwYIFSEtLg7e3N5YtW4bWrVsbu1lERET0GI7ZpUOfD5RV5gLzWwNNo3chJ1/BD5SJiOiJOF4TEREVqNCJ82+++QZRUVGIi4uDr68vFi9ejMDAQFy8eBFOTk7Gbh5VYPxWOxFRyeKYTUREVP5xvCYiIvpPhU6cL1y4EKNGjcLw4cMBAHFxcdi+fTvWrFmDSZMmGbl1VJ4UJxFOREQlh2M2ERFR+cfxmoiI6D8VNnGem5uLpKQkTJ48WSozMzODv78/EhMTi1wnJycHOTk50uM7d+4AAG7duoW8vLznak9eXh7u37+PKnlmyNconmtblV0VjcD9+5pKF6u6739b4ttUmQlMbalBiw++Q87/j9Wvk7uV+H4qOu377+bNm7CwsDB2c8o1xkp/xozV3bt3AQBCiDLdb2kxdMzmeF3yHh97b968aewmlQlTPOaZYp8B9tuU+l2e+mzq4zVgumN2WY6j5ek1b0yMA2OgxTgUYBwK6BuH4o7ZFTZx/u+//yI/Px/Ozs6ycmdnZ1y4cKHIdebMmYOYmJhC5V5eXqXSRnqyQcZuQAXyeKxqfGKUZhCREdy9exd2dnbGbsZzM3TM5nhdOnTHE44lREQlx1THa8B0x2yOo0REFZOhY3aFTZwXx+TJkxEVFSU91mg0uHXrFqpXrw6F4vk+wc7KyoK7uzv++usvqNXq521qpcZY6Y+x0g/jpD/GSn/GjJUQAnfv3oWrq2uZ7re84Hhd8thv0+m3KfYZYL9Nqd/lqc+mPl4DHLPLAuNQgHFgDLQYhwKMQwF941DcMbvCJs5r1KgBc3NzpKeny8rT09Ph4uJS5DoqlQoqlUpWZm9vX6LtUqvVJv2CNQRjpT/GSj+Mk/4YK/0ZK1aV4ZtrWoaO2RyvSw/7bTpMsc8A+21KykufTXm8BjhmlyXGoQDjwBhoMQ4FGIcC+sShOGO2WXEbZGxKpRI+Pj7Yu3evVKbRaLB37174+fkZsWVERESki2M2ERFR+cfxmoiISK7CfuMcAKKiohAaGopWrVqhdevWWLx4MbKzs6U7gBMREVH5wDGbiIio/ON4TURE9J8KnTh//fXXcePGDUyfPh1paWlo0aIFdu7cWehmJmVBpVJhxowZhX6mRoUxVvpjrPTDOOmPsdIfY1WyysuYbarPK/ttOv02xT4D7Lcp9dsU+1yWyst4DfC51mIcCjAOjIEW41CAcShQ2nFQCCFEqWyZiIiIiIiIiIiIiKgCqrBznBMRERERERERERERlQYmzomIiIiIiIiIiIiIdDBxTkRERERERERERESkg4lzIiIiIiIiIiIiIiIdTJwTEREREREREREREelg4twAc+bMwUsvvYSqVavCyckJwcHBuHjxoqzOw4cPER4ejurVq8PW1hYhISFIT083UovLj7lz50KhUCAyMlIqY6z+c+3aNbzxxhuoXr06rKys0KxZMxw/flxaLoTA9OnTUbNmTVhZWcHf3x+XLl0yYouNIz8/H9OmTYOXlxesrKxQp04dzJo1C0IIqY6pxurQoUPo3bs3XF1doVAosHXrVtlyfeJy69YtDB48GGq1Gvb29ggLC8O9e/fKsBel72lxysvLw8SJE9GsWTPY2NjA1dUVQ4cOxT///CPbhinEqaKLjY2Fp6cnLC0t4evri2PHjj21/saNG9GwYUNYWlqiWbNm2LFjRxm1tGQZ0u9169ZBoVDI/iwtLcuwtc/vWce9ohw4cAAvvvgiVCoV6tati3Xr1pV6O0uaof0+cOBAoedaoVAgLS2tbBpcAvQ5By9KRX9vF6ffFf29vXLlSjRv3hxqtRpqtRp+fn746aefnrpORX+eqWiGjuWVUXHGucqmuMf/yqY4x8bKrqgck6mIjo4uNNY3bNjQ2M0qc8/Ko5UUJs4NcPDgQYSHh+Po0aNISEhAXl4eAgICkJ2dLdUZN24cfvzxR2zcuBEHDx7EP//8g759+xqx1cb322+/YdWqVWjevLmsnLEqcPv2bbRr1w4WFhb46aefcP78eXzyySdwcHCQ6syfPx9Lly5FXFwcfv31V9jY2CAwMBAPHz40YsvL3rx587By5UosX74cv//+O+bNm4f58+dj2bJlUh1TjVV2dja8vb0RGxtb5HJ94jJ48GCcO3cOCQkJ2LZtGw4dOoTRo0eXVRfKxNPidP/+fZw4cQLTpk3DiRMn8N133+HixYvo06ePrJ4pxKki++abbxAVFYUZM2bgxIkT8Pb2RmBgIDIyMoqsf+TIEQwcOBBhYWE4efIkgoODERwcjLNnz5Zxy5+Pof0GALVajevXr0t/V65cKcMWP79nHfcel5KSgqCgIHTp0gXJycmIjIzEyJEjsWvXrlJuackytN9aFy9elD3fTk5OpdTCkqfPOfjjKsN7uzj9Bir2e9vNzQ1z585FUlISjh8/jq5du+KVV17BuXPniqxfGZ5nKqw4Y1plVNzjfWVS3ONgZWPosbGye1KOyZQ0adJENtYfPnzY2E0qU/rk0UqMoGLLyMgQAMTBgweFEEJkZmYKCwsLsXHjRqnO77//LgCIxMREYzXTqO7evSvq1asnEhISRKdOncS7774rhGCsdE2cOFG0b9/+ics1Go1wcXERCxYskMoyMzOFSqUS//d//1cWTSw3goKCxIgRI2Rlffv2FYMHDxZCMFZaAMSWLVukx/rE5fz58wKA+O2336Q6P/30k1AoFOLatWtl1vay9HicinLs2DEBQFy5ckUIYZpxqmhat24twsPDpcf5+fnC1dVVzJkzp8j6/fv3F0FBQbIyX19f8eabb5ZqO0uaof1eu3atsLOzK6PWlT593s8TJkwQTZo0kZW9/vrrIjAwsBRbVrr06ff+/fsFAHH79u0yaVNZePwcvCiV5b2tS59+V7b3thBCODg4iM8++6zIZZXxeSbDxzRToM/x3hTocxw0FU87NlZmT8oxmZIZM2YIb29vYzfDqJ6VRytJ/Mb5c7hz5w4AoFq1agCApKQk5OXlwd/fX6rTsGFD1KpVC4mJiUZpo7GFh4cjKChIFhOAsdL1ww8/oFWrVujXrx+cnJzQsmVLfPrpp9LylJQUpKWlyWJlZ2cHX19fk4tV27ZtsXfvXvzvf/8DAJw6dQqHDx9Gz549ATBWT6JPXBITE2Fvb49WrVpJdfz9/WFmZoZff/21zNtcXty5cwcKhQL29vYAGKfyLjc3F0lJSbLXupmZGfz9/Z94DEhMTCw0RgUGBlaoY0Zx+g0A9+7dg4eHB9zd3U3iW0uV4bl+Hi1atEDNmjXRvXt3/PLLL8ZuznN5/By8KJXx+dan30DleW/n5+fj66+/RnZ2Nvz8/IqsUxmfZ1NX3DGNTIO+x8HKTJ9jY2X2pByTqbl06RJcXV1Ru3ZtDB48GFevXjV2k8rUs/JoJYmJ82LSaDSIjIxEu3bt0LRpUwBAWloalEqllGDRcnZ2rlDzSJaUr7/+GidOnMCcOXMKLWOs/vPnn39i5cqVqFevHnbt2oUxY8bgnXfewfr16wFAioezs7NsPVOM1aRJkzBgwAA0bNgQFhYWaNmyJSIjIzF48GAAjNWT6BOXtLS0Qj/br1KlCqpVq2aysXv48CEmTpyIgQMHQq1WA2Ccyrt///0X+fn5Bh0D0tLSKvwxozj9btCgAdasWYPvv/8eX331FTQaDdq2bYu///67LJpsFE96rrOysvDgwQMjtar01axZE3Fxcdi8eTM2b94Md3d3dO7cGSdOnDB204qlqHPwolSG97YufftdGd7bZ86cga2tLVQqFd566y1s2bIFjRs3LrJuZXueqXhjGpkGfY+DlZUhx8bK6mk5JlPi6+uLdevWYefOnVi5ciVSUlLQoUMH3L1719hNKzPPyqOVpColvkUTER4ejrNnz5rcPEL6+uuvv/Duu+8iISGhQt2QyBg0Gg1atWqFjz76CADQsmVLnD17FnFxcQgNDTVy68qXb7/9Fhs2bEB8fDyaNGkizVHr6urKWFGJysvLQ//+/SGEwMqVK43dHKIS5+fnJ/uWUtu2bdGoUSOsWrUKs2bNMmLLqKQ1aNAADRo0kB63bdsWf/zxBxYtWoQvv/zSiC0rHlM9B9e335Xhvd2gQQMkJyfjzp072LRpE0JDQ3Hw4EGTSxARkZypHv+1TP3YyBzTf7S/uAeA5s2bw9fXFx4eHvj2228RFhZmxJaVnbLMo/Eb58UQERGBbdu2Yf/+/XBzc5PKXVxckJubi8zMTFn99PR0uLi4lHErjSspKQkZGRl48cUXUaVKFVSpUgUHDx7E0qVLUaVKFTg7OzNW/1/NmjULDXaNGjWSfmqjjUd6erqsjinGavz48dK3zps1a4YhQ4Zg3Lhx0ifOjFXR9ImLi4tLoRsuPXr0CLdu3TK52GmT5leuXEFCQoL0bXOAcSrvatSoAXNzc4OOAS4uLhX+mFGcfj9O+yuey5cvl0YTy4UnPddqtRpWVlZGapVxtG7dukI+1086By9KZXhvaxnS78dVxPe2UqlE3bp14ePjgzlz5sDb2xtLliwpsm5lep6pQEmMaVT5PM9xsLIw5NhYGT0rx5Sfn2/sJhqNvb096tevX6HG+uf1rDxaSWLi3ABCCERERGDLli3Yt28fvLy8ZMt9fHxgYWGBvXv3SmUXL17E1atXTW7uqW7duuHMmTNITk6W/lq1aoXBgwdL/2esCrRr1w4XL16Ulf3vf/+Dh4cHAMDLywsuLi6yWGVlZeHXX381uVjdv38fZmbyw5a5uTk0Gg0AxupJ9ImLn58fMjMzkZSUJNXZt28fNBoNfH19y7zNxqJNml+6dAl79uxB9erVZcsZp/JNqVTCx8dH9lrXaDTYu3fvE48Bfn5+svoAkJCQUKGOGcXp9+Py8/Nx5swZ1KxZs7SaaXSV4bkuKcnJyRXquX7WOXhRKsPzXZx+P64yvLc1Gg1ycnKKXFYZnmeSK4kxjSqPkjgOVlZPOzZWRs/KMZmbmxu7iUZz7949/PHHHxV6rDfUs/JoJapMbkFaSYwZM0bY2dmJAwcOiOvXr0t/9+/fl+q89dZbolatWmLfvn3i+PHjws/PT/j5+Rmx1eXH43c8ZqwKHDt2TFSpUkV8+OGH4tKlS2LDhg3C2tpafPXVV1KduXPnCnt7e/H999+L06dPi1deeUV4eXmJBw8eGLHlZS80NFS88MILYtu2bSIlJUV89913okaNGmLChAlSHVON1d27d8XJkyfFyZMnBQCxcOFCcfLkSXHlyhUhhH5x6dGjh2jZsqX49ddfxeHDh0W9evXEwIEDjdWlUvG0OOXm5oo+ffoINzc3kZycLDvO5+TkSNswhThVZF9//bVQqVRi3bp14vz582L06NHC3t5epKWlCSGEGDJkiJg0aZJU/5dffhFVqlQRH3/8sfj999/FjBkzhIWFhThz5oyxulAshvY7JiZG7Nq1S/zxxx8iKSlJDBgwQFhaWopz584ZqwsGe9Zxb9KkSWLIkCFS/T///FNYW1uL8ePHi99//13ExsYKc3NzsXPnTmN1oVgM7feiRYvE1q1bxaVLl8SZM2fEu+++K8zMzMSePXuM1QWD6XMOXhnf28Xpd0V/b0+aNEkcPHhQpKSkiNOnT4tJkyYJhUIhdu/eLYSonM8zFfasMc1UPOt4bwr0OQ6agmcdG03V4zkmU/Hee++JAwcOiJSUFPHLL78If39/UaNGDZGRkWHsppUZffJoJYWJcwMAKPJv7dq1Up0HDx6It99+Wzg4OAhra2vx6quviuvXrxuv0eXI4wc1xuo/P/74o2jatKlQqVSiYcOGYvXq1bLlGo1GTJs2TTg7OwuVSiW6desmLl68aKTWGk9WVpZ49913Ra1atYSlpaWoXbu2+OCDD2RJTVON1f79+4s8PoWGhgoh9IvLzZs3xcCBA4Wtra1Qq9Vi+PDh4u7du0boTel5WpxSUlKeeJzfv3+/tA1TiFNFt2zZMlGrVi2hVCpF69atxdGjR6VlnTp1kt4XWt9++62oX7++UCqVokmTJmL79u1l3OKSYUi/IyMjpbrOzs6iV69e4sSJE0ZodfE967gXGhoqOnXqVGidFi1aCKVSKWrXri07h6soDO33vHnzRJ06dYSlpaWoVq2a6Ny5s9i3b59xGl9M+pyDV8b3dnH6XdHf2yNGjBAeHh5CqVQKR0dH0a1bN1liqDI+z1S0p41ppuJZx3tToM9x0BQ869hoqkw1cf7666+LmjVrCqVSKV544QXx+uuvi8uXLxu7WWXuWXm0kqIQQoiS+e46EREREREREREREVHFxznOiYiIiIiIiIiIiIh0MHFORERERERERERERKSDiXMiIiIiIiIiIiIiIh1MnBMRERERERERERER6WDinIiIiIiIiIiIiIhIBxPnREREREREREREREQ6mDgnIiIiIiIiIiIiItLBxDkRERERERERERERkQ4mzomIiIiIiIiIiIiIdDBxTkRERERERERERESkg4lzIiIiIiIiIiIiIiIdTJwTEREREREREREREelg4pyIiIiIiIiIiIiISAcT50REREREREREREREOpg4JyIiIiIiIiIiIiLSwcQ5EREREREREREREZEOJs6JiIiIiIiIiIiIiHQwcU5EREREREREREREpIOJcyIiIiIiIiIiIiIiHUycExERERERERERERHpYOKciIiIiIiIiIiIiEgHE+dERERERERERERERDqYOCciIiIiIiIiIiIi0sHEORERERERERERERGRDibOiYiIiIiIiIiIiIh0MHFORERERERERERERKSDiXMiIiIiIiIiIiIiIh1MnBMRERERERERERER6WDinIiIiIiIiIiIiIhIBxPnREREREREREREREQ6mDgnIiIiIiIiIiIiItLBxDkRERERERERERERkQ4mzomIiIiIiIiIiIiIdDBxTkRERERERERERESkg4lzIiIiIiIiIiIiIiIdTJxTubFu3TooFAqkpqYauynPNGzYMHh6ehq7GSYtOjoaCoXC2M0gIqrwKtL4S0/H8xPDpaamQqFQYN26dcZuChERET0Fz1nJGJg4JypjO3bsQHR0tNH2Hx8fj8WLF5fqPozdR9LPRx99hK1btxq7GUREpINjqGFWrFjBpDcRERkVxyKiyouJc6Ji+PTTT3Hx4sVirbtjxw7ExMSUcIv0V1aJc2P2kfTDxDkRUfnzPGPo85yfVFTPm6zw8PDAgwcPMGTIkJJrFBERmRQmzsvGkCFD8ODBA3h4eBi7KWRCmDgnKgYLCwuoVCpjNwMAcP/+fWM3gYiIqNLQaDR4+PChsZtRLOXp/KSiUCgUsLS0hLm5ubGbQkRkVLyupEePHiE3N9fYzXgic3NzWFpacspWKlNMnFO5tmLFCjRp0gQqlQqurq4IDw9HZmamrM7PP/+Mfv36oVatWlCpVHB3d8e4cePw4MEDWb1hw4bB1tYW165dQ3BwMGxtbeHo6Ij3338f+fn5BrXr8TlEtfNjfvzxx1i9ejXq1KkDlUqFl156Cb/99ptsvdjYWAAFF2raP3117twZTZs2RVJSEjp27Ahra2tMmTIFAPD9998jKCgIrq6uUKlUqFOnDmbNmiXrW+fOnbF9+3ZcuXJF2rduP3JycjBjxgzUrVtXiuWECROQk5NjUGye1sfs7Gy89957cHd3h0qlQoMGDfDxxx9DCKH3Pp7k0aNHmDVrlhR/T09PTJkypVD79YkV8F+8z58/jy5dusDa2hovvPAC5s+fb3DbDN3n6dOn0alTJ1hbW6Nu3brYtGkTAODgwYPw9fWFlZUVGjRogD179sjW1879fvnyZQwbNgz29vaws7PD8OHDZSfDCoUC2dnZWL9+vfQcDRs2zOB+EVHlVF7HX91xsG3btrCysoKXlxfi4uIK1dV3TFMoFIiIiMCGDRukPu/cuRMAcO3aNYSFhUnHbi8vL4wZM0Z2UZmZmYnIyEhpXKtbty7mzZsHjUYj1Smr84Tinp9oXbhwAf3794ejo6M0znzwwQeyOidPnkTPnj2hVqtha2uLbt264ejRo7I62jlIDx8+jHfeeQeOjo6wt7fHm2++idzcXGRmZmLo0KFwcHCAg4MDJkyYUOg8QKPRYPHixWjSpAksLS3h7OyMN998E7dv35bqeHp64ty5czh48KAUq86dO0vL//zzT/Tr1w/VqlWDtbU12rRpg+3bt8v2U9Qc54a8ZjUaDZYsWYJmzZrB0tISjo6O6NGjB44fPy7V0ff8xNPTEy+//DIOHDiAVq1awcrKCs2aNcOBAwcAAN999520Hx8fH5w8ebLI5/C1115DtWrVYGlpiVatWuGHH34oVI+IKhbtOb72OK1Wq1G9enW8++67hT7s/eqrr+Dj4wMrKytUq1YNAwYMwF9//SWr87TryuPHjyMwMBA1atSQxtkRI0bI1tf3mk47xm7duhVNmzaFSqVCkyZNpHHWEB9//DHatm2L6tWrw8rKCj4+PtI1kq4HDx7gnXfeQY0aNVC1alX06dMH165dg0KhKDQV2rVr1zBixAg4OztLbVuzZo1B7SqJsUjf/bz88svYvXs3WrRoAUtLSzRu3BjfffddobqGnpssXrxYGqPOnz8PAFi2bBmaNGkCa2trODg4oFWrVoiPj5ftx5Bzgl9++QVRUVFwdHSEjY0NXn31Vdy4ccOgGBQ1x7k2LocPH0br1q1haWmJ2rVr44svvigyLuPGjYOnpydUKhXc3NwwdOhQ/Pvvv1KdjIwMhIWFwdnZGZaWlvD29sb69etl29GNXWxsLGrXrg1ra2sEBATgr7/+ghACs2bNgpubG6ysrPDKK6/g1q1bhdrz008/oUOHDrCxsUHVqlURFBSEc+fOGRQTKgOCqJxYu3atACBSUlKEEELMmDFDABD+/v5i2bJlIiIiQpibm4uXXnpJ5ObmSuuNHTtW9OrVS3z00Udi1apVIiwsTJibm4vXXntNtv3Q0FBhaWkpmjRpIkaMGCFWrlwpQkJCBACxYsUKg9oaGhoqPDw8pMcpKSkCgGjZsqWoW7eumDdvnpg/f76oUaOGcHNzk9p75MgR0b17dwFAfPnll9Kfvjp16iRcXFyEo6OjGDt2rFi1apXYunWrEEKI4OBg0b9/f7FgwQKxcuVK0a9fPwFAvP/++9L6u3fvFi1atBA1atSQ9r1lyxYhhBD5+fkiICBAWFtbi8jISLFq1SoREREhqlSpIl555RW92/i0Pmo0GtG1a1ehUCjEyJEjxfLly0Xv3r0FABEZGan3PoT47/WhKzQ0VAAQr732moiNjRVDhw4VAERwcLCsnj6xEqIg3q6ursLd3V28++67YsWKFaJr164CgNixY4dB7S3OPsePHy+WLVsmGjduLMzNzcXXX38tXFxcRHR0tFi8eLF44YUXhJ2dncjKyioUl5YtW4q+ffuKFStWiJEjRwoAYsKECVK9L7/8UqhUKtGhQwfpOTpy5IhBfSKiyqEijb/aY6STk5OIiIgQS5cuFe3btxcAxOeffy7VM2RMAyAaNWokHB0dRUxMjIiNjRUnT54U165dE66urtI24uLixLRp00SjRo3E7du3hRBCZGdni+bNm4vq1auLKVOmiLi4ODF06FChUCjEu+++K+2jrM4Tint+IoQQp06dEmq1WlSvXl1MnjxZrFq1SkyYMEE0a9ZMqnP27FlhY2MjatasKWbNmiXmzp0rvLy8hEqlEkePHpXqaV9TLVq0ED169BCxsbFiyJAh0ljUvn17MWjQILFixQrx8ssvCwBi/fr1sr6MHDlSVKlSRYwaNUrExcWJiRMnChsbG9nrcMuWLcLNzU00bNhQitXu3buFEEKkpaUJZ2dnUbVqVfHBBx+IhQsXCm9vb2FmZia+++67QjFau3atLI76vmaHDRsmAIiePXuKxYsXi48//li88sorYtmyZbLt6XN+4uHhIRo0aCBq1qwpoqOjxaJFi8QLL7wgbG1txVdffSVq1aol5s6dK+bOnSvs7OxE3bp1RX5+vuz5sbOzE40bNxbz5s0Ty5cvFx07dhQKhULWZyKqeLRjc7NmzUTv3r3F8uXLxRtvvCEAiCFDhkj1Zs+eLRQKhXj99dfFihUrRExMjKhRo4bw9PSUxi4hnnxdmZ6eLhwcHET9+vXFggULxKeffio++OAD0ahRI2ldQ67pAAhvb29p3Fi8eLGoXbu2sLa2Fv/++69BMXBzcxNvv/22WL58uVi4cKFo3bq1ACC2bdsmq9e/f38pLrGxsaJ///7C29tbABAzZsyQ6qWlpQk3Nzfh7u4uZs6cKVauXCn69OkjAIhFixbp3a6SGIv04eHhIerXry/s7e3FpEmTxMKFC0WzZs2EmZmZtD8hDD83ady4sahdu7aYO3euWLRokbhy5YpYvXq1NG6tWrVKLFmyRISFhYl33nlHWt/Qc4KWLVuKrl27imXLlon33ntPmJubi/79+xsUg8fPWbVxadCggXB2dhZTpkwRy5cvFy+++KJQKBTi7NmzUr27d++Kpk2bCnNzczFq1CixcuVKMWvWLPHSSy+JkydPCiGEuH//vmjUqJGwsLAQ48aNE0uXLhUdOnQQAMTixYsLxa5FixaicePGYuHChWLq1KlCqVSKNm3aiClTpoi2bduKpUuXinfeeUcoFAoxfPhwWV+++OILoVAoRI8ePcSyZcvEvHnzhKenp7C3t5f1j4yPiXMqN3QPghkZGUKpVIqAgADZBcHy5csFALFmzRqp7P79+4W2NWfOHKFQKMSVK1ekMu1Fy8yZM2V1W7ZsKXx8fAxq65MuTKtXry5u3bollX///fcCgPjxxx+lsvDw8EIJX3116tRJABBxcXGFlhUVhzfffFNYW1uLhw8fSmVBQUGytmt9+eWXwszMTPz888+y8ri4OAFA/PLLL3q380l93Lp1qwAgZs+eLSt/7bXXhEKhEJcvX9Z7H48nzpOTkwUAMXLkSFm9999/XwAQ+/btk8r0jZU23l988YVUlpOTI1xcXERISIjebS3OPuPj46WyCxcuCADCzMxMdhKya9euQhf72riMGDFCtq9XX31VVK9eXVZmY2MjQkNDDeoHEVU+FWn81R4jP/nkE6ksJydHtGjRQjg5OUkJVUPGNO3x9dy5c7K6Q4cOFWZmZuK3334r1A6NRiOEEGLWrFnCxsZG/O9//5MtnzRpkjA3NxdXr14VQpTdecLznJ907NhRVK1aVfbc6fZViIIPgZVKpfjjjz+ksn/++UdUrVpVdOzYUSrTvqYCAwNl6/v5+QmFQiHeeustqezRo0fCzc1NdOrUSSr7+eefBQCxYcMGWVt27txZqLxJkyaydbUiIyMFANlr4O7du8LLy0t4enpKr+8nJc71ec3u27dPAJAlEh6PmyHnJx4eHgKA7INs7VhvZWUle25WrVolAIj9+/dLZd26dRPNmjWTnVdoNBrRtm1bUa9evUJtJKKKQ3uO36dPH1n522+/LQCIU6dOidTUVGFubi4+/PBDWZ0zZ86IKlWqyMqfdF25ZcsWAaDIsU/LkGs6AEKpVMrKTp06JQDIPmDUx+PnHbm5uaJp06aia9euUllSUlKRCXzth5y6ifOwsDBRs2bNQgn8AQMGCDs7uyLPc57keccifWjHiM2bN0tld+7cETVr1hQtW7aUygw9N1Gr1SIjI0NW95VXXhFNmjR5ansMPSfw9/eXnROMGzdOmJubi8zMTL1j8KTEOQBx6NAhqSwjI0OoVCrx3nvvSWXTp08XAIr8wELbrsWLFwsA4quvvpKW5ebmCj8/P2Frayt9YU0bO0dHR1n7J0+eLH1YlJeXJ5UPHDhQKJVKaXy+e/eusLe3F6NGjZK1Iy0tTdjZ2RUqJ+PiVC1ULu3Zswe5ubmIjIyEmdl/L9NRo0ZBrVbLftpkZWUl/T87Oxv//vsv2rZtCyFEkT9hfeutt2SPO3TogD///LNE2v3666/DwcFBtm0AJbZ9AFCpVBg+fHihct043L17F//++y86dOiA+/fv48KFC8/c7saNG9GoUSM0bNgQ//77r/TXtWtXAMD+/fufu+07duyAubk53nnnHVn5e++9ByEEfvrpp+faNgBERUUV2jaAJ75mnhUrW1tbvPHGG9JjpVKJ1q1bG/ycGrrPAQMGSI8bNGgAe3t7NGrUCL6+vlK59v9FtaWo1/nNmzeRlZVlULuJyLRUhPG3SpUqePPNN6XHSqUSb775JjIyMpCUlATA8DGtU6dOaNy4sfRYo9Fg69at6N27N1q1alWoDdrpUzZu3IgOHTrAwcFBth9/f3/k5+fj0KFDsvXK4jyhKM/a740bN3Do0CGMGDECtWrVkq2r7Wt+fj52796N4OBg1K5dW1pes2ZNDBo0CIcPHy40xoSFhcmmmvH19YUQAmFhYVKZubk5WrVqJYvBxo0bYWdnh+7du8vi6uPjA1tbW73OSXbs2IHWrVujffv2UpmtrS1Gjx6N1NRU6afoT/Os1+zmzZuhUCgwY8aMQutq+23I+QkANG7cGH5+ftJj7VjftWtX2XPz+DnArVu3sG/fPvTv3186z/j3339x8+ZNBAYG4tKlS7h27doz+0xE5Vt4eLjs8dixYwEUHGu+++47aDQa9O/fX3bsdHFxQb169QodO4u6rrS3twcAbNu2DXl5eUW2wdBrOn9/f9SpU0d63Lx5c6jV6ue6nrp9+zbu3LmDDh064MSJE1K5dgqYt99+W7auNk5aQghs3rwZvXv3hhBCFq/AwEDcuXNHtt3iKomxSJerqyteffVV6bFarcbQoUNx8uRJpKWlATD83CQkJASOjo6yMnt7e/z9999FTusGFO+cYPTo0bJzgg4dOiA/Px9XrlwxKAZFady4sXRuAwCOjo5o0KBBoTHb29tbFj8t3THbxcUFAwcOlJZZWFjgnXfewb1793Dw4EHZev369YOdnZ30WDs2v/HGG6hSpYqsPDc3VxqHExISkJmZiYEDB8qeI3Nzc/j6+pZI7oVKTpVnVyEqe9qDZ4MGDWTlSqUStWvXlh1cr169iunTp+OHH36QzXsJAHfu3JE91s49qcvBwaHQesX1+MWm9iK1pLYPAC+88AKUSmWh8nPnzmHq1KnYt29foUHq8TgU5dKlS/j9998LxUcrIyOjeA3WceXKFbi6uqJq1aqy8kaNGknLn2fbZmZmqFu3rqzcxcUF9vb2sm0bEis3N7dC88s6ODjg9OnTBrXvefdpZ2cHd3f3QmVA0a+vp70W1Wq1QW0nItNREcZfV1dX2NjYyMrq168PoGDOyTZt2hg8pnl5ecke37hxA1lZWWjatOlT23Lp0iWcPn1a7/2UxXlCUZ61X+2F5dP6e+PGDdy/f7/QawMoGMc1Gg3++usvNGnS5In71Y5bRY1nujG4dOkS7ty5AycnpyLbos85yZUrV2QfNuu2Vbv8af3V5zX7xx9/wNXVFdWqVXtqO/Q9PwEMixnw33N4+fJlCCEwbdo0TJs2rci2ZGRk4IUXXnhiW4mo/KtXr57scZ06dWBmZobU1FSYmZlBCFGojpaFhYXscVHXlZ06dUJISAhiYmKwaNEidO7cGcHBwRg0aJB082lDr+keP64BxTsH2LZtG2bPno3k5GTZPSJ0r5u0x9zHx/XHj8E3btxAZmYmVq9ejdWrVxe5v5K6/n2esehxdevWLXSdqHsO5OLiYvC5yeOxAoCJEydiz549aN26NerWrYuAgAAMGjQI7dq1A1Ay5wQleQ6kz2vsjz/+QEhIyFO3c+XKFdSrV0/25RFA/9e2vmP2pUuXAED6QsfjeL1evjBxThVafn4+unfvjlu3bmHixIlo2LAhbGxscO3aNQwbNkx28wug4FtNpelJ2xclcONLLd1P2rUyMzPRqVMnqNVqzJw5E3Xq1IGlpSVOnDiBiRMnFopDUTQaDZo1a4aFCxcWufzxg3959aybqBkaq5J4Tktqn4a0pSxei0Rkusrb+Ps4Q8e0osZWfffTvXt3TJgwocjl2otZLWMdm8vbfosq122LRqOBk5MTNmzYUOT6T0oGlKSSfs3qe5PX4p4DaN9z77//PgIDA4us+3jiiIgqPt1ji0ajgUKhwE8//VTkMcPW1lb2uKixT6FQYNOmTTh69Ch+/PFH7Nq1CyNGjMAnn3yCo0ePFtqGPkpiDPr555/Rp08fdOzYEStWrEDNmjVhYWGBtWvXFrphpT60x8w33ngDoaGhRdZp3ry5wdstDww9NynqddCoUSNcvHgR27Ztw86dO7F582asWLEC06dPR0xMTLHaVZrnIhXhPAcoPGZ/+eWXcHFxKVRP99vqZHx8Nqhc8vDwAABcvHhR9tOf3NxcpKSkwN/fHwBw5swZ/O9//8P69esxdOhQqV5CQkLZNtgA+l44GeLAgQO4efMmvvvuO3Ts2FEqT0lJ0Xv/derUwalTp9CtW7fnbuOT1vfw8MCePXtw9+5d2TcUtFOVaJ/34vDw8IBGo8GlS5ekT4QBID09HZmZmdK2DYlVSTHGPvVRGq9FIqrYKsL4+88//yA7O1v2rfP//e9/AABPT08Azz+mOTo6Qq1W4+zZs0+tV6dOHdy7d0+KS0kwxrFZ+1w/rb+Ojo6wtrbGxYsXCy27cOECzMzMSuxD9jp16mDPnj1o167dMz/UeNo5x5Paql1eEu3ctWsXbt269cRvnet7fvK8tM+hhYVFib4eiah8uXTpkuwbwpcvX4ZGo4GnpyfMzc0hhICXl1eh5Kih2rRpgzZt2uDDDz9EfHw8Bg8ejK+//hojR44s1Wu6J9m8eTMsLS2xa9cu6ZvvALB27VpZPe0xNyUlRfbN+8uXL8vqOTo6omrVqsjPzy+RY2ZZjUXaXxfp7q+oc6CSODexsbHB66+/jtdffx25ubno27cvPvzwQ0yePLlMzwlKSp06dZ55Xufh4YHTp09Do9HIvnVe0q9t7dRFTk5OHLMrAM5xTuWSv78/lEolli5dKvuU8PPPP8edO3cQFBQE4L9P8nTrCCGwZMmSsm2wAbQX+pmZmSW2zaLikJubixUrVhS5/6Kmbunfvz+uXbuGTz/9tNCyBw8eIDs7W+/2PKmPvXr1Qn5+PpYvXy4rX7RoERQKBXr27Kn3Ph7Xq1cvAMDixYtl5dpvGz7tNfOkWJUUY+xTHzY2NiX6OiSiiq8ijL+PHj3CqlWrpMe5ublYtWoVHB0d4ePjA+D5xzQzMzMEBwfjxx9/xPHjxwst1/a7f//+SExMxK5duwrVyczMxKNHjwzqG1A65wnP4ujoiI4dO2LNmjW4evWqbJm2r+bm5ggICMD333+P1NRUaXl6ejri4+PRvn37Evtpcf/+/ZGfn49Zs2YVWvbo0SNZbJ40lvXq1QvHjh1DYmKiVJadnY3Vq1fD09NTNqd9cYWEhEAIUeS377Rx0/f85Hk5OTmhc+fOWLVqFa5fv15o+Y0bN0pkP0RkXLGxsbLHy5YtAwD07NkTffv2hbm5OWJiYgp901YIgZs3bz5z+7dv3y60bosWLQBAmh6lNK/pnsTc3BwKhQL5+flSWWpqKrZu3Sqrp/3FzePXWdo46W4vJCQEmzdvLjKZaugxs6zGon/++QdbtmyRHmdlZeGLL75AixYtpG8ul8S5yeOvFaVSicaNG0MIgby8vDI9JygpISEhOHXqlCx+WrpjdlpaGr755htp2aNHj7Bs2TLY2tqiU6dOJdKWwMBAqNVqfPTRR0XeS4BjdvnCb5xTueTo6IjJkycjJiYGPXr0QJ8+fXDx4kWsWLECL730knSzxoYNG6JOnTp4//33ce3aNajVamzevLnU5wp9HtqL+nfeeQeBgYEwNzeX3QiyONq2bQsHBweEhobinXfegUKhwJdfflnkT5N8fHzwzTffICoqCi+99BJsbW3Ru3dvDBkyBN9++y3eeust7N+/H+3atUN+fj4uXLiAb7/9Frt27SryBmmG9LF3797o0qULPvjgA6SmpsLb2xu7d+/G999/j8jISNlNYwzl7e2N0NBQrF69Wpoa5dixY1i/fj2Cg4PRpUsXg2NVUoyxT334+Phgz549WLhwIVxdXeHl5VXkHHxEZDoqwvjr6uqKefPmITU1FfXr18c333yD5ORkrF69Wpq/tSTGtI8++gi7d+9Gp06dMHr0aDRq1AjXr1/Hxo0bcfjwYdjb22P8+PH44Ycf8PLLL2PYsGHw8fFBdnY2zpw5g02bNiE1NRU1atQwqH+lcZ6gj6VLl6J9+/Z48cUXMXr0aHh5eSE1NRXbt29HcnIyAGD27NlISEhA+/bt8fbbb6NKlSpYtWoVcnJyMH/+/BJrS6dOnfDmm29izpw5SE5ORkBAACwsLHDp0iVs3LgRS5YswWuvvQagIF4rV67E7NmzUbduXTg5OaFr166YNGkS/u///g89e/bEO++8g2rVqmH9+vVISUnB5s2bC81fWhxdunTBkCFDsHTpUly6dAk9evSARqPBzz//jC5duiAiIkLv85OSEBsbi/bt26NZs2YYNWoUateujfT0dCQmJuLvv//GqVOnSmxfRGQcKSkp6NOnD3r06IHExER89dVXGDRoELy9vQEUHKcnT56M1NRUBAcHo2rVqkhJScGWLVswevRovP/++0/d/vr167FixQq8+uqrqFOnDu7evYtPP/0UarVa+iCwNK/pniQoKAgLFy5Ejx49MGjQIGRkZCA2NhZ169aV3XvKx8cHISEhWLx4MW7evIk2bdrg4MGD0reydb+pPXfuXOzfvx++vr4YNWoUGjdujFu3buHEiRPYs2cPbt26pXf7ymosql+/PsLCwvDbb7/B2dkZa9asQXp6uuyb9yVxbhIQEAAXFxe0a9cOzs7O+P3337F8+XIEBQVJvzIoq3OCkjJ+/Hhs2rQJ/fr1w4gRI+Dj44Nbt27hhx9+QFxcHLy9vTF69GisWrUKw4YNQ1JSEjw9PbFp0yb88ssvWLx4caF5/YtLrVZj5cqVGDJkCF588UUMGDAAjo6OuHr1KrZv34527doV+mCKjEgQlRNr164VAERKSopUtnz5ctGwYUNhYWEhnJ2dxZgxY8Tt27dl650/f174+/sLW1tbUaNGDTFq1Chx6tQpAUCsXbtWqhcaGipsbGwK7XfGjBnC0LdCaGio8PDwkB6npKQIAGLBggWF6gIQM2bMkB4/evRIjB07Vjg6OgqFQmHQvjt16iSaNGlS5LJffvlFtGnTRlhZWQlXV1cxYcIEsWvXLoH/x96dx1VZp/8ffwOyiMqmAjIiopb7FibS4pIIKmNpjqU5uUSafqFJadzKFLSiLLfUdJxSm0lHs5ms1BTcM4+aJLmUTprmTAY2ueCSgHD//uh3TpxA5cCBw/J6Ph489Nz3dd/357rEc5/7Oud8bsnYvn27Je7KlSvGY489Zvj4+BiSrPLIyckxXn31VaN169aGu7u74evra4SFhRlJSUnGpUuXij3OW+V4+fJlY/z48UZQUJDh6upq3HHHHcZrr71m5OfnF3v/hlH0v1tubq6RlJRkhIaGGq6urkZwcLAxZcoU4/r16yWq1c3q/dt//+Io7TFDQkKMmJiYQsslGXFxcZbH5rr8+OOPVnFF/f86duyY0bVrV6NmzZqGJGP48OE25QSgaqhM51/zc+SBAweMiIgIw8PDwwgJCTEWLlxYKLa457TfPo8W9N133xnDhg0z6tevb7i7uxtNmjQx4uLijOzsbEvM5cuXjSlTphjNmjUz3NzcjHr16hn33HOP8frrrxs5OTmGYZTf64TSvD4xDMM4cuSIMWDAAMPHx8fw8PAwmjdvbrzwwgtWMV988YURHR1t1K5d2/D09DR69Ohh7NmzxyrG/Dv1+eefWy2/2TnqZr8jS5cuNcLCwoyaNWsaderUMdq2bWtMnDjROHv2rCUmIyPDiImJMerUqWNIMrp162ZZd/LkSeMPf/iDJZ/OnTsb69evtzqGuUYl/Z29ceOG8dprrxktWrQw3NzcjPr16xt9+vQx0tLSLDHFfX1S3HN9wXH/9t/25MmTxrBhw4zAwEDD1dXV+N3vfmf8/ve/N95///1C+wVQeZiff7766ivjD3/4g1GnTh3D19fXiI+PN37++Wer2H/+85/GfffdZ9SqVcuoVauW0aJFCyMuLs44fvy4JeZm1xxffPGFMWTIEKNRo0aGu7u74e/vb/z+9783Dhw4YBVX3Gu6m51jQ0JCbL72ePvtt4077rjDcHd3N1q0aGEsX768yOflq1evGnFxcYafn59Ru3Zto3///sbx48cNScYrr7xiFZuZmWnExcUZwcHBhqurqxEYGGj07NnTWLp0qU1jK+25qDjM54jNmzcb7dq1s9Rh7dq1hWJL+9rkL3/5i9G1a1ejbt26hru7u9G0aVNjwoQJhXoCpXlNsH379kLXwrdT1GvWm507u3XrZvXvYBiG8dNPPxnx8fHG7373O8PNzc1o2LChMXz4cON///ufJSYzM9MYOXKkUa9ePcPNzc1o27at1WsEw7h57cw5/fbf5FY1iI6ONry9vQ0PDw+jadOmxogRIwr9f4NjORkGd4oDAABAxde9e3f973//u+0clQAAVCWJiYlKSkrSjz/+aPM3mSClp6erY8eOevfddzV06FBHD6dEGjdurDZt2mj9+vWOHgpQrTDHOQAAAAAAACq9n3/+udCyefPmydnZWV27dnXAiABUZsxxDhRw/vx55eTk3HS9i4uL6tevX2WOa6tLly4V+UKkIPNNSSryMezpxx9/tLpJzW+5ubnJz8+vHEcEAJVPZTkPOgr1AQBURXl5ebe9EWLt2rVVu3btYu9z1qxZSktLU48ePVSjRg198skn+uSTTzR69GgFBwfbNL7yuNbjelK6cuWKrly5csuY+vXrW25OD5QnGudAAQ8//LB27tx50/UhISFWd42u7Me11TPPPKN33nnnljGlnf2pPI5hT3fffbe+++67m67v1q2bduzYUX4DAoBKqLKcBx2F+gAAqqL//Oc/Cg0NvWXM9OnTlZiYWOx93nPPPUpNTdXMmTN15coVNWrUSImJiXr++edtHl95XOtxPSm9/vrrSkpKumXMqVOn1Lhx4/IZEFAAc5wDBaSlpenChQs3XV+zZk3de++9Vea4tvrqq6909uzZW8ZERkZW+GPY02effXbLT8j7+voqLCysHEcEAJVPZTkPOgr1AQBURdevX9fu3btvGdOkSRM1adKknEZkrTyu9bielL799lt9++23t4y577775OHhUU4jAn5F4xwAAAAAAAAAgAKq9VQt+fn5Onv2rOrUqSMnJydHDwcAAEm/TEd0+fJlBQUFydmZ+3hzvgYAVEScrwvjnA0AqIhKes6u1o3zs2fP2nxzCAAAyst//vMfNWzY0NHDcDjO1wCAiozz9a84ZwMAKjJbz9nVunFep04dSb8UzcvLy+btc3NzlZKSoqioKLm6utp7eFUO9So+amUb6lV81Mo2jqpXVlaWgoODLeep6q605+uCqvr/AfKr3KpyflU5N4n8KrPS5Mb5ujB7nbOr8u9ccVEDaiBRA4kaSNTAHvmX9JxdrRvn5q+OeXl5lbhx7unpKS8vr2r5i2sr6lV81Mo21Kv4qJVtHF0vvuL8i9Kerwty9L9pWSO/yq0q51eVc5PIrzKzR26cr39lr3N2Vf6dKy5qQA0kaiBRA4ka2DN/W8/ZTMQGAAAAAIADJCcn6+6771adOnXk7++v/v376/jx41Yx169fV1xcnOrWravatWtr4MCByszMtIo5c+aMYmJi5OnpKX9/f02YMEE3btywitmxY4fuuusuubu7q1mzZlqxYkWh8SxatEiNGzeWh4eHwsPDtX//frvnDABAZUHjHAAAAAAAB9i5c6fi4uK0d+9epaamKjc3V1FRUbp69aolZvz48fr444+1du1a7dy5U2fPntXDDz9sWZ+Xl6eYmBjl5ORoz549euedd7RixQpNmzbNEnPq1CnFxMSoR48eSk9P17hx4/Tkk09q8+bNlpg1a9YoISFB06dP1xdffKH27dsrOjpa586dK59iAABQwVTrqVoAAAAAAHCUTZs2WT1esWKF/P39lZaWpq5du+rSpUt6++23tWrVKj3wwAOSpOXLl6tly5bau3evunTpopSUFH311VfasmWLAgIC1KFDB82cOVOTJk1SYmKi3NzctGTJEoWGhmr27NmSpJYtW2r37t2aO3euoqOjJUlz5szRqFGjNHLkSEnSkiVLtGHDBi1btkyTJ08ux6oAAFAx0DgHAAAAAKACuHTpkiTJz89PkpSWlqbc3FxFRkZaYlq0aKFGjRrJZDKpS5cuMplMatu2rQICAiwx0dHRGjt2rI4ePaqOHTvKZDJZ7cMcM27cOElSTk6O0tLSNGXKFMt6Z2dnRUZGymQy3XS82dnZys7OtjzOysqS9Mt8tLm5uSWsgizblmYflR01oAYSNZCogUQN7JF/SbelcQ4AAAAAgIPl5+dr3Lhxuvfee9WmTRtJUkZGhtzc3OTj42MVGxAQoIyMDEtMwaa5eb153a1isrKy9PPPP+vChQvKy8srMubYsWM3HXNycrKSkpIKLU9JSZGnp2cxsr611NTUUu+jsqMG1ECiBhI1kKhBafK/du1aibajcW5HjSdvsHmb06/ElMFIAADArbRJ3KzsvOLfUZ3zNQCgrMXFxenIkSPavXu3o4dSbFOmTFFCQoLlcVZWloKDgxUVFSUvL68S7zc3N1epqanq1auXXF1dbdq2TeLm2wf9xpHEaJu3KWulqUFVQQ2ogUQNJGpgj/zN34iyFY1zAAAAAAAcKD4+XuvXr9euXbvUsGFDy/LAwEDl5OTo4sWLVp86z8zMVGBgoCVm//79VvvLzMy0rDP/aV5WMMbLy0s1a9aUi4uLXFxciowx76Mo7u7ucnd3L7Tc1dXVLs2dkuzHljfGCx6norJXLSszakANJGogUYPS5F/S7ZxLtBUAAAAAACgVwzAUHx+vDz74QNu2bVNoaKjV+rCwMLm6umrr1q2WZcePH9eZM2cUEREhSYqIiNDhw4d17tw5S0xqaqq8vLzUqlUrS0zBfZhjzPtwc3NTWFiYVUx+fr62bt1qiQEAoLrhE+cAAAAAADhAXFycVq1apQ8//FB16tSxzEnu7e2tmjVrytvbW7GxsUpISJCfn5+8vLz09NNPKyIiQl26dJEkRUVFqVWrVnr88cc1a9YsZWRkaOrUqYqLi7N8GnzMmDFauHChJk6cqCeeeELbtm3Te++9pw0bfp1uNCEhQcOHD1enTp3UuXNnzZs3T1evXtXIkSPLvzAAAFQANM4BAAAAAHCAxYsXS5K6d+9utXz58uUaMWKEJGnu3LlydnbWwIEDlZ2drejoaL355puWWBcXF61fv15jx45VRESEatWqpeHDh2vGjBmWmNDQUG3YsEHjx4/X/Pnz1bBhQ7311luKjv51bu9HH31UP/74o6ZNm6aMjAx16NBBmzZtKnTD0KrI1vuVce8TAKgeaJwDAAAAAOAAhmHcNsbDw0OLFi3SokWLbhoTEhKijRs33nI/3bt318GDB28ZEx8fr/j4+NuOCQCA6oA5zgEAAAAAAAAAKIDGOQAAAAAAAAAABdA4BwAAAAAAAACgABrnAAAAAAAAAAAUQOMcAAAAAAAAAIACaJwDAAAAAAAAAFAAjXMAAAAAAAAAAAqwqXGenJysu+++W3Xq1JG/v7/69++v48ePW8Vcv35dcXFxqlu3rmrXrq2BAwcqMzPTKubMmTOKiYmRp6en/P39NWHCBN24ccMqZseOHbrrrrvk7u6uZs2aacWKFYXGs2jRIjVu3FgeHh4KDw/X/v37bUkHAAAAAAAAAIBCbGqc79y5U3Fxcdq7d69SU1OVm5urqKgoXb161RIzfvx4ffzxx1q7dq127typs2fP6uGHH7asz8vLU0xMjHJycrRnzx698847WrFihaZNm2aJOXXqlGJiYtSjRw+lp6dr3LhxevLJJ7V582ZLzJo1a5SQkKDp06friy++UPv27RUdHa1z586Vph4AAFQJxXmzu3v37nJycrL6GTNmjFUMb3YDAAAAAKqjGrYEb9q0yerxihUr5O/vr7S0NHXt2lWXLl3S22+/rVWrVumBBx6QJC1fvlwtW7bU3r171aVLF6WkpOirr77Sli1bFBAQoA4dOmjmzJmaNGmSEhMT5ebmpiVLlig0NFSzZ8+WJLVs2VK7d+/W3LlzFR0dLUmaM2eORo0apZEjR0qSlixZog0bNmjZsmWaPHlykePPzs5Wdna25XFWVpYkKTc3V7m5ubaUwrJdwT/dXYwS76M6+G29cHPUyjbUq/iolW0cVS97HM/8Zvfdd9+tGzdu6LnnnlNUVJS++uor1apVyxI3atQozZgxw/LY09PT8nfzm92BgYHas2ePfvjhBw0bNkyurq56+eWXJf36ZveYMWO0cuVKbd26VU8++aQaNGhgOWeb3+xesmSJwsPDNW/ePEVHR+v48ePy9/cvda4AAAAAANibTY3z37p06ZIkyc/PT5KUlpam3NxcRUZGWmJatGihRo0ayWQyqUuXLjKZTGrbtq0CAgIsMdHR0Ro7dqyOHj2qjh07ymQyWe3DHDNu3DhJUk5OjtLS0jRlyhTLemdnZ0VGRspkMt10vMnJyUpKSiq0PCUlxapRYKvU1FRJ0qzOtm+7cePGEh+3sjLXC7dHrWxDvYqPWtmmvOt17dq1Uu/jdm92m3l6eiowMLDIfTjqzW57v9FdkOXNbmfb3uyuLG82VfU3x8iv8qrKuUnkV5mVJreqWA8AAPCrEjfO8/PzNW7cON17771q06aNJCkjI0Nubm7y8fGxig0ICFBGRoYlpmDT3LzevO5WMVlZWfr555914cIF5eXlFRlz7Nixm455ypQpSkhIsDzOyspScHCwoqKi5OXlZUP2v8jNzVVqaqp69eolV1dXtUncfPuNfuNIYrTN21RWv60Xbo5a2YZ6FR+1so2j6mVuFNvTb9/sNlu5cqXeffddBQYGql+/fnrhhRcsbyY76s3usnqju6CZnfJtiq9sb3RX9TfHyK/yqsq5SeRXmZUkN3u80Q0AACquEjfO4+LidOTIEe3evdue4ylT7u7ucnd3L7Tc1dW1VA0R8/bZeU4l2ra6KW29qxNqZRvqVXzUyjblXS97H6uoN7sl6bHHHlNISIiCgoJ06NAhTZo0ScePH9e//vUvSY57s9veb3QXZH4z5IUDzsrOL/55u7K80V3V3xwjv8qrKucmkV9lVprcyuKNbgAAUHGUqHEeHx+v9evXa9euXWrYsKFleWBgoHJycnTx4kWrT51nZmZavgYeGBhY6IZgmZmZlnXmP83LCsZ4eXmpZs2acnFxkYuLS5ExN/u6OQAA1dXN3uwePXq05e9t27ZVgwYN1LNnT508eVJNmzYt72FalNUb3QVl5zvZ9IZ3ZWsUVfU3x8iv8qrKuUnkV5mVJLeqWgsAAPALZ1uCDcNQfHy8PvjgA23btk2hoaFW68PCwuTq6qqtW7dalh0/flxnzpxRRESEJCkiIkKHDx/WuXPnLDGpqany8vJSq1atLDEF92GOMe/Dzc1NYWFhVjH5+fnaunWrJQYAAPz6Zvf27dut3uwuSnh4uCTpxIkTkm7+RrZ53a1izG9216tXjze7AQAAAACVjk2fOI+Li9OqVav04Ycfqk6dOpavaXt7e6tmzZry9vZWbGysEhIS5OfnJy8vLz399NOKiIhQly5dJElRUVFq1aqVHn/8cc2aNUsZGRmaOnWq4uLiLJ8uGzNmjBYuXKiJEyfqiSee0LZt2/Tee+9pw4YNlrEkJCRo+PDh6tSpkzp37qx58+bp6tWrlhuPVRaNJ2+4fdBvnH4lpgxGAgCoSgzD0NNPP60PPvhAO3bsKPRmd1HS09MlSQ0aNJD0yxvZL730ks6dOyd/f39JRb/Z/dv5v2/2Znf//v0l/fpmd3x8vD1SBQAAAADA7mxqnC9evFiS1L17d6vly5cv14gRIyRJc+fOlbOzswYOHKjs7GxFR0frzTfftMS6uLho/fr1Gjt2rCIiIlSrVi0NHz5cM2bMsMSEhoZqw4YNGj9+vObPn6+GDRvqrbfeUnT0r/OLPvroo/rxxx81bdo0ZWRkqEOHDtq0aVOhOVQBAKiObvdm98mTJ7Vq1Sr17dtXdevW1aFDhzR+/Hh17dpV7dq1k8Sb3QAAAACA6sumxrlhGLeN8fDw0KJFi7Ro0aKbxoSEhBT6dNpvde/eXQcPHrxlTHx8PJ9WAwCgCLd7s9vNzU1btmyxNLGDg4M1cOBATZ061RLLm90AAAAAgOqqRDcHBQAAFdvt3uwODg7Wzp07b7sf3uwGAAAAAFRHNt0cFAAAAAAAAACAqo7GOQAAAAAAAAAABdA4BwAAAAAAAACgABrnAAAAAAAAAAAUQOMcAAAAAAAAAIACaJwDAAAAAAAAAFAAjXMAAAAAAAAAAAqgcQ4AAAAAAAAAQAE0zgEAAAAAAAAAKIDGOQAAAAAAAAAABdA4BwAAAAAAAACgABrnAAAAAAAAAAAUQOMcAAAAAAAH2bVrl/r166egoCA5OTlp3bp1VutHjBghJycnq5/evXtbxZw/f15Dhw6Vl5eXfHx8FBsbqytXrljFHDp0SPfff788PDwUHBysWbNmFRrL2rVr1aJFC3l4eKht27bauHGj3fMFAKCyoHEOAAAAAICDXL16Ve3bt9eiRYtuGtO7d2/98MMPlp9//OMfVuuHDh2qo0ePKjU1VevXr9euXbs0evRoy/qsrCxFRUUpJCREaWlpeu2115SYmKilS5daYvbs2aMhQ4YoNjZWBw8eVP/+/dW/f38dOXLE/kkDAFAJ1HD0AAAAAAAAqK769OmjPn363DLG3d1dgYGBRa77+uuvtWnTJn3++efq1KmTJGnBggXq27evXn/9dQUFBWnlypXKycnRsmXL5ObmptatWys9PV1z5syxNNjnz5+v3r17a8KECZKkmTNnKjU1VQsXLtSSJUuKPHZ2drays7Mtj7OysiRJubm5ys3Nta0QBZi3Lck+3F2MEh+3uEqTm63HKI9jVVTUgBpI1ECiBvbIv6Tb0jgHAAAAAKAC27Fjh/z9/eXr66sHHnhAL774ourWrStJMplM8vHxsTTNJSkyMlLOzs7at2+fBgwYIJPJpK5du8rNzc0SEx0drVdffVUXLlyQr6+vTCaTEhISrI4bHR1daOqYgpKTk5WUlFRoeUpKijw9PUuZtZSammrzNrM6l/qwt1WeU9iUpAZVDTWgBhI1kKhBafK/du1aibajcQ4AAAAAQAXVu3dvPfzwwwoNDdXJkyf13HPPqU+fPjKZTHJxcVFGRob8/f2ttqlRo4b8/PyUkZEhScrIyFBoaKhVTEBAgGWdr6+vMjIyLMsKxpj3UZQpU6ZYNduzsrIUHBysqKgoeXl5lTjn3NxcpaamqlevXnJ1dbVp2zaJm0t83OI6khhd5scoTQ2qCmpADSRqIFEDe+Rv/kaUrWicAwAAAABQQQ0ePNjy97Zt26pdu3Zq2rSpduzYoZ49ezpwZL9MIePu7l5ouaurq12aOyXZT3aeU6mPezvl2biyVy0rM2pADSRqIFGD0uRf0u24OSgAAFVQcnKy7r77btWpU0f+/v7q37+/jh8/bhVz/fp1xcXFqW7duqpdu7YGDhyozMxMq5gzZ84oJiZGnp6e8vf314QJE3Tjxg2rmB07duiuu+6Su7u7mjVrphUrVhQaz6JFi9S4cWN5eHgoPDxc+/fvt3vOAABUB02aNFG9evV04sQJSVJgYKDOnTtnFXPjxg2dP3/eMi96YGBgoXO8+fHtYm42tzoAAFUdjXMAAKqgnTt3Ki4uTnv37lVqaqpyc3MVFRWlq1evWmLGjx+vjz/+WGvXrtXOnTt19uxZPfzww5b1eXl5iomJUU5Ojvbs2aN33nlHK1as0LRp0ywxp06dUkxMjHr06KH09HSNGzdOTz75pDZv/vVr0mvWrFFCQoKmT5+uL774Qu3bt1d0dHShi3wAAHB7//3vf/XTTz+pQYMGkqSIiAhdvHhRaWlplpht27YpPz9f4eHhlphdu3ZZ3RwtNTVVzZs3l6+vryVm69atVsdKTU1VREREWacEAECFxFQtAABUQZs2bbJ6vGLFCvn7+ystLU1du3bVpUuX9Pbbb2vVqlV64IEHJEnLly9Xy5YttXfvXnXp0kUpKSn66quvtGXLFgUEBKhDhw6aOXOmJk2apMTERLm5uWnJkiUKDQ3V7NmzJUktW7bU7t27NXfuXEVH/zL/55w5czRq1CiNHDlSkrRkyRJt2LBBy5Yt0+TJkwuNPTs7W9nZ2ZbH5vnocnNzS30nefP27s5Gibar6Oxxx/mKjPwqr6qcm0R+lVlpcrNXPa5cuWL59Lj0y5vS6enp8vPzk5+fn5KSkjRw4EAFBgbq5MmTmjhxopo1a2Y5z7Zs2VK9e/fWqFGjtGTJEuXm5io+Pl6DBw9WUFCQJOmxxx5TUlKSYmNjNWnSJB05ckTz58/X3LlzLcd95pln1K1bN82ePVsxMTFavXq1Dhw4oKVLl9olTwAAKhsa5wAAVAOXLl2SJPn5+UmS0tLSlJubq8jISEtMixYt1KhRI5lMJnXp0kUmk0lt27a1ulFYdHS0xo4dq6NHj6pjx44ymUxW+zDHjBs3TpKUk5OjtLQ0TZkyxbLe2dlZkZGRMplMRY41OTlZSUlJhZanpKTI09OzZAX4jZmd8m2K37hxo12OW15Kc8f5yoD8Kq+qnJtEfpVZSXK7du2aXY594MAB9ejRw/LYfLPN4cOHa/HixTp06JDeeecdXbx4UUFBQYqKitLMmTOt5hZfuXKl4uPj1bNnTzk7O2vgwIF64403LOu9vb2VkpKiuLg4hYWFqV69epo2bZpGjx5tibnnnnu0atUqTZ06Vc8995zuuOMOrVu3Tm3atLFLngAAVDY0zgEAqOLy8/M1btw43XvvvZaL34yMDLm5ucnHx8cqNiAgQBkZGZaYgk1z83rzulvFZGVl6eeff9aFCxeUl5dXZMyxY8eKHO+UKVMsTQPpl0+cBwcHKyoqSl5eXjZmb818R/YXDjgrO7/4Nw87khhdquOWF3vccb4iI7/KqyrnJpFfZVaa3MzfiCqt7t27yzBu/k2ogtOf3Yyfn59WrVp1y5h27drp008/vWXMoEGDNGjQoNseDwCA6oDGOQAAVVxcXJyOHDmi3bt3O3ooxeLu7m71KToze95FPjvfSdl5xW+cV7ZGkT1rVRGRX+VVlXOTyK8yK0luVbUWAADgFzbfHHTXrl3q16+fgoKC5OTkpHXr1lmtHzFihJycnKx+evfubRVz/vx5DR06VF5eXvLx8VFsbKyuXLliFXPo0CHdf//98vDwUHBwsGbNmlVoLGvXrlWLFi3k4eGhtm3bVrqvUQMAUNbi4+O1fv16bd++XQ0bNrQsDwwMVE5Oji5evGgVn5mZqcDAQEtMZmZmofXmdbeK8fLyUs2aNVWvXj25uLgUGWPeBwAAAAAAFY3NjfOrV6+qffv2WrRo0U1jevfurR9++MHy849//MNq/dChQ3X06FGlpqZq/fr12rVrl9XcallZWYqKilJISIjS0tL02muvKTEx0eqmJHv27NGQIUMUGxurgwcPqn///urfv7+OHDlia0oAAFQ5hmEoPj5eH3zwgbZt26bQ0FCr9WFhYXJ1ddXWrVsty44fP64zZ84oIiJCkhQREaHDhw/r3LlzlpjU1FR5eXmpVatWlpiC+zDHmPfh5uamsLAwq5j8/Hxt3brVEgMAAAAAQEVj81Qtffr0UZ8+fW4Z4+7uftNPkX399dfatGmTPv/8c3Xq1EmStGDBAvXt21evv/66goKCtHLlSuXk5GjZsmVyc3NT69atlZ6erjlz5lga7PPnz1fv3r01YcIESdLMmTOVmpqqhQsXasmSJbamBQBAlRIXF6dVq1bpww8/VJ06dSxzknt7e6tmzZry9vZWbGysEhIS5OfnJy8vLz399NOKiIhQly5dJElRUVFq1aqVHn/8cc2aNUsZGRmaOnWq4uLiLFOpjBkzRgsXLtTEiRP1xBNPaNu2bXrvvfe0YcMGy1gSEhI0fPhwderUSZ07d9a8efN09epVjRw5svwLAwAAAABAMZTJHOc7duyQv7+/fH199cADD+jFF19U3bp1JUkmk0k+Pj6WprkkRUZGytnZWfv27dOAAQNkMpnUtWtXubm5WWKio6P16quv6sKFC/L19ZXJZLK6cZg55rdTxxSUnZ2t7Oxsy2PzzVxyc3OVm5trc57mbcx/urvc/IYu9lSSsVYEv60Xbo5a2YZ6FR+1so2j6mWP4y1evFjSLzccK2j58uUaMWKEJGnu3LlydnbWwIEDlZ2drejoaL355puWWBcXF61fv15jx45VRESEatWqpeHDh2vGjBmWmNDQUG3YsEHjx4/X/Pnz1bBhQ7311luKjv71ZpqPPvqofvzxR02bNk0ZGRnq0KGDNm3aVOiGoQAAAAAAVBR2b5z37t1bDz/8sEJDQ3Xy5Ek999xz6tOnj0wmk1xcXJSRkSF/f3/rQdSoIT8/P8un4TIyMgp9pdx8cZ2RkSFfX19lZGQUuuAOCAiw7KMoycnJSkpKKrQ8JSVFnp6eJcpX+uUr6ZI0q3OJd2GTyj6Xu7leuD1qZRvqVXzUyjblXa9r166Veh+Gcfs3cz08PLRo0aJbTr8WEhJy2/NO9+7ddfDgwVvGxMfHKz4+/rZjAgAAAACgIrB743zw4MGWv7dt21bt2rVT06ZNtWPHDvXs2dPeh7PJlClTrD6lnpWVpeDgYEVFRcnLy8vm/eXm5io1NVW9evWSq6ur2iRutudwb+pIYvTtgyqg39YLN0etbEO9io9a2cZR9TJ/IwoAAAAAADhGmUzVUlCTJk1Ur149nThxQj179lRgYKDVTcYk6caNGzp//rxlXvTAwEBlZmZaxZgf3y7mZnOrS7/MvW6ek7UgV1fXUjVEzNtn5zmVeB+2Hq8yK229qxNqZRvqVXzUyjblXS/+bQAAAAAAcCznsj7Af//7X/30009q0KCBJCkiIkIXL15UWlqaJWbbtm3Kz89XeHi4JWbXrl1Wc7ympqaqefPm8vX1tcRs3brV6lipqamKiIgo65QAAAAAAAAAAFWYzY3zK1euKD09Xenp6ZKkU6dOKT09XWfOnNGVK1c0YcIE7d27V6dPn9bWrVv10EMPqVmzZpabhLVs2VK9e/fWqFGjtH//fn322WeKj4/X4MGDFRQUJEl67LHH5ObmptjYWB09elRr1qzR/PnzraZZeeaZZ7Rp0ybNnj1bx44dU2Jiog4cOMD8qQAAAAAAAACAUrG5cX7gwAF17NhRHTt2lCQlJCSoY8eOmjZtmlxcXHTo0CE9+OCDuvPOOxUbG6uwsDB9+umnVlOkrFy5Ui1atFDPnj3Vt29f3XfffVq6dKllvbe3t1JSUnTq1CmFhYXp2Wef1bRp0zR69GhLzD333KNVq1Zp6dKlat++vd5//32tW7dObdq0KU09AAAAAAAAAADVnM1znHfv3l2GYdx0/ebNt79Bpp+fn1atWnXLmHbt2unTTz+9ZcygQYM0aNCg2x4PAAAAAAAAAIDiKvM5zgEAAAAAAAAAqExonAMAAAAAAAAAUIDNU7UAAABUN40nb7B5m9OvxJTBSAAAAAAA5YFPnAMAAAAAAAAAUACNcwAAAAAAAAAACqBxDgAAAAAAAABAATTOAQAAAAAAAAAogMY5AAAAAAAAAAAF0DgHAAAAAAAAAKAAGucAAAAAAAAAABRA4xwAAAAAAAAAgAJonAMAAAAAAAAAUACNcwAAqqBdu3apX79+CgoKkpOTk9atW2e1fsSIEXJycrL66d27t1XM+fPnNXToUHl5ecnHx0exsbG6cuWKVcyhQ4d0//33y8PDQ8HBwZo1a1ahsaxdu1YtWrSQh4eH2rZtq40bN9o9XwAAAAAA7InGOQAAVdDVq1fVvn17LVq06KYxvXv31g8//GD5+cc//mG1fujQoTp69KhSU1O1fv167dq1S6NHj7asz8rKUlRUlEJCQpSWlqbXXntNiYmJWrp0qSVmz549GjJkiGJjY3Xw4EH1799f/fv315EjR+yfNAAAAAAAdlLD0QMAAAD216dPH/Xp0+eWMe7u7goMDCxy3ddff61Nmzbp888/V6dOnSRJCxYsUN++ffX6668rKChIK1euVE5OjpYtWyY3Nze1bt1a6enpmjNnjqXBPn/+fPXu3VsTJkyQJM2cOVOpqalauHChlixZYseMAQAAAACwHxrnAABUUzt27JC/v798fX31wAMP6MUXX1TdunUlSSaTST4+PpamuSRFRkbK2dlZ+/bt04ABA2QymdS1a1e5ublZYqKjo/Xqq6/qwoUL8vX1lclkUkJCgtVxo6OjC00dU1B2drays7Mtj7OysiRJubm5ys3NLVXO5u3dnY1S7ceWY5Un8zEdcezyQH6VV1XOTSK/yqw0uVXFegAAgF/ROAcAoBrq3bu3Hn74YYWGhurkyZN67rnn1KdPH5lMJrm4uCgjI0P+/v5W29SoUUN+fn7KyMiQJGVkZCg0NNQqJiAgwLLO19dXGRkZlmUFY8z7KEpycrKSkpIKLU9JSZGnp2eJ8v2tmZ3y7bKfW3HkXO6pqakOO3Z5IL/KqyrnJpFfZVaS3K5du1YGIwEAABUFjXMAAKqhwYMHW/7etm1btWvXTk2bNtWOHTvUs2dPB45MmjJlitWn1LOyshQcHKyoqCh5eXmVat+5ublKTU3VCweclZ3vVNqh3tKRxOgy3X9RzPn16tVLrq6u5X78skZ+lVdVzk0iv8qsNLmZvxEFAACqJhrnAABATZo0Ub169XTixAn17NlTgYGBOnfunFXMjRs3dP78ecu86IGBgcrMzLSKMT++XczN5laXfpl73d3dvdByV1dXuzVssvOdlJ1Xto1zRzaX7Fmrioj8Kq+qnJtEfpVZSXKzVy127dql1157TWlpafrhhx/0wQcfqH///pb1hmFo+vTp+utf/6qLFy/q3nvv1eLFi3XHHXdYYs6fP6+nn35aH3/8sZydnTVw4EDNnz9ftWvXtsQcOnRIcXFx+vzzz1W/fn09/fTTmjhxotVY1q5dqxdeeEGnT5/WHXfcoVdffVV9+/a1S54AAFQ2zo4eAAAAcLz//ve/+umnn9SgQQNJUkREhC5evKi0tDRLzLZt25Sfn6/w8HBLzK5du6zmeE1NTVXz5s3l6+tridm6davVsVJTUxUREVHWKQEAUClcvXpV7du316JFi4pcP2vWLL3xxhtasmSJ9u3bp1q1aik6OlrXr1+3xAwdOlRHjx5Vamqq1q9fr127dllu1C398un4qKgohYSEKC0tTa+99poSExO1dOlSS8yePXs0ZMgQxcbG6uDBg+rfv7/69++vI0eOlF3yAABUYHziHACAKujKlSs6ceKE5fGpU6eUnp4uPz8/+fn5KSkpSQMHDlRgYKBOnjypiRMnqlmzZoqO/mV6kZYtW6p3794aNWqUlixZotzcXMXHx2vw4MEKCgqSJD322GNKSkpSbGysJk2apCNHjmj+/PmaO3eu5bjPPPOMunXrptmzZysmJkarV6/WgQMHrC7UAQCozvr06aM+ffoUuc4wDM2bN09Tp07VQw89JEn629/+poCAAK1bt06DBw/W119/rU2bNunzzz+33NR7wYIF6tu3r15//XUFBQVp5cqVysnJ0bJly+Tm5qbWrVsrPT1dc+bMsTTY58+fr969e2vChAmSpJkzZyo1NVULFy7UkiVLihxfWd3QuzQ3bXV3qRo3AK/KN+UtLmpADSRqIFEDe+Rf0m1pnAMAUAUdOHBAPXr0sDw2zxk+fPhwLV68WIcOHdI777yjixcvKigoSFFRUZo5c6bVFCkrV65UfHy8evbsafna9xtvvGFZ7+3trZSUFMXFxSksLEz16tXTtGnTrD7hds8992jVqlWaOnWqnnvuOd1xxx1at26d2rRpUw5VAACgcjt16pQyMjIUGRlpWebt7a3w8HCZTCYNHjxYJpNJPj4+lqa5JEVGRsrZ2Vn79u3TgAEDZDKZ1LVrV7m5uVlioqOj9eqrr+rChQvy9fWVyWSyuseIOWbdunU3HV9Z39C7JDdtndW51Ie9rfK8AXhVvilvcVEDaiBRA4kalCb/kt7Qm8Y5AABVUPfu3WUYN//E1ebNm2+7Dz8/P61ateqWMe3atdOnn356y5hBgwZp0KBBtz0eAACwlpGRIUkKCAiwWh4QEGBZl5GRIX9/f6v1NWrUkJ+fn1VMaGhooX2Y1/n6+iojI+OWxylKWd3QuzQ3bW2TePvXOKVVHjcAr8o35S0uakANJGogUQN75F/SG3rTOAcAAAAAADYr6xt6l2Q/ZX3zb6l8bwBelW/KW1zUgBpI1ECiBqXJv6Tb0TgHAAAAAKACCgwMlCRlZmZabuBtftyhQwdLzLlz56y2u3Hjhs6fP2/ZPjAwUJmZmVYx5se3izGvx68aT95g8zanX4kpg5EAAMqSs6MHAAAAAAAACgsNDVVgYKC2bt1qWZaVlaV9+/YpIiJCkhQREaGLFy8qLS3NErNt2zbl5+crPDzcErNr1y6rm6OlpqaqefPm8vX1tcQUPI45xnwcAACqG5sb57t27VK/fv0UFBQkJyenQjcKMQxD06ZNU4MGDVSzZk1FRkbqm2++sYo5f/68hg4dKi8vL/n4+Cg2NlZXrlyxijl06JDuv/9+eXh4KDg4WLNmzSo0lrVr16pFixby8PBQ27Zty/UGHQAAAAAAlNaVK1eUnp6u9PR0Sb/cEDQ9PV1nzpyRk5OTxo0bpxdffFEfffSRDh8+rGHDhikoKEj9+/eXJLVs2VK9e/fWqFGjtH//fn322WeKj4/X4MGDFRQUJEl67LHH5ObmptjYWB09elRr1qzR/PnzreYnf+aZZ7Rp0ybNnj1bx44dU2Jiog4cOKD4+PjyLgkAABWCzY3zq1evqn379lq0aFGR62fNmqU33nhDS5Ys0b59+1SrVi1FR0fr+vXrlpihQ4fq6NGjSk1N1fr167Vr1y6NHj3asj4rK0tRUVEKCQlRWlqaXnvtNSUmJmrp0qWWmD179mjIkCGKjY3VwYMH1b9/f/Xv319HjhyxNSUAAAAAABziwIED6tixozp27ChJSkhIUMeOHTVt2jRJ0sSJE/X0009r9OjRuvvuu3XlyhVt2rRJHh4eln2sXLlSLVq0UM+ePdW3b1/dd999VtfP3t7eSklJ0alTpxQWFqZnn31W06ZNs7oOv+eee7Rq1SotXbpU7du31/vvv69169apTZs25VQJAAAqFpvnOO/Tp4/69OlT5DrDMDRv3jxNnTpVDz30kCTpb3/7mwICArRu3ToNHjxYX3/9tTZt2qTPP/9cnTp1kiQtWLBAffv21euvv66goCCtXLlSOTk5WrZsmdzc3NS6dWulp6drzpw5lhP7/Pnz1bt3b02YMEGSNHPmTKWmpmrhwoVasmRJiYoBAAAAAEB56t69uwzDuOl6JycnzZgxQzNmzLhpjJ+fn1atWnXL47Rr106ffvrpLWMGDRqkQYMG3XrAAABUE3a9OeipU6eUkZGhyMhIyzJvb2+Fh4fLZDJp8ODBMplM8vHxsTTNJSkyMlLOzs7at2+fBgwYIJPJpK5du8rNzc0SEx0drVdffVUXLlyQr6+vTCaT1dfKzDG/nTqmoOzsbGVnZ1seZ2VlSZJyc3Ot5norLvM25j/dXW7+YseeSjLWiuC39cLNUSvbUK/io1a2cVS9+PcBAAAAAMCx7No4z8jIkCQFBARYLQ8ICLCsy8jIkL+/v/UgatSQn5+fVUxoaGihfZjX+fr6KiMj45bHKUpycrKSkpIKLU9JSZGnp2dxUixSamqqJGlW5xLvwiaVfS53c71we9TKNtSr+KiVbcq7XteuXSvX4wEAAAAAAGt2bZxXdFOmTLH6lHpWVpaCg4MVFRUlLy8vm/eXm5ur1NRU9erVS66urmqTuNmew72pI4nR5XIce/ttvXBz1Mo21Kv4qJVtHFUv8zeiAAAAAACAY9i1cR4YGChJyszMVIMGDSzLMzMz1aFDB0vMuXPnrLa7ceOGzp8/b9k+MDBQmZmZVjHmx7eLMa8viru7u9zd3Qstd3V1LVVDxLx9dp5Tifdh6/Eqs9LWuzqhVrahXsVHrWxT3vXi3wYAAAAAAMdytufOQkNDFRgYqK1bt1qWZWVlad++fYqIiJAkRURE6OLFi0pLS7PEbNu2Tfn5+QoPD7fE7Nq1y2qO19TUVDVv3ly+vr6WmILHMceYjwMAAAAAAAAAQEnY3Di/cuWK0tPTlZ6eLumXG4Kmp6frzJkzcnJy0rhx4/Tiiy/qo48+0uHDhzVs2DAFBQWpf//+kqSWLVuqd+/eGjVqlPbv36/PPvtM8fHxGjx4sIKCgiRJjz32mNzc3BQbG6ujR49qzZo1mj9/vtU0K88884w2bdqk2bNn69ixY0pMTNSBAwcUHx9f+qoAAAAAAAAAAKotm6dqOXDggHr06GF5bG5mDx8+XCtWrNDEiRN19epVjR49WhcvXtR9992nTZs2ycPDw7LNypUrFR8fr549e8rZ2VkDBw7UG2+8YVnv7e2tlJQUxcXFKSwsTPXq1dO0adM0evRoS8w999yjVatWaerUqXruued0xx13aN26dWrTpk2JCgEAAAAAAAAAgFSCxnn37t1lGMZN1zs5OWnGjBmaMWPGTWP8/Py0atWqWx6nXbt2+vTTT28ZM2jQIA0aNOjWAwYAAAAAAAAAwAZ2neMcAAAAAAAAAIDKjsY5AAAAAAAAAAAF0DgHAAAAAAAAAKAAGucAAAAAAAAAABRg881B4XiNJ2+wKf70KzFlNBIAAAAAAAAAqHr4xDkAAFXQrl271K9fPwUFBcnJyUnr1q2zWm8YhqZNm6YGDRqoZs2aioyM1DfffGMVc/78eQ0dOlReXl7y8fFRbGysrly5YhVz6NAh3X///fLw8FBwcLBmzZpVaCxr165VixYt5OHhobZt22rjxo12zxcAAAAAAHuicQ4AQBV09epVtW/fXosWLSpy/axZs/TGG29oyZIl2rdvn2rVqqXo6Ghdv37dEjN06FAdPXpUqampWr9+vXbt2qXRo0db1mdlZSkqKkohISFKS0vTa6+9psTERC1dutQSs2fPHg0ZMkSxsbE6ePCg+vfvr/79++vIkSNllzwAAAAAAKXEVC0AAFRBffr0UZ8+fYpcZxiG5s2bp6lTp+qhhx6SJP3tb39TQECA1q1bp8GDB+vrr7/Wpk2b9Pnnn6tTp06SpAULFqhv3756/fXXFRQUpJUrVyonJ0fLli2Tm5ubWrdurfT0dM2ZM8fSYJ8/f7569+6tCRMmSJJmzpyp1NRULVy4UEuWLClyfNnZ2crOzrY8zsrKkiTl5uYqNze3VHUxb+/ubJRqP7YcqzyZj+mIY5cH8qu8qnJuEvlVZqXJrSrWAwAA/IrGOQAA1cypU6eUkZGhyMhIyzJvb2+Fh4fLZDJp8ODBMplM8vHxsTTNJSkyMlLOzs7at2+fBgwYIJPJpK5du8rNzc0SEx0drVdffVUXLlyQr6+vTCaTEhISrI4fHR1daOqYgpKTk5WUlFRoeUpKijw9PUuR+a9mdsq3y35uxZFT0qSmpjrs2OWB/CqvqpybRH6VWUlyu3btWhmMBAAAVBQ0zgEAqGYyMjIkSQEBAVbLAwICLOsyMjLk7+9vtb5GjRry8/OzigkNDS20D/M6X19fZWRk3PI4RZkyZYpVsz0rK0vBwcGKioqSl5eXLakWkpubq9TUVL1wwFnZ+U6l2tftHEmMLtP9F8WcX69eveTq6lruxy9r5Fd5VeXcJPKrzEqTm/kbUQAAoGqicQ4AACoUd3d3ubu7F1ru6upqt4ZNdr6TsvPKtnHuyOaSPWtVEZFf5VWVc5PIrzIrSW5VtRYAAOAX3BwUAIBqJjAwUJKUmZlptTwzM9OyLjAwUOfOnbNaf+PGDZ0/f94qpqh9FDzGzWLM6wEAAAAAqIhonAMAUM2EhoYqMDBQW7dutSzLysrSvn37FBERIUmKiIjQxYsXlZaWZonZtm2b8vPzFR4ebonZtWuX1c3RUlNT1bx5c/n6+lpiCh7HHGM+DgAAAAAAFRGNcwAAqqArV64oPT1d6enpkn65IWh6errOnDkjJycnjRs3Ti+++KI++ugjHT58WMOGDVNQUJD69+8vSWrZsqV69+6tUaNGaf/+/frss88UHx+vwYMHKygoSJL02GOPyc3NTbGxsTp69KjWrFmj+fPnW81P/swzz2jTpk2aPXu2jh07psTERB04cEDx8fHlXRIAAAAAAIqNOc4BAKiCDhw4oB49elgem5vZw4cP14oVKzRx4kRdvXpVo0eP1sWLF3Xfffdp06ZN8vDwsGyzcuVKxcfHq2fPnnJ2dtbAgQP1xhtvWNZ7e3srJSVFcXFxCgsLU7169TRt2jSNHj3aEnPPPfdo1apVmjp1qp577jndcccdWrdundq0aVMOVQAAAAAAoGRonAMAUAV1795dhmHcdL2Tk5NmzJihGTNm3DTGz89Pq1atuuVx2rVrp08//fSWMYMGDdKgQYNuPWAAAAAAACoQpmoBAAAAAAAAAKAAGucAAAAAAAAAABRA4xwAAAAAAAAAgAJonAMAAAAAAAAAUACNcwAAAAAAAAAACqBxDgAAAAAAAABAATTOAQAAAACooBITE+Xk5GT106JFC8v669evKy4uTnXr1lXt2rU1cOBAZWZmWu3jzJkziomJkaenp/z9/TVhwgTduHHDKmbHjh2666675O7urmbNmmnFihXlkR4AABUWjXMAAAAAACqw1q1b64cffrD87N6927Ju/Pjx+vjjj7V27Vrt3LlTZ8+e1cMPP2xZn5eXp5iYGOXk5GjPnj165513tGLFCk2bNs0Sc+rUKcXExKhHjx5KT0/XuHHj9OSTT2rz5s3lmicAABVJDUcPAAAAAAAA3FyNGjUUGBhYaPmlS5f09ttva9WqVXrggQckScuXL1fLli21d+9edenSRSkpKfrqq6+0ZcsWBQQEqEOHDpo5c6YmTZqkxMREubm5acmSJQoNDdXs2bMlSS1bttTu3bs1d+5cRUdHl2uuAABUFDTOAQAAAACowL755hsFBQXJw8NDERERSk5OVqNGjZSWlqbc3FxFRkZaYlu0aKFGjRrJZDKpS5cuMplMatu2rQICAiwx0dHRGjt2rI4ePaqOHTvKZDJZ7cMcM27cuFuOKzs7W9nZ2ZbHWVlZkqTc3Fzl5uaWOF/ztiXZh7uLUeLjliVbcylNDaoKakANJGogUQN75F/Sbe3eOE9MTFRSUpLVsubNm+vYsWOSfpl/7dlnn9Xq1auVnZ2t6Ohovfnmm1Yn8TNnzmjs2LHavn27ateureHDhys5OVk1avw63B07dighIUFHjx5VcHCwpk6dqhEjRtg7HQAAgBJpPHmDzducfiWmDEYCAKjMwsPDtWLFCjVv3lw//PCDkpKSdP/99+vIkSPKyMiQm5ubfHx8rLYJCAhQRkaGJCkjI8Pqetu83rzuVjFZWVn6+eefVbNmzSLHlpycXOj6X5JSUlLk6elZonwLSk1NtXmbWZ1LfdgysXHjxhJtV5IaVDXUgBpI1ECiBqXJ/9q1ayXarkw+cd66dWtt2bLl14MUaHiPHz9eGzZs0Nq1a+Xt7a34+Hg9/PDD+uyzzyT9Ov9aYGCg9uzZox9++EHDhg2Tq6urXn75ZUm/zr82ZswYrVy5Ulu3btWTTz6pBg0a8DUyAAAAAECV0adPH8vf27Vrp/DwcIWEhOi99967aUO7vEyZMkUJCQmWx1lZWQoODlZUVJS8vLxKvN/c3FylpqaqV69ecnV1tWnbNokVc172I4m29SpKU4OqghpQA4kaSNTAHvmbvxFlqzJpnDP/GgAAAAAA9ufj46M777xTJ06cUK9evZSTk6OLFy9afeo8MzPTck0eGBio/fv3W+0jMzPTss78p3lZwRgvL69bNufd3d3l7u5eaLmrq6tdmjsl2U92nlOpj1sWSloPe9WyMqMG1ECiBhI1KE3+Jd2uTBrn1WX+td/OsVNV5lIrK9V9TiZbUCvbUK/io1a2cVS9+PcBAAA3c+XKFZ08eVKPP/64wsLC5Orqqq1bt2rgwIGSpOPHj+vMmTOKiIiQJEVEROill17SuXPn5O/vL+mXr7t7eXmpVatWlpjfTiWSmppq2QcAANWR3Rvn1XH+NfMcO1VtLrWyUt3nZLIFtbIN9So+amWb8q5XSedfAwAAVc+f//xn9evXTyEhITp79qymT58uFxcXDRkyRN7e3oqNjVVCQoL8/Pzk5eWlp59+WhEREerSpYskKSoqSq1atdLjjz+uWbNmKSMjQ1OnTlVcXJzl0+JjxozRwoULNXHiRD3xxBPatm2b3nvvPW3YYPv9OlA0W+994u5iVNgeAwBUF3ZvnFen+dd+O8dOVZlLraxU9zmZbEGtbEO9io9a2cZR9Srp/GsAAKDq+e9//6shQ4bop59+Uv369XXfffdp7969ql+/viRp7ty5cnZ21sCBA5Wdna3o6Gi9+eablu1dXFy0fv16jR07VhEREapVq5aGDx+uGTNmWGJCQ0O1YcMGjR8/XvPnz1fDhg311ltvMRUqAKBaK5OpWgqqDvOvmbevanOplZXqPieTLaiVbahX8VEr25R3vfi3AQAAZqtXr77leg8PDy1atEiLFi26aUxISMhtv4ncvXt3HTx4sERjBACgKnIu6wOY519r0KCB1fxrZkXNv3b48GGdO3fOElPU/GsF92GOYf41AAAAAAAAAEBp2b1x/uc//1k7d+7U6dOntWfPHg0YMKDI+de2b9+utLQ0jRw58qbzr3355ZfavHlzkfOvffvtt5o4caKOHTumN998U++9957Gjx9v73QAAKiSEhMT5eTkZPXTokULy/rr168rLi5OdevWVe3atTVw4MBC3/Y6c+aMYmJi5OnpKX9/f02YMEE3btywitmxY4fuuusuubu7q1mzZlqxYkV5pAcAAAAAQKnYfaoW5l8DAKByaN26tbZs2WJ5XKPGry8Lxo8frw0bNmjt2rXy9vZWfHy8Hn74YX322WeSpLy8PMXExCgwMFB79uzRDz/8oGHDhsnV1VUvv/yyJOnUqVOKiYnRmDFjtHLlSm3dulVPPvmkGjRowDkbAAAAAFCh2b1xzvxrAABUDjVq1LDcP6SgS5cu6e2339aqVav0wAMPSJKWL1+uli1bau/everSpYtSUlL01VdfacuWLQoICFCHDh00c+ZMTZo0SYmJiXJzc9OSJUsUGhqq2bNnS5Jatmyp3bt3a+7cubdsnGdnZys7O9vy2Hyz1NzcXOXm5pYqZ/P27s5GqfZTVuyVX2n3U1GRX+VVlXOTyK8yK01uVbEeAADgV2V+c1AAAFAxffPNNwoKCpKHh4ciIiKUnJysRo0aKS0tTbm5uYqMjLTEtmjRQo0aNZLJZFKXLl1kMpnUtm1bBQQEWGKio6M1duxYHT16VB07dpTJZLLahzlm3LhxtxxXcnKykpKSCi1PSUmRp6dn6ZL+/2Z2yrfLfuztdh8cKK7U1FS77KeiIr/KqyrnJpFfZVaS3K5du1YGIwEAABUFjXMAAKqh8PBwrVixQs2bN9cPP/ygpKQk3X///Tpy5IgyMjLk5uYmHx8fq20CAgKUkZEhScrIyLBqmpvXm9fdKiYrK0s///yzatasWeTYpkyZooSEBMvjrKwsBQcHKyoqSl5eXqXKOzc3V6mpqXrhgLOy851Kta+ycCSxdFPYmPPr1auXXF1d7TSqioP8Kq+qnJtEfpVZaXIzfyMKAABUTTTOAQCohvr06WP5e7t27RQeHq6QkBC99957N21olxd3d3fLDcELcnV1tVvDJjvfSdl5Fa9xbq/87Fmrioj8Kq+qnJtEfpVZSXKrqrUAAAC/cHb0AAAAgOP5+Pjozjvv1IkTJxQYGKicnBxdvHjRKiYzM9MyJ3pgYKAyMzMLrTevu1WMl5eXw5vzAAAAAADcCp84rwYaT95g8zanX4kpg5EAACqqK1eu6OTJk3r88ccVFhYmV1dXbd26VQMHDpQkHT9+XGfOnFFERIQkKSIiQi+99JLOnTsnf39/Sb/MD+vl5aVWrVpZYn47Z3dqaqplHwAAAAAAVFR84hwAgGroz3/+s3bu3KnTp09rz549GjBggFxcXDRkyBB5e3srNjZWCQkJ2r59u9LS0jRy5EhFRESoS5cukqSoqCi1atVKjz/+uL788ktt3rxZU6dOVVxcnGWalTFjxujbb7/VxIkTdezYMb355pt67733NH78eEemDgAAAADAbfGJcwAAqqH//ve/GjJkiH766SfVr19f9913n/bu3av69etLkubOnStnZ2cNHDhQ2dnZio6O1ptvvmnZ3sXFRevXr9fYsWMVERGhWrVqafjw4ZoxY4YlJjQ0VBs2bND48eM1f/58NWzYUG+99Zaio0t3A0wAAAAAAMoajXMAAKqh1atX33K9h4eHFi1apEWLFt00JiQkpNBULL/VvXt3HTx4sERjBAAAAADAUZiqBQAAAAAAAACAAvjEOQAAAAAAqHDaJG5Wdp6To4cBAKimaJwDAABUEI0nb7B5m9OvxJTBSAAAAACgemOqFgAAAAAAAAAACqBxDgAAAAAAAABAATTOAQAAAAAAAAAogMY5AAAAAAAAAAAF0DgHAAAAAAAAAKCAGo4eACqmxpM32LzN6VdiymAkAAAAAAAAAFC+aJwDAAAAAABUQG0SNys7z6nY8XygDQDsh6laAAAAAAAAAAAogMY5AAAAAAAAAAAFMFULAABAJVbwviTuLoZmdb7917r5GjcAAAAA3BqfOAcAAAAAAAAAoAA+cQ67KfiJt6IU9Sk4PvEGAAAAAAAAoKLhE+cAAAAAAAAAABTAJ84BAAAAAACqgNt9E7wofBMcAIpG4xwOxUkdAIDyZ+v5l3MvAAAAgOqm0k/VsmjRIjVu3FgeHh4KDw/X/v37HT0kAABQBM7ZAABUfJyvAQD4RaX+xPmaNWuUkJCgJUuWKDw8XPPmzVN0dLSOHz8uf39/Rw8PZaQkn1K3FZ+sAwD74pwNAEDFx/m6euKb4ABQtErdOJ8zZ45GjRqlkSNHSpKWLFmiDRs2aNmyZZo8ebKDR4fKjBcOAGBfnLMrN86LAFA9cL5GcfHaAEB1UGkb5zk5OUpLS9OUKVMsy5ydnRUZGSmTyVTkNtnZ2crOzrY8vnTpkiTp/Pnzys3NtXkMubm5unbtmn766Se5urqqxo2rNu+jOqmRb+jatXzVyHVWXr6To4djd83+/J7d9uXubGhqx3x1eP5fyq6CtbK329Vr35SeDhhVxfTb5y3cmqPqdfnyZUmSYRjldsyyZOs5297n64LM/6ZV9VxUkc619jwvmhX1fF+VnuOr8nN0Vc5NIr/KrDS5VffztVR25+yqfr4ujop0TrcXW18blNd1cUV+LVGVn3+LixpQA3vkX9JzdqVtnP/vf/9TXl6eAgICrJYHBATo2LFjRW6TnJyspKSkQstDQ0PLZIwo7DFHD6ASoVa2uVW96s0ut2EAdnX58mV5e3s7ehilZus5m/N16VT188dv8+M5HoCjVdfztcQ5u6xV9XN6cZRHDXgtAVQftp6zK23jvCSmTJmihIQEy+P8/HydP39edevWlZOT7e9eZmVlKTg4WP/5z3/k5eVlz6FWSdSr+KiVbahX8VEr2ziqXoZh6PLlywoKCiq3Y1Yk9j5fF1TV/w+QX+VWlfOryrlJ5FeZlSa36n6+lsrunF2Vf+eKixpQA4kaSNRAogb2yL+k5+xK2zivV6+eXFxclJmZabU8MzNTgYGBRW7j7u4ud3d3q2U+Pj6lHouXl1e1/MUtKepVfNTKNtSr+KiVbRxRr6rwyTUzW8/ZZXW+Lqiq/x8gv8qtKudXlXOTyK8yK2lu1fl8LZX9Obsq/84VFzWgBhI1kKiBRA1Km39JztnOJT6ag7m5uSksLExbt261LMvPz9fWrVsVERHhwJEBAICCOGcDAFDxcb4GAMBapf3EuSQlJCRo+PDh6tSpkzp37qx58+bp6tWrljuAAwCAioFzNgAAFR/nawAAflWpG+ePPvqofvzxR02bNk0ZGRnq0KGDNm3aVOhmJmXF3d1d06dPL/TVNBSNehUftbIN9So+amUb6mU/jj5nm1X1f1Pyq9yqcn5VOTeJ/CqzqpxbSXC+rjioATWQqIFEDSRq4Mj8nQzDMMr9qAAAAAAAAAAAVFCVdo5zAAAAAAAAAADKAo1zAAAAAAAAAAAKoHEOAAAAAAAAAEABNM4BAAAAAAAAACigWjfOFy1apMaNG8vDw0Ph4eHav3//LePXrl2rFi1ayMPDQ23bttXGjRut1huGoWnTpqlBgwaqWbOmIiMj9c0331jFnD9/XkOHDpWXl5d8fHwUGxurK1eu2D23suCIejVu3FhOTk5WP6+88ordc7M3e9fqX//6l6KiolS3bl05OTkpPT290D6uX7+uuLg41a1bV7Vr19bAgQOVmZlpz7TKjCPq1b1790K/W2PGjLFnWmXGnvXKzc3VpEmT1LZtW9WqVUtBQUEaNmyYzp49a7WPyvrc5YhaVdbnrerC1t+JymLXrl3q16+fgoKC5OTkpHXr1jl6SHaTnJysu+++W3Xq1JG/v7/69++v48ePO3pYdrN48WK1a9dOXl5e8vLyUkREhD755BNHD6vMvPLKK3JyctK4ceMcPRS7SExMLPSc36JFC0cPy26+//57/fGPf1TdunVVs2ZNtW3bVgcOHHD0sOyiqPO1k5OT4uLiHD20KoFrbcfU4KWXXtI999wjT09P+fj42Dslm5V3DU6fPq3Y2FiFhoaqZs2aatq0qaZPn66cnJwyya84HPF78OCDD6pRo0by8PBQgwYN9Pjjjxe6ZilPjqiBWXZ2tjp06HDTvkB5oZ/muN+DDRs2KDw8XDVr1pSvr6/69+9v28CNamr16tWGm5ubsWzZMuPo0aPGqFGjDB8fHyMzM7PI+M8++8xwcXExZs2aZXz11VfG1KlTDVdXV+Pw4cOWmFdeecXw9vY21q1bZ3z55ZfGgw8+aISGhho///yzJaZ3795G+/btjb179xqffvqp0axZM2PIkCFlnm9pOapeISEhxowZM4wffvjB8nPlypUyz7c0yqJWf/vb34ykpCTjr3/9qyHJOHjwYKH9jBkzxggODja2bt1qHDhwwOjSpYtxzz33lFWaduOoenXr1s0YNWqU1e/WpUuXyipNu7F3vS5evGhERkYaa9asMY4dO2aYTCajc+fORlhYmNV+KuNzl6NqVRmft6oLW38nKpONGzcazz//vPGvf/3LkGR88MEHjh6S3URHRxvLly83jhw5YqSnpxt9+/Y1GjVqVGX+X3300UfGhg0bjH//+9/G8ePHjeeee85wdXU1jhw54uih2d3+/fuNxo0bG+3atTOeeeYZRw/HLqZPn260bt3a6jn/xx9/dPSw7OL8+fNGSEiIMWLECGPfvn3Gt99+a2zevNk4ceKEo4dmF+fOnbP6d0tNTTUkGdu3b3f00Co9rrUdV4Np06YZc+bMMRISEgxvb++yTvOWHFGDTz75xBgxYoSxefNm4+TJk8aHH35o+Pv7G88++2y55Pxbjvo9mDNnjmEymYzTp08bn332mREREWFERESUeb5FcVQNzP70pz8Zffr0uWlfoDzQT3NcDd5//33D19fXWLx4sXH8+HHj6NGjxpo1a2wae7VtnHfu3NmIi4uzPM7LyzOCgoKM5OTkIuMfeeQRIyYmxmpZeHi48dRTTxmGYRj5+flGYGCg8dprr1nWX7x40XB3dzf+8Y9/GIZhGF999ZUhyfj8888tMZ988onh5ORkfP/993bLrSw4ol6G8ct/9Llz59oxk7Jn71oVdOrUqSKf8C9evGi4uroaa9eutSz7+uuvDUmGyWQqRTZlzxH1MoxfGueV8aK9LOtltn//fkOS8d133xmGUXmfuxxRK8OonM9b1YWtvxOVVVVrnP/WuXPnDEnGzp07HT2UMuPr62u89dZbjh6GXV2+fNm44447jNTU1Ep7Di7K9OnTjfbt2zt6GGVi0qRJxn333efoYZSbZ555xmjatKmRn5/v6KFUelxrO+762Wz58uUOb5w7ugZms2bNMkJDQ0uTSolVlBp8+OGHhpOTk5GTk1OadErEkTXYuHGj0aJFC+Po0aMObZzTT3NMDXJzc43f/e53pX5NXS2nasnJyVFaWpoiIyMty5ydnRUZGSmTyVTkNiaTySpekqKjoy3xp06dUkZGhlWMt7e3wsPDLTEmk0k+Pj7q1KmTJSYyMlLOzs7at2+f3fKzN0fVy+yVV15R3bp11bFjR7322mu6ceOGvVKzu7KoVXGkpaUpNzfXaj8tWrRQo0aNbNpPeXNUvcxWrlypevXqqU2bNpoyZYquXbtm8z7KU3nV69KlS3JycrJ8vbMyPnc5qlZmlel5q7ooye8EKqZLly5Jkvz8/Bw8EvvLy8vT6tWrdfXqVUVERDh6OHYVFxenmJiYQs+zVcE333yjoKAgNWnSREOHDtWZM2ccPSS7+Oijj9SpUycNGjRI/v7+6tixo/761786elhlIicnR++++66eeOIJOTk5OXo4lRrX2o6/fq4IKlINLl265JDXDBWlBufPn9fKlSt1zz33yNXVtbRp2cSRNcjMzNSoUaP097//XZ6envZMyyaO/j2oCNeljqrBF198oe+//17Ozs7q2LGjGjRooD59+ujIkSM2jb9aNs7/97//KS8vTwEBAVbLAwIClJGRUeQ2GRkZt4w3/3m7GH9/f6v1NWrUkJ+f302PWxE4ql6S9Kc//UmrV6/W9u3b9dRTT+nll1/WxIkTS51TWSmLWhVHRkaG3NzcCjXvbN1PeXNUvSTpscce07vvvqvt27drypQp+vvf/64//vGPtiVQzsqjXtevX9ekSZM0ZMgQeXl5WfZR2Z67HFUrqfI9b1UXJfmdQMWTn5+vcePG6d5771WbNm0cPRy7OXz4sGrXri13d3eNGTNGH3zwgVq1auXoYdnN6tWr9cUXXyg5OdnRQ7G78PBwrVixQps2bdLixYt16tQp3X///bp8+bKjh1Zq3377rRYvXqw77rhDmzdv1tixY/WnP/1J77zzjqOHZnfr1q3TxYsXNWLECEcPpdLjWtux188VRUWpwYkTJ7RgwQI99dRTJcqjNBxdg0mTJqlWrVqqW7euzpw5ow8//LBU+ZSEo2pgGIZGjBihMWPGWL2Z5gj00xxXg2+//VbSL/ejmTp1qtavXy9fX191795d58+fL/b4axQ7EnCAhIQEy9/btWsnNzc3PfXUU0pOTpa7u7sDR4bKbvTo0Za/t23bVg0aNFDPnj118uRJNW3a1IEjc5zc3Fw98sgjMgxDixcvdvRwKrRb1YrnLaDsxMXF6ciRI9q9e7ejh2JXzZs3V3p6ui5duqT3339fw4cP186dO6tE8/w///mPnnnmGaWmpsrDw8PRw7G7Pn36WP7erl07hYeHKyQkRO+9955iY2MdOLLSy8/PV6dOnfTyyy9Lkjp27KgjR45oyZIlGj58uINHZ19vv/22+vTpo6CgIEcPBYCdfP/99+rdu7cGDRqkUaNGOXo45W7ChAmKjY3Vd999p6SkJA0bNkzr16+vFt+qWbBggS5fvqwpU6Y4eigOVd2vS/Pz8yVJzz//vAYOHChJWr58uRo2bKi1a9cW+w21avmJ83r16snFxUWZmZlWyzMzMxUYGFjkNoGBgbeMN/95u5hz585Zrb9x44bOnz9/0+NWBI6qV1HCw8N148YNnT592tY0ykVZ1Ko4AgMDlZOTo4sXL5ZqP+XNUfUqSnh4uKRfPpVQUZVlvcyN4O+++06pqalWn6CujM9djqpVUSr681Z1UZLfCVQs8fHxWr9+vbZv366GDRs6ejh25ebmpmbNmiksLEzJyclq37695s+f7+hh2UVaWprOnTunu+66SzVq1FCNGjW0c+dOvfHGG6pRo4by8vIcPUS78vHx0Z133lmhX08UV4MGDQq9edOyZcsqMxWN2XfffactW7boySefdPRQqgSutSvW9bOjOLoGZ8+eVY8ePXTPPfdo6dKlpcqlpBxdg3r16unOO+9Ur169tHr1am3cuFF79+4tVU62clQNtm3bJpPJJHd3d9WoUUPNmjWTJHXq1Knc3/h19O9BQY66LnVUDRo0aCBJVq9l3N3d1aRJE5tey1TLxrmbm5vCwsK0detWy7L8/Hxt3br1pvNJRkREWMVLUmpqqiU+NDRUgYGBVjFZWVnat2+fJSYiIkIXL15UWlqaJWbbtm3Kz8+3NO0qIkfVqyjp6elydnYu9DW8iqIsalUcYWFhcnV1tdrP8ePHdebMmQo9R6qj6lWU9PR0Sb8+uVZEZVUvcyP4m2++0ZYtW1S3bt1C+6hsz12OqlVRKvrzVnVRkt8JVAyGYSg+Pl4ffPCBtm3bptDQUEcPqczl5+crOzvb0cOwi549e+rw4cNKT0+3/HTq1ElDhw5Venq6XFxcHD1Eu7py5YpOnjxZoV9PFNe9996r48ePWy3797//rZCQEAeNqGwsX75c/v7+iomJcfRQqgSutSvW9bOjOLIG33//vbp3766wsDAtX75czs6OaXtVpN8D8ydvy/u1haNq8MYbb+jLL7+0vO7YuHGjJGnNmjV66aWX7Jrj7VSk3wNHXZc6qgZhYWFyd3e3ei2Tm5ur06dP2/ZaplS3Fq3EVq9ebbi7uxsrVqwwvvrqK2P06NGGj4+PkZGRYRiGYTz++OPG5MmTLfGfffaZUaNGDeP11183vv76a2P69OmGq6urcfjwYUvMK6+8Yvj4+BgffvihcejQIeOhhx4yQkNDjZ9//tkS07t3b6Njx47Gvn37jN27dxt33HGHMWTIkPJLvIQcUa89e/YYc+fONdLT042TJ08a7777rlG/fn1j2LBh5Zu8jcqiVj/99JNx8OBBY8OGDYYkY/Xq1cbBgweNH374wRIzZswYo1GjRsa2bduMAwcOGBEREUZERET5JV5CjqjXiRMnjBkzZhgHDhwwTp06ZXz44YdGkyZNjK5du5Zv8iVg73rl5OQYDz74oNGwYUMjPT3d+OGHHyw/2dnZlv1UxucuR9Sqsj5vVRe3+52ozC5fvmwcPHjQOHjwoCHJmDNnjnHw4EHju+++c/TQSm3s2LGGt7e3sWPHDqv/d9euXXP00Oxi8uTJxs6dO41Tp04Zhw4dMiZPnmw4OTkZKSkpjh5amenWrZvxzDPPOHoYdvHss88aO3bsME6dOmV89tlnRmRkpFGvXj3j3Llzjh5aqe3fv9+oUaOG8dJLLxnffPONsXLlSsPT09N49913HT00u8nLyzMaNWpkTJo0ydFDqVK41nZcDb777jvj4MGDRlJSklG7dm3La4PLly+XX/L/nyNq8N///tdo1qyZ0bNnT+O///2v1esGR3BEDfbu3WssWLDAOHjwoHH69Glj69atxj333GM0bdrUuH79evkWwHDc/4WCTp06ZUgyDh48WKa53gz9NMf9HjzzzDPG7373O2Pz5s3GsWPHjNjYWMPf3984f/58scdebRvnhmEYCxYsMBo1amS4ubkZnTt3Nvbu3WtZ161bN2P48OFW8e+9955x5513Gm5ubkbr1q2NDRs2WK3Pz883XnjhBSMgIMBwd3c3evbsaRw/ftwq5qeffjKGDBli1K5d2/Dy8jJGjhzpkJNYSZR3vdLS0ozw8HDD29vb8PDwMFq2bGm8/PLLDnmyt5W9a7V8+XJDUqGf6dOnW2J+/vln4//+7/8MX19fw9PT0xgwYIDDXiDYqrzrdebMGaNr166Gn5+f4e7ubjRr1syYMGGCcenSpbJO1S7sWS/zi4iifrZv326Jq6zPXeVdq8r8vFVd3Op3ojLbvn17kb+bv/0dr4xu9v9u+fLljh6aXTzxxBNGSEiI4ebmZtSvX9/o2bNnlW6aG0bVapw/+uijRoMGDQw3Nzfjd7/7nfHoo48aJ06ccPSw7Objjz822rRpY7i7uxstWrQwli5d6ugh2dXmzZsNSYWu2VB6XGs7pgbDhw+/7ev68lTeNbjZdaAjPzNa3jU4dOiQ0aNHD8u1buPGjY0xY8YY//3vf8s0z1txxP+FghzdODcM+mmG4Zjfg5ycHOPZZ581/P39jTp16hiRkZHGkSNHbBq3k2EYRvE/nw4AAAAAAAAAQNVWLec4BwAAAAAAAADgZmicAwAAAAAAAABQAI1zAAAAAAAAAAAKoHEOAAAAAAAAAEABNM4BAAAAAAAAACiAxjkAAAAAAAAAAAXQOAcAAAAAAAAAoAAa5wAAAAAAAAAAFEDjHAAAAABQKezatUv9+vVTUFCQnJyctG7dujI9XmJiopycnKx+WrRoUabHBAAAFQONcwAAAABApXD16lW1b99eixYtKrdjtm7dWj/88IPlZ/fu3eV2bAAA4Dg1HD0AAAAAAACKo0+fPurTp89N12dnZ+v555/XP/7xD128eFFt2rTRq6++qu7du5f4mDVq1FBgYGCJtwcAAJUTnzgHAAAAAFQJ8fHxMplMWr16tQ4dOqRBgwapd+/e+uabb0q8z2+++UZBQUFq0qSJhg4dqjNnzthxxAAAoKJyMgzDcPQgAAAAAACwhZOTkz744AP1799fknTmzBk1adJEZ86cUVBQkCUuMjJSnTt31ssvv2zzMT755BNduXJFzZs31w8//KCkpCR9//33OnLkiOrUqWOvVAAAQAXEVC0AAAAAgErv8OHDysvL05133mm1PDs7W3Xr1pUkHTt2TC1btrzlfiZNmqRXXnlFkqymhWnXrp3Cw8MVEhKi9957T7GxsXbOAAAAVCQ0zgEAAAAAld6VK1fk4uKitLQ0ubi4WK2rXbu2JKlJkyb6+uuvb7kfc5O9KD4+Prrzzjt14sSJ0g8YAABUaDTOAQAAAACVXseOHZWXl6dz587p/vvvLzLGzc1NLVq0KPExrly5opMnT+rxxx8v8T4AAEDlQOMcAAAAAFApXLlyxerT3qdOnVJ6err8/Px05513aujQoRo2bJhmz56tjh076scff9TWrVvVrl07xcTE2Hy8P//5z+rXr59CQkJ09uxZTZ8+XS4uLhoyZIg90wIAABUQNwcFAAAAAFQKO3bsUI8ePQotHz58uFasWKHc3Fy9+OKL+tvf/qbvv/9e9erVU5cuXZSUlKS2bdvafLzBgwdr165d+umnn1S/fn3dd999eumll9S0aVN7pAMAACowGucAAAAAAAAAABTg7OgBAAAAAAAAAABQkdA4BwAAAAAAAACgABrnAAAAAAAAAAAUQOMcAAAAAAAAAIACaJwDAAAAAAAAAFAAjXMAAAAAAAAAAAqgcQ4AAAAAAAAAQAE0zgEAAAAAAAAAKIDGOQAAAAAAAAAABdA4BwAAAAAAAACgABrnAAAAAAAAAAAUQOMcAAAAAAAAAIACaJwDAAAAAAAAAFAAjXMAAAAAAAAAAAqgcQ4AAAAAAAAAQAE0zgEAAAAAAAAAKIDGOQAAAAAAAAAABdA4B1AmnJyclJiY6OhhAABQblasWCEnJyedPn3a0UMBAAAokREjRqhx48aOHsZtmV93HThwwNFDQRVG4xwAAACAw7355ptasWKFo4cBAAAqEF4fwJFqOHoAAKqmn3/+WTVq8BQDAACK580331S9evU0YsQIRw8FAABUELw+gCPxiXOgkrp27Zqjh3BLHh4eNM4BAAAAAGWmol8XA6jcaJwDZSAxMVFOTk46duyYHnnkEXl5ealu3bp65plndP36davYd999V2FhYapZs6b8/Pw0ePBg/ec//7GK6d69u9q0aaO0tDR17dpVnp6eeu655yRJBw4cUHR0tOrVq6eaNWsqNDRUTzzxhNX2V69e1bPPPqvg4GC5u7urefPmev3112UYhlWck5OT4uPjtW7dOrVp00bu7u5q3bq1Nm3aZHMNfjvHubkmJ06c0IgRI+Tj4yNvb2+NHDmyyBc77777rjp37ixPT0/5+vqqa9euSklJsYp588031bp1a7m7uysoKEhxcXG6ePFikbU7dOiQunXrJk9PTzVr1kzvv/++JGnnzp0KDw9XzZo11bx5c23ZsqXQWL7//ns98cQTCggIsNRk2bJlNtcEAFD9FOdc9emnn2rQoEFq1KiR3N3dFRwcrPHjx+vnn3+2ihsxYoRq166t77//Xv3791ft2rVVv359/fnPf1ZeXp5N47L1mGfOnNHvf/971a5dW7/73e+0aNEiSdLhw4f1wAMPqFatWgoJCdGqVaustjfPP/rZZ58pISFB9evXV61atTRgwAD9+OOPlrjGjRvr6NGj2rlzp5ycnOTk5KTu3bvblBMAoGLhuljKz8/XvHnz1Lp1a3l4eCggIEBPPfWULly4YBXXuHFj/f73v9eOHTvUqVMn1axZU23bttWOHTskSf/617/Utm1beXh4KCwsTAcPHrTa3ny+/vbbbxUdHa1atWopKChIM2bMKJRfSdiax+7du9W5c2d5eHioSZMm+tvf/lZon+Zr9Jo1a6phw4Z68cUXtXz5cqv7xRTn9UF2dvYtX2MApUHjHChDjzzyiK5fv67k5GT17dtXb7zxhkaPHm1Z/9JLL2nYsGG64447NGfOHI0bN05bt25V165dC11U//TTT+rTp486dOigefPmqUePHjp37pyioqJ0+vRpTZ48WQsWLNDQoUO1d+9ey3aGYejBBx/U3Llz1bt3b82ZM0fNmzfXhAkTlJCQUGjMu3fv1v/93/9p8ODBmjVrlq5fv66BAwfqp59+sltNLl++rOTkZD3yyCNasWKFkpKSrGKSkpL0+OOPy9XVVTNmzFBSUpKCg4O1bds2S0xiYqLi4uIUFBSk2bNna+DAgfrLX/6iqKgo5ebmWu3vwoUL+v3vf6/w8HDNmjVL7u7uGjx4sNasWaPBgwerb9++euWVV3T16lX94Q9/0OXLly3bZmZmqkuXLtqyZYvi4+M1f/58NWvWTLGxsZo3b55dagIAqJqKe65au3atrl27prFjx2rBggWKjo7WggULNGzYsEL7zMvLU3R0tOrWravXX39d3bp10+zZs7V06VKbxmbrMfv06aPg4GDNmjVLjRs3Vnx8vFasWKHevXurU6dOevXVV1WnTh0NGzZMp06dKrSPp59+Wl9++aWmT5+usWPH6uOPP1Z8fLxl/bx589SwYUO1aNFCf//73/X3v/9dzz//vE05AQAqpup8XfzUU09pwoQJuvfeezV//nyNHDlSK1euVHR0dKHr1hMnTuixxx5Tv379lJycrAsXLqhfv35auXKlxo8frz/+8Y9KSkrSyZMn9cgjjyg/P99q+7y8PPXu3VsBAQGaNWuWwsLCNH36dE2fPt2mMdsjjz/84Q/q1auXZs+eLV9fX40YMUJHjx61xHz//ffq0aOHjh49qilTpmj8+PFauXKl5s+fb7Wv4rw+uN1rDKBUDAB2N336dEOS8eCDD1ot/7//+z9DkvHll18ap0+fNlxcXIyXXnrJKubw4cNGjRo1rJZ369bNkGQsWbLEKvaDDz4wJBmff/75Tceybt06Q5Lx4osvWi3/wx/+YDg5ORknTpywLJNkuLm5WS378ssvDUnGggULil+A/7+v6dOnWx6ba/LEE09YxQ0YMMCoW7eu5fE333xjODs7GwMGDDDy8vKsYvPz8w3DMIxz584Zbm5uRlRUlFXMwoULDUnGsmXLLMvMtVu1apVl2bFjxwxJhrOzs7F3717L8s2bNxuSjOXLl1uWxcbGGg0aNDD+97//WY1l8ODBhre3t3Ht2jUbqgIAqMqWL19uSDJOnTpl07mqqHNJcnKy4eTkZHz33XeWZcOHDzckGTNmzLCK7dixoxEWFmbTWG095ssvv2xZduHCBaNmzZqGk5OTsXr1asty8/m14PnfXJPIyEjLedwwDGP8+PGGi4uLcfHiRcuy1q1bG926dbMpDwBAxVXdr4s//fRTQ5KxcuVKq+WbNm0qtDwkJMSQZOzZs8eyzHx9WrNmTatz81/+8hdDkrF9+3bLMvP5+umnn7Ysy8/PN2JiYgw3Nzfjxx9/LPa4hw8fboSEhJQqj127dlmWnTt3znB3dzeeffZZy7Knn37acHJyMg4ePGhZ9tNPPxl+fn6W11JmN3t9YMtrDKCk+MQ5UIbi4uKsHj/99NOSpI0bN+pf//qX8vPz9cgjj+h///uf5ScwMFB33HGHtm/fbrWtu7u7Ro4cabXMx8dHkrR+/fpC7/Kabdy4US4uLvrTn/5ktfzZZ5+VYRj65JNPrJZHRkaqadOmlsft2rWTl5eXvv322+Infgtjxoyxenz//ffrp59+UlZWliRp3bp1ys/P17Rp0+TsbP0U5eTkJEnasmWLcnJyNG7cOKuYUaNGycvLSxs2bLDarnbt2ho8eLDlcfPmzeXj46OWLVsqPDzcstz8d3OuhmHon//8p/r16yfDMKz+naKjo3Xp0iV98cUXpS0JAKAKsuVcVbNmTcvfr169qv/973+65557ZBhGoa9iS0WfS209T9t6zCeffNLydx8fHzVv3ly1atXSI488YlluPr8WNZbRo0dbzuPmMefl5em7776zadwAgMqnul4Xr127Vt7e3urVq5dVbmFhYapdu3ah3Fq1aqWIiAjLY/P16QMPPKBGjRoVWl7UWAp+0to85UxOTk6RU5KWZR7333+/5XH9+vXVvHlzq/Fu2rRJERER6tChg2WZn5+fhg4davP4eI2BssSd+4AydMcdd1g9btq0qZydnXX69Gk5OzvLMIxCMWaurq5Wj3/3u9/Jzc3Nalm3bt00cOBAJSUlae7cuerevbv69++vxx57TO7u7pKk7777TkFBQapTp47Vti1btrSsL6jgCdnM19e30NxlJfXb/fv6+kr6ZToVLy8vnTx5Us7OzmrVqtVN92Eec/Pmza2Wu7m5qUmTJoVyatiwodWJVJK8vb0VHBxcaJl5LJL0448/6uLFi1q6dOlNvwJ/7ty5m44TAFB92XKuOnPmjKZNm6aPPvqo0Pn20qVLVo89PDxUv359q2UlOU+X9pje3t43Pb8WNZZbnf8BAFVbdb0u/uabb3Tp0iX5+/sXuf6315K/Pab5+vR2161mzs7OatKkidWyO++8U5Isc4aXRGnzkArX7rvvvrN6k8CsWbNmNo+P1xgoSzTOgXJU8OIyPz9fTk5O+uSTT+Ti4lIotnbt2laPC34yrOD+3n//fe3du1cff/yxNm/erCeeeEKzZ8/W3r17C+2jOIoaiyS73FCkPPZvyzFvNxbznHF//OMfNXz48CJj27VrZ4cRAgCqq7y8PPXq1Uvnz5/XpEmT1KJFC9WqVUvff/+9RowYUWj+0puduxxxTFvO6Y44/wMAKqbqcl2cn58vf39/rVy5ssj1v31T2h7n27JgrzzKaryOrg+qNhrnQBn65ptvFBoaanl84sQJ5efnq3HjxnJxcZFhGAoNDbW8C1xSXbp0UZcuXfTSSy9p1apVGjp0qFavXq0nn3xSISEh2rJliy5fvmz17vqxY8ckSSEhIaU6tr01bdpU+fn5+uqrr6y+tlWQeczHjx+3ekc9JydHp06dUmRkpF3GUr9+fdWpU0d5eXl22ycAoHoo7rnq8OHD+ve//6133nnH6sacqampZTY2RxyzOH776XUAQNVQXa+LmzZtqi1btujee+8tsuFvb/n5+fr222+t6vjvf/9bktS4ceMS77cs8ggJCdGJEycKLS9qGa8P4EjMcQ6UoUWLFlk9XrBggSSpT58+evjhh+Xi4qKkpKRC74QahlGsu3VfuHCh0LbmZnN2drYkqW/fvsrLy9PChQut4ubOnSsnJyf16dPHppzKWv/+/eXs7KwZM2YU+sSbOdfIyEi5ubnpjTfesMr/7bff1qVLlxQTE2OXsbi4uGjgwIH65z//qSNHjhRa/+OPP9rlOACAqqe45yrzp6QKxhiGofnz55fZ2BxxzOKoVauWLl686NAxAADsr7peFz/yyCPKy8vTzJkzC627ceNGmZzzCuZnGIYWLlwoV1dX9ezZs8T7LIs8oqOjZTKZlJ6ebll2/vz5Ij/VzusDOBKfOAfK0KlTp/Tggw+qd+/eMplMevfdd/XYY4+pffv2kqQXX3xRU6ZM0enTp9W/f3/VqVNHp06d0gcffKDRo0frz3/+8y33/8477+jNN9/UgAED1LRpU12+fFl//etf5eXlpb59+0qS+vXrpx49euj555/X6dOn1b59e6WkpOjDDz/UuHHjrG54UhE0a9ZMzz//vGbOnKn7779fDz/8sNzd3fX5558rKChIycnJql+/vqZMmaKkpCT17t1bDz74oI4fP64333xTd999t/74xz/abTyvvPKKtm/frvDwcI0aNUqtWrXS+fPn9cUXX2jLli06f/683Y4FAKg6inuuatGihZo2bao///nP+v777+Xl5aV//vOfZTovpyOOWRxhYWFavHixXnzxRTVr1kz+/v564IEHHDomAEDpVdfr4m7duumpp55ScnKy0tPTFRUVJVdXV33zzTdau3at5s+frz/84Q92O56Hh4c2bdqk4cOHKzw8XJ988ok2bNig5557rtB0Ko7OY+LEiXr33XfVq1cvPf3006pVq5beeustNWrUSOfPn7f6lDmvD+BINM6BMrRmzRpNmzZNkydPVo0aNRQfH6/XXnvNsn7y5Mm68847NXfuXCUlJUn65cYfUVFRevDBB2+7/27dumn//v1avXq1MjMz5e3trc6dO2vlypWWr8I5Ozvro48+0rRp07RmzRotX75cjRs31muvvaZnn322bBIvpRkzZig0NFQLFizQ888/L09PT7Vr106PP/64JSYxMVH169fXwoULNX78ePn5+Wn06NF6+eWXC91ApjQCAgK0f/9+zZgxQ//617/05ptvqm7dumrdurVeffVVux0HAFD1FOdc5erqqo8//lh/+tOflJycLA8PDw0YMEDx8fGWhoK9OeKYxTFt2jR99913mjVrli5fvqxu3bpxYQwAVUB1vi5esmSJwsLC9Je//EXPPfecatSoocaNG+uPf/yj7r33Xrsey8XFRZs2bdLYsWM1YcIE1alTR9OnT9e0adNKvW975xEcHKzt27frT3/6k15++WXVr19fcXFxqlWrlv70pz/Jw8PDEsvrAziSk8Fs+YDdJSYmKikpST/++KPq1avn6OEAAAAAAFCuuC4uPyNGjND777+vK1euOHoopTJu3Dj95S9/0ZUrV+xyQ3SgtJjjHAAAAAAAAEC5+fnnn60e//TTT/r73/+u++67j6Y5KgymagFQbHl5ebe9IWbt2rVVu3btchoRAAAo6Pz588rJybnpehcXl1LNcwoAQHVXWa+LK9prhIiICHXv3l0tW7ZUZmam3n77bWVlZemFF14otzEAt0PjHECx/ec//7HMEXcz06dPV2JiYvkMCAAAWHn44Ye1c+fOm64PCQnR6dOny29AAABUMZX1uriivUbo27ev3n//fS1dulROTk6666679Pbbb6tr167lNgbgdpjjHECxXb9+Xbt3775lTJMmTdSkSZNyGhEAACgoLS1NFy5cuOn6mjVr2v1mZAAAVCeV9bqY1wiA7WicAwAAAAAAAABQQLWeqiU/P19nz55VnTp15OTk5OjhAAAgSTIMQ5cvX1ZQUJCcnbmPN+drAEBFxPm6MM7ZAICKqKTn7GrdOD979qyCg4MdPQwAAIr0n//8Rw0bNnT0MByO8zUAoCLjfP0rztkAgIrM1nN2tW6c16lTR9IvRfPy8irxfnJzc5WSkqKoqCi5urraa3gOQS4VT1XJQyKXiopcKp6srCwFBwdbzlPVXUnP11Xl9+FmyK/yqsq5SeRX2ZFf8XG+Lsxe19hS1f9dvJXqmnt1zVsi9+qYe3XNW3JM7iU9Z1frxrn5q2NeXl6lbpx7enrKy8ur0v+yk0vFU1XykMiloiKXiouvOP+ipOfrqvb78FvkV3lV5dwk8qvsyM92nK9/Za9rbKnq/y7eSnXNvbrmLZF7dcy9uuYtOTZ3W8/ZTMQGAAAAAAAAAEABNM4BAAAAAAAAACiAxjkAAAAAAAAAAAXQOAcAAAAAAAAAoAAa5wAAAAAAAAAAFFDD0QOoStokblZ2nm13Zz39SkwZjQYAAFQ2jSdvKHasu4uhWZ3LcDAAAFQAtl5nc40NALAXPnEOAAAAAAAAAEABNM4BAAAAAAAAACiAxjkAAAAAAAAAAAXQOAcAAAAAAAAAoAAa5wAAAAAAAAAAFEDjHAAAAAAAAACAAmicAwAAAADgAIsXL1a7du3k5eUlLy8vRURE6JNPPrGsv379uuLi4lS3bl3Vrl1bAwcOVGZmptU+zpw5o5iYGHl6esrf318TJkzQjRs3rGJ27Nihu+66S+7u7mrWrJlWrFhRaCyLFi1S48aN5eHhofDwcO3fv79McgYAoLKgcQ4AAAAAgAM0bNhQr7zyitLS0nTgwAE98MADeuihh3T06FFJ0vjx4/Xxxx9r7dq12rlzp86ePauHH37Ysn1eXp5iYmKUk5OjPXv26J133tGKFSs0bdo0S8ypU6cUExOjHj16KD09XePGjdOTTz6pzZs3W2LWrFmjhIQETZ8+XV988YXat2+v6OhonTt3rvyKAQBABVPD0QMAAAAAAKA66tevn9Xjl156SYsXL9bevXvVsGFDvf3221q1apUeeOABSdLy5cvVsmVL7d27V126dFFKSoq++uorbdmyRQEBAerQoYNmzpypSZMmKTExUW5ublqyZIlCQ0M1e/ZsSVLLli21e/duzZ07V9HR0ZKkOXPmaNSoURo5cqQkacmSJdqwYYOWLVumyZMn33T82dnZys7OtjzOysqSJOXm5io3N7dUtTFv7+5slGi7ysycQ1XIxRbVNW+J3Av+WV1U17wlx+Re0mPROAcAAAAAwMHy8vK0du1aXb16VREREUpLS1Nubq4iIyMtMS1atFCjRo1kMpnUpUsXmUwmtW3bVgEBAZaY6OhojR07VkePHlXHjh1lMpms9mGOGTdunCQpJydHaWlpmjJlimW9s7OzIiMjZTKZbjnm5ORkJSUlFVqekpIiT0/PkpShkJmd8m2K37hxo12OWxGkpqY6eggOUV3zlsi9OqqueUvlm/u1a9dKtB2NcwAAAAAAHOTw4cOKiIjQ9evXVbt2bX3wwQdq1aqV0tPT5ebmJh8fH6v4gIAAZWRkSJIyMjKsmubm9eZ1t4rJysrSzz//rAsXLigvL6/ImGPHjt1y7FOmTFFCQoLlcVZWloKDgxUVFSUvL6/iF6EIubm5Sk1N1QsHnJWd71Ts7Y4kRpfquBWBOfdevXrJ1dXV0cMpN9U1b4ncq2Pu1TVvyTG5m78RZSsa5wAAAAAAOEjz5s2Vnp6uS5cu6f3339fw4cO1c+dORw+rWNzd3eXu7l5ouaurq92aIdn5TsrOK37jvCo1oOxZx8qkuuYtkXt1zL265i2Vb+4lPQ6NcwAAAAAAHMTNzU3NmjWTJIWFhenzzz/X/Pnz9eijjyonJ0cXL160+tR5ZmamAgMDJUmBgYHav3+/1f4yMzMt68x/mpcVjPHy8lLNmjXl4uIiFxeXImPM+wAAoDpydvQAAAAAAADAL/Lz85Wdna2wsDC5urpq69atlnXHjx/XmTNnFBERIUmKiIjQ4cOHde7cOUtMamqqvLy81KpVK0tMwX2YY8z7cHNzU1hYmFVMfn6+tm7daokBAKA64hPnAAAAAAA4wJQpU9SnTx81atRIly9f1qpVq7Rjxw5t3rxZ3t7eio2NVUJCgvz8/OTl5aWnn35aERER6tKliyQpKipKrVq10uOPP65Zs2YpIyNDU6dOVVxcnGUKlTFjxmjhwoWaOHGinnjiCW3btk3vvfeeNmzYYBlHQkKChg8frk6dOqlz586aN2+erl69qpEjRzqkLgAAVAQ0zgEAAAAAcIBz585p2LBh+uGHH+Tt7a127dpp8+bN6tWrlyRp7ty5cnZ21sCBA5Wdna3o6Gi9+eablu1dXFy0fv16jR07VhEREapVq5aGDx+uGTNmWGJCQ0O1YcMGjR8/XvPnz1fDhg311ltvKTr615toPvroo/rxxx81bdo0ZWRkqEOHDtq0aVOhG4YCAFCd0DgHAAAAAMAB3n777Vuu9/Dw0KJFi7Ro0aKbxoSEhGjjxo233E/37t118ODBW8bEx8crPj7+ljEAAFQnzHEOAEA1lJeXpxdeeEGhoaGqWbOmmjZtqpkzZ8owDEuMYRiaNm2aGjRooJo1ayoyMlLffPON1X7Onz+voUOHysvLSz4+PoqNjdWVK1esYg4dOqT7779fHh4eCg4O1qxZs8olRwAAAAAASorGOQAA1dCrr76qxYsXa+HChfr666/16quvatasWVqwYIElZtasWXrjjTe0ZMkS7du3T7Vq1VJ0dLSuX79uiRk6dKiOHj2q1NRUrV+/Xrt27dLo0aMt67OyshQVFaWQkBClpaXptddeU2JiopYuXVqu+QIAAAAAYAumagEAoBras2ePHnroIcXExEiSGjdurH/84x/av3+/pF8+bT5v3jxNnTpVDz30kCTpb3/7mwICArRu3ToNHjxYX3/9tTZt2qTPP/9cnTp1kiQtWLBAffv21euvv66goCCtXLlSOTk5WrZsmdzc3NS6dWulp6drzpw5Vg32grKzs5WdnW15nJWVJUnKzc1Vbm5usXM0x9qyjaO5uxi3DzLHOv8SW5nys0Vl/Pcrrqqcm0R+lR352b4vAABQNdE4BwCgGrrnnnu0dOlS/fvf/9add96pL7/8Urt379acOXMkSadOnVJGRoYiIyMt23h7eys8PFwmk0mDBw+WyWSSj4+PpWkuSZGRkXJ2dta+ffs0YMAAmUwmde3aVW5ubpaY6Ohovfrqq7pw4YJ8fX0LjS05OVlJSUmFlqekpMjT09PmXFNTU23exlFmdbZ9m8qUX0lU5fyqcm4S+VV25Hd7165ds8NIAABARUXjHACAamjy5MnKyspSixYt5OLiory8PL300ksaOnSoJCkjI0OSFBAQYLVdQECAZV1GRob8/f2t1teoUUN+fn5WMaGhoYX2YV5XVON8ypQpSkhIsDzOyspScHCwoqKi5OXlVewcc3NzlZqaql69esnV1bXY2zlSm8TNxY51dzY0s1N+pcrPFpXx36+4qnJuEvlVduRXfOZvRAEAgKqJxjkAANXQe++9p5UrV2rVqlWW6VPGjRunoKAgDR8+3KFjc3d3l7u7e6Hlrq6uJWpylHQ7R8jOc7J5m8qUX0lU5fyqcm4S+VV25Fe8fQAAgKqLxjkAANXQhAkTNHnyZA0ePFiS1LZtW3333XdKTk7W8OHDFRgYKEnKzMxUgwYNLNtlZmaqQ4cOkqTAwECdO3fOar83btzQ+fPnLdsHBgYqMzPT6o4cdAAAt5NJREFUKsb82BwDAAAAAEBF4+zoAQAAgPJ37do1OTtbvwxwcXFRfn6+JCk0NFSBgYHaunWrZX1WVpb27duniIgISVJERIQuXryotLQ0S8y2bduUn5+v8PBwS8yuXbusbqCWmpqq5s2bFzlNCwAAAAAAFQGNcwAAqqF+/frppZde0oYNG3T69Gl98MEHmjNnjgYMGCBJcnJy0rhx4/Tiiy/qo48+0uHDhzVs2DAFBQWpf//+kqSWLVuqd+/eGjVqlPbv36/PPvtM8fHxGjx4sIKCgiRJjz32mNzc3BQbG6ujR49qzZo1mj9/vtUc5gAAAAAAVDRM1QIAQDW0YMECvfDCC/q///s/nTt3TkFBQXrqqac0bdo0S8zEiRN19epVjR49WhcvXtR9992nTZs2ycPDwxKzcuVKxcfHq2fPnnJ2dtbAgQP1xhtvWNZ7e3srJSVFcXFxCgsLU7169TRt2jSNHj26XPNF5dB48gbL391dDM3q/MsNU2819/vpV2LKY2gAAAAAqhka5wAAVEN16tTRvHnzNG/evJvGODk5acaMGZoxY8ZNY/z8/LRq1apbHqtdu3b69NNPSzpUAAAAAADKHVO1AAAAAAAAAABQAI1zAAAAAAAAAAAKsKlxvnjxYrVr105eXl7y8vJSRESEPvnkE8v669evKy4uTnXr1lXt2rU1cOBAZWZmWu3jzJkziomJkaenp/z9/TVhwgTduHHDKmbHjh2666675O7urmbNmmnFihWFxrJo0SI1btxYHh4eCg8P1/79+21JBQAAAAAAAACAItnUOG/YsKFeeeUVpaWl6cCBA3rggQf00EMP6ejRo5Kk8ePH6+OPP9batWu1c+dOnT17Vg8//LBl+7y8PMXExCgnJ0d79uzRO++8oxUrVljdiOzUqVOKiYlRjx49lJ6ernHjxunJJ5/U5s2bLTFr1qxRQkKCpk+fri+++ELt27dXdHS0zp07V9p6AAAAAAAAAACqOZtuDtqvXz+rxy+99JIWL16svXv3qmHDhnr77be1atUqPfDAA5Kk5cuXq2XLltq7d6+6dOmilJQUffXVV9qyZYsCAgLUoUMHzZw5U5MmTVJiYqLc3Ny0ZMkShYaGavbs2ZKkli1bavfu3Zo7d66io6MlSXPmzNGoUaM0cuRISdKSJUu0YcMGLVu2TJMnT77p+LOzs5WdnW15nJWVJUnKzc1Vbm6uLaWwYt7W3dko8bYVhXk8FW1cJVFVcqkqeUjkUlGRS8VT2ccPAAAAAEBlZ1PjvKC8vDytXbtWV69eVUREhNLS0pSbm6vIyEhLTIsWLdSoUSOZTCZ16dJFJpNJbdu2VUBAgCUmOjpaY8eO1dGjR9WxY0eZTCarfZhjxo0bJ0nKyclRWlqapkyZYlnv7OysyMhImUymW445OTlZSUlJhZanpKTI09OzJGWwMrNTvs3bbNy4sdTHLQupqamOHoLdVJVcqkoeErlUVORScVy7ds3RQwAAAAAAoFqzuXF++PBhRURE6Pr166pdu7Y++OADtWrVSunp6XJzc5OPj49VfEBAgDIyMiRJGRkZVk1z83rzulvFZGVl6eeff9aFCxeUl5dXZMyxY8duOfYpU6YoISHB8jgrK0vBwcGKioqSl5dX8YvwG7m5uUpNTdULB5yVne9k07ZHEqNLfNyyYM6lV69ecnV1dfRwSqWq5FJV8pDIpaIil4rH/I0oAAAAAADgGDY3zps3b6709HRdunRJ77//voYPH66dO3eWxdjszt3dXe7u7oWWu7q62qXBkp3vpOw82xrnFbWxY6+aVARVJZeqkodELhUVuVQclXnsAAAAAABUBTY3zt3c3NSsWTNJUlhYmD7//HPNnz9fjz76qHJycnTx4kWrT51nZmYqMDBQkhQYGKj9+/db7S8zM9OyzvyneVnBGC8vL9WsWVMuLi5ycXEpMsa8DwAAAAAAAAAASsq5tDvIz89Xdna2wsLC5Orqqq1bt1rWHT9+XGfOnFFERIQk/T/27jwuqur/H/iLbVjUYXFhSUTScjcNE3E3kVFpsfxkJCUpiRqYSrlQLqiZivuWZKXW5yuZVlqpIZNrKqKSpLigJWqpQIWIig7InN8f/uZ+uLIODDMDvJ6PBw+de9/33vM+9zLnzps798LPzw+nT59GVlaWFKNWq6FUKtG2bVsppug6dDG6dSgUCvj4+MhitFot9uzZI8UQEREREREREREREVWWXlecR0VFYdCgQWjWrBlu376NuLg47N+/H7t374ajoyNCQ0MRGRkJFxcXKJVKjB8/Hn5+fujWrRsAICAgAG3btsUbb7yBmJgYZGRkYPr06QgPD5duoTJ27FisXr0aU6ZMwahRo7B3715s2bIFO3fulNoRGRmJkJAQdOnSBV27dsXy5ctx9+5djBw50oBdQ0RERERERERERER1kV6F86ysLIwYMQI3btyAo6MjOnbsiN27d2PAgAEAgGXLlsHS0hJDhw6FRqOBSqXCxx9/LC1vZWWFHTt2YNy4cfDz80O9evUQEhKCOXPmSDHe3t7YuXMnJk2ahBUrVqBp06b47LPPoFL97yGar776Kv7++2/MnDkTGRkZ6NSpE+Lj44s9MJSIiIiIiIiIiIiISF96Fc4///zzMufb2dlhzZo1WLNmTakxXl5e2LVrV5nr6du3L06ePFlmTEREBCIiIsqMISIiIiIiIiIiIiLSV5XvcU5EREREREREREREVJuwcE5EREREREREREREVAQL50RERERERERERERERbBwTkRERERERERERERUBAvnRERERERERERERERFsHBORERERERERERERFQEC+dEREREREREREREREWwcE5EREREREREREREVAQL50RERERERERERERERbBwTkRERERERERERERUBAvnRERERERERERERERFsHBORERUR127dg2vv/46GjZsCHt7e3To0AEnTpyQ5gshMHPmTLi7u8Pe3h7+/v64ePGibB3Z2dkIDg6GUqmEk5MTQkNDcefOHVnMqVOn0KtXL9jZ2cHT0xMxMTFGyY+IiIiIiIioslg4JyIiqoNu3ryJHj16wMbGBj/99BPOnj2LJUuWwNnZWYqJiYnBypUrERsbi6SkJNSrVw8qlQr379+XYoKDg3HmzBmo1Wrs2LEDBw8eRFhYmDQ/NzcXAQEB8PLyQnJyMhYtWoTo6GisW7fOqPkSERERERER6cPa1A0gIiIi41u4cCE8PT2xYcMGaZq3t7f0fyEEli9fjunTp+PFF18EAHz55ZdwdXXF9u3bERQUhHPnziE+Ph7Hjx9Hly5dAACrVq3C4MGDsXjxYnh4eGDTpk3Iz8/H+vXroVAo0K5dO6SkpGDp0qWyAjsRERERERGROWHhnIiIqA764YcfoFKp8Morr+DAgQN47LHH8Pbbb2P06NEAgPT0dGRkZMDf319axtHREb6+vkhMTERQUBASExPh5OQkFc0BwN/fH5aWlkhKSsJLL72ExMRE9O7dGwqFQopRqVRYuHAhbt68KbvCXUej0UCj0Uivc3NzAQAFBQUoKCiocI66WH2WMTVbK1HxWMuHsTUpv/IUzV+Xn+7f0tTE/GvisakP5lezMT/910VERES1EwvnREREddClS5ewdu1aREZG4v3338fx48fxzjvvQKFQICQkBBkZGQAAV1dX2XKurq7SvIyMDDRp0kQ239raGi4uLrKYoleyF11nRkZGiYXz+fPnY/bs2cWmJyQkwMHBQe9c1Wq13suYSkxX/ZepSfmVp6T853bRlrnMrl27qqk11a827buSML+ajfmVLy8vzwAtISIiInPFwjkREVEdpNVq0aVLF3z00UcAgM6dOyM1NRWxsbEICQkxaduioqIQGRkpvc7NzYWnpycCAgKgVCorvJ6CggKo1WoMGDAANjY21dFUg2sfvbvCsbaWAnO7aGtUfuUpmr8uvxknLKHRWpS6TGq0yhhNM6iaeGzqg/nVbMyv4nTfiKqK+fPn47vvvsP58+dhb2+P7t27Y+HChWjVqpUUc//+fbz77rvYvHkzNBoNVCoVPv74Y9kft69evYpx48Zh3759qF+/PkJCQjB//nxYW//vI//+/fsRGRmJM2fOwNPTE9OnT8ebb74pa8+aNWuwaNEiZGRk4KmnnsKqVavQtWsl/qpLRERUC7BwTkREVAe5u7ujbdu2smlt2rTBt99+CwBwc3MDAGRmZsLd3V2KyczMRKdOnaSYrKws2ToePHiA7OxsaXk3NzdkZmbKYnSvdTGPsrW1ha2tbbHpNjY2lSpyVHY5U9AUll4gLk1Nyq88JeWv0VqU2S81OffatO9KwvxqNuZXsXVU1YEDBxAeHo5nnnkGDx48wPvvv4+AgACcPXsW9erVAwBMmjQJO3fuxNatW+Ho6IiIiAi8/PLLOHz4MACgsLAQgYGBcHNzw5EjR3Djxg2MGDECNjY20h/I09PTERgYiLFjx2LTpk3Ys2cP3nrrLbi7u0OlevgHyK+//hqRkZGIjY2Fr68vli9fDpVKhbS0tGLfMCMiIqoLWDgnIiKqg3r06IG0tDTZtAsXLsDLywvAwweFurm5Yc+ePVKhPDc3F0lJSRg3bhwAwM/PDzk5OUhOToaPjw8AYO/evdBqtfD19ZViPvjgAxQUFEgFBrVajVatWpV4mxYiIqK6JD4+XvZ648aNaNKkCZKTk9G7d2/cunULn3/+OeLi4vDss88CADZs2IA2bdrg6NGj6NatGxISEnD27Fn8/PPPcHV1RadOnTB37lxMnToV0dHRUCgUiI2Nhbe3N5YsWQLg4R/LDx06hGXLlkmF86VLl2L06NEYOXIkACA2NhY7d+7E+vXrMW3atBLbb6jnkpREt3x5z7oobbmarLY/a6A0dTVvgLkX/beuqKt5A6bJvbLbYuGciIioDpo0aRK6d++Ojz76CMOGDcOxY8ewbt06rFu3DgBgYWGBiRMn4sMPP8QTTzwBb29vzJgxAx4eHhgyZAiAhx+6Bw4ciNGjRyM2NhYFBQWIiIhAUFAQPDw8AADDhw/H7NmzERoaiqlTpyI1NRUrVqzAsmXLTJV6rdM+erfeV6pfXhBYTa0hIqKquHXrFgDAxcUFAJCcnIyCggLZw7pbt26NZs2aITExEd26dUNiYiI6dOggu3WLSqXCuHHjcObMGXTu3BmJiYmydehiJk6cCADIz89HcnIyoqKipPmWlpbw9/dHYmJiqe019HNJSlLesy4eVZOfffGo2v6sgdLU1bwB5l4X1dW8AePmXtnnkrBwTkREVAc988wz2LZtG6KiojBnzhx4e3tj+fLlCA4OlmKmTJmCu3fvIiwsDDk5OejZsyfi4+NhZ2cnxWzatAkRERHo378/LC0tMXToUKxcuVKa7+joiISEBISHh8PHxweNGjXCzJkzERYWZtR8iYiIzJ1Wq8XEiRPRo0cPtG/fHsDDB2krFAo4OTnJYh99WHdJD/PWzSsrJjc3F/fu3cPNmzdRWFhYYsz58+dLbbOhnktSEt396Mt71sWjauKzLx5V2581UJq6mjfA3Oti7nU1b8A0uVf2uSQsnBMREdVRzz33HJ577rlS51tYWGDOnDmYM2dOqTEuLi6Ii4srczsdO3bEL7/8Uul2EhER1QXh4eFITU3FoUOHTN2UCjP0c0lKUt6zLkradm1R2581UJq6mjfA3Oti7nU1b8C4uVd2O5YGbgcRERERERER6SEiIgI7duzAvn370LRpU2m6m5sb8vPzkZOTI4vPzMzU60HcpcUolUrY29ujUaNGsLKyKjGmtId5ExER1XYsnBMRERERERGZgBACERER2LZtG/bu3Qtvb2/ZfB8fH9jY2GDPnj3StLS0NFy9ehV+fn4AHj6I+/Tp08jKypJi1Go1lEol2rZtK8UUXYcuRrcOhUIBHx8fWYxWq8WePXukGCIiorqGt2ohIiIiIiIiMoHw8HDExcXh+++/R4MGDaR7kjs6OsLe3h6Ojo4IDQ1FZGQkXFxcoFQqMX78ePj5+aFbt24AgICAALRt2xZvvPEGYmJikJGRgenTpyM8PFy6jcrYsWOxevVqTJkyBaNGjcLevXuxZcsW7Ny5U2pLZGQkQkJC0KVLF3Tt2hXLly/H3bt3MXLkSON3DBERkRlg4ZyIiIiIiIjIBNauXQsA6Nu3r2z6hg0b8OabbwIAli1bJj2AW6PRQKVS4eOPP5ZirayssGPHDowbNw5+fn6oV68eQkJCZM8o8fb2xs6dOzFp0iSsWLECTZs2xWeffQaV6n8P0nz11Vfx999/Y+bMmcjIyECnTp0QHx9f7IGhREREdQUL50REREREREQmIIQoN8bOzg5r1qzBmjVrSo3x8vLCrl27ylxP3759cfLkyTJjIiIiEBERUW6biIiI6gIWzomIiIioTmk+bWf5QY+4vCCwGlpCRERERETmig8HJSIiIiIiIiIiIiIqglecExEREVGZeIU2ERHVFByziIjIUHjFORERERERERERERFRESycExEREREREREREREVoVfhfP78+XjmmWfQoEEDNGnSBEOGDEFaWpos5v79+wgPD0fDhg1Rv359DB06FJmZmbKYq1evIjAwEA4ODmjSpAkmT56MBw8eyGL279+Pp59+Gra2tmjZsiU2btxYrD1r1qxB8+bNYWdnB19fXxw7dkyfdIiIiIiIiIiIiIiIitGrcH7gwAGEh4fj6NGjUKvVKCgoQEBAAO7evSvFTJo0CT/++CO2bt2KAwcO4Pr163j55Zel+YWFhQgMDER+fj6OHDmCL774Ahs3bsTMmTOlmPT0dAQGBqJfv35ISUnBxIkT8dZbb2H37t1SzNdff43IyEjMmjULv/76K5566imoVCpkZWVVpT+IiIiIiIiIiIiIqI7T6+Gg8fHxstcbN25EkyZNkJycjN69e+PWrVv4/PPPERcXh2effRYAsGHDBrRp0wZHjx5Ft27dkJCQgLNnz+Lnn3+Gq6srOnXqhLlz52Lq1KmIjo6GQqFAbGwsvL29sWTJEgBAmzZtcOjQISxbtgwqlQoAsHTpUowePRojR44EAMTGxmLnzp1Yv349pk2bVmL7NRoNNBqN9Do3NxcAUFBQgIKCAn26Qka3rK2lqPSy5kLXHnNrV2XUllxqSx4AczFXzMX81PT2ExEREREREdV0ehXOH3Xr1i0AgIuLCwAgOTkZBQUF8Pf3l2Jat26NZs2aITExEd26dUNiYiI6dOgAV1dXKUalUmHcuHE4c+YMOnfujMTERNk6dDETJ04EAOTn5yM5ORlRUVHSfEtLS/j7+yMxMbHU9s6fPx+zZ88uNj0hIQEODg76d8Aj5nbR6r3Mrl27qrzd6qBWq03dBIOpLbnUljwA5mKumIv5yMvLM3UTiIiIiIiIiOq0ShfOtVotJk6ciB49eqB9+/YAgIyMDCgUCjg5OcliXV1dkZGRIcUULZrr5uvmlRWTm5uLe/fu4ebNmygsLCwx5vz586W2OSoqCpGRkdLr3NxceHp6IiAgAEqlUo/s5QoKCqBWqzHjhCU0Wgu9lk2NVlV6u9VBl8uAAQNgY2Nj6uZUSW3JpbbkATAXc8VczI/uG1FEREREREREZBqVLpyHh4cjNTUVhw4dMmR7qpWtrS1sbW2LTbexsTFIgUWjtYCmUL/CubkWdgzVJ+agtuRSW/IAmIu5Yi7moya3nYiIiIiIiKg20OvhoDoRERHYsWMH9u3bh6ZNm0rT3dzckJ+fj5ycHFl8ZmYm3NzcpJjMzMxi83XzyopRKpWwt7dHo0aNYGVlVWKMbh1ERERERERERERERJWhV+FcCIGIiAhs27YNe/fuhbe3t2y+j48PbGxssGfPHmlaWloarl69Cj8/PwCAn58fTp8+jaysLClGrVZDqVSibdu2UkzRdehidOtQKBTw8fGRxWi1WuzZs0eKISIiIiIiIiIiIiKqDL1u1RIeHo64uDh8//33aNCggXRPckdHR9jb28PR0RGhoaGIjIyEi4sLlEolxo8fDz8/P3Tr1g0AEBAQgLZt2+KNN95ATEwMMjIyMH36dISHh0u3URk7dixWr16NKVOmYNSoUdi7dy+2bNmCnTt3Sm2JjIxESEgIunTpgq5du2L58uW4e/cuRo4caai+ISIiIiIiIiIiIqI6SK/C+dq1awEAffv2lU3fsGED3nzzTQDAsmXLYGlpiaFDh0Kj0UClUuHjjz+WYq2srLBjxw6MGzcOfn5+qFevHkJCQjBnzhwpxtvbGzt37sSkSZOwYsUKNG3aFJ999hlUqv89SPPVV1/F33//jZkzZyIjIwOdOnVCfHx8sQeGmrvm03aWH/SIywsCq6ElRERERERERERERAToWTgXQpQbY2dnhzVr1mDNmjWlxnh5eWHXrl1lrqdv3744efJkmTERERGIiIgot01ERERERERERERERBVVqYeDEhERERERERERERHVViycExEREREREREREREVwcI5EREREREREREREVERLJwTERERERERERERERXBwjkRERFhwYIFsLCwwMSJE6Vp9+/fR3h4OBo2bIj69etj6NChyMzMlC139epVBAYGwsHBAU2aNMHkyZPx4MEDWcz+/fvx9NNPw9bWFi1btsTGjRuNkBERERERERFR5bFwTkREVMcdP34cn3zyCTp27CibPmnSJPz444/YunUrDhw4gOvXr+Pll1+W5hcWFiIwMBD5+fk4cuQIvvjiC2zcuBEzZ86UYtLT0xEYGIh+/fohJSUFEydOxFtvvYXdu3cbLT8iIiIiIiIifVmbugFERERkOnfu3EFwcDA+/fRTfPjhh9L0W7du4fPPP0dcXByeffZZAMCGDRvQpk0bHD16FN26dUNCQgLOnj2Ln3/+Ga6urujUqRPmzp2LqVOnIjo6GgqFArGxsfD29saSJUsAAG3atMGhQ4ewbNkyqFSqEtuk0Wig0Wik17m5uQCAgoICFBQUVDg3Xaw+y5iarZWoeKylkP2rD337RJ92VXYbj26novlVdTsVZcjjqCYem/pgfjUb89N/XURERFQ7sXBORERUh4WHhyMwMBD+/v6ywnlycjIKCgrg7+8vTWvdujWaNWuGxMREdOvWDYmJiejQoQNcXV2lGJVKhXHjxuHMmTPo3LkzEhMTZevQxRS9Jcyj5s+fj9mzZxebnpCQAAcHB71zVKvVei9jKjFd9V9mbhet3svs2rVLr/jKtEvfbZS2nfLyM9R2ylOZ7ZSnJh2blcH8ajbmV768vDwDtISIiIjMFQvnREREddTmzZvx66+/4vjx48XmZWRkQKFQwMnJSTbd1dUVGRkZUkzRorluvm5eWTG5ubm4d+8e7O3ti207KioKkZGR0uvc3Fx4enoiICAASqWywvkVFBRArVZjwIABsLGxqfByhtI+unpvR2NrKTC3ixYzTlhCo7XQa9nU6JKv9i9NZXLRdxuPbqei+VV1OxVVme2UxtTHZnVjfjUb86s43TeiiIiIqHZi4ZyIiKgO+vPPPzFhwgSo1WrY2dmZujkytra2sLW1LTbdxsamUkWOyi5XVZpC/YrZld6O1kLvbenbH5XJpTJ9XtJ2ysvPUNspT3UcQ6Y6No2F+dVszK9i6yAiIqLaiw8HJSIiqoOSk5ORlZWFp59+GtbW1rC2tsaBAwewcuVKWFtbw9XVFfn5+cjJyZEtl5mZCTc3NwCAm5sbMjMzi83XzSsrRqlUlni1OREREREREZE54BXnREREdVD//v1x+vRp2bSRI0eidevWmDp1Kjw9PWFjY4M9e/Zg6NChAIC0tDRcvXoVfn5+AAA/Pz/MmzcPWVlZaNKkCYCH94xVKpVo27atFPPovaHVarW0DqLarPm0nSVOt7USiOn68JYxRa9+v7wg0FhNIyIiIiKicrBwTkREVAc1aNAA7du3l02rV68eGjZsKE0PDQ1FZGQkXFxcoFQqMX78ePj5+aFbt24AgICAALRt2xZvvPEGYmJikJGRgenTpyM8PFy61crYsWOxevVqTJkyBaNGjcLevXuxZcsW7NxZckGRiIiIiIiIyBywcE5EREQlWrZsGSwtLTF06FBoNBqoVCp8/PHH0nwrKyvs2LED48aNg5+fH+rVq4eQkBDMmTNHivH29sbOnTsxadIkrFixAk2bNsVnn30GlcpwD1ok/ZV2JTQRERERERE9xMI5ERERAQD2798ve21nZ4c1a9ZgzZo1pS7j5eVV7FYsj+rbty9OnjxpiCYSERERERERGQUfDkpEREREREREREREVAQL50RERERERERERERERbBwTkRERERERERERERUBAvnRERERERERERERERFsHBORERERERERERERFQEC+dEREREREREREREREWwcE5EREREREREREREVAQL50RERERERERERERERbBwTkRERERERERERERUBAvnRERERERERCZy8OBBPP/88/Dw8ICFhQW2b98umy+EwMyZM+Hu7g57e3v4+/vj4sWLspjs7GwEBwdDqVTCyckJoaGhuHPnjizm1KlT6NWrF+zs7ODp6YmYmJhibdm6dStat24NOzs7dOjQAbt27TJ4vkRERDUFC+dEREREREREJnL37l089dRTWLNmTYnzY2JisHLlSsTGxiIpKQn16tWDSqXC/fv3pZjg4GCcOXMGarUaO3bswMGDBxEWFibNz83NRUBAALy8vJCcnIxFixYhOjoa69atk2KOHDmC1157DaGhoTh58iSGDBmCIUOGIDU1tfqSJyIiMmPWpm4AERERERERUV01aNAgDBo0qMR5QggsX74c06dPx4svvggA+PLLL+Hq6ort27cjKCgI586dQ3x8PI4fP44uXboAAFatWoXBgwdj8eLF8PDwwKZNm5Cfn4/169dDoVCgXbt2SElJwdKlS6UC+4oVKzBw4EBMnjwZADB37lyo1WqsXr0asbGxJbZPo9FAo9FIr3NzcwEABQUFKCgoqFK/6Ja3tRRVWo8+2zIXuvaYW7uqW13NG2DuRf+tK+pq3oBpcq/stlg4JyIiIiIiIjJD6enpyMjIgL+/vzTN0dERvr6+SExMRFBQEBITE+Hk5CQVzQHA398flpaWSEpKwksvvYTExET07t0bCoVCilGpVFi4cCFu3rwJZ2dnJCYmIjIyUrZ9lUpV7NYxRc2fPx+zZ88uNj0hIQEODg5VyPx/5nbRGmQ9ZTHXW9Ko1WpTN8Ek6mreAHOvi+pq3oBxc8/Ly6vUciycExEREREREZmhjIwMAICrq6tsuqurqzQvIyMDTZo0kc23traGi4uLLMbb27vYOnTznJ2dkZGRUeZ2ShIVFSUrtufm5sLT0xMBAQFQKpX6pFpMQUEB1Go1ZpywhEZrUaV1lSc1WlWt69eXLvcBAwbAxsbG1M0xmrqaN8Dc62LudTVvwDS5674RpS8WzomIiIiIiIhIb7a2trC1tS023cbGxmDFEI3WAprC6i2cm2vRypD9WJPU1bwB5l4Xc6+reQPGzb2y2+HDQYmIiIiIiIjMkJubGwAgMzNTNj0zM1Oa5+bmhqysLNn8Bw8eIDs7WxZT0jqKbqO0GN18IiKiuoaFcyIiIiIiIiIz5O3tDTc3N+zZs0ealpubi6SkJPj5+QEA/Pz8kJOTg+TkZClm79690Gq18PX1lWIOHjwoeziaWq1Gq1at4OzsLMUU3Y4uRrcdIiKiukbvwvnBgwfx/PPPw8PDAxYWFsUeFCKEwMyZM+Hu7g57e3v4+/vj4sWLspjs7GwEBwdDqVTCyckJoaGhuHPnjizm1KlT6NWrF+zs7ODp6YmYmJhibdm6dStat24NOzs7dOjQwWwf6EFERERERERUkjt37iAlJQUpKSkAHj4QNCUlBVevXoWFhQUmTpyIDz/8ED/88ANOnz6NESNGwMPDA0OGDAEAtGnTBgMHDsTo0aNx7NgxHD58GBEREQgKCoKHhwcAYPjw4VAoFAgNDcWZM2fw9ddfY8WKFbL7k0+YMAHx8fFYsmQJzp8/j+joaJw4cQIRERHG7hIiIiKzoHfh/O7du3jqqaewZs2aEufHxMRg5cqViI2NRVJSEurVqweVSoX79+9LMcHBwThz5gzUajV27NiBgwcPIiwsTJqfm5uLgIAAeHl5ITk5GYsWLUJ0dDTWrVsnxRw5cgSvvfYaQkNDcfLkSQwZMgRDhgxBamqqvikRERERERERmcSJEyfQuXNndO7cGQAQGRmJzp07Y+bMmQCAKVOmYPz48QgLC8MzzzyDO3fuID4+HnZ2dtI6Nm3ahNatW6N///4YPHgwevbsKfv87OjoiISEBKSnp8PHxwfvvvsuZs6cKfsc3r17d8TFxWHdunV46qmn8M0332D79u1o3769kXqCiIjIvOj9cNBBgwZh0KBBJc4TQmD58uWYPn06XnzxRQDAl19+CVdXV2zfvh1BQUE4d+4c4uPjcfz4cXTp0gUAsGrVKgwePBiLFy+Gh4cHNm3ahPz8fKxfvx4KhQLt2rVDSkoKli5dKg3sK1aswMCBAzF58mQAwNy5c6FWq7F69WrExsaW2D6NRgONRiO91j1RtaCgQPaVNX3plrW1FJVeR2W2V53rrs5tGEttyaW25AEwF3PFXMxPTW8/ERERVVzfvn0hROmfJS0sLDBnzhzMmTOn1BgXFxfExcWVuZ2OHTvil19+KTPmlVdewSuvvFJ2g4mIiOoIvQvnZUlPT0dGRgb8/f2laY6OjvD19UViYiKCgoKQmJgIJycnqWgOAP7+/rC0tERSUhJeeuklJCYmonfv3lAoFFKMSqXCwoULcfPmTTg7OyMxMVH2tTJdzKO3jilq/vz5mD17drHpCQkJcHBwqELmD83toq3yOirCGLekUavV1b4NY6ktudSWPADmYq6Yi/nIy8szdROIiIiIiIiI6jSDFs4zMjIAAK6urrLprq6u0ryMjAw0adJE3ghra7i4uMhivL29i61DN8/Z2RkZGRllbqckUVFRsmJ7bm4uPD09ERAQAKVSqU+qMgUFBVCr1ZhxwhIarUWl11NRqdGqalu3LpcBAwbAxsam2rZjDLUll9qSB8BczBVzMT+6b0SR+Wg+baepm0BERERERERGZNDCubmztbWFra1tsek2NjYGKbBotBbQFFZ/4dwYxSBD9Yk5qC251JY8AOZirpiL+ajJbSciIiIiIiKqDfR+OGhZ3NzcAACZmZmy6ZmZmdI8Nzc3ZGVlyeY/ePAA2dnZspiS1lF0G6XF6OYTEREREREREREREVWGQQvn3t7ecHNzw549e6Rpubm5SEpKgp+fHwDAz88POTk5SE5OlmL27t0LrVYLX19fKebgwYOyh6Op1Wq0atUKzs7OUkzR7ehidNshIiKi0s2fPx/PPPMMGjRogCZNmmDIkCFIS0uTxdy/fx/h4eFo2LAh6tevj6FDhxb7o/XVq1cRGBgIBwcHNGnSBJMnT8aDBw9kMfv378fTTz8NW1tbtGzZEhs3bqzu9IiIiIiIiIiqRO/C+Z07d5CSkoKUlBQADx8ImpKSgqtXr8LCwgITJ07Ehx9+iB9++AGnT5/GiBEj4OHhgSFDhgAA2rRpg4EDB2L06NE4duwYDh8+jIiICAQFBcHDwwMAMHz4cCgUCoSGhuLMmTP4+uuvsWLFCtn9ySdMmID4+HgsWbIE58+fR3R0NE6cOIGIiIiq9woREVEtd+DAAYSHh+Po0aNQq9UoKChAQEAA7t69K8VMmjQJP/74I7Zu3YoDBw7g+vXrePnll6X5hYWFCAwMRH5+Po4cOYIvvvgCGzduxMyZM6WY9PR0BAYGol+/fkhJScHEiRPx1ltvYffu3UbNl4iIiIiIiEgfet/j/MSJE+jXr5/0WlfMDgkJwcaNGzFlyhTcvXsXYWFhyMnJQc+ePREfHw87OztpmU2bNiEiIgL9+/eHpaUlhg4dipUrV0rzHR0dkZCQgPDwcPj4+KBRo0aYOXMmwsLCpJju3bsjLi4O06dPx/vvv48nnngC27dvR/v27SvVEURERHVJfHy87PXGjRvRpEkTJCcno3fv3rh16xY+//xzxMXF4dlnnwUAbNiwAW3atMHRo0fRrVs3JCQk4OzZs/j555/h6uqKTp06Ye7cuZg6dSqio6OhUCgQGxsLb29vLFmyBMDDP6AfOnQIy5Ytg0pVfQ+7JiIiIiIiIqoKvQvnffv2hRCi1PkWFhaYM2cO5syZU2qMi4sL4uLiytxOx44d8csvv5QZ88orr+CVV14pu8FERERUrlu3bgF4OEYDQHJyMgoKCuDv7y/FtG7dGs2aNUNiYiK6deuGxMREdOjQAa6urlKMSqXCuHHjcObMGXTu3BmJiYmydehiJk6cWGpbNBoNNBqN9Do3NxcAUFBQILuNW3l0sfosUxpbq9LPfUzF1lLI/jU3rT7YofcytlZF/l/B/CqzfyuzPw25ndJyM8Sxag4M+btnjphfzWbI/GprHxEREdFDehfOiYiIqHbRarWYOHEievToIX1zKyMjAwqFAk5OTrJYV1dXZGRkSDFFi+a6+bp5ZcXk5ubi3r17sLe3L9ae+fPnY/bs2cWmJyQkwMHBQe/81Gq13ss8KqZrlVdRbeZ20Zq6CdWqvPx27dql9zorsz+rYzuP5laZbZgzQ/zumTPmV7MZIr+8vDwDtISIiIjMFQvnREREdVx4eDhSU1Nx6NAhUzcFABAVFSV7rklubi48PT0REBAApVJZ4fUUFBRArVZjwIABsLGxqVKb2keb3z3ZbS0F5nbRYsYJS2i0FqZujsFVNL/UaP1v+VOZ/WnI7ZSWW2W2YSz69JkuP0P87pkjQ763mCPmV3G6b0QRERFR7cTCORERUR0WERGBHTt24ODBg2jatKk03c3NDfn5+cjJyZFddZ6ZmQk3Nzcp5tixY7L1ZWZmSvN0/+qmFY1RKpUlXm0OALa2trC1tS023cbGplJFjsouV5Sm0HwL0xqthVm3r6rKy68y+7Yy/VUd23k0N3MuUla2z8w5p6pifjWbIfKrzf1DREREgKWpG0BERETGJ4RAREQEtm3bhr1798Lb21s238fHBzY2NtizZ480LS0tDVevXoWfnx8AwM/PD6dPn0ZWVpYUo1aroVQq0bZtWymm6Dp0Mbp1EBEREREREZkjXnFORERUB4WHhyMuLg7ff/89GjRoIN2T3NHREfb29nB0dERoaCgiIyPh4uICpVKJ8ePHw8/PD926dQMABAQEoG3btnjjjTcQExODjIwMTJ8+HeHh4dIV42PHjsXq1asxZcoUjBo1Cnv37sWWLVuwc+dOk+VOREREREREVB4WzomIiOqgtWvXAgD69u0rm75hwwa8+eabAIBly5bB0tISQ4cOhUajgUqlwscffyzFWllZYceOHRg3bhz8/PxQr149hISEYM6cOVKMt7c3du7ciUmTJmHFihVo2rQpPvvsM6hU5nsvZyIiIqpbmk/T7w/6lxcEVlNLiIjInLBwTkREVAcJIcqNsbOzw5o1a7BmzZpSY7y8vLBr164y19O3b1+cPHlS7zYSERERERERmQrvcU5EREREREREREREVAQL50RERERERERERERERbBwTkRERERERERERERUBAvnRERERERERERERERFsHBORERERERERERERFQEC+dEREREREREREREREWwcE5EREREREREREREVIS1qRtAREREZEzNp+00dROoBuJxQ0RERERUt/CKcyIiIiIiIiIiIiKiInjFORERERERURmKfuPA1kogpivQPno3NIUWpS5zeUGgMZpGRERERNWEV5wTERERERERERERERXBwjkRERERERERERERURG8VQsRERERkRmozANIeTsQIiIiIqLqwSvOiYiIiIiIiIiIiIiKYOGciIiIiIiIiIiIiKgI3qqFiIiIiGqsytzehIiIiIiIqDwsnBMRERER1SH8YwMRERERUfl4qxYiIiIiIiIiIiIioiJ4xTkRERERERERUQVV5ps7lxcEVkNLiIioOrFwTkRERERUQ/G2K/pjnxERERFRRfBWLURERERERERERERERfCK8xpI36tk+JUwIiIiIiIiIiIioorjFedEREREREREREREREWwcE5EREREREREREREVAQL50RERERERERERERERdT4e5yvWbMGixYtQkZGBp566imsWrUKXbt2NXWziIiI6BEcs4nqlvbRu6EptNBrGT6bh8j0OF4TERE9VKML519//TUiIyMRGxsLX19fLF++HCqVCmlpaWjSpImpm0dERET/H8dsIqqI5tN26hXPQnvllNXPtlYCMV3lf/gw537W95jR5Ucl43hdffQ5VnmcEhGZhxpdOF+6dClGjx6NkSNHAgBiY2Oxc+dOrF+/HtOmTSsWr9FooNFopNe3bt0CAGRnZ6OgoKDS7SgoKEBeXh6sCyxRqNXvqhpjaPnelgrH2loKTO+sxb///gsbG5tqbFX10+2Xmp5LbckDYC7mirmYn9u3bwMAhBAmbonh6DNmG2q8Lu14sH5wtyqpmA1rrUBentZszz+qqjbnV5tzA4ybnz7nuTpV/QBU0fz+/fdfvdftO3+P3sskRfXXe5my3gdLyq8yuRiLvu/puvwMca5Q18droPo+YwPm/zm7OhnyOK1Jasu5fGUw97qXe13NGzBN7pUes0UNpdFohJWVldi2bZts+ogRI8QLL7xQ4jKzZs0SAPjDH/7whz/8qRE/f/75pxFG1Oqn75jN8Zo//OEPf/hTk37q6ngtBMds/vCHP/zhT8360XfMrrFXnP/zzz8oLCyEq6urbLqrqyvOnz9f4jJRUVGIjIyUXmu1WmRnZ6Nhw4awsKj8X7Bzc3Ph6emJP//8E0qlstLrMQfMxfzUljwA5mKumIv5EULg9u3b8PDwMHVTDELfMdtQ43VtOR5Kw/xqrtqcG8D8ajrmV3F1fbwGqu8zNlD7j8Wy1NXc62reAHOvi7nX1bwB0+Re2TG7xhbOK8PW1ha2trayaU5OTgZbv1KprDUHO3MxP7UlD4C5mCvmYl4cHR1N3QSTMfR4XRuOh7Iwv5qrNucGML+ajvlVTF0er4Hq/4wN1P5jsSx1Nfe6mjfA3Oti7nU1b8D4uVdmzLashnYYRaNGjWBlZYXMzEzZ9MzMTLi5uZmoVURERPQojtlERETmj+M1ERGRXI0tnCsUCvj4+GDPnv89QEer1WLPnj3w8/MzYcuIiIioKI7ZRERE5o/jNRERkVyNvlVLZGQkQkJC0KVLF3Tt2hXLly/H3bt3pSeAG4utrS1mzZpV7CtqNRFzMT+1JQ+AuZgr5kLGYIoxu7YfD8yv5qrNuQHMr6ZjfnWbuXzGBur2vqqrudfVvAHmXhdzr6t5AzUrdwshhDB1I6pi9erVWLRoETIyMtCpUyesXLkSvr6+pm4WERERPYJjNhERkfnjeE1ERPRQjS+cExEREREREREREREZUo29xzkRERERERERERERUXVg4ZyIiIiIiIiIiIiIqAgWzomIiIiIiIiIiIiIimDhnIiIiIiIiIiIiIioCBbOS7FmzRo0b94cdnZ28PX1xbFjx8qM37p1K1q3bg07Ozt06NABu3btks0XQmDmzJlwd3eHvb09/P39cfHixepMAYB+eXz66afo1asXnJ2d4ezsDH9//2Lxb775JiwsLGQ/AwcOrO40AOiXy8aNG4u1087OThZjqn0C6JdL3759i+ViYWGBwMBAKcYU++XgwYN4/vnn4eHhAQsLC2zfvr3cZfbv34+nn34atra2aNmyJTZu3FgsRt/fPUPQN5fvvvsOAwYMQOPGjaFUKuHn54fdu3fLYqKjo4vtk9atW1djFg/pm8v+/ftLPL4yMjJkcTVhv5T0e2BhYYF27dpJMabaL2R8pjhm9VXe8Xj//n2Eh4ejYcOGqF+/PoYOHYrMzEzZOq5evYrAwEA4ODigSZMmmDx5Mh48eCCLqch7ryGU9ztbkXE3OzsbwcHBUCqVcHJyQmhoKO7cuSOLOXXqFHr16gU7Ozt4enoiJiamWFvKOy+rjvwqMhaba37z58/HM888gwYNGqBJkyYYMmQI0tLSZDHGPB4N/ftbkfxKOt8aO3Zsjchv7dq16NixI5RKpXRe8tNPP0nza/K+q0h+NXnfUenqQl8b6r23pluwYAEsLCwwceJEaVptzvvatWt4/fXX0bBhQ9jb26NDhw44ceKENN+UdYrqVFhYiBkzZsDb2xv29vZo0aIF5s6dCyGEFFNbcjfWObG5KSvvgoICTJ06FR06dEC9evXg4eGBESNG4Pr167J1mGXegorZvHmzUCgUYv369eLMmTNi9OjRwsnJSWRmZpYYf/jwYWFlZSViYmLE2bNnxfTp04WNjY04ffq0FLNgwQLh6Ogotm/fLn777TfxwgsvCG9vb3Hv3j2zyWP48OFizZo14uTJk+LcuXPizTffFI6OjuKvv/6SYkJCQsTAgQPFjRs3pJ/s7Oxqy6GyuWzYsEEolUpZOzMyMmQxptgnlcnl33//leWRmpoqrKysxIYNG6QYU+yXXbt2iQ8++EB89913AoDYtm1bmfGXLl0SDg4OIjIyUpw9e1asWrVKWFlZifj4eClG374xVS4TJkwQCxcuFMeOHRMXLlwQUVFRwsbGRvz6669SzKxZs0S7du1k++Tvv/+u1jyE0D+Xffv2CQAiLS1N1tbCwkIppqbsl5ycHFkOf/75p3BxcRGzZs2SYky1X8i4THXM6qu843Hs2LHC09NT7NmzR5w4cUJ069ZNdO/eXZr/4MED0b59e+Hv7y9Onjwpdu3aJRo1aiSioqKkmIq89xpKeb+zFRl3Bw4cKJ566ilx9OhR8csvv4iWLVuK1157TZp/69Yt4erqKoKDg0Vqaqr46quvhL29vfjkk0+kmIqcl1VHfhUZi801P5VKJTZs2CBSU1NFSkqKGDx4sGjWrJm4c+eOFGOs47E6fn8rkl+fPn3E6NGjZfvv1q1bNSK/H374QezcuVNcuHBBpKWliffff1/Y2NiI1NRUIUTN3ncVya8m7zsqWV3pa0O899Z0x44dE82bNxcdO3YUEyZMkKbX1ryzs7OFl5eXePPNN0VSUpK4dOmS2L17t/j999+lGFPVKarbvHnzRMOGDcWOHTtEenq62Lp1q6hfv75YsWKFFFNbcjfGObE5KivvnJwc4e/vL77++mtx/vx5kZiYKLp27Sp8fHxk6zDHvFk4L0HXrl1FeHi49LqwsFB4eHiI+fPnlxg/bNgwERgYKJvm6+srxowZI4QQQqvVCjc3N7Fo0SJpfk5OjrC1tRVfffVVNWTwkL55POrBgweiQYMG4osvvpCmhYSEiBdffNHQTS2Xvrls2LBBODo6lro+U+0TIaq+X5YtWyYaNGggO6Ey1X7RqUhRc8qUKaJdu3ayaa+++qpQqVTS66r2jSFUJJeStG3bVsyePVt6PWvWLPHUU08ZrmGVoE/h/ObNm6XG1NT9sm3bNmFhYSEuX74sTTOH/ULVzxyO2Yoo63jMyckRNjY2YuvWrdK0c+fOCQAiMTFRCPHw5NTS0lL2h+G1a9cKpVIpNBqNEKJi773V4dHf2YqMu2fPnhUAxPHjx6WYn376SVhYWIhr164JIYT4+OOPhbOzs5SfEEJMnTpVtGrVSnpd3nlZdeQnRPljcU3KLysrSwAQBw4cEEIY93g0xu/vo/kJ8bD4WrRo86ialJ8QQjg7O4vPPvus1u27R/MTovbtO6q7fV2Z996a7Pbt2+KJJ54QarVa9ntcm/OeOnWq6NmzZ6nzTVmnqG6BgYFi1KhRsmkvv/yyCA4OFkLU3tyr65zY3FXk8/uxY8cEAHHlyhUhhPnmzVu1PCI/Px/Jycnw9/eXpllaWsLf3x+JiYklLpOYmCiLBwCVSiXFp6enIyMjQxbj6OgIX1/fUtdZVZXJ41F5eXkoKCiAi4uLbPr+/fvRpEkTtGrVCuPGjcO///5r0LY/qrK53LlzB15eXvD09MSLL76IM2fOSPNMsU8Aw+yXzz//HEFBQahXr55surH3i77K+z0xRN+Yilarxe3bt4v9rly8eBEeHh54/PHHERwcjKtXr5qoheXr1KkT3N3dMWDAABw+fFiaXpP3y+effw5/f394eXnJptek/UL6q2nHbGnHY3JyMgoKCmR5tG7dGs2aNZPySExMRIcOHeDq6irFqFQq5ObmSmNeee+9xlKRcTcxMRFOTk7o0qWLFOPv7w9LS0skJSVJMb1794ZCoZBiVCoV0tLScPPmTSnGVDmXNRbXpPxu3boFANK4Zqzj0Vi/v4/mp7Np0yY0atQI7du3R1RUFPLy8qR5NSW/wsJCbN68GXfv3oWfn1+t23eP5qdTG/YdPVSX+7oy7701WXh4OAIDA4v97tXmvH/44Qd06dIFr7zyCpo0aYLOnTvj008/leabqk5hDN27d8eePXtw4cIFAMBvv/2GQ4cOYdCgQQBqd+5FGeqcuDa4desWLCws4OTkBMB887Y22ZbN1D///IPCwkLZiRUAuLq64vz58yUuk5GRUWK87h7Bun/LijG0yuTxqKlTp8LDw0P2Cz1w4EC8/PLL8Pb2xh9//IH3338fgwYNQmJiIqysrAyag05lcmnVqhXWr1+Pjh074tatW1i8eDG6d++OM2fOoGnTpibZJ0DV98uxY8eQmpqKzz//XDbdFPtFX6X9nuTm5uLevXu4efNmlY9ZU1m8eDHu3LmDYcOGSdN8fX2xceNGtGrVCjdu3MDs2bPRq1cvpKamokGDBiZsrZy7uztiY2PRpUsXaDQafPbZZ+jbty+SkpLw9NNPG+S9xBSuX7+On376CXFxcbLpNWW/UOXVpGO2rOMxIyMDCoVCOpHUefT8oqQ8dfPKitG999rb21dTdnIVGXczMjLQpEkT2Xxra2u4uLjIYry9vYutQzfP2dm53POy6lLeWFxT8tNqtZg4cSJ69OiB9u3bS9s2xvFojHOBkvIDgOHDh8PLywseHh44deoUpk6dirS0NHz33Xc1Ir/Tp0/Dz88P9+/fR/369bFt2za0bdsWKSkptWLflZYfUPP3HcnVpHHckCr73ltTbd68Gb/++iuOHz9ebF5tzvvSpUtYu3YtIiMj8f777+P48eN45513oFAoEBISYrI6hTFMmzYNubm5aN26NaysrFBYWIh58+YhODgYgGnqZqZgqHPimu7+/fuYOnUqXnvtNSiVSgDmmzcL51SiBQsWYPPmzdi/f7/soZpBQUHS/zt06ICOHTuiRYsW2L9/P/r372+KppbIz89PdhVK9+7d0aZNG3zyySeYO3euCVtWNZ9//jk6dOiArl27yqbXlP1SG8XFxWH27Nn4/vvvZW/yur+cA0DHjh3h6+sLLy8vbNmyBaGhoaZoaolatWqFVq1aSa+7d++OP/74A8uWLcN///tfE7asar744gs4OTlhyJAhsuk1Zb9Q3VDW8WisgjYZTm0Zi8PDw5GamopDhw6ZuinVorT8wsLCpP936NAB7u7u6N+/P/744w+0aNHC2M3UW6tWrZCSkoJbt27hm2++QUhICA4cOGDqZhlMafm1bdu2xu87IqD2v/cW9eeff2LChAlQq9WyWkNdoNVq0aVLF3z00UcAgM6dOyM1NRWxsbEICQkxceuq15YtW7Bp0ybExcWhXbt2SElJwcSJE+Hh4VHrcye5goICDBs2DEIIrF271tTNKRdv1fKIRo0awcrKqtgTmzMzM+Hm5lbiMm5ubmXG6/7VZ51VVZk8dBYvXowFCxYgISEBHTt2LDP28ccfR6NGjfD7779Xuc2lqUouOjY2NujcubPUTlPsE6Bqudy9exebN2+uUHHPGPtFX6X9niiVStjb2xtkPxvb5s2b8dZbb2HLli3FvmL4KCcnJzz55JNmtU9K07VrV6mdNXG/CCGwfv16vPHGG7LbHZSkJu0XqpiaeMzqFD0e3dzckJ+fj5ycHFnMo+cXJeWpm1dWjO6911gqMu66ubkhKytLNv/BgwfIzs42SM7G3v+PjsU1Ib+IiAjs2LED+/btQ9OmTaXpxjoeq/v3t7T8SuLr6wsAsv1nzvkpFAq0bNkSPj4+mD9/Pp566imsWLGi1uy70vIrSU3bdyRXF/u6Ku+9NVFycjKysrLw9NNPw9raGtbW1jhw4ABWrlwJa2truLq61sq8gYff9tV9W0anTZs20q36TFWnMIbJkydj2rRpCAoKQocOHfDGG29g0qRJmD9/PoDanXtRhjonrql0RfMrV65ArVZLV5sD5ps3C+ePUCgU8PHxwZ49e6RpWq0We/bskV3BXJSfn58sHgDUarUU7+3tDTc3N1lMbm4ukpKSSl1nVVUmDwCIiYnB3LlzER8fL7uvUGn++usv/Pvvv3B3dzdIu0tS2VyKKiwsxOnTp6V2mmKfAFXLZevWrdBoNHj99dfL3Y4x9ou+yvs9McR+NqavvvoKI0eOxFdffYXAwMBy4+/cuYM//vjDrPZJaVJSUqR21rT9AgAHDhzA77//XqE/MtWk/UIVUxOPWZ2ix6OPjw9sbGxkeaSlpeHq1atSHn5+fjh9+rTsBFN3Aqr7UFbee6+xVGTc9fPzQ05ODpKTk6WYvXv3QqvVSoUwPz8/HDx4EAUFBVKMWq1Gq1at4OzsLMWYQ86PjsXmnJ8QAhEREdi2bRv27t1b7HYxxjoeq+v3t7z8SpKSkgIAsv1nrvmVRKvVQqPR1Ph9V15+Janp+66uq0t9bYj33pqof//+OH36NFJSUqSfLl26IDg4WPp/bcwbAHr06IG0tDTZtAsXLkjPZDJVncIY8vLyYGkpL0FaWVlBq9UCqN25F2Woc+KaSFc0v3jxIn7++Wc0bNhQNt9s8zbZY0nN2ObNm4Wtra3YuHGjOHv2rAgLCxNOTk7Sk9jfeOMNMW3aNCn+8OHDwtraWixevFicO3dOzJo1S9jY2IjTp09LMQsWLBBOTk7i+++/F6dOnRIvvvii8Pb2Fvfu3TObPBYsWCAUCoX45ptvxI0bN6Sf27dvCyEePvX6vffeE4mJiSI9PV38/PPP4umnnxZPPPGEuH//frXlUZlcZs+eLXbv3i3++OMPkZycLIKCgoSdnZ04c+aMLF9j75PK5KLTs2dP8eqrrxabbqr9cvv2bXHy5Elx8uRJAUAsXbpUnDx5Unoi8rRp08Qbb7whxV+6dEk4ODiIyZMni3Pnzok1a9YIKysrER8fL8WU1zfmksumTZuEtbW1WLNmjex3JScnR4p59913xf79+0V6ero4fPiw8Pf3F40aNRJZWVlmlcuyZcvE9u3bxcWLF8Xp06fFhAkThKWlpfj555+lmJqyX3Ref/114evrW+I6TbVfyLhMdczqq7zjcezYsaJZs2Zi79694sSJE8LPz0/4+flJyz948EC0b99eBAQEiJSUFBEfHy8aN24soqKipJiKvPcaSnm/sxUZdwcOHCg6d+4skpKSxKFDh8QTTzwhXnvtNWl+Tk6OcHV1FW+88YZITU0VmzdvFg4ODuKTTz6RYipyXmbo/Co6FptrfuPGjROOjo5i//79snEtLy9PijHW8Vgdv7/l5ff777+LOXPmiBMnToj09HTx/fffi8cff1z07t27RuQ3bdo0ceDAAZGeni5OnTolpk2bJiwsLERCQoIQombvu/Lyq+n7jkpWV/raEO+9tUWfPn3EhAkTpNe1Ne9jx44Ja2trMW/ePHHx4kWxadMm4eDgIP7v//5PijFVnaK6hYSEiMcee0zs2LFDpKeni++++040atRITJkyRYqpLbkb45zYHJWVd35+vnjhhRdE06ZNRUpKiuw9T6PRSOswx7xZOC/FqlWrRLNmzYRCoRBdu3YVR48eleb16dNHhISEyOK3bNkinnzySaFQKES7du3Ezp07ZfO1Wq2YMWOGcHV1Fba2tqJ///4iLS3NrPLw8vISAIr9zJo1SwghRF5enggICBCNGzcWNjY2wsvLS4wePdpoJzD65DJx4kQp1tXVVQwePFj8+uuvsvWZap/om4sQQpw/f14AkD4AFWWq/bJv374Sjxdd20NCQkSfPn2KLdOpUyehUCjE448/LjZs2FBsvWX1jbnk0qdPnzLjhRDi1VdfFe7u7kKhUIjHHntMvPrqq+L33383u1wWLlwoWrRoIezs7ISLi4vo27ev2Lt3b7H11oT9IsTDopO9vb1Yt25dies01X4h4zPFMauv8o7He/fuibfffls4OzsLBwcH8dJLL4kbN27I1nH58mUxaNAgYW9vLxo1aiTeffddUVBQIIupyHuvIZT3O1uRcffff/8Vr732mqhfv75QKpVi5MiR0h/wdX777TfRs2dPYWtrKx577DGxYMGCYm0p77zM0PlVdCw21/xKyguA7Fgx5vFo6N/f8vK7evWq6N27t3BxcRG2traiZcuWYvLkyeLWrVs1Ir9Ro0YJLy8voVAoROPGjUX//v1l54w1ed+Vl19N33dUurrQ14Z6760NHi2c1+a8f/zxR9G+fXtha2srWrduXexziynrFNUpNzdXTJgwQTRr1kzY2dmJxx9/XHzwwQeyomltyd1Y58Tmpqy809PTS33P27dvn7QOc8zbQggh9LxInYiIiIiIiIiIiIio1uI9zomIiIiIiIiIiIiIimDhnIiIiIiIiIiIiIioCBbOiYiIiIiIiIiIiIiKYOGciIiIiIiIiIiIiKgIFs6JiIiIiIiIiIiIiIpg4ZyIiIiIiIiIiIiIqAgWzomIiIiIiIiIiIiIimDhnIiISE8HDx7E888/Dw8PD1hYWGD79u16r0MIgcWLF+PJJ5+Era0tHnvsMcybN8/wjSUiIiIiIiIivVmbugFEREQ1zd27d/HUU09h1KhRePnllyu1jgkTJiAhIQGLFy9Ghw4dkJ2djezsbAO3lIiIiIiIiIgqw0IIIUzdCCIioprKwsIC27Ztw5AhQ6RpGo0GH3zwAb766ivk5OSgffv2WLhwIfr27QsAOHfuHDp27IjU1FS0atXKNA0nIiIiIiIiolLxVi1EREQGFhERgcTERGzevBmnTp3CK6+8goEDB+LixYsAgB9//BGPP/44duzYAW9vbzRv3hxvvfUWrzgnIiIiIiIiMhMsnBMRERnQ1atXsWHDBmzduhW9evVCixYt8N5776Fnz57YsGEDAODSpUu4cuUKtm7dii+//BIbN25EcnIy/vOf/5i49UREREREREQE8B7nREREBnX69GkUFhbiySeflE3XaDRo2LAhAECr1UKj0eDLL7+U4j7//HP4+PggLS2Nt28hIiIiIiIiMjEWzomIiAzozp07sLKyQnJyMqysrGTz6tevDwBwd3eHtbW1rLjepk0bAA+vWGfhnIiIiIiIiMi0WDgnIiIyoM6dO6OwsBBZWVno1atXiTE9evTAgwcP8Mcff6BFixYAgAsXLgAAvLy8jNZWIiIiIiIiIiqZhRBCmLoRRERENcmdO3fw+++/A3hYKF+6dCn69esHFxcXNGvWDK+//joOHz6MJUuWoHPnzvj777+xZ88edOzYEYGBgdBqtXjmmWdQv359LF++HFqtFuHh4VAqlUhISDBxdkRERERERETEwjkREZGe9u/fj379+hWbHhISgo0bN6KgoAAffvghvvzyS1y7dg2NGjVCt27dMHv2bHTo0AEAcP36dYwfPx4JCQmoV68eBg0ahCVLlsDFxcXY6RARERERERHRI1g4JyIiIiIiIiIiIiIqwtLUDSAiIiIiIiIiIiIiMicsnBMRERERERERERERFcHCORERERERERERERFRESycExEREREREREREREVwcI5EREREREREREREVERLJwTERERERERERERERXBwjkRERERERERERERUREsnBMRERERERERERERFcHCORERERERERERERFRESycExEREREREREREREVwcI5EREREREREREREVERLJwTERERERERERERERXBwjkRERERERERERERUREsnBMRERERERERERERFcHCORERERERERERERFRESycExEREREREREREREVwcI5EREREREREREREVERLJwTERERERERERERERXBwjmRiWzcuBEWFha4fPmyqZtSrjfffBPNmzc3dTOIiKgOqUnjJJWN5xFEROZJN9aeOHHC1E0hA9i/fz8sLCywf//+Ci+jzzHQt29f9O3bt/IN1FN0dDQsLCyMtr3K0vX7N998Y+qmUDVg4ZyIqtWuXbsQHR1tsu3HxcVh+fLlJts+ERFRbWDq8ZyIiIhqniNHjiA6Oho5OTmmbkqVsbZQN7FwTkTl+vTTT5GWllapZXft2oXZs2cbuEUVx8GNiIio6qoynlflPIKIiIjMQ0JCAhISEvRa5siRI5g9ezYL51RjsXBOROWysbGBra2tqZsBAMjLyzN1E4iIiIxOq9Xi/v37pm5GpZjTeQQREdVstfHzYE0Z4xUKBRQKhambQWRULJwTmZGPP/4Y7dq1g62tLTw8PBAeHl7sL7O//PILXnnlFTRr1gy2trbw9PTEpEmTcO/ePVncm2++ifr16+PatWsYMmQI6tevj8aNG+O9995DYWGhXu169N6kly9fhoWFBRYvXox169ahRYsWsLW1xTPPPIPjx4/LlluzZg0AwMLCQvqpqL59+6J9+/ZITk5G79694eDggPfffx8A8P333yMwMBAeHh6wtbVFixYtMHfuXFluffv2xc6dO3HlyhVp20Xz0Gg0mDVrFlq2bCn15ZQpU6DRaPTqHyIiMg5zHSeLjlfdu3eHvb09vL29ERsbWyy2omOPhYUFIiIisGnTJinn+Ph4AMC1a9cQGhoqjYHe3t4YN24c8vPzpeVzcnIwceJEeHp6wtbWFi1btsTChQuh1WqlGGON55U9j9A5f/48hg0bhsaNG8Pe3h6tWrXCBx98IIs5efIkBg0aBKVSifr166N///44evSoLEZ3H9dDhw7hnXfeQePGjeHk5IQxY8YgPz8fOTk5GDFiBJydneHs7IwpU6ZACCFbh1arxfLly9GuXTvY2dnB1dUVY8aMwc2bNyvcH0RExlSRMSMvLw9jxoxBw4YNoVQqMWLECL3f13T3o9a9ZyuVSjRs2BATJkwosSj8f//3f/Dx8YG9vT1cXFwQFBSEP//8UxZT1ufBEydOQKVSoVGjRtK4O2rUKNnyd+/exbvvviuNha1atcLixYuLvbfrxtzt27ejffv2sLW1Rbt27aRxVx9arRYrVqxAhw4dYGdnh8aNG2PgwIGye4iXN8aPGjUKrq6uUjvWr19fbDt//fUXhgwZgnr16qFJkyaYNGlSlT7HajQaREZGonHjxqhXrx5eeukl/P3337KYku5xvmrVKrRr1w4ODg5wdnZGly5dEBcXB+DhMTF58mQAgLe3t3T+UNXn1+hz7Jw9exb9+vWDg4MDHnvsMcTExBRb35UrV/DCCy/I+nL37t2y+8WXV1sAHu77efPmoWnTprCzs0P//v3x+++/VylXMj1rUzeAiB6Kjo7G7Nmz4e/vj3HjxiEtLQ1r167F8ePHcfjwYdjY2AAAtm7diry8PIwbNw4NGzbEsWPHsGrVKvz111/YunWrbJ2FhYVQqVTw9fXF4sWL8fPPP2PJkiVo0aIFxo0bV+U2x8XF4fbt2xgzZgwsLCwQExODl19+GZcuXYKNjQ3GjBmD69evQ61W47///W+ltvHvv/9i0KBBCAoKwuuvvw5XV1cADz/81q9fH5GRkahfvz727t2LmTNnIjc3F4sWLQIAfPDBB7h16xb++usvLFu2DABQv359AA8HtRdeeAGHDh1CWFgY2rRpg9OnT2PZsmW4cOECtm/fXuX+ISIiwzH3cfLmzZsYPHgwhg0bhtdeew1btmzBuHHjoFAopA/y+o49e/fuxZYtWxAREYFGjRqhefPmuH79Orp27YqcnByEhYWhdevWuHbtGr755hvk5eVBoVAgLy8Pffr0wbVr1zBmzBg0a9YMR44cQVRUFG7cuFHsa8bGGM9LUt52AeDUqVPo1asXbGxsEBYWhubNm+OPP/7Ajz/+iHnz5gEAzpw5g169ekGpVGLKlCmwsbHBJ598gr59++LAgQPw9fWVbXf8+PFwc3PD7NmzcfToUaxbtw5OTk44cuQImjVrho8++gi7du3CokWL0L59e4wYMUJadsyYMdi4cSNGjhyJd955B+np6Vi9ejVOnjwpOw6JiMxBeWOGTkREBJycnBAdHS2Nr1euXJEeeqiPYcOGoXnz5pg/fz6OHj2KlStX4ubNm/jyyy+lmHnz5mHGjBkYNmwY3nrrLfz9999YtWoVevfujZMnT8LJyUmKLenzYFZWFgICAtC4cWNMmzYNTk5OuHz5Mr777jtpOSEEXnjhBezbtw+hoaHo1KkTdu/ejcmTJ+PatWvS50OdQ4cO4bvvvsPbb7+NBg0aYOXKlRg6dCiuXr2Khg0bVjj/0NBQbNy4EYMGDcJbb72FBw8e4JdffsHRo0fRpUsXKa6kMT4zMxPdunWTCuuNGzfGTz/9hNDQUOTm5mLixIkAgHv37qF///64evUq3nnnHXh4eOC///0v9u7dq9e+Kmr8+PFwdnbGrFmzcPnyZSxfvhwRERH4+uuvS13m008/xTvvvIP//Oc/0h9ITp06haSkJAwfPhwvv/wyLly4gK+++grLli1Do0aNAACNGzeudDv1OXZu3ryJgQMH4uWXX8awYcPwzTffYOrUqejQoQMGDRoE4OEfV5599lncuHEDEyZMgJubG+Li4rBv3z7ZdsuqLegsWLAAlpaWeO+993Dr1i3ExMQgODgYSUlJlc6XzIAgIpPYsGGDACDS09NFVlaWUCgUIiAgQBQWFkoxq1evFgDE+vXrpWl5eXnF1jV//nxhYWEhrly5Ik0LCQkRAMScOXNksZ07dxY+Pj56tTUkJER4eXlJr9PT0wUA0bBhQ5GdnS1N//777wUA8eOPP0rTwsPDRWXfavr06SMAiNjY2GLzSuqHMWPGCAcHB3H//n1pWmBgoKztOv/973+FpaWl+OWXX2TTY2NjBQBx+PDhSrWZiIgMoyaNk7rxasmSJdI0jUYjOnXqJJo0aSLy8/OFEPqNPQCEpaWlOHPmjCx2xIgRwtLSUhw/frxYO7RarRBCiLlz54p69eqJCxcuyOZPmzZNWFlZiatXrwohjDeeV+U8onfv3qJBgwayfVc0VyGEGDJkiFAoFOKPP/6Qpl2/fl00aNBA9O7dW5qmO6ZUKpVseT8/P2FhYSHGjh0rTXvw4IFo2rSp6NOnjzTtl19+EQDEpk2bZG2Jj48vcToRkamVN2bo3hd9fHyksUoIIWJiYgQA8f3331d4W7NmzRIAxAsvvCCb/vbbbwsA4rfffhNCCHH58mVhZWUl5s2bJ4s7ffq0sLa2lk0v7fPgtm3bBIAS89LZvn27ACA+/PBD2fT//Oc/wsLCQvz+++/SNABCoVDIpv32228CgFi1alUFe0CIvXv3CgDinXfeKTav6LhT2hgfGhoq3N3dxT///CObHhQUJBwdHaVznOXLlwsAYsuWLVLM3bt3RcuWLQUAsW/fvgq3WXcM+Pv7y9o4adIkYWVlJXJycqRpffr0kY2LL774omjXrl2Z61+0aJF0Pqcv3TGlU5lj58svv5SmaTQa4ebmJoYOHSpNW7JkiQAgtm/fLk27d++eaN26dbG+LK22sG/fPgFAtGnTRmg0Gmn6ihUrBABx+vRpvXMn88FbtRCZgZ9//hn5+fmYOHEiLC3/92s5evRoKJVK7Ny5U5pmb28v/f/u3bv4559/0L17dwghcPLkyWLrHjt2rOx1r169cOnSJYO0+9VXX4Wzs7Ns3QAMtn4AsLW1xciRI4tNL9oPt2/fxj///INevXohLy8P58+fL3e9W7duRZs2bdC6dWv8888/0s+zzz4LAMX+wkxERKZTE8ZJa2trjBkzRnqtUCgwZswYZGVlITk5GYD+Y0+fPn3Qtm1b6bVWq8X27dvx/PPPy65a09FdFbh161b06tULzs7Osu34+/ujsLAQBw8elC1njPG8JOVt9++//8bBgwcxatQoNGvWTLasLtfCwkIkJCRgyJAhePzxx6X57u7uGD58OA4dOoTc3FzZsqGhobIrKH19fSGEQGhoqDTNysoKXbp0kfXB1q1b4ejoiAEDBsj61cfHB/Xr1+e5AxGZlYqOGQAQFhYm+8bMuHHjYG1tjV27dum93fDwcNnr8ePHA4C0ru+++w5arRbDhg2TvZe6ubnhiSeeKPZeWtLnQd1VxTt27EBBQUGJ7di1axesrKzwzjvvyKa/++67EELgp59+kk339/dHixYtpNcdO3aEUqnUayz89ttvYWFhgVmzZhWb9+iV+4+O8UIIfPvtt3j++echhJD1jUqlwq1bt/Drr79Kubm7u+M///mPtLyDgwPCwsIq3NZHhYWFydrYq1cvFBYW4sqVK6Uu4+TkhL/++qvE26xVB32Pnfr16+P111+XXisUCnTt2lW2T+Pj4/HYY4/hhRdekKbZ2dlh9OjRerdv5MiRsnvAG+t8iqoXb9VCZAZ0g1GrVq1k0xUKBR5//HHZYHX16lXMnDkTP/zwQ7H7zt26dUv2WndPtaKcnZ0Ndh/ORz/E6j78GvI+n4899liJDyA5c+YMpk+fjr179xb7QPxoP5Tk4sWLOHfuXKlfE8vKyqpcg4mIyOBqwjjp4eGBevXqyaY9+eSTAB7e07tbt256jz3e3t6y13///Tdyc3PRvn37Mtty8eJFnDp1qsLbMcZ4XpLytqv7oFlWvn///Tfy8vKKHRsA0KZNG2i1Wvz5559o165dqdt1dHQEAHh6ehabXrQPLl68iFu3bqFJkyYltoXnDkRkTio6ZgDAE088IXtdv359uLu7V+pe1I+uq0WLFrC0tJTWdfHiRQghisXpPHrLq5I+D/bp0wdDhw7F7NmzsWzZMvTt2xdDhgzB8OHDpYdRX7lyBR4eHmjQoIFs2TZt2kjzi3p0bAD0Pyf4448/4OHhARcXl3JjSxrjc3JysG7dOqxbt67EZXTjzJUrV9CyZctixfiSxsKKqsy5wNSpU/Hzzz+ja9euaNmyJQICAjB8+HD06NGj0u0oi77HTtOmTYv1kbOzM06dOiW9vnLlClq0aFEsrmXLlnq3z1TnU1S9WDgnqkEKCwsxYMAAZGdnY+rUqWjdujXq1auHa9eu4c0335Q98At4eLVUdSpt/eKRh61URdErB3VycnLQp08fKJVKzJkzBy1atICdnR1+/fVXTJ06tVg/lESr1aJDhw5YunRpifMf/fBMRETmz9zGyUfpO/aUNAZWdDsDBgzAlClTSpyvK+jrGGM8L4m5bbek6UXbotVq0aRJE2zatKnE5atyz1Yiotrq0YKkVquFhYUFfvrppxLfdx+9b3RJY6GFhQW++eYbHD16FD/++CN2796NUaNGYcmSJTh69GixdVSEscekR/PSnaO8/vrrCAkJKXGZjh07VktbgMrl36ZNG6SlpWHHjh2Ij4/Ht99+i48//hgzZ87E7NmzDd5GfY8dY+9TU53XUPVi4ZzIDHh5eQEA0tLSZF8zzs/PR3p6Ovz9/QEAp0+fxoULF/DFF1/IHlSlVquN22A96PswmYrYv38//v33X3z33Xfo3bu3ND09Pb3C22/RogV+++039O/fv1raSEREhlMTxsnr16/j7t27sqvOL1y4AABo3rw5gKqPPY0bN4ZSqURqamqZcS1atMCdO3ekfjEEU4yVun1dVr6NGzeGg4MD0tLSis07f/48LC0tDfbH8BYtWuDnn39Gjx49Kv1HDSIiY6nomAE8vJK3X79+0us7d+7gxo0bGDx4sN7bvXjxouxq6t9//x1arVY2Fgoh4O3tXewPufrq1q0bunXrhnnz5iEuLg7BwcHYvHkz3nrrLXh5eeHnn3/G7du3ZVed627rqTu3MKQWLVpg9+7dyM7OrtBV50U1btwYDRo0QGFhYbnjt5eXF1JTUyGEkI3PJY2F1a1evXp49dVX8eqrryI/Px8vv/wy5s2bh6ioKNjZ2Rn0/MGQx46Ol5cXzp49W6wvf//992KxrBvUTbzHOZEZ8Pf3h0KhwMqVK2V/jfz8889x69YtBAYGAvjfXzCLxgghsGLFCuM2WA+6AkJOTo7B1llSP+Tn5+Pjjz8ucfsl3bpl2LBhuHbtGj799NNi8+7du4e7d+8arL1ERFQ1NWGcfPDgAT755BPpdX5+Pj755BM0btwYPj4+AKo+9lhaWmLIkCH48ccfceLEiWLzdXkPGzYMiYmJ2L17d7GYnJwcPHjwQK/cgOoZz8vTuHFj9O7dG+vXr8fVq1dl83S5WllZISAgAN9//73slgKZmZmIi4tDz549oVQqDdKeYcOGobCwEHPnzi0278GDB0btGyKi8lR0zACAdevWye4VvnbtWjx48ACDBg3Se7tr1qyRvV61ahUASOt6+eWXYWVlhdmzZxe7ElcIgX///bfcbdy8ebPYsp06dQIAaDQaAMDgwYNRWFiI1atXy+KWLVsGCwuLSuVWnqFDh0IIUeLV1uVddWxlZYWhQ4fi22+/LfGPHX///bf0/8GDB+P69ev45ptvpGl5eXml3uKlujy6rxQKBdq2bQshhHQ8GfL8wRDHzqNUKhWuXbuGH374QZp2//79Es/VSqstUO3GK86JzEDjxo0RFRWF2bNnY+DAgXjhhReQlpaGjz/+GM8884z0QIvWrVujRYsWeO+993Dt2jUolUp8++23Zn3PLF2x4J133oFKpYKVlRWCgoKqtM7u3bvD2dkZISEheOedd2BhYYH//ve/JZ6M+Pj44Ouvv0ZkZCSeeeYZ1K9fH88//zzeeOMNbNmyBWPHjsW+ffvQo0cPFBYW4vz589iyZQt2795d4kN0iIjI+GrCOOnh4YGFCxfi8uXLePLJJ/H1118jJSUF69atk+65aYix56OPPkJCQgL69OmDsLAwtGnTBjdu3MDWrVtx6NAhODk5YfLkyfjhhx/w3HPP4c0334SPjw/u3r2L06dP45tvvsHly5fRqFEjvfKrjvG8IlauXImePXvi6aefRlhYGLy9vXH58mXs3LkTKSkpAIAPP/wQarUaPXv2xNtvvw1ra2t88skn0Gg0iImJMVhb+vTpgzFjxmD+/PlISUlBQEAAbGxscPHiRWzduhUrVqyQPaiNiMjUyhszdPLz89G/f38MGzZMGl979uwpe2BiRaWnp+OFF17AwIEDkZiYiP/7v//D8OHD8dRTTwF4eNXwhx9+iKioKFy+fBlDhgxBgwYNkJ6ejm3btiEsLAzvvfdemdv44osv8PHHH+Oll15CixYtcPv2bXz66adQKpXSVfLPP/88+vXrhw8++ACXL1/GU089hYSEBHz//feYOHGi7EGghtKvXz+88cYbWLlyJS5evIiBAwdCq9Xil19+Qb9+/RAREVHm8gsWLMC+ffvg6+uL0aNHo23btsjOzsavv/6Kn3/+GdnZ2QAePhx99erVGDFiBJKTk+Hu7o7//ve/cHBwMHhOZQkICICbmxt69OgBV1dXnDt3DqtXr0ZgYKB0lb/u/OGDDz5AUFAQbGxs8Pzzzxd7LkxFGOLYedSYMWOwevVqvPbaa5gwYQLc3d2xadMm2NnZAZBfZV5abYFqOUFEJrFhwwYBQKSnp0vTVq9eLVq3bi1sbGyEq6urGDdunLh586ZsubNnzwp/f39Rv3590ahRIzF69Gjx22+/CQBiw4YNUlxISIioV69ese3OmjVL6PurHxISIry8vKTX6enpAoBYtGhRsVgAYtasWdLrBw8eiPHjx4vGjRsLCwsLvbbdp08f0a5duxLnHT58WHTr1k3Y29sLDw8PMWXKFLF7924BQOzbt0+Ku3Pnjhg+fLhwcnISAGR55Ofni4ULF4p27doJW1tb4ezsLHx8fMTs2bPFrVu3KtxOIiIyvJo0TurGqxMnTgg/Pz9hZ2cnvLy8xOrVq4vFVnTsASDCw8NL3N6VK1fEiBEjROPGjYWtra14/PHHRXh4uNBoNFLM7du3RVRUlGjZsqVQKBSiUaNGonv37mLx4sUiPz9fCGG88bwq5xFCCJGamipeeukl4eTkJOzs7ESrVq3EjBkzZDG//vqrUKlUon79+sLBwUH069dPHDlyRBajO6aOHz8um67b53///Xexdpd0jKxbt074+PgIe3t70aBBA9GhQwcxZcoUcf369Yp0BxGRUZU1ZujeFw8cOCDCwsKEs7OzqF+/vggODhb//vuvXtvRvZeePXtW/Oc//xENGjQQzs7OIiIiQty7d69Y/Lfffit69uwp6tWrJ+rVqydat24twsPDRVpamhRT2ufBX3/9Vbz22muiWbNmwtbWVjRp0kQ899xz4sSJE7K427dvi0mTJgkPDw9hY2MjnnjiCbFo0SKh1WplcaWNuV5eXiIkJESvfnjw4IFYtGiRaN26tVAoFKJx48Zi0KBBIjk5udztCSFEZmamCA8PF56ensLGxka4ubmJ/v37i3Xr1snirly5Il544QXh4OAgGjVqJCZMmCDi4+OLfR4uT2lj4759+4qtq0+fPqJPnz7S608++UT07t1bNGzYUNja2ooWLVqIyZMnF/ssPXfuXPHYY48JS0vLYud2ZSntnKwqx86j5yRCCHHp0iURGBgo7O3tRePGjcW7774rvv32WwFAHD16VIorrbag66utW7fK1qs73yl6/kk1j4UQvEs9EREREVFl9e3bF//880+F7iNLRERUG0VHR2P27Nn4+++/9f5WE5G5Wb58OSZNmoS//voLjz32mKmbQybEe5wTERERERERERFRnXPv3j3Z6/v37+OTTz7BE088waI58R7nRHVZdnY28vPzS51vZWWFxo0b15rtEhER6YPjVdnYP0REtd+dO3dw586dMmNq+3t9YWGh7OGcJalfvz7q169vpBaV7969e+U+yNLFxQUKhcJILfqfW7duFStWP8rNzc1IrXn40NFmzZqhU6dOuHXrFv7v//4P58+fx6ZNm4zWBjJfLJwT1WEvv/wyDhw4UOp8Ly8vXL58udZsl4iISB8cr8rG/iEiqv0WL16M2bNnlxmTnp5upNaYxp9//glvb+8yY2bNmoXo6GjjNKgCvv76a4wcObLMmH379qFv377GaVAREyZMwBdffFFmjDHvKq1SqfDZZ59h06ZNKCwsRNu2bbF582a8+uqrRmsDmS/e45yoDktOTsbNmzdLnW9vb48ePXrUmu0SERHpg+NV2dg/RES136VLl3Dp0qUyY3r27Ak7Ozsjtcj47t+/j0OHDpUZ8/jjj+Pxxx83UovKd+PGDZw5c6bMGB8fHzg7OxupRf9z9uxZXL9+vcwYf39/I7WGqGwsnBMRERERERERERERFVEtt2q5du0apk6dip9++gl5eXlo2bIlNmzYgC5dugB4+JWLWbNm4dNPP0VOTg569OiBtWvX4oknnpDWkZ2djfHjx+PHH3+EpaUlhg4dihUrVsjuGXXq1CmEh4fj+PHjaNy4McaPH48pU6ZUuJ1arRbXr19HgwYNYGFhYbgOICIiqgIhBG7fvg0PDw9YWvI53hyviYjIHHG8Lo5jNhERmaPKjtkGL5zfvHkTPXr0QL9+/fDTTz+hcePGuHjxouzrHzExMVi5ciW++OILeHt7Y8aMGVCpVDh79qz09Z7g4GDcuHEDarUaBQUFGDlyJMLCwhAXFwcAyM3NRUBAAPz9/REbG4vTp09j1KhRcHJyQlhYWIXaev36dXh6ehq6C4iIiAzizz//RNOmTU3dDJPjeE1EROaM4/X/cMwmIiJzpu+YbfBbtUybNg2HDx/GL7/8UuJ8IQQ8PDzw7rvv4r333gPw8Im6rq6u2LhxI4KCgnDu3Dm0bdsWx48fl65Sj4+Px+DBg/HXX3/Bw8MDa9euxQcffICMjAzpKcDTpk3D9u3bcf78+RK3rdFooNFopNe3bt1Cs2bNkJ6ejgYNGpSaU0FBAfbt24d+/frBxsamUv1ijphXzcK8apbamhdQe3Mzp7xu374Nb29v5OTkwNHR0aRtMQe3bt2Ck5MT/vzzTyiVyiqtq6CgAAkJCQgICDD5fq4r2OfGxz43Pva58ZlDn+fm5sLT05PjdRGGHLNrAnM4Ds0N+6Q49klx7BM59kdxhu6Tyo7ZBr/i/IcffoBKpcIrr7yCAwcO4LHHHsPbb7+N0aNHA3j4tOWMjAzZjf4dHR3h6+uLxMREBAUFITExEU5OTlLRHHj4YABLS0skJSXhpZdeQmJiInr37i0VzYGHT8JduHAhbt68WeIDDubPn1/i06ATExPh4OBQZl4ODg5ISkrSuz/MHfOqWZhXzVJb8wJqb27mkldeXh4A8CvO/5+uH5RKpUEK5w4ODlAqlTwpNRL2ufGxz42PfW585tTnHK//x5Bjdk1gTsehuWCfFMc+KY59Isf+KK66+kTfMdvghfNLly5h7dq1iIyMxPvvv4/jx4/jnXfegUKhQEhICDIyMgAArq6usuVcXV2leRkZGWjSpIm8odbWcHFxkcV4e3sXW4duXkmF86ioKERGRkqvdX9tCAgIKHNQLygogFqtxoABA2rVAcy8ahbmVbPU1ryA2pubOeWVm5tr0u0TERERERER1XUGL5xrtVp06dIFH330EQCgc+fOSE1NRWxsLEJCQgy9Ob3Y2trC1ta22HQbG5sKFUkqGlfTMK+ahXnVLLU1L6D25mYOeZl6+0RERERERER1ncEf/e3u7o62bdvKprVp0wZXr14FALi5uQEAMjMzZTGZmZnSPDc3N2RlZcnmP3jwANnZ2bKYktZRdBtERERERERERERERPoyeOG8R48eSEtLk027cOECvLy8AADe3t5wc3PDnj17pPm5ublISkqCn58fAMDPzw85OTlITk6WYvbu3QutVgtfX18p5uDBgygoKJBi1Go1WrVqVeJtWoiIiIiIiIiIiIiIKsLghfNJkybh6NGj+Oijj/D7778jLi4O69atQ3h4OICHN2GfOHEiPvzwQ/zwww84ffo0RowYAQ8PDwwZMgTAwyvUBw4ciNGjR+PYsWM4fPgwIiIiEBQUBA8PDwDA8OHDoVAoEBoaijNnzuDrr7/GihUrZPcwJyIiIiIiIiIiIiLSl8Hvcf7MM89g27ZtiIqKwpw5c+Dt7Y3ly5cjODhYipkyZQru3r2LsLAw5OTkoGfPnoiPj4ednZ0Us2nTJkRERKB///6wtLTE0KFDsXLlSmm+o6MjEhISEB4eDh8fHzRq1AgzZ85EWFiYoVOq8ZpP21nidFsrgZiuQPvo3dAUyp8qe3lBoDGaRkREREWUNmaXhWM2ERHR/3AsJSIiQzF44RwAnnvuOTz33HOlzrewsMCcOXMwZ86cUmNcXFwQFxdX5nY6duyIX375pdLtJCIiIiIiIiLzVJkiOBERkaFUS+GciIiIiIiIiKgm0LdAzyvUiYjqBoPf45yIiIiIiIiIiIiIqCZj4ZyIiIiIiIiIiIiIqAgWzomIiIiIiIiIiIiIimDhnIiIiIiIiIiIiIioCBbOiYiI6qDCwkLMmDED3t7esLe3R4sWLTB37lwIIaQYIQRmzpwJd3d32Nvbw9/fHxcvXpStJzs7G8HBwVAqlXByckJoaCju3Lkjizl16hR69eoFOzs7eHp6IiYmxig5EhER1QQHDx7E888/Dw8PD1hYWGD79u2y+cYcj7du3YrWrVvDzs4OHTp0wK5duwyeLxERUU3BwjkREVEdtHDhQqxduxarV6/GuXPnsHDhQsTExGDVqlVSTExMDFauXInY2FgkJSWhXr16UKlUuH//vhQTHByMM2fOQK1WY8eOHTh48CDCwsKk+bm5uQgICICXlxeSk5OxaNEiREdHY926dUbNl4iIyFzdvXsXTz31FNasWVPifGONx0eOHMFrr72G0NBQnDx5EkOGDMGQIUOQmppafckTERGZMWtTN4CIiIiM78iRI3jxxRcRGBgIAGjevDm++uorHDt2DMDDq9uWL1+O6dOn48UXXwQAfPnll3B1dcX27dsRFBSEc+fOIT4+HsePH0eXLl0AAKtWrcLgwYOxePFieHh4YNOmTcjPz8f69euhUCjQrl07pKSkYOnSpbIP9ERERHXVoEGDMGjQoBLnGXM8XrFiBQYOHIjJkycDAObOnQu1Wo3Vq1cjNjbWCD1BRERkXlg4JyIiqoO6d++OdevW4cKFC3jyySfx22+/4dChQ1i6dCkAID09HRkZGfD395eWcXR0hK+vLxITExEUFITExEQ4OTlJH9IBwN/fH5aWlkhKSsJLL72ExMRE9O7dGwqFQopRqVRYuHAhbt68CWdn52Jt02g00Gg00uvc3FwAQEFBAQoKCqqUt275qq6nuthaifKDHmGuueiYe5/XRuxz42OfG5859Lkxtm3M8TgxMRGRkZGy7atUqmK3jimqOsdsoHLjojE8evzxd/9/2CfFsU+KY5/IsT+KM3SfVHY9LJwTERHVQdOmTUNubi5at24NKysrFBYWYt68eQgODgYAZGRkAABcXV1ly7m6ukrzMjIy0KRJE9l8a2truLi4yGK8vb2LrUM3r6TC+fz58zF79uxi0xMSEuDg4FCZdItRq9UGWY+hxXTVf5macv9Zc+3z2ox9bnzsc+MzZZ/n5eVV+zaMOR5nZGSUuZ2SVPeYXZlx0RgeHXv5u18c+6Q49klx7BM59kdxhuqTyo7ZLJwTERHVQVu2bMGmTZsQFxcnfV174sSJ8PDwQEhIiEnbFhUVJbviLTc3F56enggICIBSqazSugsKCqBWqzFgwADY2NhUtallah+9u1rXr5MarTLKdirLmH1OD7HPjY99bnzm0Oe6q6vrsuocswHjjaX60o295nAcmhv2SXHsk+LYJ3Lsj+IM3SeVHbNZOCciIqqDJk+ejGnTpiEoKAgA0KFDB1y5cgXz589HSEgI3NzcAACZmZlwd3eXlsvMzESnTp0AAG5ubsjKypKt98GDB8jOzpaWd3NzQ2ZmpixG91oX8yhbW1vY2toWm25jY2OwE0lDrqs0mkKLal2/Tk05uTZGn5Mc+9z42OfGZ8o+N8Z2jTkelxZT2ngNVP+YbayxVF+P5sbf/eLYJ8WxT4pjn8ixP4ozVJ9Udh2WVd4yERER1Th5eXmwtJSfBlhZWUGr1QIAvL294ebmhj179kjzc3NzkZSUBD8/PwCAn58fcnJykJycLMXs3bsXWq0Wvr6+UszBgwdl95RTq9Vo1apVibdpISIiov8x5njs5+cn244uRrcdIiKiuoaFcyIiojro+eefx7x587Bz505cvnwZ27Ztw9KlS/HSSy8BACwsLDBx4kR8+OGH+OGHH3D69GmMGDECHh4eGDJkCACgTZs2GDhwIEaPHo1jx47h8OHDiIiIQFBQEDw8PAAAw4cPh0KhQGhoKM6cOYOvv/4aK1asKPbwMSIiorrqzp07SElJQUpKCoCHDwRNSUnB1atXjToeT5gwAfHx8ViyZAnOnz+P6OhonDhxAhEREcbuEiIiIrPAW7UQERHVQatWrcKMGTPw9ttvIysrCx4eHhgzZgxmzpwpxUyZMgV3795FWFgYcnJy0LNnT8THx8POzk6K2bRpEyIiItC/f39YWlpi6NChWLlypTTf0dERCQkJCA8Ph4+PDxo1aoSZM2ciLCzMqPkSERGZqxMnTqBfv37Sa10xOyQkBBs3bjTaeNy9e3fExcVh+vTpeP/99/HEE09g+/btaN++vRF6gYiIyPywcE5ERFQHNWjQAMuXL8fy5ctLjbGwsMCcOXMwZ86cUmNcXFwQFxdX5rY6duyIX375pbJNJSIiqtX69u0LIUSp8405Hr/yyit45ZVXym4wERFRHcHCOdUJzaft1Cv+8oLAamoJERERERERERERmTve45yIiIiIiIiIiIiIqAgWzomIiIiIiIiIiIiIimDhnIiIiIiIiIiIiIioCBbOiYiIiIiIiIiIiIiKYOGciIiIiIiIiIiIiKgIFs6JiIiIiIiIiIiIiIqwNnUDiGqL5tN26r3M5QWB1dASIiIiIiIiIiIiqgpecU5EREREREREREREVAQL50RERERERERERERERbBwTkRERERERERERERUBAvnRERERERERERERERFsHBORERERERERERERFQEC+dEREREREREREREREWwcE5EREREREREREREVIS1qRtARERERMbVfNpOveIvLwisppYQERERERGZJ15xTkRERERERERERERUBAvnRERERERERERERERFsHBORERERERERERERFQEC+dEREREREREREREREWwcE5ERERERERkpgoLCzFjxgx4e3vD3t4eLVq0wNy5cyGEkGKEEJg5cybc3d1hb28Pf39/XLx4Ubae7OxsBAcHQ6lUwsnJCaGhobhz544s5tSpU+jVqxfs7Ozg6emJmJgYo+RIRERkjlg4JyIiIiIiIjJTCxcuxNq1a7F69WqcO3cOCxcuRExMDFatWiXFxMTEYOXKlYiNjUVSUhLq1asHlUqF+/fvSzHBwcE4c+YM1Go1duzYgYMHDyIsLEyan5ubi4CAAHh5eSE5ORmLFi1CdHQ01q1bZ9R8iYiIzIW1qRtARERERERERCU7cuQIXnzxRQQGBgIAmjdvjq+++grHjh0D8PBq8+XLl2P69Ol48cUXAQBffvklXF1dsX37dgQFBeHcuXOIj4/H8ePH0aVLFwDAqlWrMHjwYCxevBgeHh7YtGkT8vPzsX79eigUCrRr1w4pKSlYunSprMBelEajgUajkV7n5uYCAAoKClBQUFDl3G2tRPlBJqDL7dF/iX1SEvZJcewTOfZHcYbuk8quh4VzIiIiIiIiIjPVvXt3rFu3DhcuXMCTTz6J3377DYcOHcLSpUsBAOnp6cjIyIC/v7+0jKOjI3x9fZGYmIigoCAkJibCyclJKpoDgL+/PywtLZGUlISXXnoJiYmJ6N27NxQKhRSjUqmwcOFC3Lx5E87OzsXaNn/+fMyePbvY9ISEBDg4OFQ595iuVV5Ftdi1a5fstVqtNlFLzBf7pDj2SXHsEzn2R3GG6pO8vLxKLcfCOREREREREZGZmjZtGnJzc9G6dWtYWVmhsLAQ8+bNQ3BwMAAgIyMDAODq6ipbztXVVZqXkZGBJk2ayOZbW1vDxcVFFuPt7V1sHbp5JRXOo6KiEBkZKb3Ozc2Fp6cnAgICoFQqq5I2AKB99O4qr6M6pEarADy8glGtVmPAgAGwsbExcavMA/ukOPZJcewTOfZHcYbuE903ovTFwjkRERERERGRmdqyZQs2bdqEuLg46fYpEydOhIeHB0JCQkzaNltbW9ja2habbmNjY5BCh6bQosrrqA6P5maofGsT9klx7JPi2Cdy7I/iDNUnlV0HC+dEREREREREZmry5MmYNm0agoKCAAAdOnTAlStXMH/+fISEhMDNzQ0AkJmZCXd3d2m5zMxMdOrUCQDg5uaGrKws2XofPHiA7OxsaXk3NzdkZmbKYnSvdTFERER1iaWpG0BERESmce3aNbz++uto2LAh7O3t0aFDB5w4cUKaL4TAzJkz4e7uDnt7e/j7++PixYuydWRnZyM4OBhKpRJOTk4IDQ3FnTt3ZDGnTp1Cr169YGdnB09PT8TExBglPyIiotogLy8Plpbyj+5WVlbQarUAAG9vb7i5uWHPnj3S/NzcXCQlJcHPzw8A4Ofnh5ycHCQnJ0sxe/fuhVarha+vrxRz8OBB2QPU1Go1WrVqVeJtWoiIiGo7Fs6JiIjqoJs3b6JHjx6wsbHBTz/9hLNnz2LJkiWyD8YxMTFYuXIlYmNjkZSUhHr16kGlUuH+/ftSTHBwMM6cOQO1Wo0dO3bg4MGDCAsLk+bn5uYiICAAXl5eSE5OxqJFixAdHY1169YZNV8iIqKa6vnnn8e8efOwc+dOXL58Gdu2bcPSpUvx0ksvAQAsLCwwceJEfPjhh/jhhx9w+vRpjBgxAh4eHhgyZAgAoE2bNhg4cCBGjx6NY8eO4fDhw4iIiEBQUBA8PDwAAMOHD4dCoUBoaCjOnDmDr7/+GitWrJDdw5yIiKguqfZbtSxYsABRUVGYMGECli9fDgC4f/8+3n33XWzevBkajQYqlQoff/yx7GEmV69exbhx47Bv3z7Ur18fISEhmD9/Pqyt/9fk/fv3IzIyEmfOnIGnpyemT5+ON998s7pTIiIiqvEWLlwIT09PbNiwQZpW9IFgQggsX74c06dPx4svvggA+PLLL+Hq6ort27cjKCgI586dQ3x8PI4fP44uXboAAFatWoXBgwdj8eLF8PDwwKZNm5Cfn4/169dDoVBI92ZdunSprMBO5q35tJ16L3N5QWA1tISIqO5ZtWoVZsyYgbfffhtZWVnw8PDAmDFjMHPmTClmypQpuHv3LsLCwpCTk4OePXsiPj4ednZ2UsymTZsQERGB/v37w9LSEkOHDsXKlSul+Y6OjkhISEB4eDh8fHzQqFEjzJw5k+M1ERHVWdVaOD9+/Dg++eQTdOzYUTZ90qRJ2LlzJ7Zu3QpHR0dERETg5ZdfxuHDhwEAhYWFCAwMhJubG44cOYIbN25gxIgRsLGxwUcffQQASE9PR2BgIMaOHYtNmzZhz549eOutt+Du7g6VSlWdaREREdV4P/zwA1QqFV555RUcOHAAjz32GN5++22MHj0awMNxNiMjA/7+/tIyjo6O8PX1RWJiIoKCgpCYmAgnJyepaA4A/v7+sLS0RFJSEl566SUkJiaid+/eUCgUUoxKpcLChQtx8+bNEr/6rdFooNFopNe6J6AXFBTIvj5eGbrlq7qeirC1EtW+DaByuRijbY/2tTH6nB5inxsf+9z4zKHPjbXtBg0aYPny5dKFaCWxsLDAnDlzMGfOnFJjXFxcEBcXV+a2OnbsiF9++aWyTSUiIqpVqq1wfufOHQQHB+PTTz/Fhx9+KE2/desWPv/8c8TFxeHZZ58FAGzYsAFt2rTB0aNH0a1bNyQkJODs2bP4+eef4erqik6dOmHu3LmYOnUqoqOjoVAoEBsbC29vbyxZsgTAw6+eHTp0CMuWLWPhnIiIqByXLl3C2rVrERkZiffffx/Hjx/HO++8A4VCgZCQEGRkZACA7Ntgute6eRkZGWjSpIlsvrW1NVxcXGQxRa9kL7rOjIyMEgvn8+fPx+zZs4tNT0hIgIODQyUzllOr1QZZT1liulb7JgAAu3bt0nsZY7Tt0XYZo89Jjn1ufOxz4zNln+fl5Zls20RERFT9qq1wHh4ejsDAQPj7+8sK58nJySgoKJBdwda6dWs0a9YMiYmJ6NatGxITE9GhQwfZh3WVSoVx48bhzJkz6Ny5MxITE2Xr0MVMnDix1DZV9go2c7iaoSpKu6rM1lLI/i2qpuYKlLy/9L2yzlhX7+mznZp+HJaGedU8tTU3c8rLGG3QarXo0qWL9E2uzp07IzU1FbGxsQgJCan27ZclKipKdj/V3NxceHp6IiAgAEqlskrrLigogFqtxoABA2BjY1PVppapffTual2/Tmq0/hcMGKNtunYZs8/pIfa58bHPjc8c+lz3eZKIiIhqp2opnG/evBm//vorjh8/XmxeRkYGFAoFnJycZNMfvYKtpCvcdPPKisnNzcW9e/dgb29fbNtVvYKtpl5BUt5VZXO7aItNq8zVa+am6P7S98o6Y129V5nt1NTjsDzMq+aprbmZQ17GuILN3d0dbdu2lU1r06YNvv32WwCAm5sbACAzMxPu7u5STGZmJjp16iTFZGVlydbx4MEDZGdnS8u7ubkhMzNTFqN7rYt5lK2tLWxtbYtNt7GxMVhxxJDrKo2m0KJa169TmTyM0bZH22WMPic59rnxsc+Nz5R9zn1NRERUuxm8cP7nn39iwoQJUKvVsgeRmIPKXsFmDlczVEVpV5XZWgrM7aLFjBOW0GjlH6Arc/WauShpf+l7ZZ2xrt7TZztVOQ6ru21VUdN/v0pTW/MCam9u5pSXMa5g69GjB9LS0mTTLly4AC8vLwAPHxTq5uaGPXv2SIXy3NxcJCUlYdy4cQAAPz8/5OTkIDk5GT4+PgCAvXv3QqvVwtfXV4r54IMPUFBQIPWrWq1Gq1atSrxNCxEREREREZE5MHjhPDk5GVlZWXj66aelaYWFhTh48CBWr16N3bt3Iz8/Hzk5ObKrzjMzM2VXpx07dky23kevTivtCjalUlni1eZA1a9gq6lXkJR3VZlGa1Espibm+aii+0vfK+uemJFQiS3qf/VeZfq5MsdhZa4sNPYxUFN/v8pTW/MCam9u5pCXMbY/adIkdO/eHR999BGGDRuGY8eOYd26dVi3bh2Ahw8ZmzhxIj788EM88cQT8Pb2xowZM+Dh4YEhQ4YAeHiF+sCBAzF69GjExsaioKAAERERCAoKgoeHBwBg+PDhmD17NkJDQzF16lSkpqZixYoVWLZsWbXnSERERERERFRZBi+c9+/fH6dPn5ZNGzlyJFq3bo2pU6fC09MTNjY22LNnD4YOHQoASEtLw9WrV+Hn5wfg4dVp8+bNQ1ZWlvTQMbVaDaVSKX2t3M/Pr8SHTunWUZs1n7bT1E0gIqIa7plnnsG2bdsQFRWFOXPmwNvbG8uXL0dwcLAUM2XKFNy9exdhYWHIyclBz549ER8fL/tG2aZNmxAREYH+/fvD0tISQ4cOxcqVK6X5jo6OSEhIQHh4OHx8fNCoUSPMnDkTYWFhRs23NuN5ARERERERkeEZvHDeoEEDtG/fXjatXr16aNiwoTQ9NDQUkZGRcHFxgVKpxPjx4+Hn54du3boBAAICAtC2bVu88cYbiImJQUZGBqZPn47w8HDpivGxY8di9erVmDJlCkaNGoW9e/diy5Yt2LmTHx6JiIgq4rnnnsNzzz1X6nwLCwvMmTMHc+bMKTXGxcUFcXFxZW6nY8eO+OWXXyrdTiIiIiIiIiJjq5aHg5Zn2bJl0lVpGo0GKpUKH3/8sTTfysoKO3bswLhx4+Dn54d69eohJCRE9sHd29sbO3fuxKRJk7BixQo0bdoUn332GVSqmntvbiIiIiIiIiIiIiIyPaMUzvfv3y97bWdnhzVr1mDNmjWlLuPl5VXsViyP6tu3L06ePGmIJhIRERERERERERERAQAsTd0AIiIiIiIiIiIiIiJzwsI5EREREREREREREVERLJwTERERERERERERERXBwjkRERERERERERERUREsnBMRERERERERERERFcHCORERERERERERERFREdambgCRvppP21nmfFsrgZiuQPvo3dAUWhipVURERFSUbrzWZ1y+vCDQGE0jIiIiIiIqF684JyIiIiIiIiIiIiIqglecU4nKu6q7JLxKjIiIiIiIiIiIiGoDXnFORERERERERERERFQEC+dEREREREREZuzatWt4/fXX0bBhQ9jb26NDhw44ceKENF8IgZkzZ8Ld3R329vbw9/fHxYsXZevIzs5GcHAwlEolnJycEBoaijt37shiTp06hV69esHOzg6enp6IiYkxSn5ERETmiLdqISIiIipHZW5hRkREZAg3b95Ejx490K9fP/z0009o3LgxLl68CGdnZykmJiYGK1euxBdffAFvb2/MmDEDKpUKZ8+ehZ2dHQAgODgYN27cgFqtRkFBAUaOHImwsDDExcUBAHJzcxEQEAB/f3/Exsbi9OnTGDVqFJycnBAWFmaS3ImIiEyJhXOiGqZ99G5oCi1M3QwiIiIiIjKChQsXwtPTExs2bJCmeXt7S/8XQmD58uWYPn06XnzxRQDAl19+CVdXV2zfvh1BQUE4d+4c4uPjcfz4cXTp0gUAsGrVKgwePBiLFy+Gh4cHNm3ahPz8fKxfvx4KhQLt2rVDSkoKli5dysI5ERHVSSycExEREREREZmpH374ASqVCq+88goOHDiAxx57DG+//TZGjx4NAEhPT0dGRgb8/f2lZRwdHeHr64vExEQEBQUhMTERTk5OUtEcAPz9/WFpaYmkpCS89NJLSExMRO/evaFQKKQYlUqFhQsX4ubNm7Ir3HU0Gg00Go30Ojc3FwBQUFCAgoKCKuduayWqvI7qoMvt0X+JfVIS9klx7BM59kdxhu6Tyq6HhXMiIiIiIiIiM3Xp0iWsXbsWkZGReP/993H8+HG88847UCgUCAkJQUZGBgDA1dVVtpyrq6s0LyMjA02aNJHNt7a2houLiyym6JXsRdeZkZFRYuF8/vz5mD17drHpCQkJcHBwqGTG/xPTtcqrqBa7du2SvVar1SZqiflinxTHPimOfSLH/ijOUH2Sl5dXqeVYOCciIiIiIiIyU1qtFl26dMFHH30EAOjcuTNSU1MRGxuLkJAQk7YtKioKkZGR0uvc3Fx4enoiICAASqWyyutvH727yuuoDqnRKgAPr2BUq9UYMGAAbGxsTNwq88A+KY59Uhz7RI79UZyh+0T3jSh9sXBOREREREREZKbc3d3Rtm1b2bQ2bdrg22+/BQC4ubkBADIzM+Hu7i7FZGZmolOnTlJMVlaWbB0PHjxAdna2tLybmxsyMzNlMbrXuphH2drawtbWtth0GxsbgxQ6zPXZTo/mZqh8axP2SXHsk+LYJ3Lsj+IM1SeVXYdllbdMRERERERERNWiR48eSEtLk027cOECvLy8ADx8UKibmxv27Nkjzc/NzUVSUhL8/PwAAH5+fsjJyUFycrIUs3fvXmi1Wvj6+koxBw8elN0HVq1Wo1WrViXepoWIiKi2Y+GciIiIiIiIyExNmvT/2rvz8KiqPP/jnyQkFZYEBDoJNAGjjizNooCQkm4aARPt2ErDM7bKICjogIVDiK2Ag6y2YVAbNxZbkDBPiwg+0iphIGFJbCS0GmBk0YwgGqch4VGHBAlUiuT8/vCXMkU2qqg1eb+e5z5Q95576ny/91ad3JObc2dq3759euaZZ3Ts2DGtX79ef/7zn2Wz2SRJYWFhSk9P19NPP6333ntPhw4d0v3336+uXbtqzJgxkn68Q/22227TQw89pI8++kgffvihpk+frnvuuUddu3aVJN13332KiorS5MmTdeTIEb311lt68cUXXaZiAQCgJWGqFgAAAAAAgtRNN92kzZs3a86cOVq0aJGSkpL0wgsvaPz48c4yTzzxhM6dO6eHH35YZ86c0S9/+Utt27ZN0dHRzjJvvPGGpk+frlGjRik8PFzjxo3TSy+95Nzevn175eTkyGazadCgQercubPmzZunhx9+2K/xAgAQLBg4BwLo6tnZl13WEmGC9qnyAAAAAHznjjvu0B133NHg9rCwMC1atEiLFi1qsEzHjh21fv36Rt+nf//++tvf/uZxOwEAaE6YqgUAAAAAAAAAgFoYOAcAAAAAAAAAoBYGzgEAAAAAAAAAqIWBcwAAAAAAAAAAamHgHAAAAAAAAACAWloFugEAgtPVs7Pd3uerJWk+aAkAf1iyZInmzJmjGTNm6IUXXpAkXbhwQY899pg2bNggu92u1NRUrVixQvHx8c79iouLNW3aNO3evVvt2rXTxIkTlZmZqVatfvoRIy8vTxkZGTpy5IgSExM1d+5cTZo0yc8RAgAAAABw+bjjHACAFu7jjz/Wq6++qv79+7usnzlzpt5//31t2rRJ+fn5OnnypMaOHevcXlVVpbS0NFVWVmrv3r1at26dsrKyNG/ePGeZEydOKC0tTbfccosOHjyo9PR0TZkyRdu3b/dbfAAAAAAAuIs7zgEAaMF++OEHjR8/Xq+99pqefvpp5/qysjKtWbNG69ev18iRIyVJa9euVe/evbVv3z4lJycrJydHR48e1Y4dOxQfH68bbrhBixcv1qxZs7RgwQJFRUVp1apVSkpK0vPPPy9J6t27t/bs2aNly5YpNTW13jbZ7XbZ7Xbn6/LyckmSw+GQw+G4onhr9ne3HkuEuaL3bcks4cbl38Zc6fHFjzw9z+E5cu5/wZBzjjcAAM0bA+cAALRgNptNaWlpGj16tMvAeWFhoRwOh0aPHu1c16tXL3Xv3l0FBQVKTk5WQUGB+vXr5zJ1S2pqqqZNm6YjR47oxhtvVEFBgUsdNWXS09MbbFNmZqYWLlxYZ31OTo7atGlzBdH+JDc3163yS4d45W1btMWDq5sss3XrVj+0pOVw9zzHlSPn/hfInFdUVATsvQEAgO8xcA6vYU5sAAgtGzZs0P79+/Xxxx/X2VZSUqKoqCh16NDBZX18fLxKSkqcZWoPmtdsr9nWWJny8nKdP39erVu3rvPec+bMUUZGhvN1eXm5EhMTlZKSotjYWPcDrcXhcCg3N1e33nqrIiMjL3u/vguYWsZTlnCjxYOr9dQn4bJXhzVa9vCC+v8KAe7x9DyH58i5/wVDzmv+IgoAADRPDJwDANACffPNN5oxY4Zyc3MVHR0d6Oa4sFgsslgsddZHRkZ6bXDE3brsVY0P+KJp9uqwJvPIgKN3efMzg8tDzv0vkDnnWAMA0LzxcFAAAFqgwsJCnT59WgMHDlSrVq3UqlUr5efn66WXXlKrVq0UHx+vyspKnTlzxmW/0tJSJSQkSJISEhJUWlpaZ3vNtsbKxMbG1nu3OQAAAAAAwYCBcwAAWqBRo0bp0KFDOnjwoHMZPHiwxo8f7/x/ZGSkdu7c6dynqKhIxcXFslqtkiSr1apDhw7p9OnTzjK5ubmKjY1Vnz59nGVq11FTpqYOAAAAAACCEVO1AADQAsXExKhv374u69q2batOnTo510+ePFkZGRnq2LGjYmNj9eijj8pqtSo5OVmSlJKSoj59+mjChAlaunSpSkpKNHfuXNlsNudUK1OnTtUrr7yiJ554Qg8++KB27dqljRs3Kjvb/ediAAAAAADgLwycexEPxwQANCfLli1TeHi4xo0bJ7vdrtTUVK1YscK5PSIiQlu2bNG0adNktVrVtm1bTZw4UYsWLXKWSUpKUnZ2tmbOnKkXX3xR3bp10+rVq5WaykMgAQAAAADBi4FzAAAgScrLy3N5HR0dreXLl2v58uUN7tOjRw9t3bq10XpHjBihAwcOeKOJAAAAAAD4BXOcAwAAAAAAAABQCwPnAAAAAAAAAADUwsA5AAAAAAAAAAC1MHAOAAAAAAAAAEAtDJwDAAAAABAilixZorCwMKWnpzvXXbhwQTabTZ06dVK7du00btw4lZaWuuxXXFystLQ0tWnTRnFxcXr88cd18eJFlzJ5eXkaOHCgLBaLrrvuOmVlZfkhIgAAghMD5wAAAAAAhICPP/5Yr776qvr37++yfubMmXr//fe1adMm5efn6+TJkxo7dqxze1VVldLS0lRZWam9e/dq3bp1ysrK0rx585xlTpw4obS0NN1yyy06ePCg0tPTNWXKFG3fvt1v8QEAEExaBboBAAAAAACgcT/88IPGjx+v1157TU8//bRzfVlZmdasWaP169dr5MiRkqS1a9eqd+/e2rdvn5KTk5WTk6OjR49qx44dio+P1w033KDFixdr1qxZWrBggaKiorRq1SolJSXp+eeflyT17t1be/bs0bJly5Samlpvm+x2u+x2u/N1eXm5JMnhcMjhcFxxzJYIc8V1+EJNbJf+C3JSH3JSFzlxRT7q8nZOPK2HgXMAAAAAAIKczWZTWlqaRo8e7TJwXlhYKIfDodGjRzvX9erVS927d1dBQYGSk5NVUFCgfv36KT4+3lkmNTVV06ZN05EjR3TjjTeqoKDApY6aMrWnhLlUZmamFi5cWGd9Tk6O2rRpcwXR/mjpkCuuwie2bt3q8jo3NzdALQle5KQuclIXOXFFPuryVk4qKio82s/rA+eZmZl655139Pnnn6t169a6+eab9R//8R/q2bOns8yFCxf02GOPacOGDbLb7UpNTdWKFStcOvHi4mJNmzZNu3fvVrt27TRx4kRlZmaqVaufmpyXl6eMjAwdOXJEiYmJmjt3riZNmuTtkAAAAAAACJgNGzZo//79+vjjj+tsKykpUVRUlDp06OCyPj4+XiUlJc4yta+3a7bXbGusTHl5uc6fP6/WrVvXee85c+YoIyPD+bq8vFyJiYlKSUlRbGys+4Feou+C4Jwm5vCCH+/Adzgcys3N1a233qrIyMgAtyo4kJO6yEld5MQV+ajL2zmp+Ysod3l94Dw/P182m0033XSTLl68qCeffFIpKSk6evSo2rZtK+nH+deys7O1adMmtW/fXtOnT9fYsWP14YcfSvpp/rWEhATt3btXp06d0v3336/IyEg988wzkn6af23q1Kl64403tHPnTk2ZMkVdunRp8M/IAAAA0LxcPTvb7X2+WpLmg5YAgG988803mjFjhnJzcxUdHR3o5riwWCyyWCx11kdGRnploMNeFXbFdfjCpbF5K97mhJzURU7qIieuyEdd3sqJp3V4feB827ZtLq+zsrIUFxenwsJCDR8+PKDzrwEAAAAAEEoKCwt1+vRpDRw40LmuqqpKH3zwgV555RVt375dlZWVOnPmjMtd56WlpUpISJAkJSQk6KOPPnKpt7S01Lmt5t+adbXLxMbG1nu3OQAAzZ3P5zgvKyuTJHXs2FFSYOdf8/TBJZc7Ib0nDy7p+e9b3N7HEuH2LvXXE25c/g0ETybnbyrPwRCXL4RCXJ4cz+b6EIzmGpfUfGMLpriCoQ0AACA4jBo1SocOHXJZ98ADD6hXr16aNWuWEhMTFRkZqZ07d2rcuHGSpKKiIhUXF8tqtUqSrFar/vjHP+r06dOKi4uT9OO8sbGxserTp4+zTH1zd9fUAQBAS+PTgfPq6mqlp6dr2LBh6tu3r6TAzr92pQ8uaWpC+mB9cElTFg+uDth7X/qD2eW43DwHMi5fCua4PDmeNZrrQzCaa1xS840tGOLy9MElAACg+YmJiXFeT9do27atOnXq5Fw/efJkZWRkqGPHjoqNjdWjjz4qq9Wq5ORkSVJKSor69OmjCRMmaOnSpSopKdHcuXNls9mcU61MnTpVr7zyip544gk9+OCD2rVrlzZu3KjsbPenxAIAoDnw6cC5zWbT4cOHtWfPHl++zWXz9MEllzshfbA+uKQhlnCjxYOr9dQn4bJXB2buuJqHqrijqTwHQ1y+EApxeXI8m+tDMJprXFLzjS2Y4vL0wSUAAKBlWrZsmcLDwzVu3DjZ7XalpqZqxYoVzu0RERHasmWLpk2bJqvVqrZt22rixIlatGiRs0xSUpKys7M1c+ZMvfjii+rWrZtWr17NVKgAgBbLZwPn06dP15YtW/TBBx+oW7duzvUJCQkBm3/tSh9c0lS5YH1wSVPs1WEBa7sng1OX29ZAxuVLwRzXlQw2NteHYDTXuKTmG1swxBXo9wcAAMEtLy/P5XV0dLSWL1+u5cuXN7hPjx49mvwL0REjRujAgQPeaCIAACHP6wPnxhg9+uij2rx5s/Ly8pSUlOSyfdCgQcy/BgAAAAAA4GVXz/bP1DpfLUnzy/sAQCB5feDcZrNp/fr1evfddxUTE+Ock7x9+/Zq3bq12rdvz/xrAAAAAAAAAICg5fWB85UrV0r68U+8alu7dq0mTZokifnXgObK3bsbuEsBAAAAQKipue6xRBgtHfLjc7iCdTpNX2no2q+xnHD9ByDU+GSqlqYw/xoAAAAAAAAAIFiFB7oBAAAAAAAAAAAEEwbOAQAAAAAAAACoxetTtQAAAACecPdZGQAAAADgK9xxDgAAAAAAAABALdxxDiCkeHI3Ik9vBwAAAAAAgDu44xwAAAAAAAAAgFq44xwAAAAtCn+9BAAAAKApDJwDCJirZ2fLEmG0dIjUd8F22avCAt0kAAAAAAAAgKlaAABoiTIzM3XTTTcpJiZGcXFxGjNmjIqKilzKXLhwQTabTZ06dVK7du00btw4lZaWupQpLi5WWlqa2rRpo7i4OD3++OO6ePGiS5m8vDwNHDhQFotF1113nbKysnwdHgAAAAAAV4SBcwAAWqD8/HzZbDbt27dPubm5cjgcSklJ0blz55xlZs6cqffff1+bNm1Sfn6+Tp48qbFjxzq3V1VVKS0tTZWVldq7d6/WrVunrKwszZs3z1nmxIkTSktL0y233KKDBw8qPT1dU6ZM0fbt2/0aLwAAAAAA7mCqFgAAWqBt27a5vM7KylJcXJwKCws1fPhwlZWVac2aNVq/fr1GjhwpSVq7dq169+6tffv2KTk5WTk5OTp69Kh27Nih+Ph43XDDDVq8eLFmzZqlBQsWKCoqSqtWrVJSUpKef/55SVLv3r21Z88eLVu2TKmpqfW2zW63y263O1+Xl5dLkhwOhxwOxxXFXbO/u/VYIswVvW9LZgk3Lv+Gqis99/zJ0/McniPn/hcMOed4AwDQvDFwDgAAVFZWJknq2LGjJKmwsFAOh0OjR492lunVq5e6d++ugoICJScnq6CgQP369VN8fLyzTGpqqqZNm6YjR47oxhtvVEFBgUsdNWXS09MbbEtmZqYWLlxYZ31OTo7atGlzJWE65ebmulV+6RCvvG2LtnhwdaCbcEW2bt0a6Ca4zd3zHFeOnPtfIHNeUVERsPcGAAC+x8A5AAAtXHV1tdLT0zVs2DD17dtXklRSUqKoqCh16NDBpWx8fLxKSkqcZWoPmtdsr9nWWJny8nKdP39erVu3rtOeOXPmKCMjw/m6vLxciYmJSklJUWxs7BXF6nA4lJubq1tvvVWRkZGXvV/fBUwt4ylLuNHiwdV66pNw2atD9yHQhxfU/xcSwcjT8xyeI+f+Fww5r/mLKAAA0DwxcA4AQAtns9l0+PBh7dmzJ9BNkSRZLBZZLJY66yMjI702OOJuXfaq0B3wDRb26rCQzmMoDoZ68zODy0PO/S+QOedYAwDQvPFwUAAAWrDp06dry5Yt2r17t7p16+Zcn5CQoMrKSp05c8alfGlpqRISEpxlSktL62yv2dZYmdjY2HrvNgcAAAAAIBgwcA4AQAtkjNH06dO1efNm7dq1S0lJSS7bBw0apMjISO3cudO5rqioSMXFxbJarZIkq9WqQ4cO6fTp084yubm5io2NVZ8+fZxlatdRU6amDiBUXD072+0FALwhMzNTN910k2JiYhQXF6cxY8aoqKjIpcyFCxdks9nUqVMntWvXTuPGjavzi+vi4mKlpaWpTZs2iouL0+OPP66LFy+6lMnLy9PAgQNlsVh03XXXKSsry9fhAQAQtBg4BwCgBbLZbPrLX/6i9evXKyYmRiUlJSopKdH58+clSe3bt9fkyZOVkZGh3bt3q7CwUA888ICsVquSk5MlSSkpKerTp48mTJig//7v/9b27ds1d+5c2Ww251QrU6dO1ZdffqknnnhCn3/+uVasWKGNGzdq5syZAYsdAIBQkp+fL5vNpn379ik3N1cOh0MpKSk6d+6cs8zMmTP1/vvva9OmTcrPz9fJkyc1duxY5/aqqiqlpaWpsrJSe/fu1bp165SVlaV58+Y5y5w4cUJpaWm65ZZbdPDgQaWnp2vKlCnavp3nfAAAWibmOAcAoAVauXKlJGnEiBEu69euXatJkyZJkpYtW6bw8HCNGzdOdrtdqampWrFihbNsRESEtmzZomnTpslqtapt27aaOHGiFi1a5CyTlJSk7OxszZw5Uy+++KK6deum1atXKzU1dB60CABAIG3bts3ldVZWluLi4lRYWKjhw4errKxMa9as0fr16zVy5EhJP/bnvXv31r59+5ScnKycnBwdPXpUO3bsUHx8vG644QYtXrxYs2bN0oIFCxQVFaVVq1YpKSlJzz//vCSpd+/e2rNnj5YtW0a/DQBokRg4BwCgBTLGNFkmOjpay5cv1/Llyxss06NHD23durXRekaMGKEDBw643UYAAFBXWVmZJKljx46SpMLCQjkcDo0ePdpZplevXurevbsKCgqUnJysgoIC9evXT/Hx8c4yqampmjZtmo4cOaIbb7xRBQUFLnXUlElPT2+wLXa7XXa73fm6vLxckuRwOORwOK44VktE0z+vBJIl3Lj8i8Zz4o1zIhTVxN1S468POXFFPurydk48rYeBcwAAAAAAQkB1dbXS09M1bNgw9e3bV5JUUlKiqKgodejQwaVsfHy8SkpKnGVqD5rXbK/Z1liZ8vJynT9/vt6HemdmZmrhwoV11ufk5KhNmzaeBVnL0iFXXIVfLB5cHegmBJ36ctLUzRbNXW5ubqCbEHTIiSvyUZe3clJRUeHRfgycAwAAAAAQAmw2mw4fPqw9e/YEuimSpDlz5igjI8P5ury8XImJiUpJSVFsbOwV1993QXDPr24JN1o8uFpPfRIue3VYoJsTFBrLyeEFLXPKH4fDodzcXN16662KjIwMdHOCAjlxRT7q8nZOav4iyl0MnAMAAAAAEOSmT5+uLVu26IMPPlC3bt2c6xMSElRZWakzZ8643HVeWlqqhIQEZ5mPPvrIpb7S0lLntpp/a9bVLhMbG1vv3eaSZLFYnA8Ery0yMtIrAx32qtAYjLZXh4VMW/2lvpy09AFBb30umhNy4op81OWtnHhaR/gVvzMAAAAAAPAJY4ymT5+uzZs3a9euXUpKSnLZPmjQIEVGRmrnzp3OdUVFRSouLpbVapUkWa1WHTp0SKdPn3aWyc3NVWxsrPr06eMsU7uOmjI1dQAA0NJwxzkAAAAAAEHKZrNp/fr1evfddxUTE+Ock7x9+/Zq3bq12rdvr8mTJysjI0MdO3ZUbGysHn30UVmtViUnJ0uSUlJS1KdPH02YMEFLly5VSUmJ5s6dK5vN5rxjfOrUqXrllVf0xBNP6MEHH9SuXbu0ceNGZWdnByx2AAACiTvOAQAAAAAIUitXrlRZWZlGjBihLl26OJe33nrLWWbZsmW64447NG7cOA0fPlwJCQl65513nNsjIiK0ZcsWRUREyGq16l/+5V90//33a9GiRc4ySUlJys7OVm5urgYMGKDnn39eq1evVmpqy5yXGgAA7jgHAAAAACBIGWOaLBMdHa3ly5dr+fLlDZbp0aOHtm7d2mg9I0aM0IEDB9xuIwAAzRF3nAMAAAAAAAAAUAsD5wAAAAAAAAAA1MJULQCavatnu/9Ao6+WpPmgJQAAAAAAAAgF3HEOAAAAAAAAAEAtDJwDAAAAAAAAAFALU7UgoDyZQgMAAAAAAAAAfImBcwCoB/OiAwD8jb4HAAAACB5M1QIAAAAAAAAAQC0MnAMAAAAAAAAAUAtTtQAAAAAAAKBFYqo0AA1h4BwAAADwAR6CDgDAT+gXAYQaBs4BAAAAAACAIOPuLxu4Ex7wLgbOAQAAgBBV3wW1JcJo6RCp74LtsleF1dnORTUAAFfGnQHtmn7ZH5h2BvAuBs4BAECL09CAIgAAAAAAkhQe6AYAAAAAAAAAABBMGDgHAAAAAAAAAKAWpmoBAAAAWhDmPwUAAACaxsA5AHhJ7YGIph7MVoOBCAAAAAAAgODDwDkABJC7d/0x0A4AAAAAAOB7zHEOAAAAAAAAAEAtIX/H+fLly/Xss8+qpKREAwYM0Msvv6whQ4YEulkA4BPMS4tQRp8NhC76H6DloL8GAOBHIT1w/tZbbykjI0OrVq3S0KFD9cILLyg1NVVFRUWKi4sLdPMAAMD/R58N4HIwhRkQWPTXAAD8JKQHzv/0pz/poYce0gMPPCBJWrVqlbKzs/X6669r9uzZdcrb7XbZ7Xbn67KyMknS999/L4fD0eD7OBwOVVRU6LvvvlNkZGSD5VpdPOdpKAHRqtqooqJarRzhqqpu+OGFoYa4Qgtx+d51f9jo1fos4UZzb6zWDf/+juy1Yvv7nFFefR9/u9zven84e/asJMkYE9B2eJM7fban/fXlqDnOwfDZbCmC6fuwpQiWnHvS/7h7cfLdd9+5/R6+EEx9SEsRDDlv6f215Ns+Wwr+a+xg+b4NJuSkrpqcePJ95Y/PgL/60qGZO53/b+ia8lKhfo15uYKhTws23s6Jx322CVF2u91ERESYzZs3u6y///77zZ133lnvPvPnzzeSWFhYWFhYQmL55ptv/NCj+p67fTb9NQsLCwtLKC0ttb82hj6bhYWFhSW0Fnf77JC94/zbb79VVVWV4uPjXdbHx8fr888/r3efOXPmKCMjw/m6urpa33//vTp16qSwsIZ/w1VeXq7ExER98803io2N9U4AQYC4QgtxhZbmGpfUfGMLpriMMTp79qy6du0a0HZ4i7t9tqf99eUIpuPcUpBz/yPn/kfO/S8Yct7S+2vJt312KAiG8zDYkJO6yEld5MQV+ajL2znxtM8O2YFzT1gsFlksFpd1HTp0uOz9Y2Njm+UJTFyhhbhCS3ONS2q+sQVLXO3btw90EwLmSvvryxEsx7klIef+R879j5z7X6Bz3pL7a8k/fXYoCPR5GIzISV3kpC5y4op81OXNnHjSZ4d75Z0DoHPnzoqIiFBpaanL+tLSUiUkJASoVQAA4FL02QAABD/6awAAXIXswHlUVJQGDRqknTt/erhAdXW1du7cKavVGsCWAQCA2uizAQAIfvTXAAC4CumpWjIyMjRx4kQNHjxYQ4YM0QsvvKBz5845nwDuLRaLRfPnz6/zJ2ihjrhCC3GFluYal9R8Y2uucQULf/XZTeE4+x859z9y7n/k3P/IuW8ES38dKjgP6yIndZGTusiJK/JRV7DkJMwYYwLagiv0yiuv6Nlnn1VJSYluuOEGvfTSSxo6dGigmwUAAC5Bnw0AQPCjvwYA4EchP3AOAAAAAAAAAIA3hewc5wAAAAAAAAAA+AID5wAAAAAAAAAA1MLAOQAAAAAAAAAAtTBwDgAAAAAAAABALS1+4HzBggUKCwtzWXr16tXoPps2bVKvXr0UHR2tfv36aevWrX5q7eW7+uqr68QVFhYmm81Wb/msrKw6ZaOjo/3c6ro++OAD/fa3v1XXrl0VFhamv/71ry7bjTGaN2+eunTpotatW2v06NH64osvmqx3+fLluvrqqxUdHa2hQ4fqo48+8lEE9WssLofDoVmzZqlfv35q27atunbtqvvvv18nT55stE5PzmVva+p4TZo0qU4bb7vttibrDfTxkpqOrb7PW1hYmJ599tkG6wz0McvMzNRNN92kmJgYxcXFacyYMSoqKnIpc+HCBdlsNnXq1Ent2rXTuHHjVFpa2mi9nn4uvaWpuL7//ns9+uij6tmzp1q3bq3u3bvr3/7t31RWVtZovZ6ev/A/d78zQqFfD3bu5Py1117Tr371K1111VW66qqrNHr06IB8r4c6T/vGDRs2KCwsTGPGjPFtA5shd3N+5swZ2Ww2denSRRaLRddffz3fL25yN+cvvPCCs39PTEzUzJkzdeHCBT+1Fi1JoH+ODwa+ulYPZb66Hg5VvrreDGWXk5MRI0bUOU+mTp0aoBb73sqVK9W/f3/FxsYqNjZWVqtV//Vf/+XcHuhzpMUPnEvSL37xC506dcq57Nmzp8Gye/fu1b333qvJkyfrwIEDGjNmjMaMGaPDhw/7scVN+/jjj11iys3NlST98z//c4P7xMbGuuzz9ddf+6u5DTp37pwGDBig5cuX17t96dKleumll7Rq1Sr9/e9/V9u2bZWamtroD8hvvfWWMjIyNH/+fO3fv18DBgxQamqqTp8+7asw6mgsroqKCu3fv19PPfWU9u/fr3feeUdFRUW68847m6zXnXPZF5o6XpJ02223ubTxzTffbLTOYDheUtOx1Y7p1KlTev311xUWFqZx48Y1Wm8gj1l+fr5sNpv27dun3NxcORwOpaSk6Ny5c84yM2fO1Pvvv69NmzYpPz9fJ0+e1NixYxut15PPpTc1FdfJkyd18uRJPffcczp8+LCysrK0bds2TZ48ucm63T1/4X/ufmeESr8ezNzNeV5enu69917t3r1bBQUFSkxMVEpKiv7xj3/4ueWhy9O+8auvvtIf/vAH/epXv/JTS5sPd3NeWVmpW2+9VV999ZXefvttFRUV6bXXXtPPf/5zP7c8dLmb8/Xr12v27NmaP3++PvvsM61Zs0ZvvfWWnnzyST+3HC1FoK+9As0X1+qhzhfXw6HMV9eboexyciJJDz30kMt5snTp0gC12Pe6deumJUuWqLCwUJ988olGjhypu+66S0eOHJEUBOeIaeHmz59vBgwYcNnl7777bpOWluaybujQoeZf//Vfvdwy75oxY4a59tprTXV1db3b165da9q3b+/fRrlJktm8ebPzdXV1tUlISDDPPvusc92ZM2eMxWIxb775ZoP1DBkyxNhsNufrqqoq07VrV5OZmemTdjfl0rjq89FHHxlJ5uuvv26wjLvnsq/VF9fEiRPNXXfd5VY9wXa8jLm8Y3bXXXeZkSNHNlom2I7Z6dOnjSSTn59vjPnx8xQZGWk2bdrkLPPZZ58ZSaagoKDeOjz9XPrSpXHVZ+PGjSYqKso4HI4Gy3hy/sL/3P3OCNV+PZhc6ff0xYsXTUxMjFm3bp2vmtjseJLzixcvmptvvtmsXr2a7zMPuJvzlStXmmuuucZUVlb6q4nNjrs5t9lsdX72ysjIMMOGDfNpO9EyBdvP8YHmrWv15sRb18PNiTeuN5ub+q5Vf/3rX5sZM2YErlFB4KqrrjKrV68OinOEO84lffHFF+ratauuueYajR8/XsXFxQ2WLSgo0OjRo13WpaamqqCgwNfN9FhlZaX+8pe/6MEHH1RYWFiD5X744Qf16NFDiYmJLr/dCVYnTpxQSUmJy/Fo3769hg4d2uDxqKysVGFhocs+4eHhGj16dFAfw7KyMoWFhalDhw6NlnPnXA6UvLw8xcXFqWfPnpo2bZq+++67BsuG6vEqLS1Vdnb2Zd3BHEzHrGaqko4dO0qSCgsL5XA4XPLfq1cvde/evcH8e/K59LVL42qoTGxsrFq1atVoXe6cv/A/T74zQrFfDybe+J6uqKiQw+Fo9DOKn3ia80WLFikuLu6y+ia48iTn7733nqxWq2w2m+Lj49W3b18988wzqqqq8lezQ5onOb/55ptVWFjonM7lyy+/1NatW/Wb3/zGL21GyxNMP8cHm2C8JggWLfl6whvXm81NQ9eqb7zxhjp37qy+fftqzpw5qqioCETz/K6qqkobNmzQuXPnZLVag+IcaXyEoAUYOnSosrKy1LNnT506dUoLFy7Ur371Kx0+fFgxMTF1ypeUlCg+Pt5lXXx8vEpKSvzVZLf99a9/1ZkzZzRp0qQGy/Ts2VOvv/66+vfvr7KyMj333HO6+eabdeTIEXXr1s1/jXVDTc7dOR7ffvutqqqq6t3n888/901Dr9CFCxc0a9Ys3XvvvYqNjW2wnLvnciDcdtttGjt2rJKSknT8+HE9+eSTuv3221VQUKCIiIg65UPxeEnSunXrFBMT0+SfDwXTMauurlZ6erqGDRumvn37SvrxMxYVFVXnFzaNfcY8+Vz6Un1xXerbb7/V4sWL9fDDDzdal7vnL/zPk++MUOzXg4k3vqdnzZqlrl271vkFBurnSc737NmjNWvW6ODBg35oYfPjSc6//PJL7dq1S+PHj9fWrVt17NgxPfLII3I4HJo/f74/mh3SPMn5fffdp2+//Va//OUvZYzRxYsXNXXqVKZqgU8E08/xwSjYrgmCRUu+nvDW9WZz0tC16n333acePXqoa9eu+vTTTzVr1iwVFRXpnXfeCWBrfevQoUOyWq26cOGC2rVrp82bN6tPnz46ePBgwM+RFj9wfvvttzv/379/fw0dOlQ9evTQxo0bm80dOWvWrNHtt9+url27NljGarXKarU6X998883q3bu3Xn31VS1evNgfzUQ9HA6H7r77bhljtHLlykbLhsK5fM899zj/369fP/Xv31/XXnut8vLyNGrUqAC2zLtef/11jR8/vskH7AbTMbPZbDp8+HCzm5uxqbjKy8uVlpamPn36aMGCBY3W1VLOX8CflixZog0bNigvLy8oHkreHJ09e1YTJkzQa6+9ps6dOwe6OS1GdXW14uLi9Oc//1kREREaNGiQ/vGPf+jZZ59l4NxH8vLy9Mwzz2jFihUaOnSojh07phkzZmjx4sV66qmnAt08NDPB9HM8QkdLvp5ortebV6KhnNS+oatfv37q0qWLRo0apePHj+vaa6/1dzP9omfPnjp48KDKysr09ttva+LEicrPzw90syTxcNA6OnTooOuvv17Hjh2rd3tCQkKdp7eWlpYqISHBH81z29dff60dO3ZoypQpbu0XGRmpG2+8scE8BIOanLtzPDp37qyIiIiQOIY1g+Zff/21cnNzG73bvD5NncvB4JprrlHnzp0bbGMoHa8af/vb31RUVOT2Z04K3DGbPn26tmzZot27d7v8hUlCQoIqKyt15swZl/KN5d+Tz6WvNBRXjbNnz+q2225TTEyMNm/erMjISLfqb+r8hf958p0Rav16sLmS7+nnnntOS5YsUU5Ojvr37+/LZjYr7ub8+PHj+uqrr/Tb3/5WrVq1UqtWrfSf//mfeu+999SqVSsdP37cX00PWZ6c5126dNH111/vcgdh7969VVJSosrKSp+2tznwJOdPPfWUJkyYoClTpqhfv3763e9+p2eeeUaZmZmqrq72R7PRgoXCtZc/BdM1QTBrKdcT3rzebC6aulatbejQoZLUrM+TqKgoXXfddRo0aJAyMzM1YMAAvfjii0FxjjBwfokffvhBx48fV5cuXerdbrVatXPnTpd1ubm5LndrB5O1a9cqLi5OaWlpbu1XVVWlQ4cONZiHYJCUlKSEhASX41FeXq6///3vDR6PqKgoDRo0yGWf6upq7dy5M6iOYc2g+RdffKEdO3aoU6dObtfR1LkcDP73f/9X3333XYNtDJXjVduaNWs0aNAgDRgwwO19/X3MjDGaPn26Nm/erF27dikpKcll+6BBgxQZGemS/6KiIhUXFzeYf08+l97WVFw1bUpJSVFUVJTee+89j+50ber8hf958p0Rav16sPH0e3rp0qVavHixtm3bpsGDB/ujqc2Guznv1auXDh06pIMHDzqXO++8U7fccosOHjyoxMREfzY/JHlyng8bNkzHjh1zGbD9n//5H3Xp0kVRUVE+b3Oo8yTnFRUVCg93vbyt+cWFMcZ3jQUUGtde/hQM1wShoLlfT/jiejPUXc616qVqptprrudJfaqrq2W324PjHPHLI0iD2GOPPWby8vLMiRMnzIcffmhGjx5tOnfubE6fPm2MMWbChAlm9uzZzvIffvihadWqlXnuuefMZ599ZubPn28iIyPNoUOHAhVCg6qqqkz37t3NrFmz6my7NK6FCxea7du3m+PHj5vCwkJzzz33mOjoaHPkyBF/NrmOs2fPmgMHDpgDBw4YSeZPf/qTOXDggPn666+NMcYsWbLEdOjQwbz77rvm008/NXfddZdJSkoy58+fd9YxcuRI8/LLLztfb9iwwVgsFpOVlWWOHj1qHn74YdOhQwdTUlISFHFVVlaaO++803Tr1s0cPHjQnDp1yrnY7fYG42rqXA50XGfPnjV/+MMfTEFBgTlx4oTZsWOHGThwoPmnf/onc+HChQbjCobj1VRsNcrKykybNm3MypUr660j2I7ZtGnTTPv27U1eXp7LeVZRUeEsM3XqVNO9e3eza9cu88knnxir1WqsVqtLPT179jTvvPOO8/XlfC4DGVdZWZkZOnSo6devnzl27JhLmYsXL9Yb1+Wevwi8pr4zQrlfD1bu5nzJkiUmKirKvP322y6fv7NnzwYqhJDjbs4vNXHiRHPXXXf5qbXNg7s5Ly4uNjExMWb69OmmqKjIbNmyxcTFxZmnn346UCGEHHdzPn/+fBMTE2PefPNN8+WXX5qcnBxz7bXXmrvvvjtQIaAZC/TP8cHAG9fqzY03roebE29dbzYnTeXk2LFjZtGiReaTTz4xJ06cMO+++6655pprzPDhwwPcct+ZPXu2yc/PNydOnDCffvqpmT17tgkLCzM5OTnGmMCfIy1+4Pz3v/+96dKli4mKijI///nPze9//3tz7Ngx5/Zf//rXZuLEiS77bNy40Vx//fUmKirK/OIXvzDZ2dl+bvXl2b59u5FkioqK6my7NK709HTTvXt3ExUVZeLj481vfvMbs3//fj+2tn67d+82kuosNW2vrq42Tz31lImPjzcWi8WMGjWqTrw9evQw8+fPd1n38ssvO+MdMmSI2bdvn58i+lFjcZ04caLebZLM7t27G4yrqXM50HFVVFSYlJQU87Of/cxERkaaHj16mIceeqjOAHgwHi9jmj4XjTHm1VdfNa1btzZnzpypt45gO2YNnWdr1651ljl//rx55JFHzFVXXWXatGljfve735lTp07Vqaf2PpfzufSlpuJq6FhKMidOnKg3rss9fxEcGvvOCOV+PZi5k/MePXrU+/m79LsfjXP3PK+NgXPPuJvzvXv3mqFDhxqLxWKuueYa88c//tHlF7Romjs5dzgcZsGCBebaa6810dHRJjEx0TzyyCPm//7v//zfcDR7gf45Phh441q9ufHG9XBz4q3rzeakqZwUFxeb4cOHm44dOxqLxWKuu+468/jjj5uysrLANtyHHnzwQdOjRw8TFRVlfvazn5lRo0Y5B82NCfw5EmYMf7cGAAAAAAAAAEAN5jgHAAAAAAAAAKAWBs4BAAAAAAAAAKiFgXMAAAAAAAAAAGph4BwAAAAAAAAAgFoYOAcAAAAAAAAAoBYGzgEAAAAAAAAAqIWBcwAAAAAAAAAAamHgHAAAAAAAAACAWhg4BwAAAAAAAACgFgbOAQAAAAAAAACohYFzAAAAAAAAAABq+X/z8QX9pKqsHQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1500x1000 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train[\"loantoincome\"] = ((train[\"loan_amnt\"] / train[\"person_income\"])).astype('Float64')\n",
    "# train[\"loan_percent_incometoincome\"] = ((train[\"loan_percent_income\"] / train[\"person_income\"])).astype('Float64')\n",
    "# train['person_age_to_person_income'] = (train['person_age'] / train['person_income']).astype(str).astype('Float64')\n",
    "# train['person_emp_length_to_person_age'] = (train['person_emp_length'] / train['person_age']).astype('Float64')\n",
    "# train['loan_int_rate_to_loan_amnt'] = (train['loan_int_rate'] / train['loan_amnt']).astype('Float64')\n",
    "# train['person_home_ownership'] = train['person_home_ownership'].replace({'RENT': 0, 'MORTGAGE': 1, 'OWN': 2, 'OTHER': 3}).astype('category')\n",
    "# train['loan_intent'] = train['loan_intent'].replace({'EDUCATION': 0, 'MEDICAL': 1, 'PERSONAL': 2, 'VENTURE': 3, 'DEBTCONSOLIDATION': 4, 'HOMEIMPROVEMENT': 5}).astype('category')\n",
    "# train['loan_grade'] = train['loan_grade'].replace({'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6}).astype('category')\n",
    "# train['cb_person_default_on_file'] = train['cb_person_default_on_file'].replace({'N': 0, 'Y': 1}).astype('category')\n",
    "\n",
    "# Plot histograms for numerical columns\n",
    "numerical_columns = ['person_age','loantoincome','person_emp_length_to_person_age',\n",
    "                     'loan_int_rate_to_loan_amnt','loan_percent_incometoincome',\n",
    "                     'person_age_to_person_income','person_income', 'loan_amnt',\"person_emp_length\" ,\n",
    "                     'loan_int_rate', 'loan_percent_income', 'cb_person_cred_hist_length']\n",
    "train[numerical_columns].hist(bins=30, figsize=(15, 10))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot count plots for categorical columns\n",
    "categorical_columns = ['person_home_ownership', 'loan_intent', 'loan_grade', 'cb_person_default_on_file', 'loan_status',\n",
    "    \"person_home_ownership_income\"\n",
    "]\n",
    "\n",
    "numerical_features = numerical_columns\n",
    "categorical_features = categorical_columns\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 15))  # Adjusted to 3x2 grid\n",
    "for ax, col in zip(axes.flatten(), categorical_columns):\n",
    "    sns.countplot(data=train, x=col, ax=ax)\n",
    "    ax.set_title(f'Distribution of {col}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "features = numerical_columns + categorical_columns \n",
    "categorical_columns.remove('loan_status')\n",
    "features.remove('loan_status')\n",
    "# Define the preprocessing for numerical and categorical features\n",
    "#print how many 'load_status' 0 and 1 and find the ratio\n",
    "print(train['loan_status'].value_counts())\n",
    "print(train['loan_status'].value_counts(normalize=True))\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58645, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_intent</th>\n",
       "      <th>loan_grade</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>...</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>loantoincome</th>\n",
       "      <th>loan_percent_incometoincome</th>\n",
       "      <th>person_age_to_person_income</th>\n",
       "      <th>person_emp_length_to_person_age</th>\n",
       "      <th>loan_int_rate_to_loan_amnt</th>\n",
       "      <th>income_to_age</th>\n",
       "      <th>loan_to_income</th>\n",
       "      <th>rate_to_loan</th>\n",
       "      <th>person_home_ownership_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>35000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6000</td>\n",
       "      <td>11.49</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>945.945946</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>56000</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4000</td>\n",
       "      <td>13.35</td>\n",
       "      <td>0.07</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.003337</td>\n",
       "      <td>2545.454545</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.003337</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>28800</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>8.90</td>\n",
       "      <td>0.21</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.001483</td>\n",
       "      <td>993.103448</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.001483</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>70000</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>12000</td>\n",
       "      <td>11.11</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>2333.333333</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  person_age  person_income person_home_ownership  person_emp_length  \\\n",
       "0   0          37          35000                     0                0.0   \n",
       "1   1          22          56000                     2                6.0   \n",
       "2   2          29          28800                     2                8.0   \n",
       "3   3          30          70000                     0               14.0   \n",
       "\n",
       "  loan_intent loan_grade  loan_amnt  loan_int_rate  loan_percent_income  ...  \\\n",
       "0           0          1       6000          11.49                 0.17  ...   \n",
       "1           1          2       4000          13.35                 0.07  ...   \n",
       "2           2          0       6000           8.90                 0.21  ...   \n",
       "3           3          1      12000          11.11                 0.17  ...   \n",
       "\n",
       "  loan_status  loantoincome  loan_percent_incometoincome  \\\n",
       "0           0      0.171429                     0.000005   \n",
       "1           0      0.071429                     0.000001   \n",
       "2           0      0.208333                     0.000007   \n",
       "3           0      0.171429                     0.000002   \n",
       "\n",
       "   person_age_to_person_income  person_emp_length_to_person_age  \\\n",
       "0                     0.001057                              0.0   \n",
       "1                     0.000393                         0.272727   \n",
       "2                     0.001007                         0.275862   \n",
       "3                     0.000429                         0.466667   \n",
       "\n",
       "   loan_int_rate_to_loan_amnt  income_to_age  loan_to_income  rate_to_loan  \\\n",
       "0                    0.001915     945.945946        0.171429      0.001915   \n",
       "1                    0.003337    2545.454545        0.071429      0.003337   \n",
       "2                    0.001483     993.103448        0.208333      0.001483   \n",
       "3                    0.000926    2333.333333        0.171429      0.000926   \n",
       "\n",
       "   person_home_ownership_income  \n",
       "0                             0  \n",
       "1                             1  \n",
       "2                             2  \n",
       "3                             3  \n",
       "\n",
       "[4 rows x 22 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(train.head(4))\n",
    "print(train.shape)\n",
    "train.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['person_age',\n",
       " 'loantoincome',\n",
       " 'person_emp_length_to_person_age',\n",
       " 'loan_int_rate_to_loan_amnt',\n",
       " 'loan_percent_incometoincome',\n",
       " 'person_age_to_person_income',\n",
       " 'person_income',\n",
       " 'loan_amnt',\n",
       " 'person_emp_length',\n",
       " 'loan_int_rate',\n",
       " 'loan_percent_income',\n",
       " 'cb_person_cred_hist_length',\n",
       " 'person_home_ownership',\n",
       " 'loan_intent',\n",
       " 'loan_grade',\n",
       " 'cb_person_default_on_file',\n",
       " 'person_home_ownership_income']"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((58645, 17), (58645, 1), (39098, 17), (39098,))"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target = ['loan_status']  # Replace with the actual target column name\n",
    "\n",
    "# Preprocess the data\n",
    "X = train[features]\n",
    "y = train[target]\n",
    "ids = train['id']\n",
    "testx = test[features]\n",
    "test_ids = test['id']\n",
    "\n",
    "X.shape , y.shape , testx.shape,  test_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140748, 17)\n",
      "(35187, 17)\n",
      "(140748, 1)\n",
      "(35187, 1)\n",
      "(140748,)\n",
      "(35187,)\n",
      "(39098, 17)\n",
      "(39098,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test, ids_train, ids_test = train_test_split(X, y, ids, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the preprocessing for numerical and categorical features\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    # ('onehot', OneHotEncoder(handle_unknown='error'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "testx = preprocessor.transform(testx)\n",
    "\n",
    "# Function to add noise\n",
    "def add_noise(data, noise_level=0.01):\n",
    "    noise = np.random.normal(0, noise_level, data.shape)\n",
    "    return data + noise\n",
    "\n",
    "# Add noise to the numerical features\n",
    "X_train_noisy = X_train.copy()\n",
    "X_test_noisy = X_test.copy()\n",
    "X_train_noisy[:, :len(numerical_features)] = add_noise(X_train[:, :len(numerical_features)])\n",
    "X_test_noisy[:, :len(numerical_features)] = add_noise(X_test[:, :len(numerical_features)])\n",
    "\n",
    "\n",
    "X_train_less_noise = X_train.copy()\n",
    "X_test_less_noise = X_test.copy()\n",
    "X_train_less_noise[:, :len(numerical_features)] = add_noise(X_train[:, :len(numerical_features)],noise_level=0.001)\n",
    "X_test_less_noise[:, :len(numerical_features)] = add_noise(X_test[:, :len(numerical_features)],noise_level=0.001)\n",
    "\n",
    "# Concatenate the original data with the noisy data vertically\n",
    "X_train_combined = np.vstack((X_train, X_train_noisy, X_train_less_noise))\n",
    "X_test_combined = np.vstack((X_test, X_test_noisy, X_test_less_noise))\n",
    "\n",
    "# Concatenate the target variable as well\n",
    "y_train_combined = np.vstack((y_train, y_train, y_train))\n",
    "y_test_combined = np.vstack((y_test, y_test,y_test))\n",
    "\n",
    "# Concatenate the ids as well\n",
    "ids_train_combined = np.hstack((ids_train, ids_train, ids_train))\n",
    "ids_test_combined = np.hstack((ids_test, ids_test, ids_test))\n",
    "\n",
    "# Update the original variables\n",
    "X_train = X_train_combined\n",
    "X_test = X_test_combined\n",
    "y_train = y_train_combined\n",
    "y_test = y_test_combined\n",
    "ids_train = ids_train_combined\n",
    "ids_test = ids_test_combined\n",
    "xult , yult  , idsult= np.vstack((X_train, X_test)), np.vstack((y_train, y_test)) , np.hstack((ids_train, ids_test))\n",
    "print(X_train.shape)  # Should output (46916 + 46916, 26)\n",
    "print(X_test.shape)   # Should output (11729 + 11729, 26)\n",
    "print(y_train.shape)  # Should output (46916 + 46916, 1)\n",
    "print(y_test.shape)   # Should output (11729 + 11729, 1)\n",
    "print(ids_train.shape)  # Should output (46916 + 46916,)\n",
    "print(ids_test.shape)   # Should output (11729 + 11729,)\n",
    "print(testx.shape)   # Should output (11729 + 11729,)\n",
    "print(test_ids.shape)   # Should output (11729 + 11729,)\n",
    "fmax = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class ensemble:\n",
    "    def __init__(self):\n",
    "        self.models = []\n",
    "        \n",
    "    def add_model(self, model):\n",
    "        self.models.append(model)\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        predictions = []\n",
    "        for model in self.models:\n",
    "            pred = model.predict(X_test)\n",
    "            predictions.append(pred)\n",
    "            count_greater_than_0_5 = (pred > model.THRESHOLD).sum()\n",
    "            count_less_than_or_equal_0_5 = (pred <= model.THRESHOLD).sum()\n",
    "            print(f'Percentage of predictions greater than {model.THRESHOLD}: {count_greater_than_0_5 / len(pred) * 100:.2f}%')\n",
    "            passc = count_greater_than_0_5 / len(pred) * 100\n",
    "            if passc < 5:\n",
    "                predictions.pop()\n",
    "                continue\n",
    "            print(f'Percentage of predictions less than or equal to {model.THRESHOLD}: {count_less_than_or_equal_0_5 / len(pred) * 100:.2f}%')\n",
    "        \n",
    "        # Stack predictions to form a 2D array\n",
    "        stacked_predictions = np.hstack(predictions)\n",
    "        \n",
    "        # Average the predictions across models\n",
    "        y_pred = np.mean(stacked_predictions, axis=1)\n",
    "        \n",
    "        # Apply threshold\n",
    "        y_pred = (y_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Flatten the predictions to form a 1D array\n",
    "        y_pred = y_pred.flatten()\n",
    "        \n",
    "        # Assuming test_ids is defined elsewhere in your code\n",
    "        ids = test_ids\n",
    "        predictions_df = pd.DataFrame({'id': ids, 'loan_status': y_pred})\n",
    "        return predictions_df\n",
    "    \n",
    "    def save(self, testx, path=\"ftt.csv\"):\n",
    "        df = self.predict(testx)\n",
    "        df.to_csv(path, index=False)\n",
    "        \n",
    "    def rmamodel(self):\n",
    "        self.models = []\n",
    "\n",
    "ens = ensemble()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ktrain( model , xult , yult,splits=5,epochs=15,batch_size=32,random_state=42):\n",
    "    global fmax \n",
    "    if splits==1:\n",
    "        class temp:\n",
    "            def split(self, X):\n",
    "                n_samples = len(X)\n",
    "                indices = list(range(n_samples))\n",
    "                yield indices, indices  # Use the same indices for train and test\n",
    "\n",
    "        kf = temp()\n",
    "    else:\n",
    "        kf = KFold(n_splits=splits, shuffle=True, random_state=random_state)\n",
    "        obj = kf \n",
    "    losses, aucs, precisions, recalls, f1s, roc_aucs = [], [], [], [], [], []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        xt, xv = xult[train_index], xult[test_index]\n",
    "        yt, yv = yult[train_index], yult[test_index]\n",
    "        \n",
    "        # Initialize and compile the model\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(xt, yt, epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        results = model.evaluate(xv, yv)\n",
    "        loss, auc, precision, recall = results[0], results[1], results[2], results[3]\n",
    "        \n",
    "        # Predict probabilities for the test set\n",
    "        y_pred_prob = model.predict(xult)\n",
    "        y_pred = (y_pred_prob > model.THRESHOLD).astype(int)\n",
    "        \n",
    "        # Calculate F1 score and ROC AUC score\n",
    "        f1 = f1_score(yult, y_pred)\n",
    "        roc_auc = roc_auc_score(yult, y_pred_prob)\n",
    "        if f1 > fmax:\n",
    "            fmax = f1\n",
    "            model.save('best.keras')\n",
    "            print(colored(f'F1 Score improved to {f1}. Saving model...', 'green','on_red'))\n",
    "        # Store metrics\n",
    "        losses.append(loss)\n",
    "        aucs.append(auc)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1s.append(f1)\n",
    "        roc_aucs.append(roc_auc)\n",
    "    print('losses: ', losses)\n",
    "    print('aucs: ', aucs)\n",
    "    print('precisions: ', precisions)\n",
    "    print('recalls: ', recalls)\n",
    "    print('f1s: ', f1s)\n",
    "    print('roc_aucs: ', roc_aucs)\n",
    "    print(f'Average Loss: {sum(losses) / len(losses)}')\n",
    "    print(f'Average AUC: {sum(aucs) / len(aucs)}')\n",
    "    print(f'Average Precision: {sum(precisions) / len(precisions)}')\n",
    "    print(f'Average Recall: {sum(recalls) / len(recalls)}')\n",
    "    print(f'Average F1 Score: {sum(f1s) / len(f1s)}')\n",
    "    print(f'Average ROC AUC Score: {sum(roc_aucs) / len(roc_aucs)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - auc_58: 0.7112 - loss: 0.4083 - precision_58: 0.5150 - recall_58: 0.1318 - val_auc_58: 0.8356 - val_loss: 0.3239 - val_precision_58: 0.8043 - val_recall_58: 0.2209\n",
      "Epoch 2/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - auc_58: 0.8289 - loss: 0.3107 - precision_58: 0.7406 - recall_58: 0.2542 - val_auc_58: 0.8939 - val_loss: 0.2693 - val_precision_58: 0.6844 - val_recall_58: 0.5983\n",
      "Epoch 3/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - auc_58: 0.8739 - loss: 0.2685 - precision_58: 0.7719 - recall_58: 0.4025 - val_auc_58: 0.8345 - val_loss: 0.3321 - val_precision_58: 0.7408 - val_recall_58: 0.2480\n",
      "Epoch 4/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - auc_58: 0.8545 - loss: 0.2834 - precision_58: 0.7635 - recall_58: 0.3523 - val_auc_58: 0.8708 - val_loss: 0.2577 - val_precision_58: 0.7675 - val_recall_58: 0.5072\n",
      "Epoch 5/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - auc_58: 0.8790 - loss: 0.2594 - precision_58: 0.7821 - recall_58: 0.4553 - val_auc_58: 0.8806 - val_loss: 0.2669 - val_precision_58: 0.7332 - val_recall_58: 0.3567\n",
      "Epoch 6/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - auc_58: 0.8926 - loss: 0.2478 - precision_58: 0.7883 - recall_58: 0.4501 - val_auc_58: 0.8945 - val_loss: 0.2492 - val_precision_58: 0.8006 - val_recall_58: 0.5275\n",
      "Epoch 7/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - auc_58: 0.9011 - loss: 0.2395 - precision_58: 0.7874 - recall_58: 0.5195 - val_auc_58: 0.9087 - val_loss: 0.2331 - val_precision_58: 0.7856 - val_recall_58: 0.5673\n",
      "Epoch 8/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - auc_58: 0.8827 - loss: 0.2598 - precision_58: 0.7755 - recall_58: 0.4726 - val_auc_58: 0.9042 - val_loss: 0.2493 - val_precision_58: 0.6590 - val_recall_58: 0.6541\n",
      "Epoch 9/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - auc_58: 0.8972 - loss: 0.2437 - precision_58: 0.7874 - recall_58: 0.5083 - val_auc_58: 0.9058 - val_loss: 0.2332 - val_precision_58: 0.7644 - val_recall_58: 0.5553\n",
      "Epoch 10/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - auc_58: 0.9042 - loss: 0.2330 - precision_58: 0.8086 - recall_58: 0.5232 - val_auc_58: 0.9059 - val_loss: 0.2382 - val_precision_58: 0.8326 - val_recall_58: 0.5008\n",
      "Epoch 11/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - auc_58: 0.8987 - loss: 0.2381 - precision_58: 0.8077 - recall_58: 0.5102 - val_auc_58: 0.9084 - val_loss: 0.2350 - val_precision_58: 0.7232 - val_recall_58: 0.6250\n",
      "Epoch 12/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - auc_58: 0.9043 - loss: 0.2342 - precision_58: 0.7863 - recall_58: 0.5328 - val_auc_58: 0.9156 - val_loss: 0.2252 - val_precision_58: 0.7478 - val_recall_58: 0.6481\n",
      "Epoch 13/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - auc_58: 0.9099 - loss: 0.2250 - precision_58: 0.7981 - recall_58: 0.5377 - val_auc_58: 0.8869 - val_loss: 0.2475 - val_precision_58: 0.8795 - val_recall_58: 0.4359\n",
      "Epoch 14/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - auc_58: 0.9109 - loss: 0.2226 - precision_58: 0.8319 - recall_58: 0.5307 - val_auc_58: 0.9123 - val_loss: 0.2310 - val_precision_58: 0.7201 - val_recall_58: 0.6298\n",
      "Epoch 15/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - auc_58: 0.9134 - loss: 0.2187 - precision_58: 0.8178 - recall_58: 0.5686 - val_auc_58: 0.9117 - val_loss: 0.2328 - val_precision_58: 0.7733 - val_recall_58: 0.5593\n",
      "\u001b[1m1833/1833\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_58: 0.9125 - loss: 0.2311 - precision_58: 0.7722 - recall_58: 0.5604\n",
      "\u001b[32mPredicting with encoding_dim 512...\u001b[0m\n",
      "\u001b[1m5498/5498\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 896us/step\n",
      "\u001b[41m\u001b[32mF1 Score improved to 0.6529185761236865. Saving model...\u001b[0m\n",
      "losses:  [0.2319091260433197]\n",
      "aucs:  [0.9126980304718018]\n",
      "precisions:  [0.775210440158844]\n",
      "recalls:  [0.5616405606269836]\n",
      "f1s:  [0.6529185761236865]\n",
      "roc_aucs:  [0.9132453542065884]\n",
      "Average Loss: 0.2319091260433197\n",
      "Average AUC: 0.9126980304718018\n",
      "Average Precision: 0.775210440158844\n",
      "Average Recall: 0.5616405606269836\n",
      "Average F1 Score: 0.6529185761236865\n",
      "Average ROC AUC Score: 0.9132453542065884\n",
      "Epoch 1/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - auc_59: 0.6634 - loss: 0.4292 - precision_59: 0.3506 - recall_59: 0.0303 - val_auc_59: 0.8261 - val_loss: 0.3065 - val_precision_59: 0.8314 - val_recall_59: 0.1748\n",
      "Epoch 2/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_59: 0.7973 - loss: 0.3298 - precision_59: 0.7114 - recall_59: 0.2261 - val_auc_59: 0.8627 - val_loss: 0.2799 - val_precision_59: 0.8573 - val_recall_59: 0.2990\n",
      "Epoch 3/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_59: 0.8397 - loss: 0.2971 - precision_59: 0.7578 - recall_59: 0.3316 - val_auc_59: 0.8785 - val_loss: 0.2892 - val_precision_59: 0.9533 - val_recall_59: 0.1624\n",
      "Epoch 4/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_59: 0.8654 - loss: 0.2715 - precision_59: 0.7709 - recall_59: 0.4163 - val_auc_59: 0.9028 - val_loss: 0.2432 - val_precision_59: 0.7967 - val_recall_59: 0.5131\n",
      "Epoch 5/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_59: 0.8903 - loss: 0.2476 - precision_59: 0.7870 - recall_59: 0.4944 - val_auc_59: 0.9064 - val_loss: 0.2308 - val_precision_59: 0.8104 - val_recall_59: 0.5311\n",
      "Epoch 6/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_59: 0.8962 - loss: 0.2396 - precision_59: 0.7952 - recall_59: 0.5184 - val_auc_59: 0.9085 - val_loss: 0.2287 - val_precision_59: 0.7709 - val_recall_59: 0.5975\n",
      "Epoch 7/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_59: 0.9018 - loss: 0.2383 - precision_59: 0.7800 - recall_59: 0.5334 - val_auc_59: 0.9142 - val_loss: 0.2207 - val_precision_59: 0.8227 - val_recall_59: 0.5430\n",
      "Epoch 8/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_59: 0.9091 - loss: 0.2313 - precision_59: 0.7986 - recall_59: 0.5585 - val_auc_59: 0.9011 - val_loss: 0.2568 - val_precision_59: 0.9302 - val_recall_59: 0.3181\n",
      "Epoch 9/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_59: 0.9062 - loss: 0.2296 - precision_59: 0.7998 - recall_59: 0.5326 - val_auc_59: 0.9114 - val_loss: 0.2232 - val_precision_59: 0.8387 - val_recall_59: 0.5589\n",
      "Epoch 10/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_59: 0.9099 - loss: 0.2265 - precision_59: 0.8034 - recall_59: 0.5384 - val_auc_59: 0.9150 - val_loss: 0.2290 - val_precision_59: 0.7014 - val_recall_59: 0.6640\n",
      "Epoch 11/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - auc_59: 0.9117 - loss: 0.2253 - precision_59: 0.8031 - recall_59: 0.5488 - val_auc_59: 0.9193 - val_loss: 0.2168 - val_precision_59: 0.8554 - val_recall_59: 0.5462\n",
      "Epoch 12/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_59: 0.9121 - loss: 0.2223 - precision_59: 0.8058 - recall_59: 0.5622 - val_auc_59: 0.9171 - val_loss: 0.2163 - val_precision_59: 0.8425 - val_recall_59: 0.5450\n",
      "Epoch 13/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_59: 0.9119 - loss: 0.2195 - precision_59: 0.8069 - recall_59: 0.5499 - val_auc_59: 0.9203 - val_loss: 0.2109 - val_precision_59: 0.8656 - val_recall_59: 0.5386\n",
      "Epoch 14/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_59: 0.9154 - loss: 0.2209 - precision_59: 0.8035 - recall_59: 0.5752 - val_auc_59: 0.9172 - val_loss: 0.2225 - val_precision_59: 0.9145 - val_recall_59: 0.4427\n",
      "Epoch 15/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_59: 0.9175 - loss: 0.2171 - precision_59: 0.8141 - recall_59: 0.5634 - val_auc_59: 0.9198 - val_loss: 0.2177 - val_precision_59: 0.8757 - val_recall_59: 0.5358\n",
      "\u001b[1m1833/1833\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 944us/step - auc_59: 0.9212 - loss: 0.2141 - precision_59: 0.8718 - recall_59: 0.5365\n",
      "\u001b[32mPredicting with encoding_dim 256...\u001b[0m\n",
      "\u001b[1m5498/5498\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 742us/step\n",
      "\u001b[41m\u001b[32mF1 Score improved to 0.670716049382716. Saving model...\u001b[0m\n",
      "losses:  [0.21536099910736084]\n",
      "aucs:  [0.9212594628334045]\n",
      "precisions:  [0.8777972459793091]\n",
      "recalls:  [0.5393997430801392]\n",
      "f1s:  [0.670716049382716]\n",
      "roc_aucs:  [0.922543323995876]\n",
      "Average Loss: 0.21536099910736084\n",
      "Average AUC: 0.9212594628334045\n",
      "Average Precision: 0.8777972459793091\n",
      "Average Recall: 0.5393997430801392\n",
      "Average F1 Score: 0.670716049382716\n",
      "Average ROC AUC Score: 0.922543323995876\n",
      "Epoch 1/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - auc_60: 0.6646 - loss: 0.4148 - precision_60: 0.2528 - recall_60: 0.0228 - val_auc_60: 0.8741 - val_loss: 0.2829 - val_precision_60: 0.7369 - val_recall_60: 0.3300\n",
      "Epoch 2/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_60: 0.8502 - loss: 0.3011 - precision_60: 0.6034 - recall_60: 0.3248 - val_auc_60: 0.8824 - val_loss: 0.2787 - val_precision_60: 0.8862 - val_recall_60: 0.2727\n",
      "Epoch 3/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_60: 0.8787 - loss: 0.2720 - precision_60: 0.7023 - recall_60: 0.4700 - val_auc_60: 0.8888 - val_loss: 0.2738 - val_precision_60: 0.8831 - val_recall_60: 0.2918\n",
      "Epoch 4/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_60: 0.8578 - loss: 0.2966 - precision_60: 0.6081 - recall_60: 0.3669 - val_auc_60: 0.8997 - val_loss: 0.2597 - val_precision_60: 0.8240 - val_recall_60: 0.3746\n",
      "Epoch 5/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_60: 0.8908 - loss: 0.2540 - precision_60: 0.7705 - recall_60: 0.4744 - val_auc_60: 0.8071 - val_loss: 0.3253 - val_precision_60: 0.6389 - val_recall_60: 0.1254\n",
      "Epoch 6/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_60: 0.8743 - loss: 0.2735 - precision_60: 0.7526 - recall_60: 0.3904 - val_auc_60: 0.8964 - val_loss: 0.2547 - val_precision_60: 0.8700 - val_recall_60: 0.3889\n",
      "Epoch 7/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_60: 0.9005 - loss: 0.2380 - precision_60: 0.7969 - recall_60: 0.4954 - val_auc_60: 0.9086 - val_loss: 0.2365 - val_precision_60: 0.7926 - val_recall_60: 0.4976\n",
      "Epoch 8/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_60: 0.9022 - loss: 0.2354 - precision_60: 0.7904 - recall_60: 0.5159 - val_auc_60: 0.9117 - val_loss: 0.2307 - val_precision_60: 0.8748 - val_recall_60: 0.4813\n",
      "Epoch 9/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_60: 0.9044 - loss: 0.2331 - precision_60: 0.8023 - recall_60: 0.5233 - val_auc_60: 0.9108 - val_loss: 0.2318 - val_precision_60: 0.8209 - val_recall_60: 0.4817\n",
      "Epoch 10/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_60: 0.9095 - loss: 0.2278 - precision_60: 0.8023 - recall_60: 0.5395 - val_auc_60: 0.9143 - val_loss: 0.2222 - val_precision_60: 0.7955 - val_recall_60: 0.5991\n",
      "Epoch 11/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_60: 0.9073 - loss: 0.2299 - precision_60: 0.7928 - recall_60: 0.5397 - val_auc_60: 0.9164 - val_loss: 0.2231 - val_precision_60: 0.8994 - val_recall_60: 0.4697\n",
      "Epoch 12/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_60: 0.9114 - loss: 0.2254 - precision_60: 0.8048 - recall_60: 0.5474 - val_auc_60: 0.9094 - val_loss: 0.2293 - val_precision_60: 0.8900 - val_recall_60: 0.4606\n",
      "Epoch 13/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_60: 0.9084 - loss: 0.2327 - precision_60: 0.8115 - recall_60: 0.5223 - val_auc_60: 0.9192 - val_loss: 0.2158 - val_precision_60: 0.8507 - val_recall_60: 0.5219\n",
      "Epoch 14/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_60: 0.9115 - loss: 0.2250 - precision_60: 0.8011 - recall_60: 0.5293 - val_auc_60: 0.9167 - val_loss: 0.2315 - val_precision_60: 0.8838 - val_recall_60: 0.4208\n",
      "Epoch 15/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_60: 0.9154 - loss: 0.2179 - precision_60: 0.8033 - recall_60: 0.5324 - val_auc_60: 0.9182 - val_loss: 0.2211 - val_precision_60: 0.7727 - val_recall_60: 0.6035\n",
      "\u001b[1m1833/1833\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 908us/step - auc_60: 0.9190 - loss: 0.2173 - precision_60: 0.7802 - recall_60: 0.6069\n",
      "\u001b[32mPredicting with encoding_dim 128...\u001b[0m\n",
      "\u001b[1m5498/5498\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 703us/step\n",
      "\u001b[41m\u001b[32mF1 Score improved to 0.6835437351183791. Saving model...\u001b[0m\n",
      "losses:  [0.21834492683410645]\n",
      "aucs:  [0.918958306312561]\n",
      "precisions:  [0.7835464477539062]\n",
      "recalls:  [0.6081549525260925]\n",
      "f1s:  [0.6835437351183791]\n",
      "roc_aucs:  [0.9193691523405123]\n",
      "Average Loss: 0.21834492683410645\n",
      "Average AUC: 0.918958306312561\n",
      "Average Precision: 0.7835464477539062\n",
      "Average Recall: 0.6081549525260925\n",
      "Average F1 Score: 0.6835437351183791\n",
      "Average ROC AUC Score: 0.9193691523405123\n",
      "Epoch 1/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - auc_61: 0.6204 - loss: 0.4393 - precision_61: 0.2738 - recall_61: 0.0456 - val_auc_61: 0.8446 - val_loss: 0.3135 - val_precision_61: 0.7944 - val_recall_61: 0.2154\n",
      "Epoch 2/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_61: 0.8378 - loss: 0.3058 - precision_61: 0.6260 - recall_61: 0.3175 - val_auc_61: 0.8285 - val_loss: 0.3444 - val_precision_61: 0.5127 - val_recall_61: 0.4837\n",
      "Epoch 3/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_61: 0.8453 - loss: 0.3002 - precision_61: 0.6696 - recall_61: 0.3248 - val_auc_61: 0.8832 - val_loss: 0.2831 - val_precision_61: 0.8096 - val_recall_61: 0.3842\n",
      "Epoch 4/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_61: 0.8753 - loss: 0.2791 - precision_61: 0.7228 - recall_61: 0.4495 - val_auc_61: 0.8983 - val_loss: 0.2537 - val_precision_61: 0.8521 - val_recall_61: 0.3762\n",
      "Epoch 5/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_61: 0.8787 - loss: 0.2651 - precision_61: 0.7419 - recall_61: 0.4530 - val_auc_61: 0.8931 - val_loss: 0.2561 - val_precision_61: 0.7071 - val_recall_61: 0.5669\n",
      "Epoch 6/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_61: 0.8897 - loss: 0.2590 - precision_61: 0.7482 - recall_61: 0.4816 - val_auc_61: 0.8940 - val_loss: 0.2575 - val_precision_61: 0.8936 - val_recall_61: 0.3443\n",
      "Epoch 7/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_61: 0.8839 - loss: 0.2571 - precision_61: 0.7781 - recall_61: 0.4649 - val_auc_61: 0.8987 - val_loss: 0.2703 - val_precision_61: 0.9087 - val_recall_61: 0.2655\n",
      "Epoch 8/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_61: 0.8890 - loss: 0.2507 - precision_61: 0.8409 - recall_61: 0.4006 - val_auc_61: 0.9033 - val_loss: 0.2594 - val_precision_61: 0.8920 - val_recall_61: 0.3750\n",
      "Epoch 9/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_61: 0.8972 - loss: 0.2457 - precision_61: 0.8066 - recall_61: 0.5000 - val_auc_61: 0.9052 - val_loss: 0.2457 - val_precision_61: 0.8193 - val_recall_61: 0.5251\n",
      "Epoch 10/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_61: 0.9001 - loss: 0.2401 - precision_61: 0.7837 - recall_61: 0.5174 - val_auc_61: 0.9096 - val_loss: 0.2292 - val_precision_61: 0.8773 - val_recall_61: 0.4697\n",
      "Epoch 11/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_61: 0.9083 - loss: 0.2281 - precision_61: 0.7981 - recall_61: 0.5410 - val_auc_61: 0.9125 - val_loss: 0.2272 - val_precision_61: 0.7403 - val_recall_61: 0.6027\n",
      "Epoch 12/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_61: 0.9068 - loss: 0.2284 - precision_61: 0.7704 - recall_61: 0.5544 - val_auc_61: 0.9103 - val_loss: 0.2243 - val_precision_61: 0.8627 - val_recall_61: 0.5104\n",
      "Epoch 13/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_61: 0.9097 - loss: 0.2261 - precision_61: 0.8114 - recall_61: 0.5423 - val_auc_61: 0.9146 - val_loss: 0.2202 - val_precision_61: 0.8204 - val_recall_61: 0.5673\n",
      "Epoch 14/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_61: 0.9064 - loss: 0.2246 - precision_61: 0.8211 - recall_61: 0.5226 - val_auc_61: 0.9112 - val_loss: 0.2245 - val_precision_61: 0.8309 - val_recall_61: 0.5338\n",
      "Epoch 15/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - auc_61: 0.9141 - loss: 0.2205 - precision_61: 0.8130 - recall_61: 0.5670 - val_auc_61: 0.9151 - val_loss: 0.2193 - val_precision_61: 0.7618 - val_recall_61: 0.6342\n",
      "\u001b[1m1833/1833\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 861us/step - auc_61: 0.9168 - loss: 0.2155 - precision_61: 0.7687 - recall_61: 0.6350\n",
      "\u001b[32mPredicting with encoding_dim 64...\u001b[0m\n",
      "\u001b[1m5498/5498\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 677us/step\n",
      "\u001b[41m\u001b[32mF1 Score improved to 0.6980106129757824. Saving model...\u001b[0m\n",
      "losses:  [0.21638472378253937]\n",
      "aucs:  [0.9170829057693481]\n",
      "precisions:  [0.7677438259124756]\n",
      "recalls:  [0.6363745331764221]\n",
      "f1s:  [0.6980106129757824]\n",
      "roc_aucs:  [0.9186091960295202]\n",
      "Average Loss: 0.21638472378253937\n",
      "Average AUC: 0.9170829057693481\n",
      "Average Precision: 0.7677438259124756\n",
      "Average Recall: 0.6363745331764221\n",
      "Average F1 Score: 0.6980106129757824\n",
      "Average ROC AUC Score: 0.9186091960295202\n",
      "Epoch 1/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - auc_62: 0.6265 - loss: 0.4342 - precision_62: 0.1666 - recall_62: 8.5073e-04 - val_auc_62: 0.7941 - val_loss: 0.3302 - val_precision_62: 0.0000e+00 - val_recall_62: 0.0000e+00\n",
      "Epoch 2/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_62: 0.7975 - loss: 0.3372 - precision_62: 0.1546 - recall_62: 0.0045 - val_auc_62: 0.8613 - val_loss: 0.3748 - val_precision_62: 0.8005 - val_recall_62: 0.2731\n",
      "Epoch 3/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_62: 0.8433 - loss: 0.3059 - precision_62: 0.6170 - recall_62: 0.3571 - val_auc_62: 0.8762 - val_loss: 0.2789 - val_precision_62: 0.7968 - val_recall_62: 0.3543\n",
      "Epoch 4/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_62: 0.8724 - loss: 0.2722 - precision_62: 0.7884 - recall_62: 0.3344 - val_auc_62: 0.8964 - val_loss: 0.2514 - val_precision_62: 0.8379 - val_recall_62: 0.4033\n",
      "Epoch 5/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_62: 0.8926 - loss: 0.2524 - precision_62: 0.7581 - recall_62: 0.4830 - val_auc_62: 0.9025 - val_loss: 0.2438 - val_precision_62: 0.7441 - val_recall_62: 0.5752\n",
      "Epoch 6/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_62: 0.8970 - loss: 0.2457 - precision_62: 0.7792 - recall_62: 0.4918 - val_auc_62: 0.8996 - val_loss: 0.2567 - val_precision_62: 0.8885 - val_recall_62: 0.3583\n",
      "Epoch 7/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_62: 0.8871 - loss: 0.2560 - precision_62: 0.7809 - recall_62: 0.4528 - val_auc_62: 0.9106 - val_loss: 0.2342 - val_precision_62: 0.8733 - val_recall_62: 0.3814\n",
      "Epoch 8/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_62: 0.9023 - loss: 0.2402 - precision_62: 0.8031 - recall_62: 0.5019 - val_auc_62: 0.9115 - val_loss: 0.2499 - val_precision_62: 0.9099 - val_recall_62: 0.3619\n",
      "Epoch 9/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_62: 0.9052 - loss: 0.2360 - precision_62: 0.8023 - recall_62: 0.5123 - val_auc_62: 0.9141 - val_loss: 0.2250 - val_precision_62: 0.8379 - val_recall_62: 0.5084\n",
      "Epoch 10/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_62: 0.9061 - loss: 0.2303 - precision_62: 0.8006 - recall_62: 0.5295 - val_auc_62: 0.9115 - val_loss: 0.2323 - val_precision_62: 0.6588 - val_recall_62: 0.6979\n",
      "Epoch 11/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_62: 0.9076 - loss: 0.2306 - precision_62: 0.7794 - recall_62: 0.5311 - val_auc_62: 0.9084 - val_loss: 0.2384 - val_precision_62: 0.7047 - val_recall_62: 0.6099\n",
      "Epoch 12/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_62: 0.9108 - loss: 0.2251 - precision_62: 0.8174 - recall_62: 0.5394 - val_auc_62: 0.9135 - val_loss: 0.2255 - val_precision_62: 0.8473 - val_recall_62: 0.5322\n",
      "Epoch 13/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_62: 0.9074 - loss: 0.2274 - precision_62: 0.7935 - recall_62: 0.5330 - val_auc_62: 0.9146 - val_loss: 0.2223 - val_precision_62: 0.8650 - val_recall_62: 0.5203\n",
      "Epoch 14/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_62: 0.9073 - loss: 0.2288 - precision_62: 0.8150 - recall_62: 0.5324 - val_auc_62: 0.9132 - val_loss: 0.2360 - val_precision_62: 0.9048 - val_recall_62: 0.4049\n",
      "Epoch 15/15\n",
      "\u001b[1m1283/1283\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auc_62: 0.9091 - loss: 0.2285 - precision_62: 0.7812 - recall_62: 0.5165 - val_auc_62: 0.9183 - val_loss: 0.2162 - val_precision_62: 0.7925 - val_recall_62: 0.5824\n",
      "\u001b[1m1833/1833\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 932us/step - auc_62: 0.9198 - loss: 0.2123 - precision_62: 0.8010 - recall_62: 0.5881\n",
      "\u001b[32mPredicting with encoding_dim 256...\u001b[0m\n",
      "\u001b[1m5498/5498\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 749us/step\n",
      "losses:  [0.21300029754638672]\n",
      "aucs:  [0.9200470447540283]\n",
      "precisions:  [0.8057742714881897]\n",
      "recalls:  [0.5873490571975708]\n",
      "f1s:  [0.6787694013303769]\n",
      "roc_aucs:  [0.9205303475958908]\n",
      "Average Loss: 0.21300029754638672\n",
      "Average AUC: 0.9200470447540283\n",
      "Average Precision: 0.8057742714881897\n",
      "Average Recall: 0.5873490571975708\n",
      "Average F1 Score: 0.6787694013303769\n",
      "Average ROC AUC Score: 0.9205303475958908\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Reshape, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from colorama import init\n",
    "from termcolor import colored\n",
    "# Define the L2 regularizers\n",
    "\n",
    "\n",
    "k = .0001\n",
    "kernel_regularizer = l2(0.0001*k)\n",
    "bias_regularizer = l2(0.00001*k)\n",
    "\n",
    "# Define the CNN model with different regularization strengths for kernel and bias\n",
    "class AutoencoderModel:\n",
    "    def __init__(self, input_dim, encoding_dim=512):\n",
    "        self.input_dim = input_dim\n",
    "        self.encoding_dim = encoding_dim\n",
    "        self.autoencoder = self.build_model()\n",
    "        self.THRESHOLD = 0.5\n",
    "    def build_model(self):\n",
    "        # Encoder\n",
    "        input_layer = Input(shape=(self.input_dim,))\n",
    "        encoded = Dense(self.encoding_dim, activation='relu')(input_layer)\n",
    "        encoded = Dense(self.encoding_dim // 2, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(encoded)\n",
    "        encoded = Dense(self.encoding_dim // 4, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(encoded)\n",
    "        encoded = Dense(self.encoding_dim // 8, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(encoded)\n",
    "        encoded = Dense(self.encoding_dim // 16, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(encoded)\n",
    "        encoded = Dense(self.encoding_dim // 32, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(encoded)\n",
    "    \n",
    "        # Decoder\n",
    "        decoded = Dense(self.encoding_dim // 32, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(encoded)\n",
    "        decoded = Dense(self.encoding_dim // 16, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(encoded)\n",
    "        decoded = Dense(self.encoding_dim // 8, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(encoded)\n",
    "        decoded = Dense(self.encoding_dim // 4, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(decoded)\n",
    "        decoded = Dense(self.encoding_dim // 2, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(decoded)\n",
    "        decoded = Dense(1, activation='sigmoid')(decoded)\n",
    "    \n",
    "        # Autoencoder\n",
    "        autoencoder = Model(input_layer, decoded)\n",
    "    \n",
    "        # Compile the model with Binary Crossentropy loss\n",
    "        autoencoder.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(), metrics=[AUC(), Precision(), Recall()])    \n",
    "        return autoencoder\n",
    "\n",
    "    def fit(self, X_train, y_train, epochs=10, verbose=0, batch_size=32, validation_split=0.3, validation_data=None):\n",
    "        if validation_data is not None:\n",
    "            self.autoencoder.fit(X_train, y_train, epochs=epochs, verbose=verbose, batch_size=batch_size, validation_data=validation_data, validation_split=validation_split)\n",
    "            return \n",
    "        self.autoencoder.fit(X_train, y_train, epochs=epochs, verbose=verbose, batch_size=batch_size, validation_split=validation_split)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        print(colored(f'Predicting with encoding_dim {self.encoding_dim}...', 'green'))\n",
    "        return self.autoencoder.predict(X_test)\n",
    "\n",
    "    def summary(self):\n",
    "        self.autoencoder.summary()\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        return self.autoencoder.evaluate(X_test, y_test)\n",
    "    def save(self, path):\n",
    "        self.autoencoder.save(path)\n",
    "\n",
    "dim = [512, 256, 128, 64, 256]\n",
    "for i in range(5):\n",
    "    automodel = AutoencoderModel(X_train.shape[1], encoding_dim=dim[i])\n",
    "    ktrain(automodel, xult, yult, splits=1, epochs=15, batch_size=32, random_state=i)\n",
    "    ens.add_model(automodel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 08:29:47.971809: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-22 08:29:47.974963: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-22 08:29:47.984124: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-22 08:29:47.998481: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-22 08:29:48.002727: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-22 08:29:48.014528: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-22 08:29:49.494433: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'xult' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 67\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Assuming xult and yult are your feature matrix and target vector\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m---> 67\u001b[0m     dense_model \u001b[38;5;241m=\u001b[39m DenseModel(input_dim\u001b[38;5;241m=\u001b[39m\u001b[43mxult\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     68\u001b[0m     ktrain(dense_model, xult, yult,epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m37\u001b[39m)\n\u001b[1;32m     69\u001b[0m     ens\u001b[38;5;241m.\u001b[39madd_model(dense_model)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xult' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from colorama import init\n",
    "from termcolor import colored\n",
    "\n",
    "# Define the L2 regularizers\n",
    "k = .0001\n",
    "kernel_regularizer = l2(0.0001*k)\n",
    "bias_regularizer = l2(0.00001*k)\n",
    "\n",
    "# Define the Dense model with different regularization strengths for kernel and bias\n",
    "class DenseModel:\n",
    "    def __init__(self, input_dim, hidden_dim=64):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.model = self.build_model()\n",
    "        self.THRESHOLD = 0.5\n",
    "\n",
    "    def build_model(self):\n",
    "        input_layer = Input(shape=(self.input_dim,))\n",
    "        x = Dense(self.hidden_dim, activation='relu')(input_layer)\n",
    "        x = Dense(self.hidden_dim // 2, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(x)\n",
    "        x = Dense(self.hidden_dim // 4, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(x)\n",
    "        x = Dense(self.hidden_dim // 8, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(x)\n",
    "        x = Dense(self.hidden_dim // 16, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(x)\n",
    "        x = Dense(self.hidden_dim // 32, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)(x)\n",
    "        output_layer = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "        model = Model(input_layer, output_layer)\n",
    "\n",
    "        # Compile the model with Binary Crossentropy loss\n",
    "        model.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(), metrics=[AUC(), Precision(), Recall()])\n",
    "        return model\n",
    "\n",
    "    def fit(self, X_train, y_train, epochs=10, verbose=0, batch_size=32, validation_split=0.3, validation_data=None):\n",
    "        if validation_data is not None:\n",
    "            self.model.fit(X_train, y_train, epochs=epochs, verbose=verbose, batch_size=batch_size, validation_data=validation_data, validation_split=validation_split)\n",
    "            return \n",
    "        self.model.fit(X_train, y_train, epochs=epochs, verbose=verbose, batch_size=batch_size, validation_split=validation_split)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        print(colored(f'predicting using dense model of hidden {self.hidden_dim}', 'green'))\n",
    "        return self.model.predict(X_test)\n",
    "\n",
    "    def summary(self):\n",
    "        self.model.summary()\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        return self.model.evaluate(X_test, y_test)\n",
    "\n",
    "    def save(self, path):\n",
    "        self.model.save(path)\n",
    "\n",
    "# Example usage\n",
    "# Assuming xult and yult are your feature matrix and target vector\n",
    "for i in range(5):\n",
    "    dense_model = DenseModel(input_dim=xult.shape[1])\n",
    "    ktrain(dense_model, xult, yult,epochs=15,batch_size=32,splits=5,random_state=i)\n",
    "    ens.add_model(dense_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [08:05:41] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41m\u001b[32mF1 Score improved to 0.952375127420999. Saving model...\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [08:05:44] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41m\u001b[32mF1 Score improved to 0.9525806780006109. Saving model...\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [08:05:51] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41m\u001b[32mF1 Score improved to 0.952899802817474. Saving model...\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [08:05:55] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41m\u001b[32mF1 Score improved to 0.953284730990103. Saving model...\u001b[0m\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [0.9999797941675777, 1.0, 0.9999999398384783, 1.0, 1.0]\n",
      "precisions:  [1.0, 1.0, 0.9993939393939394, 1.0, 1.0]\n",
      "recalls:  [0.9935408103347034, 1.0, 1.0, 1.0, 1.0]\n",
      "f1s:  [0.952375127420999, 0.9525806780006109, 0.9525263007956373, 0.952899802817474, 0.953284730990103]\n",
      "roc_aucs:  [0.964076822991853, 0.9646992861875414, 0.9648857866333145, 0.9654881349737149, 0.9650316704298927]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 0.9999959468012112\n",
      "Average Precision: 0.999878787878788\n",
      "Average Recall: 0.9987081620669407\n",
      "Average F1 Score: 0.9527333280049648\n",
      "Average ROC AUC Score: 0.9648363402432633\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [0.9999465306406164, 1.0, 0.9999995223355879, 1.0, 1.0]\n",
      "precisions:  [0.9988009592326139, 1.0, 0.9982003599280144, 1.0, 1.0]\n",
      "recalls:  [0.995221027479092, 1.0, 1.0, 1.0, 1.0]\n",
      "f1s:  [0.9515100910331344, 0.9522569621025652, 0.9516217367492241, 0.9526654878767555, 0.9529206271833618]\n",
      "roc_aucs:  [0.9639942879922628, 0.9648560399828635, 0.9655790774549916, 0.965431723291661, 0.9658343934459345]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 0.9999892105952408\n",
      "Average Precision: 0.9994002638321255\n",
      "Average Recall: 0.9990442054958184\n",
      "Average F1 Score: 0.9521949809890081\n",
      "Average ROC AUC Score: 0.9651391044335427\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [08:06:19] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41m\u001b[32mF1 Score improved to 0.9599498361584207. Saving model...\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [08:06:34] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41m\u001b[32mF1 Score improved to 0.9599821873165597. Saving model...\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [1.0, 1.0, 1.0, 0.9999997609278961, 1.0]\n",
      "precisions:  [1.0, 0.9993993993993994, 1.0, 0.9987980769230769, 1.0]\n",
      "recalls:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "f1s:  [0.9599498361584207, 0.9599449470722772, 0.9599821873165597, 0.9598802274060736, 0.9598348044376063]\n",
      "roc_aucs:  [0.9714489521801412, 0.9712025714948471, 0.9711925527610651, 0.9713224867493366, 0.9710528322021827]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 0.9999999521855791\n",
      "Average Precision: 0.9996394952644951\n",
      "Average Recall: 1.0\n",
      "Average F1 Score: 0.9599184004781876\n",
      "Average ROC AUC Score: 0.9712438790775145\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [0.9999992276648089, 1.0, 1.0, 0.9999988717641155, 1.0]\n",
      "precisions:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "recalls:  [0.997610513739546, 1.0, 1.0, 0.9976119402985074, 0.9993935718617344]\n",
      "f1s:  [0.9516217814111843, 0.9514882888744307, 0.9521388035717918, 0.9519271883208111, 0.9534311232274734]\n",
      "roc_aucs:  [0.9636545796963584, 0.9646102783993599, 0.9648195109929261, 0.9643102580999647, 0.9654810430833334]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 0.9999996198857849\n",
      "Average Precision: 1.0\n",
      "Average Recall: 0.9989232051799576\n",
      "Average F1 Score: 0.9521214370811384\n",
      "Average ROC AUC Score: 0.9645751340543885\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [1.0, 0.9999992186926229, 0.9999992817007889, 1.0, 1.0]\n",
      "precisions:  [1.0, 1.0, 0.9987959060806743, 1.0, 1.0]\n",
      "recalls:  [0.9982089552238806, 0.9993943064809206, 1.0, 1.0, 1.0]\n",
      "f1s:  [0.9519019304390324, 0.9520865533230294, 0.9528246231462457, 0.9524061235692358, 0.9523055690858906]\n",
      "roc_aucs:  [0.9642570054244826, 0.9648595085403305, 0.9651652277510789, 0.9651589097379355, 0.9657616450169548]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 0.9999997000786823\n",
      "Average Precision: 0.9997591812161349\n",
      "Average Recall: 0.9995206523409603\n",
      "Average F1 Score: 0.9523049599126867\n",
      "Average ROC AUC Score: 0.9650404592941564\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, precision_score, recall_score\n",
    "\n",
    "class XGBoostClassifierModel:\n",
    "    def __init__(self, eval_metric='logloss', model_path='xgb_model.json', **kwargs):\n",
    "        self.model = xgb.XGBClassifier(objective='binary:logistic', eval_metric=eval_metric, **kwargs)\n",
    "        self.model_path = model_path\n",
    "        self.THRESHOLD = 0.5\n",
    "        self.load_model()\n",
    "\n",
    "    def fit(self, X_train, y_train, verbose=0, **kwargs):\n",
    "        self.model.fit(X_train, y_train, verbose=verbose, xgb_model=self.model_path if self.model_exists() else None)\n",
    "        self.save_model()\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        print(colored('predicting using xgboost model', 'green'))\n",
    "        return self.model.predict(X_test).reshape(-1, 1)\n",
    "\n",
    "    def predict_proba(self, X_test):\n",
    "        return self.model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        y_pred = self.predict(X_test)\n",
    "        y_pred_proba = self.predict_proba(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        # Assuming loss is not directly available, using log loss as a proxy\n",
    "        loss = -1  # Placeholder, as XGBoost does not directly provide loss in this context\n",
    "        return [loss, auc, precision, recall]\n",
    "\n",
    "    def summary(self):\n",
    "        print(self.model)\n",
    "\n",
    "    def save_model(self):\n",
    "        self.model.save_model(self.model_path)\n",
    "\n",
    "    def load_model(self):\n",
    "        if self.model_exists():\n",
    "            self.model.load_model(self.model_path)\n",
    "\n",
    "    def model_exists(self):\n",
    "        try:\n",
    "            with open(self.model_path, 'r'):\n",
    "                return True\n",
    "        except FileNotFoundError:\n",
    "            return False\n",
    "    def save(self, path):\n",
    "        self.model.save_model(path)\n",
    "\n",
    "# Example usage\n",
    "# Assuming xult and yult are your feature matrix and target vector\n",
    "# Split the data into training and test sets\n",
    "\n",
    "for i in range(5):\n",
    "    if i%2==0:\n",
    "        xgb_model = XGBoostClassifierModel( model_path=f'xgb_model{i}.json')\n",
    "    else:\n",
    "        xgb_model = XGBoostClassifierModel(eval_metric='auc', model_path=f'xgb_model{i}.json')\n",
    "    ktrain(xgb_model, xult, yult, epochs=10, batch_size=32, splits=5, random_state=i)\n",
    "    ens.add_model(xgb_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [0.9590146476843895, 0.9676690808980635, 0.9671616797872485, 0.9699788875859983, 0.970141239954228]\n",
      "precisions:  [0.9411764705882353, 0.9252336448598131, 0.9396751740139211, 0.9349470499243571, 0.9318181818181818]\n",
      "recalls:  [0.7219512195121951, 0.7283874923359902, 0.7168141592920354, 0.7202797202797203, 0.7317073170731707]\n",
      "f1s:  [0.805731332489604, 0.8083455509191384, 0.8095828915608293, 0.8107194374323837, 0.8131739755571531]\n",
      "roc_aucs:  [0.8512618743028904, 0.8531380444201566, 0.8537397736587666, 0.8545647644962585, 0.8567175262756126]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 0.9667931071819854\n",
      "Average Precision: 0.9345701042409017\n",
      "Average Recall: 0.7238279816986223\n",
      "Average F1 Score: 0.8095106375918217\n",
      "Average ROC AUC Score: 0.853884396630737\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [0.9601867767116566, 0.9680834747737045, 0.967434086936275, 0.9701741465698321, 0.970225783579686]\n",
      "precisions:  [0.9436060365369341, 0.9224806201550387, 0.938996138996139, 0.9379258137774413, 0.9356060606060606]\n",
      "recalls:  [0.724390243902439, 0.7296137339055794, 0.7174041297935103, 0.722027972027972, 0.734681737061273]\n",
      "f1s:  [0.8075602926564899, 0.8100387492114987, 0.811119127062855, 0.8122914600054107, 0.8146167157336449]\n",
      "roc_aucs:  [0.852422640552477, 0.8543355718228519, 0.8546976253279305, 0.8553027457362837, 0.857372353414257]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 0.9672208537142307\n",
      "Average Precision: 0.9357229340143227\n",
      "Average Recall: 0.7256235633381547\n",
      "Average F1 Score: 0.8111252689339798\n",
      "Average ROC AUC Score: 0.8548261873707601\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [0.9735546320672841, 0.9779363342857411, 0.9774067874242325, 0.9798039355364833, 0.9790945164578259]\n",
      "precisions:  [0.9457601222307105, 0.9221556886227545, 0.9426470588235294, 0.9448075526506899, 0.9416974169741698]\n",
      "recalls:  [0.7548780487804878, 0.7553648068669528, 0.7563421828908554, 0.7581585081585082, 0.7590719809637121]\n",
      "f1s:  [0.8271366810774858, 0.8282546637456019, 0.8299163087278041, 0.8310469953093194, 0.8321990454304402]\n",
      "roc_aucs:  [0.8676927207321118, 0.8688107947540649, 0.8695386798725842, 0.8703236731626717, 0.871311813196353]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 0.9775592411543134\n",
      "Average Precision: 0.9394135678603709\n",
      "Average Recall: 0.7567631055321032\n",
      "Average F1 Score: 0.8297107388581303\n",
      "Average ROC AUC Score: 0.8695355363435571\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [0.9601867767116566, 0.9680834747737045, 0.967434086936275, 0.9701741465698321, 0.970225783579686]\n",
      "precisions:  [0.9436060365369341, 0.9224806201550387, 0.938996138996139, 0.9379258137774413, 0.9356060606060606]\n",
      "recalls:  [0.724390243902439, 0.7296137339055794, 0.7174041297935103, 0.722027972027972, 0.734681737061273]\n",
      "f1s:  [0.8075602926564899, 0.8100387492114987, 0.811119127062855, 0.8122914600054107, 0.8146167157336449]\n",
      "roc_aucs:  [0.852422640552477, 0.8543355718228519, 0.8546976253279305, 0.8553027457362837, 0.857372353414257]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 0.9672208537142307\n",
      "Average Precision: 0.9357229340143227\n",
      "Average Recall: 0.7256235633381547\n",
      "Average F1 Score: 0.8111252689339798\n",
      "Average ROC AUC Score: 0.8548261873707601\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [0.9588405568489227, 0.9662086536613171, 0.9666482043647469, 0.9674620545738093, 0.9684507818746046]\n",
      "precisions:  [0.9391304347826087, 0.9212355212355212, 0.9372128637059725, 0.9327286470143613, 0.9332321699544764]\n",
      "recalls:  [0.724390243902439, 0.7314530962599632, 0.7221238938053097, 0.7191142191142191, 0.7317073170731707]\n",
      "f1s:  [0.8053760778045431, 0.8103192779199785, 0.8109469518091255, 0.8119560083665069, 0.8142616885301043]\n",
      "roc_aucs:  [0.8521149231510138, 0.8553978532645417, 0.8553006701578453, 0.8557860300871565, 0.8577923663558655]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 0.9655220502646801\n",
      "Average Precision: 0.9327079273385881\n",
      "Average Recall: 0.7257577540310203\n",
      "Average F1 Score: 0.8105720008860515\n",
      "Average ROC AUC Score: 0.8552783686032847\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, precision_score, recall_score\n",
    "\n",
    "class XGBRFClassifierModel:\n",
    "    def __init__(self, objective='binary:logistic', eval_metric='auc', n_estimators=600, max_depth=5, subsample=0.9,\n",
    "                 colsample_bynode=0.9, reg_alpha=0.1, reg_lambda=1.0, min_child_weight=1, random_state=42, model_path='xgbrf_model.json', **kwargs):\n",
    "        self.model = xgb.XGBRFClassifier(objective=objective, eval_metric=eval_metric, n_estimators=n_estimators,\n",
    "                                         max_depth=max_depth, subsample=subsample, colsample_bynode=colsample_bynode, reg_alpha=reg_alpha,\n",
    "                                         reg_lambda=reg_lambda, min_child_weight=min_child_weight, random_state=random_state, **kwargs)\n",
    "        self.model_path = model_path\n",
    "        self.THRESHOLD = 0.5\n",
    "        self.load_model()\n",
    "\n",
    "    def fit(self, X_train, y_train, verbose=0, **kwargs):\n",
    "        self.model.fit(X_train, y_train, verbose=verbose, xgb_model=self.model_path if self.model_exists() else None)\n",
    "        self.save_model()\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        print(colored('predicting using xgbrf model', 'green'))\n",
    "        return self.model.predict(X_test).reshape(-1, 1)\n",
    "\n",
    "    def predict_proba(self, X_test):\n",
    "        return self.model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        y_pred = self.predict(X_test)\n",
    "        y_pred_proba = self.predict_proba(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        # Assuming loss is not directly available, using log loss as a proxy\n",
    "        loss = -1  # Placeholder, as XGBoost does not directly provide loss in this context\n",
    "        return [loss, auc, precision, recall]\n",
    "\n",
    "    def summary(self):\n",
    "        print(self.model)\n",
    "\n",
    "    def save_model(self):\n",
    "        self.model.save_model(self.model_path)\n",
    "\n",
    "    def load_model(self):\n",
    "        if self.model_exists():\n",
    "            self.model.load_model(self.model_path)\n",
    "\n",
    "    def model_exists(self):\n",
    "        try:\n",
    "            with open(self.model_path, 'r'):\n",
    "                return True\n",
    "        except FileNotFoundError:\n",
    "            return False\n",
    "    def save(self, path):\n",
    "        self.model.save_model(path)\n",
    "\n",
    "for i in range(5):\n",
    "    if i%2==0:\n",
    "        xgbrf_model = XGBRFClassifierModel(model_path=f'xgbrf_model{i}.json')\n",
    "    else:\n",
    "        xgbrf_model = XGBRFClassifierModel(eval_metric='logloss', model_path=f'xgbrf_model{i}.json')\n",
    "    ktrain(xgbrf_model, xult, yult, epochs=10, batch_size=32, splits=5, random_state=5)\n",
    "    ens.add_model(xgbrf_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6660, number of negative: 40256\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001036 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6728, number of negative: 40188\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001100 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6714, number of negative: 40202\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000939 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6737, number of negative: 40179\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000946 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6613, number of negative: 40303\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000942 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [0.9990478660356824, 0.9996082088308735, 0.9997796283461838, 0.9999274995224465, 0.9999615764534093]\n",
      "precisions:  [0.9873096446700508, 0.9923126201153107, 0.993577392421323, 1.0, 1.0]\n",
      "recalls:  [0.913681738109219, 0.9474006116207951, 0.9381443298969072, 0.9674046740467405, 0.9737142857142858]\n",
      "f1s:  [0.9132952864087931, 0.9214734497467902, 0.9276659833493703, 0.9346463742166518, 0.9374428084186008]\n",
      "roc_aucs:  [0.9290437238655207, 0.9356133622009387, 0.9406661892439399, 0.9462510787154192, 0.948216643559486]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 0.9996649558377191\n",
      "Average Precision: 0.994639931441337\n",
      "Average Recall: 0.9480691278775895\n",
      "Average F1 Score: 0.9269047804280411\n",
      "Average ROC AUC Score: 0.9399581995170608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6689, number of negative: 40227\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000946 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6689, number of negative: 40227\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000942 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6699, number of negative: 40217\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000977 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6623, number of negative: 40293\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000941 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6752, number of negative: 40164\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000966 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [0.9991667097392061, 0.9997357425438463, 0.9998847634605831, 0.9999439613459863, 0.9999799387709203]\n",
      "precisions:  [0.9923076923076923, 0.994328922495274, 0.9975323874151758, 0.9970501474926253, 1.0]\n",
      "recalls:  [0.9247311827956989, 0.942652329749104, 0.9717548076923077, 0.9712643678160919, 0.9851024208566108]\n",
      "f1s:  [0.9200715714135355, 0.9271969681107226, 0.9326766559539212, 0.9358592692828146, 0.9399481058640373]\n",
      "roc_aucs:  [0.9342160018366685, 0.9400538995574811, 0.9442981498976399, 0.9469593133049935, 0.9503122971672718]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 0.9997422231721085\n",
      "Average Precision: 0.9962438299421535\n",
      "Average Recall: 0.9591010217819627\n",
      "Average F1 Score: 0.9311505141250063\n",
      "Average ROC AUC Score: 0.943167932352811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6659, number of negative: 40257\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000926 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6699, number of negative: 40217\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000927 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6664, number of negative: 40252\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000941 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6701, number of negative: 40215\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000943 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6729, number of negative: 40187\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000930 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [0.9999998243827052, 1.0, 1.0, 1.0, 1.0]\n",
      "precisions:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "recalls:  [0.9976525821596244, 1.0, 1.0, 1.0, 1.0]\n",
      "f1s:  [0.9544465875979808, 0.9550133278654911, 0.9551075654724063, 0.9554581216194067, 0.9551865518655187]\n",
      "roc_aucs:  [0.9627965919240155, 0.9633987854889684, 0.9633820618034237, 0.9639478037661628, 0.9635751124255119]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 0.999999964876541\n",
      "Average Precision: 1.0\n",
      "Average Recall: 0.9995305164319248\n",
      "Average F1 Score: 0.9550424308841607\n",
      "Average ROC AUC Score: 0.9634200710816165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6689, number of negative: 40227\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000930 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6697, number of negative: 40219\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000925 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6664, number of negative: 40252\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000935 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6688, number of negative: 40228\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000947 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6714, number of negative: 40202\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000936 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [0.9994454039223933, 0.9995958236221052, 0.9999082798690451, 0.9999285648542646, 0.9999764166835119]\n",
      "precisions:  [0.9935649935649936, 0.9924953095684803, 0.9981785063752276, 0.9975490196078431, 0.9987639060568603]\n",
      "recalls:  [0.9223416965352449, 0.9525810324129652, 0.9676280164802825, 0.9719402985074627, 0.9799878714372346]\n",
      "f1s:  [0.919246553719878, 0.9266976277143216, 0.9311532919877216, 0.9357221632644568, 0.9390567917635337]\n",
      "roc_aucs:  [0.9338337560885783, 0.9400975978255242, 0.9432305564832162, 0.9470493271335845, 0.949820232286198]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 0.999770897790264\n",
      "Average Precision: 0.996110347034681\n",
      "Average Recall: 0.9588957830746379\n",
      "Average F1 Score: 0.9303752856899823\n",
      "Average ROC AUC Score: 0.9428062939634202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6688, number of negative: 40228\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000955 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6712, number of negative: 40204\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000964 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6704, number of negative: 40212\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000933 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6647, number of negative: 40269\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000943 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6701, number of negative: 40215\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000930 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [0.9987983694022429, 0.9992479014985356, 0.9997800208665921, 0.9998775484643856, 0.9999726860121423]\n",
      "precisions:  [0.991508817766166, 0.9896305897602073, 0.9919103920348475, 0.9975801572897761, 0.9987730061349693]\n",
      "recalls:  [0.9062686567164179, 0.9248940036341611, 0.9608197709463532, 0.960955710955711, 0.9795427196149218]\n",
      "f1s:  [0.9135718965990995, 0.9217102776261078, 0.9271814187068425, 0.9320177725859947, 0.937124815653366]\n",
      "roc_aucs:  [0.9292033271165193, 0.9359594658977105, 0.9402770063809156, 0.9440889173040736, 0.948486607657535]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 0.9995353052487796\n",
      "Average Precision: 0.9938805925971932\n",
      "Average Recall: 0.9464961723735129\n",
      "Average F1 Score: 0.9263212362342822\n",
      "Average ROC AUC Score: 0.9396030648713507\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, precision_score, recall_score\n",
    "\n",
    "class LGBMClassifierModel:\n",
    "    def __init__(self, eval_metric='logloss', model_path='lgbm_model.txt', **kwargs):\n",
    "        self.model = lgb.LGBMClassifier(objective='binary', metric=eval_metric, **kwargs)\n",
    "        self.model_path = model_path\n",
    "        self.THRESHOLD = 0.5\n",
    "        self.init_model = None\n",
    "        self.load_model()\n",
    "\n",
    "    def fit(self, X_train, y_train, verbose=0, **kwargs):\n",
    "        self.model.fit(X_train, y_train,   init_model=self.init_model)\n",
    "        self.save_model()\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        ret = self.model.predict(X_test).astype(float)\n",
    "        # All ret values multiplied by 1.1\n",
    "        # ret *= 1.1\n",
    "        print(colored('predicting using lgbm model', 'green'))\n",
    "        return ret.reshape(-1, 1)\n",
    "\n",
    "    def predict_proba(self, X_test):\n",
    "        return self.model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        y_pred = self.predict(X_test)\n",
    "        y_pred_proba = self.predict_proba(X_test)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        # Assuming loss is not directly available, using log loss as a proxy\n",
    "        loss = -1  # Placeholder, as LightGBM does not directly provide loss in this context\n",
    "        return [loss, auc, precision, recall]\n",
    "\n",
    "    def summary(self):\n",
    "        print(self.model)\n",
    "\n",
    "    def save_model(self):\n",
    "        self.model.booster_.save_model(self.model_path)\n",
    "\n",
    "    def load_model(self):\n",
    "        if self.model_exists():\n",
    "            self.init_model = self.model_path\n",
    "\n",
    "    def model_exists(self):\n",
    "        try:\n",
    "            with open(self.model_path, 'r'):\n",
    "                return True\n",
    "        except FileNotFoundError:\n",
    "            return False\n",
    "\n",
    "    def save(self, path):\n",
    "        self.model.booster_.save_model(path)\n",
    "\n",
    "# Example usage\n",
    "# Assuming xult and yult are your feature matrix and target vector\n",
    "# Split the data into training and test sets\n",
    "\n",
    "for i in range(5):\n",
    "    # Initialize the LightGBM classifier model\n",
    "    if i % 2 == 0:\n",
    "        lgbm_model = LGBMClassifierModel(model_path=f'lgbm_model{i}.txt')\n",
    "    else:\n",
    "        lgbm_model = LGBMClassifierModel(eval_metric='auc', model_path=f'lgbm_model{i}.txt')\n",
    "    # Fit the model on training data\n",
    "    ktrain(lgbm_model, xult, yult, epochs=10, batch_size=32, splits=5, random_state=i)\n",
    "    ens.add_model(lgbm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6660, number of negative: 40256\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000841 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.141956 -> initscore=-1.799140\n",
      "[LightGBM] [Info] Start training from score -1.799140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6728, number of negative: 40188\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.143405 -> initscore=-1.787291\n",
      "[LightGBM] [Info] Start training from score -1.787291\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6714, number of negative: 40202\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000856 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.143107 -> initscore=-1.789722\n",
      "[LightGBM] [Info] Start training from score -1.789722\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6737, number of negative: 40179\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.143597 -> initscore=-1.785730\n",
      "[LightGBM] [Info] Start training from score -1.785730\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6613, number of negative: 40303\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001456 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.140954 -> initscore=-1.807388\n",
      "[LightGBM] [Info] Start training from score -1.807388\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [0.9260143532862707, 0.9317522020832917, 0.9204729958993907, 0.927042361584657, 0.9233621462213505]\n",
      "precisions:  [0.899184581171238, 0.9085271317829458, 0.9173290937996821, 0.8966846569005397, 0.9116527037319117]\n",
      "recalls:  [0.7122724603640634, 0.7168195718654434, 0.6998180715585203, 0.7152521525215252, 0.684]\n",
      "f1s:  [0.7966840211829375, 0.7948786820664339, 0.7966765950775984, 0.7958991385498924, 0.7949418084153984]\n",
      "roc_aucs:  [0.8496116882449437, 0.8482144052683974, 0.849012111972496, 0.8481501278187239, 0.8482709717258992]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 0.9257288118149921\n",
      "Average Precision: 0.9066756334772634\n",
      "Average Recall: 0.7056324512619105\n",
      "Average F1 Score: 0.795816049058452\n",
      "Average ROC AUC Score: 0.8486518610060921\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6689, number of negative: 40227\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000835 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142574 -> initscore=-1.794074\n",
      "[LightGBM] [Info] Start training from score -1.794074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6689, number of negative: 40227\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000873 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142574 -> initscore=-1.794074\n",
      "[LightGBM] [Info] Start training from score -1.794074\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6699, number of negative: 40217\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000835 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142787 -> initscore=-1.792332\n",
      "[LightGBM] [Info] Start training from score -1.792332\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6623, number of negative: 40293\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000833 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.141167 -> initscore=-1.805629\n",
      "[LightGBM] [Info] Start training from score -1.805629\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6752, number of negative: 40164\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.143917 -> initscore=-1.783132\n",
      "[LightGBM] [Info] Start training from score -1.783132\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [0.927947958866616, 0.9293793336173151, 0.9295645611219381, 0.9228845983455365, 0.9227144523916359]\n",
      "precisions:  [0.9056316590563166, 0.9062015503875969, 0.9, 0.9166034874905231, 0.9153225806451613]\n",
      "recalls:  [0.7108721624850657, 0.6983273596176822, 0.7085336538461539, 0.6948275862068966, 0.7045313469894475]\n",
      "f1s:  [0.7948557089084065, 0.796169508211393, 0.7947777152504221, 0.795579862823329, 0.7961199928148015]\n",
      "roc_aucs:  [0.8479412821637766, 0.8489926162189985, 0.8466722306455783, 0.8482103949968638, 0.8480266666190434]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 0.9264981808686084\n",
      "Average Precision: 0.9087518555159194\n",
      "Average Recall: 0.7034184218290491\n",
      "Average F1 Score: 0.7955005576016705\n",
      "Average ROC AUC Score: 0.8479686381288521\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6659, number of negative: 40257\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000844 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.141935 -> initscore=-1.799315\n",
      "[LightGBM] [Info] Start training from score -1.799315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6699, number of negative: 40217\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000826 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142787 -> initscore=-1.792332\n",
      "[LightGBM] [Info] Start training from score -1.792332\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6664, number of negative: 40252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005033 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142041 -> initscore=-1.798440\n",
      "[LightGBM] [Info] Start training from score -1.798440\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6701, number of negative: 40215\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004288 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142830 -> initscore=-1.791983\n",
      "[LightGBM] [Info] Start training from score -1.791983\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6729, number of negative: 40187\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000844 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.143427 -> initscore=-1.787117\n",
      "[LightGBM] [Info] Start training from score -1.787117\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [0.9255203247749171, 0.9234652940979785, 0.9264235838687588, 0.9305179066798777, 0.9277499010319953]\n",
      "precisions:  [0.9021820917983446, 0.9019908116385911, 0.9063214013709063, 0.8920754716981132, 0.9281678773204197]\n",
      "recalls:  [0.7036384976525821, 0.7079326923076923, 0.7004120070629782, 0.7111913357400722, 0.7037943696450428]\n",
      "f1s:  [0.795577637527416, 0.7979321195774332, 0.7945371639075451, 0.7955561516452074, 0.7945745109449841]\n",
      "roc_aucs:  [0.8486134520897562, 0.8486911255528509, 0.8471054987152645, 0.8489232589597622, 0.8480681345332001]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 0.9267354020907055\n",
      "Average Precision: 0.9061475307652751\n",
      "Average Recall: 0.7053937804816736\n",
      "Average F1 Score: 0.7956355167205171\n",
      "Average ROC AUC Score: 0.8482802939701667\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6689, number of negative: 40227\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000842 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142574 -> initscore=-1.794074\n",
      "[LightGBM] [Info] Start training from score -1.794074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6697, number of negative: 40219\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000844 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142744 -> initscore=-1.792680\n",
      "[LightGBM] [Info] Start training from score -1.792680\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6664, number of negative: 40252\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000835 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142041 -> initscore=-1.798440\n",
      "[LightGBM] [Info] Start training from score -1.798440\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6688, number of negative: 40228\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000865 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142553 -> initscore=-1.794248\n",
      "[LightGBM] [Info] Start training from score -1.794248\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6714, number of negative: 40202\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000878 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.143107 -> initscore=-1.789722\n",
      "[LightGBM] [Info] Start training from score -1.789722\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [0.9203898569813458, 0.9340816720208903, 0.9357084426532057, 0.9207709413940839, 0.9207798497405837]\n",
      "precisions:  [0.9188337273443656, 0.9061561561561562, 0.9121212121212121, 0.9050925925925926, 0.9037095501183899]\n",
      "recalls:  [0.6965352449223416, 0.7244897959183674, 0.7086521483225426, 0.7002985074626865, 0.6943602183141298]\n",
      "f1s:  [0.7979573012980585, 0.7956648044692738, 0.7961178105527413, 0.7940061463917988, 0.796385974352076]\n",
      "roc_aucs:  [0.8484712551237121, 0.8490630569063682, 0.8484896813391808, 0.8471859581364164, 0.8485693668830944]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 0.9263461525580219\n",
      "Average Precision: 0.9091826476665433\n",
      "Average Recall: 0.7048671829880137\n",
      "Average F1 Score: 0.7960264074127897\n",
      "Average ROC AUC Score: 0.8483558636777543\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6688, number of negative: 40228\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000871 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142553 -> initscore=-1.794248\n",
      "[LightGBM] [Info] Start training from score -1.794248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6712, number of negative: 40204\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000842 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.143064 -> initscore=-1.790070\n",
      "[LightGBM] [Info] Start training from score -1.790070\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6704, number of negative: 40212\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000849 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142894 -> initscore=-1.791461\n",
      "[LightGBM] [Info] Start training from score -1.791461\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6647, number of negative: 40269\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000837 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.141679 -> initscore=-1.801416\n",
      "[LightGBM] [Info] Start training from score -1.801416\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 6701, number of negative: 40215\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006775 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3334\n",
      "[LightGBM] [Info] Number of data points in the train set: 46916, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.142830 -> initscore=-1.791983\n",
      "[LightGBM] [Info] Start training from score -1.791983\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "losses:  [-1, -1, -1, -1, -1]\n",
      "aucs:  [0.9287293391803664, 0.9284555632631195, 0.9247293059493732, 0.9220501983784716, 0.9239210406999935]\n",
      "precisions:  [0.9111457521434139, 0.9273875295974744, 0.8974751338944147, 0.9030075187969925, 0.9038461538461539]\n",
      "recalls:  [0.697910447761194, 0.7116898849182314, 0.7070524412296564, 0.6998834498834499, 0.7069795427196149]\n",
      "f1s:  [0.7959563355972474, 0.7972106624676639, 0.7949837644160789, 0.7947512203860451, 0.7945512389658108]\n",
      "roc_aucs:  [0.8483998996737612, 0.8481088920677384, 0.8481443515196467, 0.8480413147261496, 0.8477950114285795]\n",
      "Average Loss: -1.0\n",
      "Average AUC: 0.9255770894942648\n",
      "Average Precision: 0.90857241765569\n",
      "Average Recall: 0.7047031533024294\n",
      "Average F1 Score: 0.7954906443665692\n",
      "Average ROC AUC Score: 0.848097893883175\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, precision_score, recall_score\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, precision_score, recall_score\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, precision_score, recall_score\n",
    "\n",
    "class LGBMRandomForestClassifierModel:\n",
    "    def __init__(self, eval_metric='logloss', model_path='lgbm_rf_model.txt', bagging_freq=1, bagging_fraction=0.8, feature_fraction=0.8, **kwargs):\n",
    "        self.model_path = model_path\n",
    "        self.model = lgb.LGBMClassifier(boosting_type='rf', objective='binary', metric=eval_metric,\n",
    "                                        bagging_freq=bagging_freq, bagging_fraction=bagging_fraction,\n",
    "                                        feature_fraction=feature_fraction, **kwargs)\n",
    "        self.THRESHOLD = 0.5\n",
    "        self.load_model()  # Load the saved model if available\n",
    "\n",
    "    def fit(self, X_train, y_train, verbose=0, **kwargs):\n",
    "        # Train model from scratch\n",
    "        self.model.fit(X_train, y_train)\n",
    "        self.save_model()  # Save model state after training\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        print(colored('predicting using lgbm_rf model', 'green'))\n",
    "        ret = self.model.predict(X_test).astype(float)\n",
    "        return ret.reshape(-1, 1)\n",
    "\n",
    "    def predict_proba(self, X_test):\n",
    "        return self.model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        y_pred = self.predict(X_test)\n",
    "        y_pred_proba = self.predict_proba(X_test)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        loss = -1  # Placeholder for loss\n",
    "        return [loss, auc, precision, recall]\n",
    "\n",
    "    def summary(self):\n",
    "        print(self.model)\n",
    "\n",
    "    def save_model(self):\n",
    "        self.model.booster_.save_model(self.model_path)\n",
    "\n",
    "    def load_model(self):\n",
    "        if self.model_exists():\n",
    "            # Load the booster and convert to LGBMClassifier\n",
    "            booster = lgb.Booster(model_file=self.model_path)\n",
    "            self.model._Booster = booster  # Inject the booster into the LGBMClassifier\n",
    "\n",
    "    def model_exists(self):\n",
    "        try:\n",
    "            with open(self.model_path, 'r'):\n",
    "                return True\n",
    "        except FileNotFoundError:\n",
    "            return False\n",
    "\n",
    "# Assuming xult and yult are your feature matrix and target vector\n",
    "# Split the data into training and test sets\n",
    "\n",
    "# yyyyyyy.shape \n",
    "for i in range(5):\n",
    "    # Initialize the LightGBM classifier model\n",
    "    if i % 2 == 0:\n",
    "        lgbm_rf_model = LGBMRandomForestClassifierModel(model_path=f'lgbm_rf_model{i}.txt')\n",
    "    else:\n",
    "        lgbm_rf_model = LGBMRandomForestClassifierModel(eval_metric='auc', model_path=f'lgbm_rf_model{i}.txt')\n",
    "    # Fit the model on training data\n",
    "    ktrain(lgbm_rf_model, xult, yult, epochs=1, batch_size=32, splits=5, random_state=i)\n",
    "    ens.add_model(lgbm_rf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mPredicting with encoding_dim 512...\u001b[0m\n",
      "\u001b[1m1050/1222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1222/1222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 870us/step\n",
      "Percentage of predictions greater than 0.5: 10.69%\n",
      "Percentage of predictions less than or equal to 0.5: 89.31%\n",
      "\u001b[32mPredicting with encoding_dim 256...\u001b[0m\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 738us/step\n",
      "Percentage of predictions greater than 0.5: 8.63%\n",
      "Percentage of predictions less than or equal to 0.5: 91.37%\n",
      "\u001b[32mPredicting with encoding_dim 128...\u001b[0m\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 673us/step\n",
      "Percentage of predictions greater than 0.5: 10.93%\n",
      "Percentage of predictions less than or equal to 0.5: 89.07%\n",
      "\u001b[32mPredicting with encoding_dim 64...\u001b[0m\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 666us/step\n",
      "Percentage of predictions greater than 0.5: 12.00%\n",
      "Percentage of predictions less than or equal to 0.5: 88.00%\n",
      "\u001b[32mPredicting with encoding_dim 256...\u001b[0m\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 719us/step\n",
      "Percentage of predictions greater than 0.5: 10.56%\n",
      "Percentage of predictions less than or equal to 0.5: 89.44%\n",
      "\u001b[32mpredicting using dense model of hidden 64\u001b[0m\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step\n",
      "Percentage of predictions greater than 0.5: 8.47%\n",
      "Percentage of predictions less than or equal to 0.5: 91.53%\n",
      "\u001b[32mpredicting using dense model of hidden 64\u001b[0m\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step\n",
      "Percentage of predictions greater than 0.5: 12.03%\n",
      "Percentage of predictions less than or equal to 0.5: 87.97%\n",
      "\u001b[32mpredicting using dense model of hidden 64\u001b[0m\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step\n",
      "Percentage of predictions greater than 0.5: 11.72%\n",
      "Percentage of predictions less than or equal to 0.5: 88.28%\n",
      "\u001b[32mpredicting using dense model of hidden 64\u001b[0m\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step\n",
      "Percentage of predictions greater than 0.5: 0.00%\n",
      "Percentage of predictions less than or equal to 0.5: 100.00%\n",
      "\u001b[32mpredicting using dense model of hidden 64\u001b[0m\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662us/step\n",
      "Percentage of predictions greater than 0.5: 9.75%\n",
      "Percentage of predictions less than or equal to 0.5: 90.25%\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "Percentage of predictions greater than 0.5: 11.45%\n",
      "Percentage of predictions less than or equal to 0.5: 88.55%\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "Percentage of predictions greater than 0.5: 11.57%\n",
      "Percentage of predictions less than or equal to 0.5: 88.43%\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "Percentage of predictions greater than 0.5: 11.89%\n",
      "Percentage of predictions less than or equal to 0.5: 88.11%\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "Percentage of predictions greater than 0.5: 11.64%\n",
      "Percentage of predictions less than or equal to 0.5: 88.36%\n",
      "\u001b[32mpredicting using xgboost model\u001b[0m\n",
      "Percentage of predictions greater than 0.5: 11.67%\n",
      "Percentage of predictions less than or equal to 0.5: 88.33%\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "Percentage of predictions greater than 0.5: 10.73%\n",
      "Percentage of predictions less than or equal to 0.5: 89.27%\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "Percentage of predictions greater than 0.5: 10.73%\n",
      "Percentage of predictions less than or equal to 0.5: 89.27%\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "Percentage of predictions greater than 0.5: 10.81%\n",
      "Percentage of predictions less than or equal to 0.5: 89.19%\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "Percentage of predictions greater than 0.5: 10.73%\n",
      "Percentage of predictions less than or equal to 0.5: 89.27%\n",
      "\u001b[32mpredicting using xgbrf model\u001b[0m\n",
      "Percentage of predictions greater than 0.5: 10.73%\n",
      "Percentage of predictions less than or equal to 0.5: 89.27%\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "Percentage of predictions greater than 0.5: 10.93%\n",
      "Percentage of predictions less than or equal to 0.5: 89.07%\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "Percentage of predictions greater than 0.5: 10.91%\n",
      "Percentage of predictions less than or equal to 0.5: 89.09%\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "Percentage of predictions greater than 0.5: 10.96%\n",
      "Percentage of predictions less than or equal to 0.5: 89.04%\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "Percentage of predictions greater than 0.5: 11.03%\n",
      "Percentage of predictions less than or equal to 0.5: 88.97%\n",
      "\u001b[32mpredicting using lgbm model\u001b[0m\n",
      "Percentage of predictions greater than 0.5: 10.88%\n",
      "Percentage of predictions less than or equal to 0.5: 89.12%\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Percentage of predictions greater than 0.5: 10.84%\n",
      "Percentage of predictions less than or equal to 0.5: 89.16%\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Percentage of predictions greater than 0.5: 10.73%\n",
      "Percentage of predictions less than or equal to 0.5: 89.27%\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Percentage of predictions greater than 0.5: 10.78%\n",
      "Percentage of predictions less than or equal to 0.5: 89.22%\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Percentage of predictions greater than 0.5: 10.77%\n",
      "Percentage of predictions less than or equal to 0.5: 89.23%\n",
      "\u001b[32mpredicting using lgbm_rf model\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Percentage of predictions greater than 0.5: 10.81%\n",
      "Percentage of predictions less than or equal to 0.5: 89.19%\n"
     ]
    }
   ],
   "source": [
    "ens.save(testx, 'finals.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
